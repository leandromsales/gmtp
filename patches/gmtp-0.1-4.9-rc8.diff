diff -uprN --new-file linux-4.9-rc2-original/.cocciconfig linux-4.9-rc2/.cocciconfig
--- linux-4.9-rc2-original/.cocciconfig	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/.cocciconfig	1969-12-31 21:00:00.000000000 -0300
@@ -1,3 +0,0 @@
-[spatch]
-	options = --timeout 200
-	options = --use-gitgrep
diff -uprN --new-file linux-4.9-rc2-original/.config linux-4.9-rc2/.config
--- linux-4.9-rc2-original/.config	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/.config	2016-12-14 08:28:16.304297860 -0300
@@ -0,0 +1,1269 @@
+#
+# Automatically generated file; DO NOT EDIT.
+# Linux/x86 4.9.0-rc2 Kernel Configuration
+#
+# CONFIG_64BIT is not set
+CONFIG_X86_32=y
+CONFIG_X86=y
+CONFIG_INSTRUCTION_DECODER=y
+CONFIG_OUTPUT_FORMAT="elf32-i386"
+CONFIG_ARCH_DEFCONFIG="arch/x86/configs/i386_defconfig"
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_STACKTRACE_SUPPORT=y
+CONFIG_MMU=y
+CONFIG_ARCH_MMAP_RND_BITS_MIN=8
+CONFIG_ARCH_MMAP_RND_BITS_MAX=16
+CONFIG_ARCH_MMAP_RND_COMPAT_BITS_MIN=8
+CONFIG_ARCH_MMAP_RND_COMPAT_BITS_MAX=16
+CONFIG_NEED_SG_DMA_LENGTH=y
+CONFIG_GENERIC_ISA_DMA=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_ARCH_MAY_HAVE_PC_FDC=y
+CONFIG_RWSEM_XCHGADD_ALGORITHM=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_ARCH_HAS_CPU_RELAX=y
+CONFIG_ARCH_HAS_CACHE_LINE_SIZE=y
+CONFIG_HAVE_SETUP_PER_CPU_AREA=y
+CONFIG_NEED_PER_CPU_EMBED_FIRST_CHUNK=y
+CONFIG_NEED_PER_CPU_PAGE_FIRST_CHUNK=y
+CONFIG_ARCH_HIBERNATION_POSSIBLE=y
+CONFIG_ARCH_SUSPEND_POSSIBLE=y
+CONFIG_ARCH_WANT_HUGE_PMD_SHARE=y
+CONFIG_ARCH_WANT_GENERAL_HUGETLB=y
+CONFIG_ARCH_SUPPORTS_OPTIMIZED_INLINING=y
+CONFIG_ARCH_SUPPORTS_DEBUG_PAGEALLOC=y
+CONFIG_X86_32_LAZY_GS=y
+CONFIG_ARCH_SUPPORTS_UPROBES=y
+CONFIG_FIX_EARLYCON_MEM=y
+CONFIG_DEBUG_RODATA=y
+CONFIG_PGTABLE_LEVELS=2
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+CONFIG_IRQ_WORK=y
+CONFIG_BUILDTIME_EXTABLE_SORT=y
+CONFIG_THREAD_INFO_IN_TASK=y
+
+#
+# General setup
+#
+CONFIG_BROKEN_ON_SMP=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+CONFIG_CROSS_COMPILE=""
+# CONFIG_COMPILE_TEST is not set
+CONFIG_LOCALVERSION=""
+# CONFIG_LOCALVERSION_AUTO is not set
+CONFIG_HAVE_KERNEL_GZIP=y
+CONFIG_HAVE_KERNEL_BZIP2=y
+CONFIG_HAVE_KERNEL_LZMA=y
+CONFIG_HAVE_KERNEL_XZ=y
+CONFIG_HAVE_KERNEL_LZO=y
+CONFIG_HAVE_KERNEL_LZ4=y
+# CONFIG_KERNEL_GZIP is not set
+# CONFIG_KERNEL_BZIP2 is not set
+# CONFIG_KERNEL_LZMA is not set
+CONFIG_KERNEL_XZ=y
+# CONFIG_KERNEL_LZO is not set
+# CONFIG_KERNEL_LZ4 is not set
+CONFIG_DEFAULT_HOSTNAME="(none)"
+# CONFIG_SYSVIPC is not set
+# CONFIG_POSIX_MQUEUE is not set
+# CONFIG_CROSS_MEMORY_ATTACH is not set
+# CONFIG_FHANDLE is not set
+# CONFIG_USELIB is not set
+# CONFIG_AUDIT is not set
+CONFIG_HAVE_ARCH_AUDITSYSCALL=y
+
+#
+# IRQ subsystem
+#
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_GENERIC_IRQ_SHOW=y
+CONFIG_IRQ_FORCED_THREADING=y
+CONFIG_SPARSE_IRQ=y
+CONFIG_CLOCKSOURCE_WATCHDOG=y
+CONFIG_ARCH_CLOCKSOURCE_DATA=y
+CONFIG_CLOCKSOURCE_VALIDATE_LAST_CYCLE=y
+CONFIG_GENERIC_TIME_VSYSCALL=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+CONFIG_GENERIC_CLOCKEVENTS_MIN_ADJUST=y
+CONFIG_GENERIC_CMOS_UPDATE=y
+
+#
+# Timers subsystem
+#
+CONFIG_HZ_PERIODIC=y
+# CONFIG_NO_HZ_IDLE is not set
+# CONFIG_NO_HZ is not set
+# CONFIG_HIGH_RES_TIMERS is not set
+
+#
+# CPU/Task time and stats accounting
+#
+CONFIG_TICK_CPU_ACCOUNTING=y
+# CONFIG_IRQ_TIME_ACCOUNTING is not set
+
+#
+# RCU Subsystem
+#
+CONFIG_TINY_RCU=y
+# CONFIG_RCU_EXPERT is not set
+CONFIG_SRCU=y
+# CONFIG_TASKS_RCU is not set
+# CONFIG_RCU_STALL_COMMON is not set
+# CONFIG_TREE_RCU_TRACE is not set
+# CONFIG_RCU_EXPEDITE_BOOT is not set
+# CONFIG_BUILD_BIN2C is not set
+# CONFIG_IKCONFIG is not set
+CONFIG_HAVE_UNSTABLE_SCHED_CLOCK=y
+# CONFIG_CGROUPS is not set
+# CONFIG_CHECKPOINT_RESTORE is not set
+# CONFIG_SCHED_AUTOGROUP is not set
+# CONFIG_RELAY is not set
+# CONFIG_BLK_DEV_INITRD is not set
+# CONFIG_CC_OPTIMIZE_FOR_PERFORMANCE is not set
+CONFIG_CC_OPTIMIZE_FOR_SIZE=y
+CONFIG_ANON_INODES=y
+CONFIG_HAVE_UID16=y
+CONFIG_SYSCTL_EXCEPTION_TRACE=y
+CONFIG_HAVE_PCSPKR_PLATFORM=y
+CONFIG_BPF=y
+CONFIG_EXPERT=y
+# CONFIG_MULTIUSER is not set
+# CONFIG_SGETMASK_SYSCALL is not set
+# CONFIG_SYSFS_SYSCALL is not set
+# CONFIG_KALLSYMS is not set
+# CONFIG_PRINTK is not set
+# CONFIG_BUG is not set
+# CONFIG_PCSPKR_PLATFORM is not set
+# CONFIG_BASE_FULL is not set
+# CONFIG_FUTEX is not set
+# CONFIG_EPOLL is not set
+# CONFIG_SIGNALFD is not set
+# CONFIG_TIMERFD is not set
+# CONFIG_EVENTFD is not set
+# CONFIG_BPF_SYSCALL is not set
+# CONFIG_SHMEM is not set
+# CONFIG_AIO is not set
+# CONFIG_ADVISE_SYSCALLS is not set
+# CONFIG_USERFAULTFD is not set
+# CONFIG_MEMBARRIER is not set
+CONFIG_EMBEDDED=y
+CONFIG_HAVE_PERF_EVENTS=y
+
+#
+# Kernel Performance Events And Counters
+#
+CONFIG_PERF_EVENTS=y
+# CONFIG_DEBUG_PERF_USE_VMALLOC is not set
+# CONFIG_VM_EVENT_COUNTERS is not set
+# CONFIG_COMPAT_BRK is not set
+# CONFIG_SLAB is not set
+# CONFIG_SLUB is not set
+CONFIG_SLOB=y
+# CONFIG_SYSTEM_DATA_VERIFICATION is not set
+# CONFIG_PROFILING is not set
+CONFIG_HAVE_OPROFILE=y
+CONFIG_OPROFILE_NMI_TIMER=y
+# CONFIG_KPROBES is not set
+# CONFIG_JUMP_LABEL is not set
+# CONFIG_UPROBES is not set
+# CONFIG_HAVE_64BIT_ALIGNED_ACCESS is not set
+CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS=y
+CONFIG_ARCH_USE_BUILTIN_BSWAP=y
+CONFIG_HAVE_IOREMAP_PROT=y
+CONFIG_HAVE_KPROBES=y
+CONFIG_HAVE_KRETPROBES=y
+CONFIG_HAVE_OPTPROBES=y
+CONFIG_HAVE_KPROBES_ON_FTRACE=y
+CONFIG_HAVE_NMI=y
+CONFIG_HAVE_ARCH_TRACEHOOK=y
+CONFIG_HAVE_DMA_CONTIGUOUS=y
+CONFIG_GENERIC_SMP_IDLE_THREAD=y
+CONFIG_ARCH_WANTS_DYNAMIC_TASK_STRUCT=y
+CONFIG_HAVE_REGS_AND_STACK_ACCESS_API=y
+CONFIG_HAVE_DMA_API_DEBUG=y
+CONFIG_HAVE_HW_BREAKPOINT=y
+CONFIG_HAVE_MIXED_BREAKPOINTS_REGS=y
+CONFIG_HAVE_USER_RETURN_NOTIFIER=y
+CONFIG_HAVE_PERF_EVENTS_NMI=y
+CONFIG_HAVE_PERF_REGS=y
+CONFIG_HAVE_PERF_USER_STACK_DUMP=y
+CONFIG_HAVE_ARCH_JUMP_LABEL=y
+CONFIG_ARCH_HAVE_NMI_SAFE_CMPXCHG=y
+CONFIG_HAVE_CMPXCHG_LOCAL=y
+CONFIG_HAVE_CMPXCHG_DOUBLE=y
+CONFIG_ARCH_WANT_IPC_PARSE_VERSION=y
+CONFIG_HAVE_ARCH_SECCOMP_FILTER=y
+CONFIG_HAVE_GCC_PLUGINS=y
+# CONFIG_GCC_PLUGINS is not set
+CONFIG_HAVE_CC_STACKPROTECTOR=y
+# CONFIG_CC_STACKPROTECTOR is not set
+CONFIG_CC_STACKPROTECTOR_NONE=y
+# CONFIG_CC_STACKPROTECTOR_REGULAR is not set
+# CONFIG_CC_STACKPROTECTOR_STRONG is not set
+CONFIG_HAVE_ARCH_WITHIN_STACK_FRAMES=y
+CONFIG_HAVE_IRQ_TIME_ACCOUNTING=y
+CONFIG_HAVE_ARCH_TRANSPARENT_HUGEPAGE=y
+CONFIG_MODULES_USE_ELF_REL=y
+CONFIG_ARCH_HAS_ELF_RANDOMIZE=y
+CONFIG_HAVE_ARCH_MMAP_RND_BITS=y
+CONFIG_HAVE_EXIT_THREAD=y
+CONFIG_ARCH_MMAP_RND_BITS=8
+CONFIG_HAVE_COPY_THREAD_TLS=y
+# CONFIG_HAVE_ARCH_HASH is not set
+# CONFIG_ISA_BUS_API is not set
+CONFIG_CLONE_BACKWARDS=y
+CONFIG_OLD_SIGSUSPEND3=y
+CONFIG_OLD_SIGACTION=y
+# CONFIG_CPU_NO_EFFICIENT_FFS is not set
+# CONFIG_HAVE_ARCH_VMAP_STACK is not set
+
+#
+# GCOV-based kernel profiling
+#
+CONFIG_ARCH_HAS_GCOV_PROFILE_ALL=y
+CONFIG_HAVE_GENERIC_DMA_COHERENT=y
+CONFIG_BASE_SMALL=1
+CONFIG_MODULES=y
+CONFIG_MODULE_FORCE_LOAD=y
+CONFIG_MODULE_UNLOAD=y
+CONFIG_MODULE_FORCE_UNLOAD=y
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+# CONFIG_MODULE_SIG is not set
+# CONFIG_MODULE_COMPRESS is not set
+# CONFIG_TRIM_UNUSED_KSYMS is not set
+CONFIG_MODULES_TREE_LOOKUP=y
+# CONFIG_BLOCK is not set
+CONFIG_INLINE_SPIN_UNLOCK_IRQ=y
+CONFIG_INLINE_READ_UNLOCK=y
+CONFIG_INLINE_READ_UNLOCK_IRQ=y
+CONFIG_INLINE_WRITE_UNLOCK=y
+CONFIG_INLINE_WRITE_UNLOCK_IRQ=y
+CONFIG_ARCH_SUPPORTS_ATOMIC_RMW=y
+CONFIG_ARCH_USE_QUEUED_SPINLOCKS=y
+CONFIG_ARCH_USE_QUEUED_RWLOCKS=y
+# CONFIG_FREEZER is not set
+
+#
+# Processor type and features
+#
+# CONFIG_ZONE_DMA is not set
+# CONFIG_SMP is not set
+# CONFIG_X86_FEATURE_NAMES is not set
+# CONFIG_X86_FAST_FEATURE_TESTS is not set
+# CONFIG_GOLDFISH is not set
+# CONFIG_X86_EXTENDED_PLATFORM is not set
+# CONFIG_X86_32_IRIS is not set
+# CONFIG_SCHED_OMIT_FRAME_POINTER is not set
+# CONFIG_HYPERVISOR_GUEST is not set
+CONFIG_NO_BOOTMEM=y
+# CONFIG_M486 is not set
+# CONFIG_M586 is not set
+# CONFIG_M586TSC is not set
+# CONFIG_M586MMX is not set
+# CONFIG_M686 is not set
+# CONFIG_MPENTIUMII is not set
+# CONFIG_MPENTIUMIII is not set
+# CONFIG_MPENTIUMM is not set
+# CONFIG_MPENTIUM4 is not set
+# CONFIG_MK6 is not set
+# CONFIG_MK7 is not set
+# CONFIG_MK8 is not set
+# CONFIG_MCRUSOE is not set
+# CONFIG_MEFFICEON is not set
+# CONFIG_MWINCHIPC6 is not set
+# CONFIG_MWINCHIP3D is not set
+# CONFIG_MELAN is not set
+# CONFIG_MGEODEGX1 is not set
+# CONFIG_MGEODE_LX is not set
+# CONFIG_MCYRIXIII is not set
+# CONFIG_MVIAC3_2 is not set
+# CONFIG_MVIAC7 is not set
+# CONFIG_MCORE2 is not set
+CONFIG_MATOM=y
+# CONFIG_X86_GENERIC is not set
+CONFIG_X86_INTERNODE_CACHE_SHIFT=6
+CONFIG_X86_L1_CACHE_SHIFT=6
+CONFIG_X86_USE_PPRO_CHECKSUM=y
+CONFIG_X86_TSC=y
+CONFIG_X86_CMPXCHG64=y
+CONFIG_X86_CMOV=y
+CONFIG_X86_MINIMUM_CPU_FAMILY=5
+CONFIG_X86_DEBUGCTLMSR=y
+# CONFIG_PROCESSOR_SELECT is not set
+CONFIG_CPU_SUP_INTEL=y
+CONFIG_CPU_SUP_CYRIX_32=y
+CONFIG_CPU_SUP_AMD=y
+CONFIG_CPU_SUP_CENTAUR=y
+CONFIG_CPU_SUP_TRANSMETA_32=y
+CONFIG_CPU_SUP_UMC_32=y
+# CONFIG_HPET_TIMER is not set
+# CONFIG_DMI is not set
+CONFIG_NR_CPUS=1
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_VOLUNTARY is not set
+# CONFIG_PREEMPT is not set
+# CONFIG_X86_UP_APIC is not set
+# CONFIG_X86_MCE is not set
+
+#
+# Performance monitoring
+#
+# CONFIG_PERF_EVENTS_AMD_POWER is not set
+# CONFIG_X86_LEGACY_VM86 is not set
+# CONFIG_VM86 is not set
+# CONFIG_TOSHIBA is not set
+# CONFIG_I8K is not set
+# CONFIG_X86_REBOOTFIXUPS is not set
+# CONFIG_MICROCODE is not set
+# CONFIG_X86_MSR is not set
+# CONFIG_X86_CPUID is not set
+CONFIG_NOHIGHMEM=y
+# CONFIG_HIGHMEM4G is not set
+# CONFIG_HIGHMEM64G is not set
+CONFIG_VMSPLIT_3G=y
+# CONFIG_VMSPLIT_3G_OPT is not set
+# CONFIG_VMSPLIT_2G is not set
+# CONFIG_VMSPLIT_2G_OPT is not set
+# CONFIG_VMSPLIT_1G is not set
+CONFIG_PAGE_OFFSET=0xC0000000
+# CONFIG_X86_PAE is not set
+CONFIG_ARCH_FLATMEM_ENABLE=y
+CONFIG_ARCH_SPARSEMEM_ENABLE=y
+CONFIG_ARCH_SELECT_MEMORY_MODEL=y
+CONFIG_ILLEGAL_POINTER_VALUE=0
+CONFIG_SELECT_MEMORY_MODEL=y
+CONFIG_FLATMEM_MANUAL=y
+# CONFIG_SPARSEMEM_MANUAL is not set
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+CONFIG_SPARSEMEM_STATIC=y
+CONFIG_HAVE_MEMBLOCK=y
+CONFIG_HAVE_MEMBLOCK_NODE_MAP=y
+CONFIG_ARCH_DISCARD_MEMBLOCK=y
+# CONFIG_HAVE_BOOTMEM_INFO_NODE is not set
+CONFIG_SPLIT_PTLOCK_CPUS=4
+# CONFIG_COMPACTION is not set
+# CONFIG_PHYS_ADDR_T_64BIT is not set
+CONFIG_VIRT_TO_BUS=y
+# CONFIG_KSM is not set
+CONFIG_DEFAULT_MMAP_MIN_ADDR=4096
+# CONFIG_TRANSPARENT_HUGEPAGE is not set
+CONFIG_NEED_PER_CPU_KM=y
+# CONFIG_CLEANCACHE is not set
+# CONFIG_CMA is not set
+# CONFIG_ZPOOL is not set
+# CONFIG_ZBUD is not set
+# CONFIG_ZSMALLOC is not set
+CONFIG_GENERIC_EARLY_IOREMAP=y
+CONFIG_ARCH_SUPPORTS_DEFERRED_STRUCT_PAGE_INIT=y
+# CONFIG_X86_CHECK_BIOS_CORRUPTION is not set
+CONFIG_X86_RESERVE_LOW=64
+# CONFIG_MTRR is not set
+# CONFIG_ARCH_RANDOM is not set
+# CONFIG_X86_SMAP is not set
+# CONFIG_X86_INTEL_MPX is not set
+# CONFIG_SECCOMP is not set
+# CONFIG_HZ_100 is not set
+CONFIG_HZ_250=y
+# CONFIG_HZ_300 is not set
+# CONFIG_HZ_1000 is not set
+CONFIG_HZ=250
+# CONFIG_SCHED_HRTICK is not set
+# CONFIG_KEXEC is not set
+CONFIG_PHYSICAL_START=0x1000000
+# CONFIG_RELOCATABLE is not set
+CONFIG_PHYSICAL_ALIGN=0x200000
+# CONFIG_COMPAT_VDSO is not set
+# CONFIG_CMDLINE_BOOL is not set
+# CONFIG_MODIFY_LDT_SYSCALL is not set
+
+#
+# Power management and ACPI options
+#
+# CONFIG_SUSPEND is not set
+# CONFIG_PM is not set
+# CONFIG_SFI is not set
+
+#
+# CPU Frequency scaling
+#
+# CONFIG_CPU_FREQ is not set
+
+#
+# CPU Idle
+#
+# CONFIG_CPU_IDLE is not set
+# CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED is not set
+
+#
+# Bus options (PCI etc.)
+#
+# CONFIG_PCI is not set
+# CONFIG_ISA_BUS is not set
+CONFIG_ISA_DMA_API=y
+# CONFIG_ISA is not set
+# CONFIG_SCx200 is not set
+# CONFIG_OLPC is not set
+# CONFIG_ALIX is not set
+# CONFIG_NET5501 is not set
+# CONFIG_PCCARD is not set
+# CONFIG_X86_SYSFB is not set
+
+#
+# Executable file formats / Emulations
+#
+# CONFIG_BINFMT_ELF is not set
+# CONFIG_BINFMT_SCRIPT is not set
+CONFIG_HAVE_AOUT=y
+# CONFIG_BINFMT_AOUT is not set
+# CONFIG_BINFMT_MISC is not set
+# CONFIG_COREDUMP is not set
+CONFIG_HAVE_ATOMIC_IOMAP=y
+CONFIG_NET=y
+
+#
+# Networking options
+#
+# CONFIG_PACKET is not set
+# CONFIG_UNIX is not set
+CONFIG_XFRM=y
+# CONFIG_XFRM_USER is not set
+# CONFIG_XFRM_SUB_POLICY is not set
+# CONFIG_XFRM_MIGRATE is not set
+# CONFIG_NET_KEY is not set
+CONFIG_INET=y
+CONFIG_IP_MULTICAST=y
+CONFIG_IP_ADVANCED_ROUTER=y
+# CONFIG_IP_FIB_TRIE_STATS is not set
+# CONFIG_IP_MULTIPLE_TABLES is not set
+# CONFIG_IP_ROUTE_MULTIPATH is not set
+# CONFIG_IP_ROUTE_VERBOSE is not set
+CONFIG_IP_PNP=y
+# CONFIG_IP_PNP_DHCP is not set
+# CONFIG_IP_PNP_BOOTP is not set
+# CONFIG_IP_PNP_RARP is not set
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_IPGRE_DEMUX is not set
+CONFIG_NET_IP_TUNNEL=y
+# CONFIG_IP_MROUTE is not set
+# CONFIG_SYN_COOKIES is not set
+# CONFIG_NET_IPVTI is not set
+# CONFIG_NET_UDP_TUNNEL is not set
+# CONFIG_NET_FOU is not set
+# CONFIG_NET_FOU_IP_TUNNELS is not set
+# CONFIG_INET_AH is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_XFRM_TUNNEL is not set
+CONFIG_INET_TUNNEL=y
+CONFIG_INET_XFRM_MODE_TRANSPORT=y
+CONFIG_INET_XFRM_MODE_TUNNEL=y
+CONFIG_INET_XFRM_MODE_BEET=y
+CONFIG_INET_DIAG=y
+CONFIG_INET_TCP_DIAG=y
+# CONFIG_INET_UDP_DIAG is not set
+# CONFIG_INET_DIAG_DESTROY is not set
+# CONFIG_TCP_CONG_ADVANCED is not set
+CONFIG_TCP_CONG_CUBIC=y
+CONFIG_DEFAULT_TCP_CONG="cubic"
+# CONFIG_TCP_MD5SIG is not set
+CONFIG_IPV6=y
+# CONFIG_IPV6_ROUTER_PREF is not set
+# CONFIG_IPV6_OPTIMISTIC_DAD is not set
+# CONFIG_INET6_AH is not set
+# CONFIG_INET6_ESP is not set
+# CONFIG_INET6_IPCOMP is not set
+# CONFIG_IPV6_MIP6 is not set
+# CONFIG_INET6_XFRM_TUNNEL is not set
+# CONFIG_INET6_TUNNEL is not set
+CONFIG_INET6_XFRM_MODE_TRANSPORT=y
+CONFIG_INET6_XFRM_MODE_TUNNEL=y
+CONFIG_INET6_XFRM_MODE_BEET=y
+# CONFIG_INET6_XFRM_MODE_ROUTEOPTIMIZATION is not set
+# CONFIG_IPV6_VTI is not set
+CONFIG_IPV6_SIT=y
+# CONFIG_IPV6_SIT_6RD is not set
+CONFIG_IPV6_NDISC_NODETYPE=y
+# CONFIG_IPV6_TUNNEL is not set
+# CONFIG_IPV6_FOU is not set
+# CONFIG_IPV6_FOU_TUNNEL is not set
+# CONFIG_IPV6_MULTIPLE_TABLES is not set
+# CONFIG_IPV6_MROUTE is not set
+# CONFIG_NETWORK_SECMARK is not set
+# CONFIG_NET_PTP_CLASSIFY is not set
+# CONFIG_NETWORK_PHY_TIMESTAMPING is not set
+# CONFIG_NETFILTER is not set
+# CONFIG_IP_DCCP is not set
+# CONFIG_IP_SCTP is not set
+# CONFIG_RDS is not set
+# CONFIG_TIPC is not set
+CONFIG_GMTP=y
+
+#
+# GMTP-Inter Configuration
+#
+CONFIG_GMTP_INTER=y
+# CONFIG_ATM is not set
+# CONFIG_L2TP is not set
+# CONFIG_BRIDGE is not set
+# CONFIG_VLAN_8021Q is not set
+# CONFIG_DECNET is not set
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_PHONET is not set
+# CONFIG_6LOWPAN is not set
+# CONFIG_IEEE802154 is not set
+# CONFIG_NET_SCHED is not set
+# CONFIG_DCB is not set
+# CONFIG_BATMAN_ADV is not set
+# CONFIG_OPENVSWITCH is not set
+# CONFIG_VSOCKETS is not set
+# CONFIG_NETLINK_DIAG is not set
+# CONFIG_MPLS is not set
+# CONFIG_HSR is not set
+# CONFIG_NET_SWITCHDEV is not set
+# CONFIG_NET_L3_MASTER_DEV is not set
+# CONFIG_NET_NCSI is not set
+# CONFIG_SOCK_CGROUP_DATA is not set
+CONFIG_NET_RX_BUSY_POLL=y
+
+#
+# Network testing
+#
+# CONFIG_HAMRADIO is not set
+# CONFIG_CAN is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+# CONFIG_AF_RXRPC is not set
+# CONFIG_AF_KCM is not set
+# CONFIG_STREAM_PARSER is not set
+# CONFIG_WIRELESS is not set
+# CONFIG_WIMAX is not set
+# CONFIG_RFKILL is not set
+# CONFIG_NET_9P is not set
+# CONFIG_CAIF is not set
+# CONFIG_CEPH_LIB is not set
+# CONFIG_NFC is not set
+# CONFIG_LWTUNNEL is not set
+CONFIG_DST_CACHE=y
+# CONFIG_NET_DEVLINK is not set
+CONFIG_MAY_USE_DEVLINK=y
+
+#
+# Device Drivers
+#
+
+#
+# Generic Driver Options
+#
+# CONFIG_UEVENT_HELPER is not set
+# CONFIG_DEVTMPFS is not set
+# CONFIG_STANDALONE is not set
+# CONFIG_PREVENT_FIRMWARE_BUILD is not set
+# CONFIG_FW_LOADER is not set
+# CONFIG_ALLOW_DEV_COREDUMP is not set
+# CONFIG_DEBUG_DRIVER is not set
+# CONFIG_DEBUG_DEVRES is not set
+# CONFIG_DEBUG_TEST_DRIVER_REMOVE is not set
+# CONFIG_SYS_HYPERVISOR is not set
+# CONFIG_GENERIC_CPU_DEVICES is not set
+CONFIG_GENERIC_CPU_AUTOPROBE=y
+# CONFIG_DMA_SHARED_BUFFER is not set
+
+#
+# Bus devices
+#
+# CONFIG_QCOM_EBI2 is not set
+# CONFIG_CONNECTOR is not set
+# CONFIG_MTD is not set
+# CONFIG_OF is not set
+CONFIG_ARCH_MIGHT_HAVE_PC_PARPORT=y
+# CONFIG_PARPORT is not set
+
+#
+# Misc devices
+#
+# CONFIG_DUMMY_IRQ is not set
+# CONFIG_ENCLOSURE_SERVICES is not set
+# CONFIG_SRAM is not set
+# CONFIG_C2PORT is not set
+
+#
+# EEPROM support
+#
+# CONFIG_EEPROM_93CX6 is not set
+
+#
+# Texas Instruments shared transport line discipline
+#
+
+#
+# Altera FPGA firmware download module
+#
+
+#
+# Intel MIC Bus Driver
+#
+
+#
+# SCIF Bus Driver
+#
+
+#
+# VOP Bus Driver
+#
+
+#
+# Intel MIC Host Driver
+#
+
+#
+# Intel MIC Card Driver
+#
+
+#
+# SCIF Driver
+#
+
+#
+# Intel MIC Coprocessor State Management (COSM) Drivers
+#
+
+#
+# VOP Driver
+#
+# CONFIG_ECHO is not set
+# CONFIG_CXL_BASE is not set
+# CONFIG_CXL_AFU_DRIVER_OPS is not set
+CONFIG_HAVE_IDE=y
+
+#
+# SCSI device support
+#
+CONFIG_SCSI_MOD=y
+# CONFIG_SCSI_DMA is not set
+# CONFIG_SCSI_NETLINK is not set
+# CONFIG_MACINTOSH_DRIVERS is not set
+# CONFIG_NETDEVICES is not set
+
+#
+# Input device support
+#
+# CONFIG_INPUT is not set
+
+#
+# Hardware I/O ports
+#
+# CONFIG_SERIO is not set
+CONFIG_ARCH_MIGHT_HAVE_PC_SERIO=y
+# CONFIG_GAMEPORT is not set
+
+#
+# Character devices
+#
+# CONFIG_TTY is not set
+# CONFIG_DEVMEM is not set
+# CONFIG_DEVKMEM is not set
+# CONFIG_IPMI_HANDLER is not set
+# CONFIG_HW_RANDOM is not set
+# CONFIG_NVRAM is not set
+# CONFIG_PC8736x_GPIO is not set
+# CONFIG_NSC_GPIO is not set
+# CONFIG_HANGCHECK_TIMER is not set
+# CONFIG_TCG_TPM is not set
+# CONFIG_TELCLOCK is not set
+
+#
+# I2C support
+#
+# CONFIG_I2C is not set
+# CONFIG_SPI is not set
+# CONFIG_SPMI is not set
+# CONFIG_HSI is not set
+
+#
+# PPS support
+#
+# CONFIG_PPS is not set
+
+#
+# PPS generators support
+#
+
+#
+# PTP clock support
+#
+# CONFIG_PTP_1588_CLOCK is not set
+
+#
+# Enable PHYLIB and NETWORK_PHY_TIMESTAMPING to see the additional clocks.
+#
+# CONFIG_PTP_1588_CLOCK_PCH is not set
+# CONFIG_GPIOLIB is not set
+# CONFIG_W1 is not set
+# CONFIG_POWER_AVS is not set
+# CONFIG_POWER_RESET is not set
+# CONFIG_POWER_SUPPLY is not set
+# CONFIG_HWMON is not set
+# CONFIG_THERMAL is not set
+# CONFIG_WATCHDOG is not set
+CONFIG_SSB_POSSIBLE=y
+
+#
+# Sonics Silicon Backplane
+#
+# CONFIG_SSB is not set
+CONFIG_BCMA_POSSIBLE=y
+
+#
+# Broadcom specific AMBA
+#
+# CONFIG_BCMA is not set
+
+#
+# Multifunction device drivers
+#
+# CONFIG_MFD_CORE is not set
+# CONFIG_MFD_CROS_EC is not set
+# CONFIG_MFD_EXYNOS_LPASS is not set
+# CONFIG_HTC_PASIC3 is not set
+# CONFIG_MFD_KEMPLD is not set
+# CONFIG_MFD_MT6397 is not set
+# CONFIG_MFD_SM501 is not set
+# CONFIG_ABX500_CORE is not set
+# CONFIG_MFD_SYSCON is not set
+# CONFIG_MFD_TI_AM335X_TSCADC is not set
+# CONFIG_MFD_TMIO is not set
+# CONFIG_REGULATOR is not set
+# CONFIG_MEDIA_SUPPORT is not set
+
+#
+# Graphics support
+#
+# CONFIG_DRM is not set
+
+#
+# ACP (Audio CoProcessor) Configuration
+#
+
+#
+# Frame buffer Devices
+#
+# CONFIG_FB is not set
+# CONFIG_BACKLIGHT_LCD_SUPPORT is not set
+# CONFIG_VGASTATE is not set
+# CONFIG_SOUND is not set
+CONFIG_USB_OHCI_LITTLE_ENDIAN=y
+# CONFIG_USB_SUPPORT is not set
+# CONFIG_UWB is not set
+# CONFIG_MMC is not set
+# CONFIG_MEMSTICK is not set
+# CONFIG_NEW_LEDS is not set
+# CONFIG_ACCESSIBILITY is not set
+CONFIG_EDAC_ATOMIC_SCRUB=y
+CONFIG_EDAC_SUPPORT=y
+# CONFIG_EDAC is not set
+CONFIG_RTC_LIB=y
+CONFIG_RTC_MC146818_LIB=y
+# CONFIG_RTC_CLASS is not set
+# CONFIG_DMADEVICES is not set
+
+#
+# DMABUF options
+#
+# CONFIG_SYNC_FILE is not set
+# CONFIG_AUXDISPLAY is not set
+# CONFIG_UIO is not set
+# CONFIG_VIRT_DRIVERS is not set
+
+#
+# Virtio drivers
+#
+# CONFIG_VIRTIO_MMIO is not set
+
+#
+# Microsoft Hyper-V guest support
+#
+# CONFIG_STAGING is not set
+# CONFIG_X86_PLATFORM_DEVICES is not set
+# CONFIG_CHROME_PLATFORMS is not set
+
+#
+# Hardware Spinlock drivers
+#
+
+#
+# Clock Source drivers
+#
+CONFIG_CLKSRC_I8253=y
+CONFIG_CLKEVT_I8253=y
+CONFIG_CLKBLD_I8253=y
+# CONFIG_ATMEL_PIT is not set
+# CONFIG_SH_TIMER_CMT is not set
+# CONFIG_SH_TIMER_MTU2 is not set
+# CONFIG_SH_TIMER_TMU is not set
+# CONFIG_EM_TIMER_STI is not set
+# CONFIG_MAILBOX is not set
+# CONFIG_IOMMU_SUPPORT is not set
+
+#
+# Remoteproc drivers
+#
+# CONFIG_STE_MODEM_RPROC is not set
+
+#
+# Rpmsg drivers
+#
+
+#
+# SOC (System On Chip) specific Drivers
+#
+
+#
+# Broadcom SoC drivers
+#
+# CONFIG_SUNXI_SRAM is not set
+# CONFIG_SOC_TI is not set
+# CONFIG_PM_DEVFREQ is not set
+# CONFIG_EXTCON is not set
+# CONFIG_MEMORY is not set
+# CONFIG_IIO is not set
+# CONFIG_PWM is not set
+CONFIG_ARM_GIC_MAX_NR=1
+# CONFIG_IPACK_BUS is not set
+# CONFIG_RESET_CONTROLLER is not set
+# CONFIG_FMC is not set
+
+#
+# PHY Subsystem
+#
+# CONFIG_GENERIC_PHY is not set
+# CONFIG_PHY_PXA_28NM_HSIC is not set
+# CONFIG_PHY_PXA_28NM_USB2 is not set
+# CONFIG_BCM_KONA_USB2_PHY is not set
+# CONFIG_POWERCAP is not set
+# CONFIG_MCB is not set
+
+#
+# Performance monitor support
+#
+# CONFIG_RAS is not set
+
+#
+# Android
+#
+# CONFIG_ANDROID is not set
+# CONFIG_NVMEM is not set
+# CONFIG_STM is not set
+# CONFIG_INTEL_TH is not set
+
+#
+# FPGA Configuration Support
+#
+# CONFIG_FPGA is not set
+
+#
+# Firmware Drivers
+#
+# CONFIG_EDD is not set
+# CONFIG_FIRMWARE_MEMMAP is not set
+# CONFIG_DELL_RBU is not set
+# CONFIG_DCDBAS is not set
+# CONFIG_GOOGLE_FIRMWARE is not set
+
+#
+# File systems
+#
+CONFIG_DCACHE_WORD_ACCESS=y
+# CONFIG_FS_POSIX_ACL is not set
+# CONFIG_EXPORTFS_BLOCK_OPS is not set
+# CONFIG_FILE_LOCKING is not set
+# CONFIG_FSNOTIFY is not set
+# CONFIG_DNOTIFY is not set
+# CONFIG_INOTIFY_USER is not set
+# CONFIG_FANOTIFY is not set
+# CONFIG_QUOTA is not set
+# CONFIG_QUOTACTL is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+# CONFIG_OVERLAY_FS is not set
+
+#
+# Caches
+#
+# CONFIG_FSCACHE is not set
+
+#
+# Pseudo filesystems
+#
+# CONFIG_PROC_FS is not set
+# CONFIG_PROC_CHILDREN is not set
+# CONFIG_KERNFS is not set
+# CONFIG_SYSFS is not set
+# CONFIG_HUGETLBFS is not set
+# CONFIG_HUGETLB_PAGE is not set
+# CONFIG_CONFIGFS_FS is not set
+# CONFIG_MISC_FILESYSTEMS is not set
+CONFIG_NETWORK_FILESYSTEMS=y
+# CONFIG_CEPH_FS is not set
+# CONFIG_CIFS is not set
+# CONFIG_NCP_FS is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_AFS_FS is not set
+# CONFIG_NLS is not set
+
+#
+# Kernel hacking
+#
+CONFIG_TRACE_IRQFLAGS_SUPPORT=y
+
+#
+# printk and dmesg options
+#
+CONFIG_MESSAGE_LOGLEVEL_DEFAULT=4
+
+#
+# Compile-time checks and compiler options
+#
+# CONFIG_DEBUG_INFO is not set
+# CONFIG_ENABLE_WARN_DEPRECATED is not set
+# CONFIG_ENABLE_MUST_CHECK is not set
+CONFIG_FRAME_WARN=1024
+# CONFIG_STRIP_ASM_SYMS is not set
+# CONFIG_READABLE_ASM is not set
+# CONFIG_UNUSED_SYMBOLS is not set
+# CONFIG_PAGE_OWNER is not set
+# CONFIG_DEBUG_FS is not set
+# CONFIG_HEADERS_CHECK is not set
+# CONFIG_DEBUG_SECTION_MISMATCH is not set
+# CONFIG_SECTION_MISMATCH_WARN_ONLY is not set
+CONFIG_ARCH_WANT_FRAME_POINTERS=y
+# CONFIG_FRAME_POINTER is not set
+# CONFIG_DEBUG_FORCE_WEAK_PER_CPU is not set
+# CONFIG_MAGIC_SYSRQ is not set
+CONFIG_DEBUG_KERNEL=y
+
+#
+# Memory Debugging
+#
+# CONFIG_PAGE_EXTENSION is not set
+# CONFIG_DEBUG_PAGEALLOC is not set
+# CONFIG_PAGE_POISONING is not set
+# CONFIG_DEBUG_OBJECTS is not set
+CONFIG_HAVE_DEBUG_KMEMLEAK=y
+# CONFIG_DEBUG_KMEMLEAK is not set
+# CONFIG_DEBUG_STACK_USAGE is not set
+# CONFIG_DEBUG_VM is not set
+# CONFIG_DEBUG_VIRTUAL is not set
+# CONFIG_DEBUG_MEMORY_INIT is not set
+CONFIG_HAVE_DEBUG_STACKOVERFLOW=y
+# CONFIG_DEBUG_STACKOVERFLOW is not set
+CONFIG_HAVE_ARCH_KMEMCHECK=y
+# CONFIG_DEBUG_SHIRQ is not set
+
+#
+# Debug Lockups and Hangs
+#
+# CONFIG_LOCKUP_DETECTOR is not set
+# CONFIG_DETECT_HUNG_TASK is not set
+# CONFIG_WQ_WATCHDOG is not set
+# CONFIG_PANIC_ON_OOPS is not set
+CONFIG_PANIC_ON_OOPS_VALUE=0
+CONFIG_PANIC_TIMEOUT=0
+# CONFIG_SCHED_INFO is not set
+# CONFIG_SCHED_STACK_END_CHECK is not set
+# CONFIG_DEBUG_TIMEKEEPING is not set
+
+#
+# Lock Debugging (spinlocks, mutexes, etc...)
+#
+# CONFIG_DEBUG_SPINLOCK is not set
+# CONFIG_DEBUG_MUTEXES is not set
+# CONFIG_DEBUG_WW_MUTEX_SLOWPATH is not set
+# CONFIG_DEBUG_LOCK_ALLOC is not set
+# CONFIG_PROVE_LOCKING is not set
+# CONFIG_LOCK_STAT is not set
+# CONFIG_DEBUG_ATOMIC_SLEEP is not set
+# CONFIG_DEBUG_LOCKING_API_SELFTESTS is not set
+# CONFIG_LOCK_TORTURE_TEST is not set
+# CONFIG_STACKTRACE is not set
+# CONFIG_DEBUG_KOBJECT is not set
+# CONFIG_DEBUG_LIST is not set
+# CONFIG_DEBUG_PI_LIST is not set
+# CONFIG_DEBUG_SG is not set
+# CONFIG_DEBUG_NOTIFIERS is not set
+# CONFIG_DEBUG_CREDENTIALS is not set
+
+#
+# RCU Debugging
+#
+# CONFIG_PROVE_RCU is not set
+# CONFIG_SPARSE_RCU_POINTER is not set
+# CONFIG_TORTURE_TEST is not set
+# CONFIG_RCU_PERF_TEST is not set
+# CONFIG_RCU_TORTURE_TEST is not set
+# CONFIG_RCU_TRACE is not set
+# CONFIG_RCU_EQS_DEBUG is not set
+# CONFIG_DEBUG_WQ_FORCE_RR_CPU is not set
+# CONFIG_NOTIFIER_ERROR_INJECTION is not set
+# CONFIG_FAULT_INJECTION is not set
+CONFIG_USER_STACKTRACE_SUPPORT=y
+CONFIG_HAVE_FUNCTION_TRACER=y
+CONFIG_HAVE_FUNCTION_GRAPH_TRACER=y
+CONFIG_HAVE_DYNAMIC_FTRACE=y
+CONFIG_HAVE_DYNAMIC_FTRACE_WITH_REGS=y
+CONFIG_HAVE_FTRACE_MCOUNT_RECORD=y
+CONFIG_HAVE_SYSCALL_TRACEPOINTS=y
+CONFIG_HAVE_C_RECORDMCOUNT=y
+CONFIG_TRACING_SUPPORT=y
+# CONFIG_FTRACE is not set
+
+#
+# Runtime Testing
+#
+# CONFIG_TEST_LIST_SORT is not set
+# CONFIG_BACKTRACE_SELF_TEST is not set
+# CONFIG_RBTREE_TEST is not set
+# CONFIG_INTERVAL_TREE_TEST is not set
+# CONFIG_PERCPU_TEST is not set
+# CONFIG_ATOMIC64_SELFTEST is not set
+# CONFIG_TEST_HEXDUMP is not set
+# CONFIG_TEST_STRING_HELPERS is not set
+# CONFIG_TEST_KSTRTOX is not set
+# CONFIG_TEST_PRINTF is not set
+# CONFIG_TEST_BITMAP is not set
+# CONFIG_TEST_UUID is not set
+# CONFIG_TEST_RHASHTABLE is not set
+# CONFIG_TEST_HASH is not set
+# CONFIG_DMA_API_DEBUG is not set
+# CONFIG_TEST_LKM is not set
+# CONFIG_TEST_USER_COPY is not set
+# CONFIG_TEST_BPF is not set
+# CONFIG_TEST_UDELAY is not set
+# CONFIG_MEMTEST is not set
+# CONFIG_TEST_STATIC_KEYS is not set
+# CONFIG_SAMPLES is not set
+CONFIG_HAVE_ARCH_KGDB=y
+# CONFIG_KGDB is not set
+CONFIG_ARCH_HAS_UBSAN_SANITIZE_ALL=y
+# CONFIG_ARCH_WANTS_UBSAN_NO_NULL is not set
+# CONFIG_UBSAN is not set
+CONFIG_ARCH_HAS_DEVMEM_IS_ALLOWED=y
+# CONFIG_STRICT_DEVMEM is not set
+# CONFIG_X86_VERBOSE_BOOTUP is not set
+# CONFIG_EARLY_PRINTK is not set
+# CONFIG_X86_PTDUMP_CORE is not set
+# CONFIG_X86_PTDUMP is not set
+# CONFIG_DEBUG_RODATA_TEST is not set
+# CONFIG_DEBUG_WX is not set
+# CONFIG_DEBUG_SET_MODULE_RONX is not set
+# CONFIG_DEBUG_NX_TEST is not set
+# CONFIG_DOUBLEFAULT is not set
+# CONFIG_DEBUG_TLBFLUSH is not set
+# CONFIG_IOMMU_STRESS is not set
+CONFIG_HAVE_MMIOTRACE_SUPPORT=y
+CONFIG_IO_DELAY_TYPE_0X80=0
+CONFIG_IO_DELAY_TYPE_0XED=1
+CONFIG_IO_DELAY_TYPE_UDELAY=2
+CONFIG_IO_DELAY_TYPE_NONE=3
+CONFIG_IO_DELAY_0X80=y
+# CONFIG_IO_DELAY_0XED is not set
+# CONFIG_IO_DELAY_UDELAY is not set
+# CONFIG_IO_DELAY_NONE is not set
+CONFIG_DEFAULT_IO_DELAY_TYPE=0
+# CONFIG_CPA_DEBUG is not set
+CONFIG_OPTIMIZE_INLINING=y
+# CONFIG_DEBUG_ENTRY is not set
+# CONFIG_X86_DEBUG_FPU is not set
+# CONFIG_PUNIT_ATOM_DEBUG is not set
+
+#
+# Security options
+#
+# CONFIG_KEYS is not set
+# CONFIG_SECURITY_DMESG_RESTRICT is not set
+# CONFIG_SECURITYFS is not set
+CONFIG_HAVE_ARCH_HARDENED_USERCOPY=y
+CONFIG_DEFAULT_SECURITY_DAC=y
+CONFIG_DEFAULT_SECURITY=""
+CONFIG_CRYPTO=y
+
+#
+# Crypto core or helper
+#
+CONFIG_CRYPTO_ALGAPI=y
+CONFIG_CRYPTO_ALGAPI2=y
+CONFIG_CRYPTO_AEAD=m
+CONFIG_CRYPTO_AEAD2=y
+CONFIG_CRYPTO_BLKCIPHER2=y
+CONFIG_CRYPTO_HASH=m
+CONFIG_CRYPTO_HASH2=y
+CONFIG_CRYPTO_RNG=m
+CONFIG_CRYPTO_RNG2=y
+CONFIG_CRYPTO_RNG_DEFAULT=m
+CONFIG_CRYPTO_AKCIPHER2=y
+CONFIG_CRYPTO_KPP2=y
+# CONFIG_CRYPTO_RSA is not set
+# CONFIG_CRYPTO_DH is not set
+# CONFIG_CRYPTO_ECDH is not set
+CONFIG_CRYPTO_MANAGER=m
+CONFIG_CRYPTO_MANAGER2=y
+# CONFIG_CRYPTO_USER is not set
+CONFIG_CRYPTO_MANAGER_DISABLE_TESTS=y
+# CONFIG_CRYPTO_GF128MUL is not set
+CONFIG_CRYPTO_NULL=m
+CONFIG_CRYPTO_NULL2=y
+CONFIG_CRYPTO_WORKQUEUE=y
+# CONFIG_CRYPTO_CRYPTD is not set
+# CONFIG_CRYPTO_MCRYPTD is not set
+# CONFIG_CRYPTO_AUTHENC is not set
+# CONFIG_CRYPTO_TEST is not set
+
+#
+# Authenticated Encryption with Associated Data
+#
+# CONFIG_CRYPTO_CCM is not set
+# CONFIG_CRYPTO_GCM is not set
+# CONFIG_CRYPTO_CHACHA20POLY1305 is not set
+# CONFIG_CRYPTO_SEQIV is not set
+CONFIG_CRYPTO_ECHAINIV=m
+
+#
+# Block modes
+#
+# CONFIG_CRYPTO_CBC is not set
+# CONFIG_CRYPTO_CTR is not set
+# CONFIG_CRYPTO_CTS is not set
+# CONFIG_CRYPTO_ECB is not set
+# CONFIG_CRYPTO_LRW is not set
+# CONFIG_CRYPTO_PCBC is not set
+# CONFIG_CRYPTO_XTS is not set
+# CONFIG_CRYPTO_KEYWRAP is not set
+
+#
+# Hash modes
+#
+# CONFIG_CRYPTO_CMAC is not set
+CONFIG_CRYPTO_HMAC=m
+# CONFIG_CRYPTO_XCBC is not set
+# CONFIG_CRYPTO_VMAC is not set
+
+#
+# Digest
+#
+# CONFIG_CRYPTO_CRC32C is not set
+# CONFIG_CRYPTO_CRC32C_INTEL is not set
+# CONFIG_CRYPTO_CRC32 is not set
+# CONFIG_CRYPTO_CRC32_PCLMUL is not set
+# CONFIG_CRYPTO_CRCT10DIF is not set
+# CONFIG_CRYPTO_GHASH is not set
+# CONFIG_CRYPTO_POLY1305 is not set
+# CONFIG_CRYPTO_MD4 is not set
+# CONFIG_CRYPTO_MD5 is not set
+# CONFIG_CRYPTO_MICHAEL_MIC is not set
+# CONFIG_CRYPTO_RMD128 is not set
+# CONFIG_CRYPTO_RMD160 is not set
+# CONFIG_CRYPTO_RMD256 is not set
+# CONFIG_CRYPTO_RMD320 is not set
+# CONFIG_CRYPTO_SHA1 is not set
+CONFIG_CRYPTO_SHA256=m
+# CONFIG_CRYPTO_SHA512 is not set
+# CONFIG_CRYPTO_SHA3 is not set
+# CONFIG_CRYPTO_TGR192 is not set
+# CONFIG_CRYPTO_WP512 is not set
+
+#
+# Ciphers
+#
+CONFIG_CRYPTO_AES=y
+# CONFIG_CRYPTO_AES_586 is not set
+# CONFIG_CRYPTO_AES_NI_INTEL is not set
+# CONFIG_CRYPTO_ANUBIS is not set
+# CONFIG_CRYPTO_ARC4 is not set
+# CONFIG_CRYPTO_BLOWFISH is not set
+# CONFIG_CRYPTO_CAMELLIA is not set
+# CONFIG_CRYPTO_CAST5 is not set
+# CONFIG_CRYPTO_CAST6 is not set
+# CONFIG_CRYPTO_DES is not set
+# CONFIG_CRYPTO_FCRYPT is not set
+# CONFIG_CRYPTO_KHAZAD is not set
+# CONFIG_CRYPTO_SALSA20 is not set
+# CONFIG_CRYPTO_SALSA20_586 is not set
+# CONFIG_CRYPTO_CHACHA20 is not set
+# CONFIG_CRYPTO_SEED is not set
+# CONFIG_CRYPTO_SERPENT is not set
+# CONFIG_CRYPTO_SERPENT_SSE2_586 is not set
+# CONFIG_CRYPTO_TEA is not set
+# CONFIG_CRYPTO_TWOFISH is not set
+# CONFIG_CRYPTO_TWOFISH_586 is not set
+
+#
+# Compression
+#
+# CONFIG_CRYPTO_DEFLATE is not set
+# CONFIG_CRYPTO_LZO is not set
+# CONFIG_CRYPTO_842 is not set
+# CONFIG_CRYPTO_LZ4 is not set
+# CONFIG_CRYPTO_LZ4HC is not set
+
+#
+# Random Number Generation
+#
+# CONFIG_CRYPTO_ANSI_CPRNG is not set
+CONFIG_CRYPTO_DRBG_MENU=m
+CONFIG_CRYPTO_DRBG_HMAC=y
+# CONFIG_CRYPTO_DRBG_HASH is not set
+CONFIG_CRYPTO_DRBG=m
+CONFIG_CRYPTO_JITTERENTROPY=m
+# CONFIG_CRYPTO_USER_API_HASH is not set
+# CONFIG_CRYPTO_USER_API_SKCIPHER is not set
+# CONFIG_CRYPTO_USER_API_RNG is not set
+# CONFIG_CRYPTO_USER_API_AEAD is not set
+CONFIG_CRYPTO_HW=y
+# CONFIG_CRYPTO_DEV_PADLOCK is not set
+
+#
+# Certificates for signature checking
+#
+CONFIG_HAVE_KVM=y
+# CONFIG_VIRTUALIZATION is not set
+# CONFIG_BINARY_PRINTF is not set
+
+#
+# Library routines
+#
+CONFIG_GENERIC_STRNCPY_FROM_USER=y
+CONFIG_GENERIC_STRNLEN_USER=y
+CONFIG_GENERIC_NET_UTILS=y
+CONFIG_GENERIC_FIND_FIRST_BIT=y
+CONFIG_GENERIC_PCI_IOMAP=y
+CONFIG_GENERIC_IOMAP=y
+CONFIG_GENERIC_IO=y
+CONFIG_ARCH_HAS_FAST_MULTIPLIER=y
+# CONFIG_CRC_CCITT is not set
+# CONFIG_CRC16 is not set
+# CONFIG_CRC_T10DIF is not set
+# CONFIG_CRC_ITU_T is not set
+# CONFIG_CRC32 is not set
+# CONFIG_CRC7 is not set
+# CONFIG_LIBCRC32C is not set
+# CONFIG_CRC8 is not set
+# CONFIG_AUDIT_ARCH_COMPAT_GENERIC is not set
+# CONFIG_RANDOM32_SELFTEST is not set
+# CONFIG_XZ_DEC is not set
+# CONFIG_XZ_DEC_BCJ is not set
+CONFIG_HAS_IOMEM=y
+CONFIG_HAS_IOPORT_MAP=y
+CONFIG_HAS_DMA=y
+CONFIG_NLATTR=y
+# CONFIG_CORDIC is not set
+# CONFIG_DDR is not set
+# CONFIG_IRQ_POLL is not set
+# CONFIG_SG_SPLIT is not set
+# CONFIG_SG_POOL is not set
+CONFIG_ARCH_HAS_SG_CHAIN=y
+CONFIG_ARCH_HAS_MMIO_FLUSH=y
diff -uprN --new-file linux-4.9-rc2-original/changes linux-4.9-rc2/changes
--- linux-4.9-rc2-original/changes	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/changes	2016-12-14 00:09:09.657438119 -0300
@@ -0,0 +1,84 @@
+sk = __inet_lookup_skb(&gmtp_inet_hashinfo, skb, 0,
+        gh->sport, gh->dport, NULL);
+
+terceiro parametro eh novo, alterei pra 0, e agora usam 
+um ponteiro pra contador de referencia deve ser algo de alocacao
+
+---
+
+req = inet_reqsk_alloc(&gmtp_request_sock_ops, sk, true);
+
+novo terceiro parametro, um boolean
+
+---
+
+__inet_hash_nolisten
+mudei para 
+inet_ehash_nolisten(newsk, NULL);
+a primeira funcao nao existe mais
+
+---
+
+struct inet_connection_sock_af_ops {
+    struct sock *(*syn_recv_sock)(const struct sock *sk, struct sk_buff *skb,
+                      struct request_sock *req,
+                      struct dst_entry *dst,
+                      struct request_sock *req_unhash,
+                      bool *own_req);
+
+mudou, dois parametros novos q nao faco a minima ideia o q sejam
+
+---
+
+// static unsigned int hook_func_gmtp_out(unsigned int hooknum, struct sk_buff *skb,
+//         const struct net_device *in, const struct net_device *out,
+//         int (*okfn)(struct sk_buff *))
+static unsigned int hook_func_gmtp_out(unsigned int hooknum, struct sk_buff *skb,
+        const struct nf_hook_state *state)
+
+
+varificar como usar nf_hook_state, junta status numa unica estrutura
+
+---
+
+1316     /****
+1317     nfho_gmtp_out.hook = hook_func_gmtp_out;
+1318     nfho_gmtp_out.hooknum = NF_INET_LOCAL_OUT;
+1319     nfho_gmtp_out.pf = PF_INET;
+1320     nfho_gmtp_out.priority = NF_IP_PRI_FIRST;
+1321     nf_register_hook(&nfho_gmtp_out);
+1322     ****/
+
+em ipv4.c foi comentado 
+
+---
+
+foi retirado todo register_hooks, do gmtp/ipv4.c  e gmtp-inter.c
+tah comentado
+
+---
+
+mudado pra __u32 tava __u64 ?
+__u32 secure_gmtp_sequence_number(__be32 saddr, __be32 daddr,
+				 __be16 sport, __be16 dport)
+
+---
+
+I got this if 
+
+delta = DIV_ROUND_CLOSEST(mult, (s64) GMTP_GHAMA(C)); /* 112 net/gmtp/gmtp-inter/ucc.c */
+
+net/built-in.o: In function `gmtp_ucc_equation':
+(.text+0x8c7e4): undefined reference to `__divdi3'
+net/built-in.o: In function `gmtp_ucc_equation':
+(.text+0x8c80d): undefined reference to `__divdi3'
+net/built-in.o: In function `gmtp_ucc_equation':
+(.text+0x8c81e): undefined reference to `__divdi3'
+net/built-in.o: In function `gmtp_ucc_equation':
+(.text+0x8c8a5): undefined reference to `__divdi3'
+net/built-in.o: In function `gmtp_ucc_equation':
+(.text+0x8c8c7): undefined reference to `__divdi3'
+make: *** [vmlinux] Error 1
+
+did delta = 0; only to complile
+
diff -uprN --new-file linux-4.9-rc2-original/config_bkp linux-4.9-rc2/config_bkp
--- linux-4.9-rc2-original/config_bkp	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/config_bkp	2016-12-03 05:19:06.285858428 -0300
@@ -0,0 +1,4300 @@
+#
+# Automatically generated file; DO NOT EDIT.
+# Linux/x86 4.9.0-rc2 Kernel Configuration
+#
+CONFIG_64BIT=y
+CONFIG_X86_64=y
+CONFIG_X86=y
+CONFIG_INSTRUCTION_DECODER=y
+CONFIG_OUTPUT_FORMAT="elf64-x86-64"
+CONFIG_ARCH_DEFCONFIG="arch/x86/configs/x86_64_defconfig"
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_STACKTRACE_SUPPORT=y
+CONFIG_MMU=y
+CONFIG_ARCH_MMAP_RND_BITS_MIN=28
+CONFIG_ARCH_MMAP_RND_BITS_MAX=32
+CONFIG_ARCH_MMAP_RND_COMPAT_BITS_MIN=8
+CONFIG_ARCH_MMAP_RND_COMPAT_BITS_MAX=16
+CONFIG_NEED_DMA_MAP_STATE=y
+CONFIG_NEED_SG_DMA_LENGTH=y
+CONFIG_GENERIC_ISA_DMA=y
+CONFIG_GENERIC_BUG=y
+CONFIG_GENERIC_BUG_RELATIVE_POINTERS=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_ARCH_MAY_HAVE_PC_FDC=y
+CONFIG_RWSEM_XCHGADD_ALGORITHM=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_ARCH_HAS_CPU_RELAX=y
+CONFIG_ARCH_HAS_CACHE_LINE_SIZE=y
+CONFIG_HAVE_SETUP_PER_CPU_AREA=y
+CONFIG_NEED_PER_CPU_EMBED_FIRST_CHUNK=y
+CONFIG_NEED_PER_CPU_PAGE_FIRST_CHUNK=y
+CONFIG_ARCH_HIBERNATION_POSSIBLE=y
+CONFIG_ARCH_SUSPEND_POSSIBLE=y
+CONFIG_ARCH_WANT_HUGE_PMD_SHARE=y
+CONFIG_ARCH_WANT_GENERAL_HUGETLB=y
+CONFIG_ZONE_DMA32=y
+CONFIG_AUDIT_ARCH=y
+CONFIG_ARCH_SUPPORTS_OPTIMIZED_INLINING=y
+CONFIG_ARCH_SUPPORTS_DEBUG_PAGEALLOC=y
+CONFIG_X86_64_SMP=y
+CONFIG_ARCH_SUPPORTS_UPROBES=y
+CONFIG_FIX_EARLYCON_MEM=y
+CONFIG_DEBUG_RODATA=y
+CONFIG_PGTABLE_LEVELS=4
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+CONFIG_IRQ_WORK=y
+CONFIG_BUILDTIME_EXTABLE_SORT=y
+CONFIG_THREAD_INFO_IN_TASK=y
+
+#
+# General setup
+#
+CONFIG_INIT_ENV_ARG_LIMIT=32
+CONFIG_CROSS_COMPILE=""
+# CONFIG_COMPILE_TEST is not set
+CONFIG_LOCALVERSION=""
+# CONFIG_LOCALVERSION_AUTO is not set
+CONFIG_HAVE_KERNEL_GZIP=y
+CONFIG_HAVE_KERNEL_BZIP2=y
+CONFIG_HAVE_KERNEL_LZMA=y
+CONFIG_HAVE_KERNEL_XZ=y
+CONFIG_HAVE_KERNEL_LZO=y
+CONFIG_HAVE_KERNEL_LZ4=y
+# CONFIG_KERNEL_GZIP is not set
+# CONFIG_KERNEL_BZIP2 is not set
+CONFIG_KERNEL_LZMA=y
+# CONFIG_KERNEL_XZ is not set
+# CONFIG_KERNEL_LZO is not set
+# CONFIG_KERNEL_LZ4 is not set
+CONFIG_DEFAULT_HOSTNAME="darkstar"
+CONFIG_SWAP=y
+CONFIG_SYSVIPC=y
+CONFIG_SYSVIPC_SYSCTL=y
+CONFIG_POSIX_MQUEUE=y
+CONFIG_POSIX_MQUEUE_SYSCTL=y
+# CONFIG_CROSS_MEMORY_ATTACH is not set
+# CONFIG_FHANDLE is not set
+# CONFIG_USELIB is not set
+# CONFIG_AUDIT is not set
+CONFIG_HAVE_ARCH_AUDITSYSCALL=y
+
+#
+# IRQ subsystem
+#
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_GENERIC_IRQ_SHOW=y
+CONFIG_GENERIC_PENDING_IRQ=y
+CONFIG_GENERIC_IRQ_CHIP=y
+CONFIG_IRQ_DOMAIN=y
+CONFIG_IRQ_DOMAIN_HIERARCHY=y
+CONFIG_GENERIC_MSI_IRQ=y
+CONFIG_GENERIC_MSI_IRQ_DOMAIN=y
+# CONFIG_IRQ_DOMAIN_DEBUG is not set
+CONFIG_IRQ_FORCED_THREADING=y
+CONFIG_SPARSE_IRQ=y
+CONFIG_CLOCKSOURCE_WATCHDOG=y
+CONFIG_ARCH_CLOCKSOURCE_DATA=y
+CONFIG_CLOCKSOURCE_VALIDATE_LAST_CYCLE=y
+CONFIG_GENERIC_TIME_VSYSCALL=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+CONFIG_GENERIC_CLOCKEVENTS_BROADCAST=y
+CONFIG_GENERIC_CLOCKEVENTS_MIN_ADJUST=y
+CONFIG_GENERIC_CMOS_UPDATE=y
+
+#
+# Timers subsystem
+#
+CONFIG_TICK_ONESHOT=y
+CONFIG_NO_HZ_COMMON=y
+# CONFIG_HZ_PERIODIC is not set
+CONFIG_NO_HZ_IDLE=y
+# CONFIG_NO_HZ_FULL is not set
+CONFIG_NO_HZ=y
+CONFIG_HIGH_RES_TIMERS=y
+
+#
+# CPU/Task time and stats accounting
+#
+CONFIG_TICK_CPU_ACCOUNTING=y
+# CONFIG_VIRT_CPU_ACCOUNTING_GEN is not set
+# CONFIG_IRQ_TIME_ACCOUNTING is not set
+CONFIG_BSD_PROCESS_ACCT=y
+CONFIG_BSD_PROCESS_ACCT_V3=y
+CONFIG_TASKSTATS=y
+CONFIG_TASK_DELAY_ACCT=y
+CONFIG_TASK_XACCT=y
+CONFIG_TASK_IO_ACCOUNTING=y
+
+#
+# RCU Subsystem
+#
+CONFIG_TREE_RCU=y
+# CONFIG_RCU_EXPERT is not set
+CONFIG_SRCU=y
+# CONFIG_TASKS_RCU is not set
+CONFIG_RCU_STALL_COMMON=y
+# CONFIG_TREE_RCU_TRACE is not set
+# CONFIG_RCU_EXPEDITE_BOOT is not set
+CONFIG_BUILD_BIN2C=y
+CONFIG_IKCONFIG=y
+CONFIG_IKCONFIG_PROC=y
+CONFIG_LOG_BUF_SHIFT=18
+CONFIG_LOG_CPU_MAX_BUF_SHIFT=12
+CONFIG_NMI_LOG_BUF_SHIFT=13
+CONFIG_HAVE_UNSTABLE_SCHED_CLOCK=y
+CONFIG_ARCH_SUPPORTS_NUMA_BALANCING=y
+CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH=y
+CONFIG_ARCH_SUPPORTS_INT128=y
+# CONFIG_CGROUPS is not set
+# CONFIG_CHECKPOINT_RESTORE is not set
+# CONFIG_NAMESPACES is not set
+# CONFIG_SCHED_AUTOGROUP is not set
+# CONFIG_SYSFS_DEPRECATED is not set
+CONFIG_RELAY=y
+# CONFIG_BLK_DEV_INITRD is not set
+CONFIG_CC_OPTIMIZE_FOR_PERFORMANCE=y
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+CONFIG_SYSCTL=y
+CONFIG_ANON_INODES=y
+CONFIG_SYSCTL_EXCEPTION_TRACE=y
+CONFIG_HAVE_PCSPKR_PLATFORM=y
+CONFIG_BPF=y
+CONFIG_EXPERT=y
+CONFIG_MULTIUSER=y
+CONFIG_SGETMASK_SYSCALL=y
+CONFIG_SYSFS_SYSCALL=y
+# CONFIG_SYSCTL_SYSCALL is not set
+CONFIG_KALLSYMS=y
+CONFIG_KALLSYMS_ALL=y
+CONFIG_KALLSYMS_ABSOLUTE_PERCPU=y
+CONFIG_KALLSYMS_BASE_RELATIVE=y
+CONFIG_PRINTK=y
+CONFIG_PRINTK_NMI=y
+CONFIG_BUG=y
+CONFIG_ELF_CORE=y
+CONFIG_PCSPKR_PLATFORM=y
+CONFIG_BASE_FULL=y
+CONFIG_FUTEX=y
+CONFIG_EPOLL=y
+CONFIG_SIGNALFD=y
+CONFIG_TIMERFD=y
+CONFIG_EVENTFD=y
+# CONFIG_BPF_SYSCALL is not set
+CONFIG_SHMEM=y
+CONFIG_AIO=y
+# CONFIG_ADVISE_SYSCALLS is not set
+# CONFIG_USERFAULTFD is not set
+# CONFIG_PCI_QUIRKS is not set
+# CONFIG_MEMBARRIER is not set
+# CONFIG_EMBEDDED is not set
+CONFIG_HAVE_PERF_EVENTS=y
+
+#
+# Kernel Performance Events And Counters
+#
+CONFIG_PERF_EVENTS=y
+# CONFIG_DEBUG_PERF_USE_VMALLOC is not set
+CONFIG_VM_EVENT_COUNTERS=y
+CONFIG_SLUB_DEBUG=y
+# CONFIG_COMPAT_BRK is not set
+# CONFIG_SLAB is not set
+CONFIG_SLUB=y
+# CONFIG_SLOB is not set
+# CONFIG_SLAB_FREELIST_RANDOM is not set
+# CONFIG_SLUB_CPU_PARTIAL is not set
+# CONFIG_SYSTEM_DATA_VERIFICATION is not set
+# CONFIG_PROFILING is not set
+CONFIG_TRACEPOINTS=y
+CONFIG_KEXEC_CORE=y
+CONFIG_HAVE_OPROFILE=y
+CONFIG_OPROFILE_NMI_TIMER=y
+# CONFIG_KPROBES is not set
+# CONFIG_JUMP_LABEL is not set
+# CONFIG_UPROBES is not set
+# CONFIG_HAVE_64BIT_ALIGNED_ACCESS is not set
+CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS=y
+CONFIG_ARCH_USE_BUILTIN_BSWAP=y
+CONFIG_HAVE_IOREMAP_PROT=y
+CONFIG_HAVE_KPROBES=y
+CONFIG_HAVE_KRETPROBES=y
+CONFIG_HAVE_OPTPROBES=y
+CONFIG_HAVE_KPROBES_ON_FTRACE=y
+CONFIG_HAVE_NMI=y
+CONFIG_HAVE_ARCH_TRACEHOOK=y
+CONFIG_HAVE_DMA_CONTIGUOUS=y
+CONFIG_GENERIC_SMP_IDLE_THREAD=y
+CONFIG_ARCH_WANTS_DYNAMIC_TASK_STRUCT=y
+CONFIG_HAVE_REGS_AND_STACK_ACCESS_API=y
+CONFIG_HAVE_CLK=y
+CONFIG_HAVE_DMA_API_DEBUG=y
+CONFIG_HAVE_HW_BREAKPOINT=y
+CONFIG_HAVE_MIXED_BREAKPOINTS_REGS=y
+CONFIG_HAVE_USER_RETURN_NOTIFIER=y
+CONFIG_HAVE_PERF_EVENTS_NMI=y
+CONFIG_HAVE_PERF_REGS=y
+CONFIG_HAVE_PERF_USER_STACK_DUMP=y
+CONFIG_HAVE_ARCH_JUMP_LABEL=y
+CONFIG_ARCH_HAVE_NMI_SAFE_CMPXCHG=y
+CONFIG_HAVE_ALIGNED_STRUCT_PAGE=y
+CONFIG_HAVE_CMPXCHG_LOCAL=y
+CONFIG_HAVE_CMPXCHG_DOUBLE=y
+CONFIG_HAVE_ARCH_SECCOMP_FILTER=y
+CONFIG_SECCOMP_FILTER=y
+CONFIG_HAVE_GCC_PLUGINS=y
+# CONFIG_GCC_PLUGINS is not set
+CONFIG_HAVE_CC_STACKPROTECTOR=y
+CONFIG_CC_STACKPROTECTOR=y
+# CONFIG_CC_STACKPROTECTOR_NONE is not set
+CONFIG_CC_STACKPROTECTOR_REGULAR=y
+# CONFIG_CC_STACKPROTECTOR_STRONG is not set
+CONFIG_HAVE_ARCH_WITHIN_STACK_FRAMES=y
+CONFIG_HAVE_CONTEXT_TRACKING=y
+CONFIG_HAVE_VIRT_CPU_ACCOUNTING_GEN=y
+CONFIG_HAVE_IRQ_TIME_ACCOUNTING=y
+CONFIG_HAVE_ARCH_TRANSPARENT_HUGEPAGE=y
+CONFIG_HAVE_ARCH_HUGE_VMAP=y
+CONFIG_HAVE_ARCH_SOFT_DIRTY=y
+CONFIG_MODULES_USE_ELF_RELA=y
+CONFIG_HAVE_IRQ_EXIT_ON_IRQ_STACK=y
+CONFIG_ARCH_HAS_ELF_RANDOMIZE=y
+CONFIG_HAVE_ARCH_MMAP_RND_BITS=y
+CONFIG_HAVE_EXIT_THREAD=y
+CONFIG_ARCH_MMAP_RND_BITS=28
+CONFIG_HAVE_COPY_THREAD_TLS=y
+CONFIG_HAVE_STACK_VALIDATION=y
+# CONFIG_HAVE_ARCH_HASH is not set
+# CONFIG_ISA_BUS_API is not set
+# CONFIG_CPU_NO_EFFICIENT_FFS is not set
+CONFIG_HAVE_ARCH_VMAP_STACK=y
+# CONFIG_VMAP_STACK is not set
+
+#
+# GCOV-based kernel profiling
+#
+# CONFIG_GCOV_KERNEL is not set
+CONFIG_ARCH_HAS_GCOV_PROFILE_ALL=y
+# CONFIG_HAVE_GENERIC_DMA_COHERENT is not set
+CONFIG_SLABINFO=y
+CONFIG_RT_MUTEXES=y
+CONFIG_BASE_SMALL=0
+CONFIG_MODULES=y
+CONFIG_MODULE_FORCE_LOAD=y
+CONFIG_MODULE_UNLOAD=y
+CONFIG_MODULE_FORCE_UNLOAD=y
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+# CONFIG_MODULE_SIG is not set
+# CONFIG_MODULE_COMPRESS is not set
+CONFIG_MODULES_TREE_LOOKUP=y
+CONFIG_BLOCK=y
+CONFIG_BLK_DEV_BSG=y
+CONFIG_BLK_DEV_BSGLIB=y
+CONFIG_BLK_DEV_INTEGRITY=y
+CONFIG_BLK_CMDLINE_PARSER=y
+
+#
+# Partition Types
+#
+CONFIG_PARTITION_ADVANCED=y
+# CONFIG_ACORN_PARTITION is not set
+# CONFIG_AIX_PARTITION is not set
+# CONFIG_OSF_PARTITION is not set
+# CONFIG_AMIGA_PARTITION is not set
+CONFIG_ATARI_PARTITION=y
+# CONFIG_MAC_PARTITION is not set
+CONFIG_MSDOS_PARTITION=y
+# CONFIG_BSD_DISKLABEL is not set
+# CONFIG_MINIX_SUBPARTITION is not set
+# CONFIG_SOLARIS_X86_PARTITION is not set
+# CONFIG_UNIXWARE_DISKLABEL is not set
+# CONFIG_LDM_PARTITION is not set
+# CONFIG_SGI_PARTITION is not set
+# CONFIG_ULTRIX_PARTITION is not set
+# CONFIG_SUN_PARTITION is not set
+# CONFIG_KARMA_PARTITION is not set
+# CONFIG_EFI_PARTITION is not set
+# CONFIG_SYSV68_PARTITION is not set
+# CONFIG_CMDLINE_PARTITION is not set
+CONFIG_BLK_MQ_PCI=y
+
+#
+# IO Schedulers
+#
+CONFIG_IOSCHED_NOOP=y
+CONFIG_IOSCHED_DEADLINE=y
+CONFIG_IOSCHED_CFQ=y
+# CONFIG_DEFAULT_DEADLINE is not set
+CONFIG_DEFAULT_CFQ=y
+# CONFIG_DEFAULT_NOOP is not set
+CONFIG_DEFAULT_IOSCHED="cfq"
+CONFIG_INLINE_SPIN_UNLOCK_IRQ=y
+CONFIG_INLINE_READ_UNLOCK=y
+CONFIG_INLINE_READ_UNLOCK_IRQ=y
+CONFIG_INLINE_WRITE_UNLOCK=y
+CONFIG_INLINE_WRITE_UNLOCK_IRQ=y
+CONFIG_ARCH_SUPPORTS_ATOMIC_RMW=y
+CONFIG_MUTEX_SPIN_ON_OWNER=y
+CONFIG_RWSEM_SPIN_ON_OWNER=y
+CONFIG_LOCK_SPIN_ON_OWNER=y
+CONFIG_ARCH_USE_QUEUED_SPINLOCKS=y
+CONFIG_QUEUED_SPINLOCKS=y
+CONFIG_ARCH_USE_QUEUED_RWLOCKS=y
+CONFIG_QUEUED_RWLOCKS=y
+# CONFIG_FREEZER is not set
+
+#
+# Processor type and features
+#
+CONFIG_ZONE_DMA=y
+CONFIG_SMP=y
+CONFIG_X86_FEATURE_NAMES=y
+CONFIG_X86_FAST_FEATURE_TESTS=y
+CONFIG_X86_MPPARSE=y
+# CONFIG_GOLDFISH is not set
+# CONFIG_X86_EXTENDED_PLATFORM is not set
+CONFIG_X86_INTEL_LPSS=y
+# CONFIG_X86_AMD_PLATFORM_DEVICE is not set
+CONFIG_IOSF_MBI=y
+# CONFIG_IOSF_MBI_DEBUG is not set
+CONFIG_X86_SUPPORTS_MEMORY_FAILURE=y
+CONFIG_SCHED_OMIT_FRAME_POINTER=y
+# CONFIG_HYPERVISOR_GUEST is not set
+CONFIG_NO_BOOTMEM=y
+# CONFIG_MK8 is not set
+# CONFIG_MPSC is not set
+# CONFIG_MCORE2 is not set
+CONFIG_MATOM=y
+# CONFIG_GENERIC_CPU is not set
+CONFIG_X86_INTERNODE_CACHE_SHIFT=6
+CONFIG_X86_L1_CACHE_SHIFT=6
+CONFIG_X86_USE_PPRO_CHECKSUM=y
+CONFIG_X86_TSC=y
+CONFIG_X86_CMPXCHG64=y
+CONFIG_X86_CMOV=y
+CONFIG_X86_MINIMUM_CPU_FAMILY=64
+CONFIG_X86_DEBUGCTLMSR=y
+# CONFIG_PROCESSOR_SELECT is not set
+CONFIG_CPU_SUP_INTEL=y
+CONFIG_CPU_SUP_AMD=y
+CONFIG_CPU_SUP_CENTAUR=y
+CONFIG_HPET_TIMER=y
+CONFIG_DMI=y
+CONFIG_GART_IOMMU=y
+# CONFIG_CALGARY_IOMMU is not set
+CONFIG_SWIOTLB=y
+CONFIG_IOMMU_HELPER=y
+# CONFIG_MAXSMP is not set
+CONFIG_NR_CPUS=2
+CONFIG_SCHED_SMT=y
+CONFIG_SCHED_MC=y
+# CONFIG_PREEMPT_NONE is not set
+CONFIG_PREEMPT_VOLUNTARY=y
+# CONFIG_PREEMPT is not set
+CONFIG_X86_LOCAL_APIC=y
+CONFIG_X86_IO_APIC=y
+CONFIG_X86_REROUTE_FOR_BROKEN_BOOT_IRQS=y
+CONFIG_X86_MCE=y
+CONFIG_X86_MCE_INTEL=y
+# CONFIG_X86_MCE_AMD is not set
+CONFIG_X86_MCE_THRESHOLD=y
+# CONFIG_X86_MCE_INJECT is not set
+CONFIG_X86_THERMAL_VECTOR=y
+
+#
+# Performance monitoring
+#
+CONFIG_PERF_EVENTS_INTEL_UNCORE=y
+CONFIG_PERF_EVENTS_INTEL_RAPL=y
+CONFIG_PERF_EVENTS_INTEL_CSTATE=y
+# CONFIG_PERF_EVENTS_AMD_POWER is not set
+# CONFIG_VM86 is not set
+# CONFIG_X86_VSYSCALL_EMULATION is not set
+# CONFIG_I8K is not set
+CONFIG_MICROCODE=y
+CONFIG_MICROCODE_INTEL=y
+# CONFIG_MICROCODE_AMD is not set
+CONFIG_MICROCODE_OLD_INTERFACE=y
+CONFIG_X86_MSR=y
+CONFIG_X86_CPUID=y
+CONFIG_ARCH_PHYS_ADDR_T_64BIT=y
+CONFIG_ARCH_DMA_ADDR_T_64BIT=y
+CONFIG_X86_DIRECT_GBPAGES=y
+# CONFIG_NUMA is not set
+CONFIG_ARCH_SPARSEMEM_ENABLE=y
+CONFIG_ARCH_SPARSEMEM_DEFAULT=y
+CONFIG_ARCH_SELECT_MEMORY_MODEL=y
+CONFIG_ARCH_MEMORY_PROBE=y
+CONFIG_ARCH_PROC_KCORE_TEXT=y
+CONFIG_ILLEGAL_POINTER_VALUE=0xdead000000000000
+CONFIG_SELECT_MEMORY_MODEL=y
+CONFIG_SPARSEMEM_MANUAL=y
+CONFIG_SPARSEMEM=y
+CONFIG_HAVE_MEMORY_PRESENT=y
+CONFIG_SPARSEMEM_EXTREME=y
+CONFIG_SPARSEMEM_VMEMMAP_ENABLE=y
+CONFIG_SPARSEMEM_ALLOC_MEM_MAP_TOGETHER=y
+CONFIG_SPARSEMEM_VMEMMAP=y
+CONFIG_HAVE_MEMBLOCK=y
+CONFIG_HAVE_MEMBLOCK_NODE_MAP=y
+CONFIG_ARCH_DISCARD_MEMBLOCK=y
+CONFIG_MEMORY_ISOLATION=y
+CONFIG_HAVE_BOOTMEM_INFO_NODE=y
+CONFIG_MEMORY_HOTPLUG=y
+CONFIG_MEMORY_HOTPLUG_SPARSE=y
+# CONFIG_MEMORY_HOTPLUG_DEFAULT_ONLINE is not set
+CONFIG_MEMORY_HOTREMOVE=y
+CONFIG_SPLIT_PTLOCK_CPUS=4
+CONFIG_ARCH_ENABLE_SPLIT_PMD_PTLOCK=y
+CONFIG_MEMORY_BALLOON=y
+# CONFIG_BALLOON_COMPACTION is not set
+CONFIG_COMPACTION=y
+CONFIG_MIGRATION=y
+CONFIG_PHYS_ADDR_T_64BIT=y
+# CONFIG_BOUNCE is not set
+CONFIG_VIRT_TO_BUS=y
+CONFIG_MMU_NOTIFIER=y
+# CONFIG_KSM is not set
+CONFIG_DEFAULT_MMAP_MIN_ADDR=98304
+CONFIG_ARCH_SUPPORTS_MEMORY_FAILURE=y
+# CONFIG_MEMORY_FAILURE is not set
+CONFIG_TRANSPARENT_HUGEPAGE=y
+CONFIG_TRANSPARENT_HUGEPAGE_ALWAYS=y
+# CONFIG_TRANSPARENT_HUGEPAGE_MADVISE is not set
+CONFIG_TRANSPARENT_HUGE_PAGECACHE=y
+# CONFIG_CLEANCACHE is not set
+# CONFIG_FRONTSWAP is not set
+# CONFIG_CMA is not set
+CONFIG_ZPOOL=m
+# CONFIG_ZBUD is not set
+# CONFIG_Z3FOLD is not set
+CONFIG_ZSMALLOC=m
+# CONFIG_PGTABLE_MAPPING is not set
+# CONFIG_ZSMALLOC_STAT is not set
+CONFIG_GENERIC_EARLY_IOREMAP=y
+CONFIG_ARCH_SUPPORTS_DEFERRED_STRUCT_PAGE_INIT=y
+# CONFIG_DEFERRED_STRUCT_PAGE_INIT is not set
+# CONFIG_IDLE_PAGE_TRACKING is not set
+# CONFIG_ZONE_DEVICE is not set
+CONFIG_ARCH_USES_HIGH_VMA_FLAGS=y
+CONFIG_ARCH_HAS_PKEYS=y
+CONFIG_X86_PMEM_LEGACY_DEVICE=y
+CONFIG_X86_PMEM_LEGACY=y
+# CONFIG_X86_CHECK_BIOS_CORRUPTION is not set
+CONFIG_X86_RESERVE_LOW=64
+CONFIG_MTRR=y
+CONFIG_MTRR_SANITIZER=y
+CONFIG_MTRR_SANITIZER_ENABLE_DEFAULT=0
+CONFIG_MTRR_SANITIZER_SPARE_REG_NR_DEFAULT=1
+CONFIG_X86_PAT=y
+CONFIG_ARCH_USES_PG_UNCACHED=y
+CONFIG_ARCH_RANDOM=y
+CONFIG_X86_SMAP=y
+# CONFIG_X86_INTEL_MPX is not set
+CONFIG_X86_INTEL_MEMORY_PROTECTION_KEYS=y
+# CONFIG_EFI is not set
+CONFIG_SECCOMP=y
+# CONFIG_HZ_100 is not set
+# CONFIG_HZ_250 is not set
+# CONFIG_HZ_300 is not set
+CONFIG_HZ_1000=y
+CONFIG_HZ=1000
+CONFIG_SCHED_HRTICK=y
+# CONFIG_KEXEC is not set
+CONFIG_KEXEC_FILE=y
+# CONFIG_KEXEC_VERIFY_SIG is not set
+# CONFIG_CRASH_DUMP is not set
+CONFIG_PHYSICAL_START=0x1000000
+CONFIG_RELOCATABLE=y
+CONFIG_RANDOMIZE_BASE=y
+CONFIG_X86_NEED_RELOCS=y
+CONFIG_PHYSICAL_ALIGN=0x1000000
+CONFIG_RANDOMIZE_MEMORY=y
+CONFIG_RANDOMIZE_MEMORY_PHYSICAL_PADDING=0xa
+CONFIG_HOTPLUG_CPU=y
+# CONFIG_BOOTPARAM_HOTPLUG_CPU0 is not set
+# CONFIG_DEBUG_HOTPLUG_CPU0 is not set
+# CONFIG_LEGACY_VSYSCALL_NATIVE is not set
+CONFIG_LEGACY_VSYSCALL_EMULATE=y
+# CONFIG_LEGACY_VSYSCALL_NONE is not set
+# CONFIG_CMDLINE_BOOL is not set
+# CONFIG_MODIFY_LDT_SYSCALL is not set
+CONFIG_HAVE_LIVEPATCH=y
+# CONFIG_LIVEPATCH is not set
+CONFIG_ARCH_ENABLE_MEMORY_HOTPLUG=y
+CONFIG_ARCH_ENABLE_MEMORY_HOTREMOVE=y
+
+#
+# Power management and ACPI options
+#
+# CONFIG_SUSPEND is not set
+# CONFIG_HIBERNATION is not set
+CONFIG_PM=y
+# CONFIG_PM_DEBUG is not set
+CONFIG_PM_CLK=y
+# CONFIG_WQ_POWER_EFFICIENT_DEFAULT is not set
+CONFIG_ACPI=y
+CONFIG_ACPI_LEGACY_TABLES_LOOKUP=y
+CONFIG_ARCH_MIGHT_HAVE_ACPI_PDC=y
+CONFIG_ACPI_SYSTEM_POWER_STATES_SUPPORT=y
+# CONFIG_ACPI_DEBUGGER is not set
+CONFIG_ACPI_PROCFS_POWER=y
+CONFIG_ACPI_REV_OVERRIDE_POSSIBLE=y
+CONFIG_ACPI_EC_DEBUGFS=m
+CONFIG_ACPI_AC=m
+CONFIG_ACPI_BATTERY=m
+CONFIG_ACPI_BUTTON=m
+CONFIG_ACPI_VIDEO=m
+CONFIG_ACPI_FAN=m
+CONFIG_ACPI_DOCK=y
+CONFIG_ACPI_CPU_FREQ_PSS=y
+CONFIG_ACPI_PROCESSOR_CSTATE=y
+CONFIG_ACPI_PROCESSOR_IDLE=y
+CONFIG_ACPI_PROCESSOR=y
+CONFIG_ACPI_HOTPLUG_CPU=y
+CONFIG_ACPI_PROCESSOR_AGGREGATOR=m
+CONFIG_ACPI_THERMAL=m
+# CONFIG_ACPI_CUSTOM_DSDT is not set
+CONFIG_ARCH_HAS_ACPI_TABLE_UPGRADE=y
+# CONFIG_ACPI_DEBUG is not set
+CONFIG_ACPI_PCI_SLOT=y
+CONFIG_X86_PM_TIMER=y
+CONFIG_ACPI_CONTAINER=y
+CONFIG_ACPI_HOTPLUG_MEMORY=y
+CONFIG_ACPI_HOTPLUG_IOAPIC=y
+CONFIG_ACPI_SBS=m
+CONFIG_ACPI_HED=y
+# CONFIG_ACPI_CUSTOM_METHOD is not set
+# CONFIG_ACPI_REDUCED_HARDWARE_ONLY is not set
+CONFIG_ACPI_NFIT=m
+CONFIG_HAVE_ACPI_APEI=y
+CONFIG_HAVE_ACPI_APEI_NMI=y
+CONFIG_ACPI_APEI=y
+CONFIG_ACPI_APEI_GHES=y
+CONFIG_ACPI_APEI_PCIEAER=y
+CONFIG_ACPI_APEI_EINJ=m
+CONFIG_ACPI_APEI_ERST_DEBUG=m
+# CONFIG_DPTF_POWER is not set
+CONFIG_ACPI_EXTLOG=m
+CONFIG_PMIC_OPREGION=y
+# CONFIG_ACPI_CONFIGFS is not set
+# CONFIG_SFI is not set
+
+#
+# CPU Frequency scaling
+#
+CONFIG_CPU_FREQ=y
+CONFIG_CPU_FREQ_GOV_ATTR_SET=y
+CONFIG_CPU_FREQ_GOV_COMMON=y
+# CONFIG_CPU_FREQ_STAT is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_PERFORMANCE is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_POWERSAVE is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_USERSPACE is not set
+CONFIG_CPU_FREQ_DEFAULT_GOV_ONDEMAND=y
+# CONFIG_CPU_FREQ_DEFAULT_GOV_CONSERVATIVE is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_SCHEDUTIL is not set
+CONFIG_CPU_FREQ_GOV_PERFORMANCE=y
+CONFIG_CPU_FREQ_GOV_POWERSAVE=y
+CONFIG_CPU_FREQ_GOV_USERSPACE=y
+CONFIG_CPU_FREQ_GOV_ONDEMAND=y
+CONFIG_CPU_FREQ_GOV_CONSERVATIVE=y
+# CONFIG_CPU_FREQ_GOV_SCHEDUTIL is not set
+
+#
+# CPU frequency scaling drivers
+#
+CONFIG_X86_INTEL_PSTATE=y
+CONFIG_X86_PCC_CPUFREQ=m
+CONFIG_X86_ACPI_CPUFREQ=m
+CONFIG_X86_ACPI_CPUFREQ_CPB=y
+CONFIG_X86_POWERNOW_K8=m
+CONFIG_X86_AMD_FREQ_SENSITIVITY=m
+CONFIG_X86_SPEEDSTEP_CENTRINO=m
+CONFIG_X86_P4_CLOCKMOD=m
+
+#
+# shared options
+#
+CONFIG_X86_SPEEDSTEP_LIB=m
+
+#
+# CPU Idle
+#
+CONFIG_CPU_IDLE=y
+CONFIG_CPU_IDLE_GOV_LADDER=y
+CONFIG_CPU_IDLE_GOV_MENU=y
+# CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED is not set
+CONFIG_INTEL_IDLE=y
+
+#
+# Memory power savings
+#
+CONFIG_I7300_IDLE_IOAT_CHANNEL=y
+CONFIG_I7300_IDLE=y
+
+#
+# Bus options (PCI etc.)
+#
+CONFIG_PCI=y
+CONFIG_PCI_DIRECT=y
+CONFIG_PCI_MMCONFIG=y
+CONFIG_PCI_DOMAINS=y
+# CONFIG_PCI_CNB20LE_QUIRK is not set
+CONFIG_PCIEPORTBUS=y
+CONFIG_HOTPLUG_PCI_PCIE=y
+CONFIG_PCIEAER=y
+# CONFIG_PCIE_ECRC is not set
+CONFIG_PCIEAER_INJECT=m
+CONFIG_PCIEASPM=y
+# CONFIG_PCIEASPM_DEBUG is not set
+CONFIG_PCIEASPM_DEFAULT=y
+# CONFIG_PCIEASPM_POWERSAVE is not set
+# CONFIG_PCIEASPM_PERFORMANCE is not set
+CONFIG_PCIE_PME=y
+# CONFIG_PCIE_DPC is not set
+# CONFIG_PCIE_PTM is not set
+CONFIG_PCI_BUS_ADDR_T_64BIT=y
+CONFIG_PCI_MSI=y
+CONFIG_PCI_MSI_IRQ_DOMAIN=y
+# CONFIG_PCI_DEBUG is not set
+# CONFIG_PCI_REALLOC_ENABLE_AUTO is not set
+CONFIG_PCI_STUB=m
+CONFIG_HT_IRQ=y
+CONFIG_PCI_ATS=y
+CONFIG_PCI_IOV=y
+CONFIG_PCI_PRI=y
+CONFIG_PCI_PASID=y
+CONFIG_PCI_LABEL=y
+CONFIG_HOTPLUG_PCI=y
+CONFIG_HOTPLUG_PCI_ACPI=y
+CONFIG_HOTPLUG_PCI_ACPI_IBM=m
+# CONFIG_HOTPLUG_PCI_CPCI is not set
+CONFIG_HOTPLUG_PCI_SHPC=m
+
+#
+# PCI host controller drivers
+#
+# CONFIG_PCIE_DW_PLAT is not set
+# CONFIG_VMD is not set
+# CONFIG_ISA_BUS is not set
+CONFIG_ISA_DMA_API=y
+CONFIG_AMD_NB=y
+CONFIG_PCCARD=m
+CONFIG_PCMCIA=m
+CONFIG_PCMCIA_LOAD_CIS=y
+CONFIG_CARDBUS=y
+
+#
+# PC-card bridges
+#
+CONFIG_YENTA=m
+CONFIG_YENTA_O2=y
+CONFIG_YENTA_RICOH=y
+CONFIG_YENTA_TI=y
+CONFIG_YENTA_ENE_TUNE=y
+CONFIG_YENTA_TOSHIBA=y
+CONFIG_PD6729=m
+CONFIG_I82092=m
+CONFIG_PCCARD_NONSTATIC=y
+# CONFIG_RAPIDIO is not set
+# CONFIG_X86_SYSFB is not set
+
+#
+# Executable file formats / Emulations
+#
+CONFIG_BINFMT_ELF=y
+CONFIG_ELFCORE=y
+# CONFIG_CORE_DUMP_DEFAULT_ELF_HEADERS is not set
+CONFIG_BINFMT_SCRIPT=y
+# CONFIG_HAVE_AOUT is not set
+# CONFIG_BINFMT_MISC is not set
+CONFIG_COREDUMP=y
+# CONFIG_IA32_EMULATION is not set
+# CONFIG_X86_X32 is not set
+CONFIG_X86_DEV_DMA_OPS=y
+CONFIG_PMC_ATOM=y
+CONFIG_NET=y
+CONFIG_NET_INGRESS=y
+CONFIG_NET_EGRESS=y
+
+#
+# Networking options
+#
+CONFIG_PACKET=y
+CONFIG_PACKET_DIAG=m
+CONFIG_UNIX=y
+CONFIG_UNIX_DIAG=m
+CONFIG_XFRM=y
+CONFIG_XFRM_ALGO=y
+CONFIG_XFRM_USER=y
+# CONFIG_XFRM_SUB_POLICY is not set
+# CONFIG_XFRM_MIGRATE is not set
+# CONFIG_XFRM_STATISTICS is not set
+CONFIG_XFRM_IPCOMP=m
+CONFIG_NET_KEY=m
+# CONFIG_NET_KEY_MIGRATE is not set
+CONFIG_INET=y
+CONFIG_IP_MULTICAST=y
+CONFIG_IP_ADVANCED_ROUTER=y
+# CONFIG_IP_FIB_TRIE_STATS is not set
+CONFIG_IP_MULTIPLE_TABLES=y
+CONFIG_IP_ROUTE_MULTIPATH=y
+CONFIG_IP_ROUTE_VERBOSE=y
+CONFIG_IP_ROUTE_CLASSID=y
+# CONFIG_IP_PNP is not set
+CONFIG_NET_IPIP=m
+CONFIG_NET_IPGRE_DEMUX=m
+CONFIG_NET_IP_TUNNEL=m
+CONFIG_NET_IPGRE=m
+CONFIG_NET_IPGRE_BROADCAST=y
+CONFIG_IP_MROUTE=y
+CONFIG_IP_MROUTE_MULTIPLE_TABLES=y
+CONFIG_IP_PIMSM_V1=y
+CONFIG_IP_PIMSM_V2=y
+CONFIG_SYN_COOKIES=y
+CONFIG_NET_IPVTI=m
+CONFIG_NET_UDP_TUNNEL=m
+CONFIG_NET_FOU=m
+CONFIG_NET_FOU_IP_TUNNELS=y
+CONFIG_INET_AH=m
+CONFIG_INET_ESP=m
+CONFIG_INET_IPCOMP=m
+CONFIG_INET_XFRM_TUNNEL=m
+CONFIG_INET_TUNNEL=m
+CONFIG_INET_XFRM_MODE_TRANSPORT=m
+CONFIG_INET_XFRM_MODE_TUNNEL=m
+CONFIG_INET_XFRM_MODE_BEET=m
+CONFIG_INET_DIAG=m
+CONFIG_INET_TCP_DIAG=m
+CONFIG_INET_UDP_DIAG=m
+# CONFIG_INET_DIAG_DESTROY is not set
+# CONFIG_TCP_CONG_ADVANCED is not set
+CONFIG_TCP_CONG_CUBIC=y
+CONFIG_DEFAULT_TCP_CONG="cubic"
+# CONFIG_TCP_MD5SIG is not set
+CONFIG_IPV6=m
+CONFIG_IPV6_ROUTER_PREF=y
+CONFIG_IPV6_ROUTE_INFO=y
+CONFIG_IPV6_OPTIMISTIC_DAD=y
+CONFIG_INET6_AH=m
+CONFIG_INET6_ESP=m
+CONFIG_INET6_IPCOMP=m
+CONFIG_IPV6_MIP6=m
+CONFIG_IPV6_ILA=m
+CONFIG_INET6_XFRM_TUNNEL=m
+CONFIG_INET6_TUNNEL=m
+CONFIG_INET6_XFRM_MODE_TRANSPORT=m
+CONFIG_INET6_XFRM_MODE_TUNNEL=m
+CONFIG_INET6_XFRM_MODE_BEET=m
+CONFIG_INET6_XFRM_MODE_ROUTEOPTIMIZATION=m
+CONFIG_IPV6_VTI=m
+CONFIG_IPV6_SIT=m
+# CONFIG_IPV6_SIT_6RD is not set
+CONFIG_IPV6_NDISC_NODETYPE=y
+CONFIG_IPV6_TUNNEL=m
+CONFIG_IPV6_GRE=m
+CONFIG_IPV6_FOU=m
+CONFIG_IPV6_FOU_TUNNEL=m
+CONFIG_IPV6_MULTIPLE_TABLES=y
+CONFIG_IPV6_SUBTREES=y
+# CONFIG_IPV6_MROUTE is not set
+# CONFIG_NETLABEL is not set
+# CONFIG_NETWORK_SECMARK is not set
+CONFIG_NET_PTP_CLASSIFY=y
+# CONFIG_NETWORK_PHY_TIMESTAMPING is not set
+CONFIG_NETFILTER=y
+# CONFIG_NETFILTER_DEBUG is not set
+CONFIG_NETFILTER_ADVANCED=y
+CONFIG_BRIDGE_NETFILTER=m
+
+#
+# Core Netfilter Configuration
+#
+CONFIG_NETFILTER_INGRESS=y
+CONFIG_NETFILTER_NETLINK=m
+CONFIG_NETFILTER_NETLINK_ACCT=m
+CONFIG_NETFILTER_NETLINK_QUEUE=m
+CONFIG_NETFILTER_NETLINK_LOG=m
+CONFIG_NF_CONNTRACK=m
+CONFIG_NF_LOG_COMMON=m
+CONFIG_NF_CONNTRACK_MARK=y
+CONFIG_NF_CONNTRACK_ZONES=y
+# CONFIG_NF_CONNTRACK_PROCFS is not set
+# CONFIG_NF_CONNTRACK_EVENTS is not set
+# CONFIG_NF_CONNTRACK_TIMEOUT is not set
+# CONFIG_NF_CONNTRACK_TIMESTAMP is not set
+CONFIG_NF_CONNTRACK_LABELS=y
+CONFIG_NF_CT_PROTO_DCCP=m
+CONFIG_NF_CT_PROTO_GRE=m
+CONFIG_NF_CT_PROTO_SCTP=m
+CONFIG_NF_CT_PROTO_UDPLITE=m
+CONFIG_NF_CONNTRACK_AMANDA=m
+CONFIG_NF_CONNTRACK_FTP=m
+CONFIG_NF_CONNTRACK_H323=m
+CONFIG_NF_CONNTRACK_IRC=m
+CONFIG_NF_CONNTRACK_BROADCAST=m
+CONFIG_NF_CONNTRACK_NETBIOS_NS=m
+CONFIG_NF_CONNTRACK_SNMP=m
+CONFIG_NF_CONNTRACK_PPTP=m
+CONFIG_NF_CONNTRACK_SANE=m
+CONFIG_NF_CONNTRACK_SIP=m
+CONFIG_NF_CONNTRACK_TFTP=m
+CONFIG_NF_CT_NETLINK=m
+CONFIG_NF_CT_NETLINK_TIMEOUT=m
+# CONFIG_NETFILTER_NETLINK_GLUE_CT is not set
+CONFIG_NF_NAT=m
+CONFIG_NF_NAT_NEEDED=y
+CONFIG_NF_NAT_PROTO_DCCP=m
+CONFIG_NF_NAT_PROTO_UDPLITE=m
+CONFIG_NF_NAT_PROTO_SCTP=m
+CONFIG_NF_NAT_AMANDA=m
+CONFIG_NF_NAT_FTP=m
+CONFIG_NF_NAT_IRC=m
+CONFIG_NF_NAT_SIP=m
+CONFIG_NF_NAT_TFTP=m
+CONFIG_NF_NAT_REDIRECT=m
+CONFIG_NETFILTER_SYNPROXY=m
+CONFIG_NF_TABLES=m
+CONFIG_NF_TABLES_INET=m
+CONFIG_NF_TABLES_NETDEV=m
+CONFIG_NFT_EXTHDR=m
+CONFIG_NFT_META=m
+# CONFIG_NFT_NUMGEN is not set
+CONFIG_NFT_CT=m
+# CONFIG_NFT_SET_RBTREE is not set
+# CONFIG_NFT_SET_HASH is not set
+CONFIG_NFT_COUNTER=m
+CONFIG_NFT_LOG=m
+CONFIG_NFT_LIMIT=m
+CONFIG_NFT_MASQ=m
+CONFIG_NFT_REDIR=m
+CONFIG_NFT_NAT=m
+CONFIG_NFT_QUEUE=m
+# CONFIG_NFT_QUOTA is not set
+CONFIG_NFT_REJECT=m
+CONFIG_NFT_REJECT_INET=m
+CONFIG_NFT_COMPAT=m
+CONFIG_NFT_HASH=m
+# CONFIG_NF_DUP_NETDEV is not set
+# CONFIG_NFT_DUP_NETDEV is not set
+# CONFIG_NFT_FWD_NETDEV is not set
+CONFIG_NETFILTER_XTABLES=m
+
+#
+# Xtables combined modules
+#
+CONFIG_NETFILTER_XT_MARK=m
+CONFIG_NETFILTER_XT_CONNMARK=m
+CONFIG_NETFILTER_XT_SET=m
+
+#
+# Xtables targets
+#
+CONFIG_NETFILTER_XT_TARGET_CHECKSUM=m
+CONFIG_NETFILTER_XT_TARGET_CLASSIFY=m
+CONFIG_NETFILTER_XT_TARGET_CONNMARK=m
+CONFIG_NETFILTER_XT_TARGET_CT=m
+CONFIG_NETFILTER_XT_TARGET_DSCP=m
+CONFIG_NETFILTER_XT_TARGET_HL=m
+CONFIG_NETFILTER_XT_TARGET_HMARK=m
+CONFIG_NETFILTER_XT_TARGET_IDLETIMER=m
+CONFIG_NETFILTER_XT_TARGET_LED=m
+CONFIG_NETFILTER_XT_TARGET_LOG=m
+CONFIG_NETFILTER_XT_TARGET_MARK=m
+CONFIG_NETFILTER_XT_NAT=m
+CONFIG_NETFILTER_XT_TARGET_NETMAP=m
+CONFIG_NETFILTER_XT_TARGET_NFLOG=m
+CONFIG_NETFILTER_XT_TARGET_NFQUEUE=m
+CONFIG_NETFILTER_XT_TARGET_NOTRACK=m
+CONFIG_NETFILTER_XT_TARGET_RATEEST=m
+CONFIG_NETFILTER_XT_TARGET_REDIRECT=m
+CONFIG_NETFILTER_XT_TARGET_TEE=m
+CONFIG_NETFILTER_XT_TARGET_TPROXY=m
+CONFIG_NETFILTER_XT_TARGET_TRACE=m
+CONFIG_NETFILTER_XT_TARGET_TCPMSS=m
+CONFIG_NETFILTER_XT_TARGET_TCPOPTSTRIP=m
+
+#
+# Xtables matches
+#
+CONFIG_NETFILTER_XT_MATCH_ADDRTYPE=m
+CONFIG_NETFILTER_XT_MATCH_BPF=m
+CONFIG_NETFILTER_XT_MATCH_CLUSTER=m
+CONFIG_NETFILTER_XT_MATCH_COMMENT=m
+CONFIG_NETFILTER_XT_MATCH_CONNBYTES=m
+CONFIG_NETFILTER_XT_MATCH_CONNLABEL=m
+CONFIG_NETFILTER_XT_MATCH_CONNLIMIT=m
+CONFIG_NETFILTER_XT_MATCH_CONNMARK=m
+CONFIG_NETFILTER_XT_MATCH_CONNTRACK=m
+CONFIG_NETFILTER_XT_MATCH_CPU=m
+CONFIG_NETFILTER_XT_MATCH_DCCP=m
+CONFIG_NETFILTER_XT_MATCH_DEVGROUP=m
+CONFIG_NETFILTER_XT_MATCH_DSCP=m
+CONFIG_NETFILTER_XT_MATCH_ECN=m
+CONFIG_NETFILTER_XT_MATCH_ESP=m
+CONFIG_NETFILTER_XT_MATCH_HASHLIMIT=m
+CONFIG_NETFILTER_XT_MATCH_HELPER=m
+CONFIG_NETFILTER_XT_MATCH_HL=m
+CONFIG_NETFILTER_XT_MATCH_IPCOMP=m
+CONFIG_NETFILTER_XT_MATCH_IPRANGE=m
+CONFIG_NETFILTER_XT_MATCH_IPVS=m
+CONFIG_NETFILTER_XT_MATCH_L2TP=m
+CONFIG_NETFILTER_XT_MATCH_LENGTH=m
+CONFIG_NETFILTER_XT_MATCH_LIMIT=m
+CONFIG_NETFILTER_XT_MATCH_MAC=m
+CONFIG_NETFILTER_XT_MATCH_MARK=m
+CONFIG_NETFILTER_XT_MATCH_MULTIPORT=m
+CONFIG_NETFILTER_XT_MATCH_NFACCT=m
+CONFIG_NETFILTER_XT_MATCH_OSF=m
+CONFIG_NETFILTER_XT_MATCH_OWNER=m
+CONFIG_NETFILTER_XT_MATCH_POLICY=m
+CONFIG_NETFILTER_XT_MATCH_PHYSDEV=m
+CONFIG_NETFILTER_XT_MATCH_PKTTYPE=m
+CONFIG_NETFILTER_XT_MATCH_QUOTA=m
+CONFIG_NETFILTER_XT_MATCH_RATEEST=m
+CONFIG_NETFILTER_XT_MATCH_REALM=m
+CONFIG_NETFILTER_XT_MATCH_RECENT=m
+CONFIG_NETFILTER_XT_MATCH_SCTP=m
+CONFIG_NETFILTER_XT_MATCH_SOCKET=m
+CONFIG_NETFILTER_XT_MATCH_STATE=m
+CONFIG_NETFILTER_XT_MATCH_STATISTIC=m
+CONFIG_NETFILTER_XT_MATCH_STRING=m
+CONFIG_NETFILTER_XT_MATCH_TCPMSS=m
+CONFIG_NETFILTER_XT_MATCH_TIME=m
+CONFIG_NETFILTER_XT_MATCH_U32=m
+CONFIG_IP_SET=m
+CONFIG_IP_SET_MAX=256
+CONFIG_IP_SET_BITMAP_IP=m
+CONFIG_IP_SET_BITMAP_IPMAC=m
+CONFIG_IP_SET_BITMAP_PORT=m
+CONFIG_IP_SET_HASH_IP=m
+CONFIG_IP_SET_HASH_IPMARK=m
+CONFIG_IP_SET_HASH_IPPORT=m
+CONFIG_IP_SET_HASH_IPPORTIP=m
+CONFIG_IP_SET_HASH_IPPORTNET=m
+CONFIG_IP_SET_HASH_MAC=m
+CONFIG_IP_SET_HASH_NETPORTNET=m
+CONFIG_IP_SET_HASH_NET=m
+CONFIG_IP_SET_HASH_NETNET=m
+CONFIG_IP_SET_HASH_NETPORT=m
+CONFIG_IP_SET_HASH_NETIFACE=m
+CONFIG_IP_SET_LIST_SET=m
+CONFIG_IP_VS=m
+# CONFIG_IP_VS_IPV6 is not set
+# CONFIG_IP_VS_DEBUG is not set
+CONFIG_IP_VS_TAB_BITS=12
+
+#
+# IPVS transport protocol load balancing support
+#
+CONFIG_IP_VS_PROTO_TCP=y
+CONFIG_IP_VS_PROTO_UDP=y
+CONFIG_IP_VS_PROTO_AH_ESP=y
+CONFIG_IP_VS_PROTO_ESP=y
+CONFIG_IP_VS_PROTO_AH=y
+CONFIG_IP_VS_PROTO_SCTP=y
+
+#
+# IPVS scheduler
+#
+CONFIG_IP_VS_RR=m
+CONFIG_IP_VS_WRR=m
+CONFIG_IP_VS_LC=m
+CONFIG_IP_VS_WLC=m
+CONFIG_IP_VS_FO=m
+CONFIG_IP_VS_OVF=m
+CONFIG_IP_VS_LBLC=m
+CONFIG_IP_VS_LBLCR=m
+CONFIG_IP_VS_DH=m
+CONFIG_IP_VS_SH=m
+CONFIG_IP_VS_SED=m
+CONFIG_IP_VS_NQ=m
+
+#
+# IPVS SH scheduler
+#
+CONFIG_IP_VS_SH_TAB_BITS=8
+
+#
+# IPVS application helper
+#
+CONFIG_IP_VS_FTP=m
+CONFIG_IP_VS_NFCT=y
+CONFIG_IP_VS_PE_SIP=m
+
+#
+# IP: Netfilter Configuration
+#
+CONFIG_NF_DEFRAG_IPV4=m
+CONFIG_NF_CONNTRACK_IPV4=m
+CONFIG_NF_TABLES_IPV4=m
+CONFIG_NFT_CHAIN_ROUTE_IPV4=m
+CONFIG_NFT_REJECT_IPV4=m
+CONFIG_NFT_DUP_IPV4=m
+CONFIG_NF_TABLES_ARP=m
+CONFIG_NF_DUP_IPV4=m
+CONFIG_NF_LOG_ARP=m
+CONFIG_NF_LOG_IPV4=m
+CONFIG_NF_REJECT_IPV4=m
+CONFIG_NF_NAT_IPV4=m
+CONFIG_NFT_CHAIN_NAT_IPV4=m
+CONFIG_NF_NAT_MASQUERADE_IPV4=m
+CONFIG_NFT_MASQ_IPV4=m
+CONFIG_NFT_REDIR_IPV4=m
+CONFIG_NF_NAT_SNMP_BASIC=m
+CONFIG_NF_NAT_PROTO_GRE=m
+CONFIG_NF_NAT_PPTP=m
+CONFIG_NF_NAT_H323=m
+CONFIG_IP_NF_IPTABLES=m
+CONFIG_IP_NF_MATCH_AH=m
+CONFIG_IP_NF_MATCH_ECN=m
+CONFIG_IP_NF_MATCH_RPFILTER=m
+CONFIG_IP_NF_MATCH_TTL=m
+CONFIG_IP_NF_FILTER=m
+CONFIG_IP_NF_TARGET_REJECT=m
+CONFIG_IP_NF_TARGET_SYNPROXY=m
+CONFIG_IP_NF_NAT=m
+CONFIG_IP_NF_TARGET_MASQUERADE=m
+CONFIG_IP_NF_TARGET_NETMAP=m
+CONFIG_IP_NF_TARGET_REDIRECT=m
+CONFIG_IP_NF_MANGLE=m
+CONFIG_IP_NF_TARGET_CLUSTERIP=m
+CONFIG_IP_NF_TARGET_ECN=m
+CONFIG_IP_NF_TARGET_TTL=m
+CONFIG_IP_NF_RAW=m
+CONFIG_IP_NF_SECURITY=m
+CONFIG_IP_NF_ARPTABLES=m
+CONFIG_IP_NF_ARPFILTER=m
+CONFIG_IP_NF_ARP_MANGLE=m
+
+#
+# IPv6: Netfilter Configuration
+#
+CONFIG_NF_DEFRAG_IPV6=m
+CONFIG_NF_CONNTRACK_IPV6=m
+CONFIG_NF_TABLES_IPV6=m
+CONFIG_NFT_CHAIN_ROUTE_IPV6=m
+CONFIG_NFT_REJECT_IPV6=m
+CONFIG_NFT_DUP_IPV6=m
+CONFIG_NF_DUP_IPV6=m
+CONFIG_NF_REJECT_IPV6=m
+CONFIG_NF_LOG_IPV6=m
+CONFIG_NF_NAT_IPV6=m
+CONFIG_NFT_CHAIN_NAT_IPV6=m
+CONFIG_NF_NAT_MASQUERADE_IPV6=m
+CONFIG_NFT_MASQ_IPV6=m
+CONFIG_NFT_REDIR_IPV6=m
+CONFIG_IP6_NF_IPTABLES=m
+CONFIG_IP6_NF_MATCH_AH=m
+CONFIG_IP6_NF_MATCH_EUI64=m
+CONFIG_IP6_NF_MATCH_FRAG=m
+CONFIG_IP6_NF_MATCH_OPTS=m
+CONFIG_IP6_NF_MATCH_HL=m
+CONFIG_IP6_NF_MATCH_IPV6HEADER=m
+CONFIG_IP6_NF_MATCH_MH=m
+CONFIG_IP6_NF_MATCH_RPFILTER=m
+CONFIG_IP6_NF_MATCH_RT=m
+CONFIG_IP6_NF_TARGET_HL=m
+CONFIG_IP6_NF_FILTER=m
+CONFIG_IP6_NF_TARGET_REJECT=m
+CONFIG_IP6_NF_TARGET_SYNPROXY=m
+CONFIG_IP6_NF_MANGLE=m
+CONFIG_IP6_NF_RAW=m
+CONFIG_IP6_NF_SECURITY=m
+CONFIG_IP6_NF_NAT=m
+CONFIG_IP6_NF_TARGET_MASQUERADE=m
+CONFIG_IP6_NF_TARGET_NPT=m
+
+#
+# DECnet: Netfilter Configuration
+#
+# CONFIG_DECNET_NF_GRABULATOR is not set
+CONFIG_NF_TABLES_BRIDGE=m
+CONFIG_NFT_BRIDGE_META=m
+CONFIG_NFT_BRIDGE_REJECT=m
+CONFIG_NF_LOG_BRIDGE=m
+CONFIG_BRIDGE_NF_EBTABLES=m
+CONFIG_BRIDGE_EBT_BROUTE=m
+CONFIG_BRIDGE_EBT_T_FILTER=m
+CONFIG_BRIDGE_EBT_T_NAT=m
+CONFIG_BRIDGE_EBT_802_3=m
+CONFIG_BRIDGE_EBT_AMONG=m
+CONFIG_BRIDGE_EBT_ARP=m
+CONFIG_BRIDGE_EBT_IP=m
+CONFIG_BRIDGE_EBT_IP6=m
+CONFIG_BRIDGE_EBT_LIMIT=m
+CONFIG_BRIDGE_EBT_MARK=m
+CONFIG_BRIDGE_EBT_PKTTYPE=m
+CONFIG_BRIDGE_EBT_STP=m
+CONFIG_BRIDGE_EBT_VLAN=m
+CONFIG_BRIDGE_EBT_ARPREPLY=m
+CONFIG_BRIDGE_EBT_DNAT=m
+CONFIG_BRIDGE_EBT_MARK_T=m
+CONFIG_BRIDGE_EBT_REDIRECT=m
+CONFIG_BRIDGE_EBT_SNAT=m
+CONFIG_BRIDGE_EBT_LOG=m
+CONFIG_BRIDGE_EBT_NFLOG=m
+CONFIG_IP_DCCP=m
+CONFIG_INET_DCCP_DIAG=m
+
+#
+# DCCP CCIDs Configuration
+#
+# CONFIG_IP_DCCP_CCID2_DEBUG is not set
+# CONFIG_IP_DCCP_CCID3 is not set
+
+#
+# DCCP Kernel Hacking
+#
+# CONFIG_IP_DCCP_DEBUG is not set
+CONFIG_IP_SCTP=m
+# CONFIG_SCTP_DBG_OBJCNT is not set
+CONFIG_SCTP_DEFAULT_COOKIE_HMAC_MD5=y
+# CONFIG_SCTP_DEFAULT_COOKIE_HMAC_SHA1 is not set
+# CONFIG_SCTP_DEFAULT_COOKIE_HMAC_NONE is not set
+CONFIG_SCTP_COOKIE_HMAC_MD5=y
+CONFIG_SCTP_COOKIE_HMAC_SHA1=y
+CONFIG_INET_SCTP_DIAG=m
+CONFIG_RDS=m
+CONFIG_RDS_TCP=m
+# CONFIG_RDS_DEBUG is not set
+CONFIG_TIPC=m
+CONFIG_TIPC_MEDIA_UDP=y
+CONFIG_GMTP=y
+
+#
+# GMTP-Inter Configuration
+#
+CONFIG_GMTP_INTER=y
+CONFIG_ATM=m
+CONFIG_ATM_CLIP=m
+# CONFIG_ATM_CLIP_NO_ICMP is not set
+CONFIG_ATM_LANE=m
+CONFIG_ATM_MPOA=m
+CONFIG_ATM_BR2684=m
+# CONFIG_ATM_BR2684_IPFILTER is not set
+CONFIG_L2TP=m
+CONFIG_L2TP_DEBUGFS=m
+CONFIG_L2TP_V3=y
+CONFIG_L2TP_IP=m
+CONFIG_L2TP_ETH=m
+CONFIG_STP=m
+CONFIG_GARP=m
+CONFIG_BRIDGE=m
+CONFIG_BRIDGE_IGMP_SNOOPING=y
+CONFIG_BRIDGE_VLAN_FILTERING=y
+CONFIG_HAVE_NET_DSA=y
+CONFIG_VLAN_8021Q=m
+CONFIG_VLAN_8021Q_GVRP=y
+# CONFIG_VLAN_8021Q_MVRP is not set
+CONFIG_DECNET=m
+# CONFIG_DECNET_ROUTER is not set
+CONFIG_LLC=m
+CONFIG_LLC2=m
+CONFIG_IPX=m
+# CONFIG_IPX_INTERN is not set
+CONFIG_ATALK=m
+CONFIG_DEV_APPLETALK=m
+CONFIG_IPDDP=m
+CONFIG_IPDDP_ENCAP=y
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_PHONET is not set
+CONFIG_6LOWPAN=m
+# CONFIG_6LOWPAN_DEBUGFS is not set
+CONFIG_6LOWPAN_NHC=m
+CONFIG_6LOWPAN_NHC_DEST=m
+CONFIG_6LOWPAN_NHC_FRAGMENT=m
+CONFIG_6LOWPAN_NHC_HOP=m
+CONFIG_6LOWPAN_NHC_IPV6=m
+CONFIG_6LOWPAN_NHC_MOBILITY=m
+CONFIG_6LOWPAN_NHC_ROUTING=m
+CONFIG_6LOWPAN_NHC_UDP=m
+# CONFIG_6LOWPAN_GHC_EXT_HDR_HOP is not set
+# CONFIG_6LOWPAN_GHC_UDP is not set
+# CONFIG_6LOWPAN_GHC_ICMPV6 is not set
+# CONFIG_6LOWPAN_GHC_EXT_HDR_DEST is not set
+# CONFIG_6LOWPAN_GHC_EXT_HDR_FRAG is not set
+# CONFIG_6LOWPAN_GHC_EXT_HDR_ROUTE is not set
+CONFIG_IEEE802154=m
+# CONFIG_IEEE802154_NL802154_EXPERIMENTAL is not set
+CONFIG_IEEE802154_SOCKET=m
+CONFIG_IEEE802154_6LOWPAN=m
+CONFIG_MAC802154=m
+CONFIG_NET_SCHED=y
+
+#
+# Queueing/Scheduling
+#
+CONFIG_NET_SCH_CBQ=m
+CONFIG_NET_SCH_HTB=m
+CONFIG_NET_SCH_HFSC=m
+CONFIG_NET_SCH_ATM=m
+CONFIG_NET_SCH_PRIO=m
+CONFIG_NET_SCH_MULTIQ=m
+CONFIG_NET_SCH_RED=m
+CONFIG_NET_SCH_SFB=m
+CONFIG_NET_SCH_SFQ=m
+CONFIG_NET_SCH_TEQL=m
+CONFIG_NET_SCH_TBF=m
+CONFIG_NET_SCH_GRED=m
+CONFIG_NET_SCH_DSMARK=m
+CONFIG_NET_SCH_NETEM=m
+CONFIG_NET_SCH_DRR=m
+CONFIG_NET_SCH_MQPRIO=m
+CONFIG_NET_SCH_CHOKE=m
+CONFIG_NET_SCH_QFQ=m
+CONFIG_NET_SCH_CODEL=m
+CONFIG_NET_SCH_FQ_CODEL=m
+CONFIG_NET_SCH_FQ=m
+CONFIG_NET_SCH_HHF=m
+CONFIG_NET_SCH_PIE=m
+CONFIG_NET_SCH_INGRESS=m
+CONFIG_NET_SCH_PLUG=m
+
+#
+# Classification
+#
+CONFIG_NET_CLS=y
+CONFIG_NET_CLS_BASIC=m
+CONFIG_NET_CLS_TCINDEX=m
+CONFIG_NET_CLS_ROUTE4=m
+CONFIG_NET_CLS_FW=m
+CONFIG_NET_CLS_U32=m
+# CONFIG_CLS_U32_PERF is not set
+CONFIG_CLS_U32_MARK=y
+CONFIG_NET_CLS_RSVP=m
+CONFIG_NET_CLS_RSVP6=m
+CONFIG_NET_CLS_FLOW=m
+CONFIG_NET_CLS_BPF=m
+CONFIG_NET_CLS_FLOWER=m
+# CONFIG_NET_CLS_MATCHALL is not set
+CONFIG_NET_EMATCH=y
+CONFIG_NET_EMATCH_STACK=32
+CONFIG_NET_EMATCH_CMP=m
+CONFIG_NET_EMATCH_NBYTE=m
+CONFIG_NET_EMATCH_U32=m
+CONFIG_NET_EMATCH_META=m
+CONFIG_NET_EMATCH_TEXT=m
+CONFIG_NET_EMATCH_IPSET=m
+CONFIG_NET_CLS_ACT=y
+CONFIG_NET_ACT_POLICE=y
+CONFIG_NET_ACT_GACT=m
+CONFIG_GACT_PROB=y
+CONFIG_NET_ACT_MIRRED=m
+CONFIG_NET_ACT_IPT=m
+CONFIG_NET_ACT_NAT=m
+CONFIG_NET_ACT_PEDIT=m
+CONFIG_NET_ACT_SIMP=m
+CONFIG_NET_ACT_SKBEDIT=m
+CONFIG_NET_ACT_CSUM=m
+CONFIG_NET_ACT_VLAN=m
+CONFIG_NET_ACT_BPF=m
+CONFIG_NET_ACT_CONNMARK=m
+# CONFIG_NET_ACT_SKBMOD is not set
+# CONFIG_NET_ACT_IFE is not set
+# CONFIG_NET_ACT_TUNNEL_KEY is not set
+# CONFIG_NET_CLS_IND is not set
+CONFIG_NET_SCH_FIFO=y
+# CONFIG_DCB is not set
+CONFIG_DNS_RESOLVER=y
+CONFIG_BATMAN_ADV=m
+CONFIG_BATMAN_ADV_BLA=y
+CONFIG_BATMAN_ADV_DAT=y
+CONFIG_BATMAN_ADV_NC=y
+CONFIG_BATMAN_ADV_MCAST=y
+CONFIG_BATMAN_ADV_DEBUGFS=y
+# CONFIG_BATMAN_ADV_DEBUG is not set
+CONFIG_OPENVSWITCH=m
+CONFIG_OPENVSWITCH_GRE=m
+CONFIG_VSOCKETS=m
+# CONFIG_VIRTIO_VSOCKETS is not set
+CONFIG_NETLINK_DIAG=m
+CONFIG_MPLS=y
+CONFIG_NET_MPLS_GSO=m
+CONFIG_MPLS_ROUTING=m
+CONFIG_MPLS_IPTUNNEL=m
+CONFIG_HSR=m
+# CONFIG_NET_SWITCHDEV is not set
+# CONFIG_NET_L3_MASTER_DEV is not set
+# CONFIG_NET_NCSI is not set
+CONFIG_RPS=y
+CONFIG_RFS_ACCEL=y
+CONFIG_XPS=y
+# CONFIG_SOCK_CGROUP_DATA is not set
+CONFIG_NET_RX_BUSY_POLL=y
+CONFIG_BQL=y
+CONFIG_BPF_JIT=y
+CONFIG_NET_FLOW_LIMIT=y
+
+#
+# Network testing
+#
+# CONFIG_NET_PKTGEN is not set
+# CONFIG_NET_DROP_MONITOR is not set
+# CONFIG_HAMRADIO is not set
+# CONFIG_CAN is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+CONFIG_AF_RXRPC=y
+# CONFIG_AF_RXRPC_INJECT_LOSS is not set
+# CONFIG_AF_RXRPC_DEBUG is not set
+# CONFIG_RXKAD is not set
+# CONFIG_AF_KCM is not set
+# CONFIG_STREAM_PARSER is not set
+CONFIG_FIB_RULES=y
+# CONFIG_WIRELESS is not set
+# CONFIG_WIMAX is not set
+# CONFIG_RFKILL is not set
+CONFIG_RFKILL_REGULATOR=m
+# CONFIG_NET_9P is not set
+# CONFIG_CAIF is not set
+CONFIG_CEPH_LIB=m
+# CONFIG_CEPH_LIB_PRETTYDEBUG is not set
+# CONFIG_CEPH_LIB_USE_DNS_RESOLVER is not set
+# CONFIG_NFC is not set
+CONFIG_LWTUNNEL=y
+CONFIG_DST_CACHE=y
+# CONFIG_NET_DEVLINK is not set
+CONFIG_MAY_USE_DEVLINK=y
+CONFIG_HAVE_EBPF_JIT=y
+
+#
+# Device Drivers
+#
+
+#
+# Generic Driver Options
+#
+# CONFIG_UEVENT_HELPER is not set
+CONFIG_DEVTMPFS=y
+CONFIG_DEVTMPFS_MOUNT=y
+CONFIG_STANDALONE=y
+# CONFIG_PREVENT_FIRMWARE_BUILD is not set
+CONFIG_FW_LOADER=y
+# CONFIG_FIRMWARE_IN_KERNEL is not set
+CONFIG_EXTRA_FIRMWARE=""
+CONFIG_FW_LOADER_USER_HELPER=y
+# CONFIG_FW_LOADER_USER_HELPER_FALLBACK is not set
+# CONFIG_ALLOW_DEV_COREDUMP is not set
+# CONFIG_DEBUG_DRIVER is not set
+# CONFIG_DEBUG_DEVRES is not set
+# CONFIG_DEBUG_TEST_DRIVER_REMOVE is not set
+# CONFIG_SYS_HYPERVISOR is not set
+# CONFIG_GENERIC_CPU_DEVICES is not set
+CONFIG_GENERIC_CPU_AUTOPROBE=y
+CONFIG_REGMAP=y
+CONFIG_REGMAP_I2C=m
+CONFIG_REGMAP_MMIO=y
+CONFIG_REGMAP_IRQ=y
+CONFIG_DMA_SHARED_BUFFER=y
+# CONFIG_FENCE_TRACE is not set
+
+#
+# Bus devices
+#
+# CONFIG_QCOM_EBI2 is not set
+CONFIG_CONNECTOR=y
+CONFIG_PROC_EVENTS=y
+# CONFIG_MTD is not set
+# CONFIG_OF is not set
+CONFIG_ARCH_MIGHT_HAVE_PC_PARPORT=y
+# CONFIG_PARPORT is not set
+CONFIG_PNP=y
+CONFIG_PNP_DEBUG_MESSAGES=y
+
+#
+# Protocols
+#
+CONFIG_PNPACPI=y
+CONFIG_BLK_DEV=y
+CONFIG_BLK_DEV_NULL_BLK=m
+CONFIG_BLK_DEV_FD=y
+CONFIG_BLK_DEV_PCIESSD_MTIP32XX=m
+CONFIG_ZRAM=m
+CONFIG_BLK_CPQ_CISS_DA=y
+CONFIG_CISS_SCSI_TAPE=y
+CONFIG_BLK_DEV_DAC960=y
+CONFIG_BLK_DEV_UMEM=m
+# CONFIG_BLK_DEV_COW_COMMON is not set
+CONFIG_BLK_DEV_LOOP=m
+CONFIG_BLK_DEV_LOOP_MIN_COUNT=8
+CONFIG_BLK_DEV_CRYPTOLOOP=m
+CONFIG_BLK_DEV_DRBD=m
+# CONFIG_DRBD_FAULT_INJECTION is not set
+CONFIG_BLK_DEV_NBD=m
+CONFIG_BLK_DEV_SKD=m
+CONFIG_BLK_DEV_OSD=m
+CONFIG_BLK_DEV_SX8=y
+CONFIG_BLK_DEV_RAM=y
+CONFIG_BLK_DEV_RAM_COUNT=16
+CONFIG_BLK_DEV_RAM_SIZE=16384
+CONFIG_CDROM_PKTCDVD=m
+CONFIG_CDROM_PKTCDVD_BUFFERS=8
+# CONFIG_CDROM_PKTCDVD_WCACHE is not set
+CONFIG_ATA_OVER_ETH=m
+CONFIG_VIRTIO_BLK=y
+# CONFIG_BLK_DEV_HD is not set
+CONFIG_BLK_DEV_RBD=m
+CONFIG_BLK_DEV_RSXX=m
+# CONFIG_BLK_DEV_NVME is not set
+# CONFIG_NVME_TARGET is not set
+
+#
+# Misc devices
+#
+# CONFIG_SENSORS_LIS3LV02D is not set
+# CONFIG_AD525X_DPOT is not set
+# CONFIG_DUMMY_IRQ is not set
+# CONFIG_IBM_ASM is not set
+# CONFIG_PHANTOM is not set
+# CONFIG_SGI_IOC4 is not set
+# CONFIG_TIFM_CORE is not set
+# CONFIG_ICS932S401 is not set
+# CONFIG_ENCLOSURE_SERVICES is not set
+# CONFIG_HP_ILO is not set
+# CONFIG_APDS9802ALS is not set
+# CONFIG_ISL29003 is not set
+# CONFIG_ISL29020 is not set
+# CONFIG_SENSORS_TSL2550 is not set
+# CONFIG_SENSORS_BH1770 is not set
+# CONFIG_SENSORS_APDS990X is not set
+# CONFIG_HMC6352 is not set
+# CONFIG_DS1682 is not set
+# CONFIG_USB_SWITCH_FSA9480 is not set
+# CONFIG_SRAM is not set
+# CONFIG_C2PORT is not set
+
+#
+# EEPROM support
+#
+CONFIG_EEPROM_AT24=m
+CONFIG_EEPROM_LEGACY=m
+CONFIG_EEPROM_MAX6875=m
+CONFIG_EEPROM_93CX6=m
+# CONFIG_CB710_CORE is not set
+
+#
+# Texas Instruments shared transport line discipline
+#
+CONFIG_TI_ST=m
+# CONFIG_SENSORS_LIS3_I2C is not set
+
+#
+# Altera FPGA firmware download module
+#
+# CONFIG_ALTERA_STAPL is not set
+# CONFIG_INTEL_MEI is not set
+# CONFIG_INTEL_MEI_ME is not set
+# CONFIG_INTEL_MEI_TXE is not set
+# CONFIG_VMWARE_VMCI is not set
+
+#
+# Intel MIC Bus Driver
+#
+# CONFIG_INTEL_MIC_BUS is not set
+
+#
+# SCIF Bus Driver
+#
+# CONFIG_SCIF_BUS is not set
+
+#
+# VOP Bus Driver
+#
+# CONFIG_VOP_BUS is not set
+
+#
+# Intel MIC Host Driver
+#
+
+#
+# Intel MIC Card Driver
+#
+
+#
+# SCIF Driver
+#
+
+#
+# Intel MIC Coprocessor State Management (COSM) Drivers
+#
+
+#
+# VOP Driver
+#
+# CONFIG_GENWQE is not set
+# CONFIG_ECHO is not set
+# CONFIG_CXL_BASE is not set
+# CONFIG_CXL_AFU_DRIVER_OPS is not set
+CONFIG_HAVE_IDE=y
+# CONFIG_IDE is not set
+
+#
+# SCSI device support
+#
+CONFIG_SCSI_MOD=y
+CONFIG_RAID_ATTRS=y
+CONFIG_SCSI=y
+CONFIG_SCSI_DMA=y
+CONFIG_SCSI_NETLINK=y
+# CONFIG_SCSI_MQ_DEFAULT is not set
+CONFIG_SCSI_PROC_FS=y
+
+#
+# SCSI support type (disk, tape, CD-ROM)
+#
+CONFIG_BLK_DEV_SD=y
+CONFIG_CHR_DEV_ST=y
+CONFIG_CHR_DEV_OSST=m
+CONFIG_BLK_DEV_SR=y
+CONFIG_BLK_DEV_SR_VENDOR=y
+CONFIG_CHR_DEV_SG=m
+CONFIG_CHR_DEV_SCH=m
+# CONFIG_SCSI_CONSTANTS is not set
+# CONFIG_SCSI_LOGGING is not set
+# CONFIG_SCSI_SCAN_ASYNC is not set
+
+#
+# SCSI Transports
+#
+CONFIG_SCSI_SPI_ATTRS=y
+CONFIG_SCSI_FC_ATTRS=y
+CONFIG_SCSI_ISCSI_ATTRS=m
+CONFIG_SCSI_SAS_ATTRS=y
+CONFIG_SCSI_SAS_LIBSAS=y
+CONFIG_SCSI_SAS_ATA=y
+CONFIG_SCSI_SAS_HOST_SMP=y
+CONFIG_SCSI_SRP_ATTRS=m
+CONFIG_SCSI_LOWLEVEL=y
+CONFIG_ISCSI_TCP=m
+CONFIG_ISCSI_BOOT_SYSFS=y
+CONFIG_SCSI_CXGB3_ISCSI=m
+CONFIG_SCSI_CXGB4_ISCSI=m
+CONFIG_SCSI_BNX2_ISCSI=m
+CONFIG_SCSI_BNX2X_FCOE=m
+CONFIG_BE2ISCSI=m
+CONFIG_BLK_DEV_3W_XXXX_RAID=y
+CONFIG_SCSI_HPSA=y
+CONFIG_SCSI_3W_9XXX=y
+CONFIG_SCSI_3W_SAS=y
+CONFIG_SCSI_ACARD=y
+CONFIG_SCSI_AACRAID=y
+CONFIG_SCSI_AIC7XXX=y
+CONFIG_AIC7XXX_CMDS_PER_DEVICE=4
+CONFIG_AIC7XXX_RESET_DELAY_MS=15000
+# CONFIG_AIC7XXX_BUILD_FIRMWARE is not set
+# CONFIG_AIC7XXX_DEBUG_ENABLE is not set
+CONFIG_AIC7XXX_DEBUG_MASK=0
+# CONFIG_AIC7XXX_REG_PRETTY_PRINT is not set
+CONFIG_SCSI_AIC79XX=y
+CONFIG_AIC79XX_CMDS_PER_DEVICE=4
+CONFIG_AIC79XX_RESET_DELAY_MS=15000
+# CONFIG_AIC79XX_BUILD_FIRMWARE is not set
+# CONFIG_AIC79XX_DEBUG_ENABLE is not set
+CONFIG_AIC79XX_DEBUG_MASK=0
+# CONFIG_AIC79XX_REG_PRETTY_PRINT is not set
+CONFIG_SCSI_AIC94XX=y
+# CONFIG_AIC94XX_DEBUG is not set
+CONFIG_SCSI_MVSAS=y
+# CONFIG_SCSI_MVSAS_DEBUG is not set
+# CONFIG_SCSI_MVSAS_TASKLET is not set
+CONFIG_SCSI_MVUMI=m
+CONFIG_SCSI_DPT_I2O=m
+CONFIG_SCSI_ADVANSYS=y
+CONFIG_SCSI_ARCMSR=y
+CONFIG_SCSI_ESAS2R=m
+CONFIG_MEGARAID_NEWGEN=y
+CONFIG_MEGARAID_MM=y
+CONFIG_MEGARAID_MAILBOX=y
+CONFIG_MEGARAID_LEGACY=m
+CONFIG_MEGARAID_SAS=y
+CONFIG_SCSI_MPT3SAS=y
+CONFIG_SCSI_MPT2SAS_MAX_SGE=128
+CONFIG_SCSI_MPT3SAS_MAX_SGE=128
+CONFIG_SCSI_MPT2SAS=y
+# CONFIG_SCSI_SMARTPQI is not set
+CONFIG_SCSI_UFSHCD=m
+CONFIG_SCSI_UFSHCD_PCI=m
+# CONFIG_SCSI_UFS_DWC_TC_PCI is not set
+CONFIG_SCSI_UFSHCD_PLATFORM=m
+# CONFIG_SCSI_UFS_DWC_TC_PLATFORM is not set
+CONFIG_SCSI_HPTIOP=y
+CONFIG_SCSI_BUSLOGIC=y
+CONFIG_SCSI_FLASHPOINT=y
+CONFIG_VMWARE_PVSCSI=m
+CONFIG_LIBFC=y
+CONFIG_LIBFCOE=y
+CONFIG_FCOE=y
+CONFIG_FCOE_FNIC=y
+CONFIG_SCSI_SNIC=m
+# CONFIG_SCSI_SNIC_DEBUG_FS is not set
+CONFIG_SCSI_DMX3191D=y
+CONFIG_SCSI_EATA=y
+# CONFIG_SCSI_EATA_TAGGED_QUEUE is not set
+# CONFIG_SCSI_EATA_LINKED_COMMANDS is not set
+CONFIG_SCSI_EATA_MAX_TAGS=16
+CONFIG_SCSI_FUTURE_DOMAIN=y
+CONFIG_SCSI_GDTH=y
+CONFIG_SCSI_ISCI=m
+CONFIG_SCSI_IPS=y
+CONFIG_SCSI_INITIO=y
+CONFIG_SCSI_INIA100=y
+CONFIG_SCSI_STEX=y
+CONFIG_SCSI_SYM53C8XX_2=y
+CONFIG_SCSI_SYM53C8XX_DMA_ADDRESSING_MODE=1
+CONFIG_SCSI_SYM53C8XX_DEFAULT_TAGS=16
+CONFIG_SCSI_SYM53C8XX_MAX_TAGS=64
+CONFIG_SCSI_SYM53C8XX_MMIO=y
+CONFIG_SCSI_IPR=y
+# CONFIG_SCSI_IPR_TRACE is not set
+# CONFIG_SCSI_IPR_DUMP is not set
+CONFIG_SCSI_QLOGIC_1280=y
+CONFIG_SCSI_QLA_FC=y
+CONFIG_SCSI_QLA_ISCSI=m
+CONFIG_SCSI_LPFC=y
+# CONFIG_SCSI_LPFC_DEBUG_FS is not set
+CONFIG_SCSI_DC395x=y
+CONFIG_SCSI_AM53C974=m
+CONFIG_SCSI_WD719X=m
+CONFIG_SCSI_DEBUG=m
+CONFIG_SCSI_PMCRAID=y
+CONFIG_SCSI_PM8001=y
+CONFIG_SCSI_BFA_FC=y
+CONFIG_SCSI_VIRTIO=y
+CONFIG_SCSI_CHELSIO_FCOE=m
+CONFIG_SCSI_LOWLEVEL_PCMCIA=y
+CONFIG_PCMCIA_AHA152X=m
+CONFIG_PCMCIA_FDOMAIN=m
+CONFIG_PCMCIA_QLOGIC=m
+CONFIG_PCMCIA_SYM53C500=m
+CONFIG_SCSI_DH=y
+CONFIG_SCSI_DH_RDAC=m
+CONFIG_SCSI_DH_HP_SW=m
+CONFIG_SCSI_DH_EMC=m
+CONFIG_SCSI_DH_ALUA=m
+CONFIG_SCSI_OSD_INITIATOR=m
+CONFIG_SCSI_OSD_ULD=m
+CONFIG_SCSI_OSD_DPRINT_SENSE=1
+# CONFIG_SCSI_OSD_DEBUG is not set
+CONFIG_ATA=y
+# CONFIG_ATA_NONSTANDARD is not set
+CONFIG_ATA_VERBOSE_ERROR=y
+CONFIG_ATA_ACPI=y
+# CONFIG_SATA_ZPODD is not set
+CONFIG_SATA_PMP=y
+
+#
+# Controllers with non-SFF native interface
+#
+CONFIG_SATA_AHCI=y
+CONFIG_SATA_AHCI_PLATFORM=y
+CONFIG_SATA_INIC162X=y
+CONFIG_SATA_ACARD_AHCI=y
+CONFIG_SATA_SIL24=y
+CONFIG_ATA_SFF=y
+
+#
+# SFF controllers with custom DMA interface
+#
+CONFIG_PDC_ADMA=y
+CONFIG_SATA_QSTOR=y
+CONFIG_SATA_SX4=y
+CONFIG_ATA_BMDMA=y
+
+#
+# SATA SFF controllers with BMDMA
+#
+CONFIG_ATA_PIIX=y
+# CONFIG_SATA_DWC is not set
+CONFIG_SATA_MV=y
+CONFIG_SATA_NV=y
+CONFIG_SATA_PROMISE=y
+CONFIG_SATA_SIL=y
+CONFIG_SATA_SIS=y
+CONFIG_SATA_SVW=y
+CONFIG_SATA_ULI=y
+CONFIG_SATA_VIA=y
+CONFIG_SATA_VITESSE=y
+
+#
+# PATA SFF controllers with BMDMA
+#
+CONFIG_PATA_ALI=y
+CONFIG_PATA_AMD=y
+CONFIG_PATA_ARTOP=y
+CONFIG_PATA_ATIIXP=y
+CONFIG_PATA_ATP867X=y
+CONFIG_PATA_CMD64X=y
+CONFIG_PATA_CYPRESS=y
+CONFIG_PATA_EFAR=y
+CONFIG_PATA_HPT366=y
+CONFIG_PATA_HPT37X=y
+CONFIG_PATA_HPT3X2N=y
+CONFIG_PATA_HPT3X3=y
+CONFIG_PATA_HPT3X3_DMA=y
+CONFIG_PATA_IT8213=y
+CONFIG_PATA_IT821X=y
+CONFIG_PATA_JMICRON=y
+CONFIG_PATA_MARVELL=y
+CONFIG_PATA_NETCELL=y
+CONFIG_PATA_NINJA32=y
+CONFIG_PATA_NS87415=y
+CONFIG_PATA_OLDPIIX=y
+CONFIG_PATA_OPTIDMA=y
+CONFIG_PATA_PDC2027X=y
+CONFIG_PATA_PDC_OLD=y
+CONFIG_PATA_RADISYS=y
+CONFIG_PATA_RDC=y
+CONFIG_PATA_SCH=y
+CONFIG_PATA_SERVERWORKS=y
+CONFIG_PATA_SIL680=y
+CONFIG_PATA_SIS=y
+CONFIG_PATA_TOSHIBA=m
+CONFIG_PATA_TRIFLEX=y
+CONFIG_PATA_VIA=y
+CONFIG_PATA_WINBOND=y
+
+#
+# PIO-only SFF controllers
+#
+CONFIG_PATA_CMD640_PCI=y
+CONFIG_PATA_MPIIX=y
+CONFIG_PATA_NS87410=y
+CONFIG_PATA_OPTI=y
+CONFIG_PATA_PCMCIA=m
+# CONFIG_PATA_PLATFORM is not set
+CONFIG_PATA_RZ1000=y
+
+#
+# Generic fallback / legacy drivers
+#
+CONFIG_PATA_ACPI=y
+CONFIG_ATA_GENERIC=y
+CONFIG_PATA_LEGACY=y
+CONFIG_MD=y
+CONFIG_BLK_DEV_MD=y
+CONFIG_MD_AUTODETECT=y
+CONFIG_MD_LINEAR=y
+CONFIG_MD_RAID0=y
+CONFIG_MD_RAID1=y
+CONFIG_MD_RAID10=y
+CONFIG_MD_RAID456=y
+CONFIG_MD_MULTIPATH=y
+CONFIG_MD_FAULTY=m
+CONFIG_MD_CLUSTER=m
+CONFIG_BCACHE=m
+# CONFIG_BCACHE_DEBUG is not set
+# CONFIG_BCACHE_CLOSURES_DEBUG is not set
+CONFIG_BLK_DEV_DM_BUILTIN=y
+CONFIG_BLK_DEV_DM=y
+# CONFIG_DM_MQ_DEFAULT is not set
+# CONFIG_DM_DEBUG is not set
+CONFIG_DM_BUFIO=y
+# CONFIG_DM_DEBUG_BLOCK_STACK_TRACING is not set
+CONFIG_DM_BIO_PRISON=m
+CONFIG_DM_PERSISTENT_DATA=m
+CONFIG_DM_CRYPT=y
+CONFIG_DM_SNAPSHOT=y
+CONFIG_DM_THIN_PROVISIONING=m
+CONFIG_DM_CACHE=m
+CONFIG_DM_CACHE_SMQ=m
+CONFIG_DM_CACHE_CLEANER=m
+CONFIG_DM_ERA=m
+CONFIG_DM_MIRROR=y
+CONFIG_DM_LOG_USERSPACE=m
+CONFIG_DM_RAID=m
+CONFIG_DM_ZERO=m
+CONFIG_DM_MULTIPATH=m
+CONFIG_DM_MULTIPATH_QL=m
+CONFIG_DM_MULTIPATH_ST=m
+# CONFIG_DM_DELAY is not set
+CONFIG_DM_UEVENT=y
+CONFIG_DM_FLAKEY=m
+CONFIG_DM_VERITY=m
+# CONFIG_DM_VERITY_FEC is not set
+CONFIG_DM_SWITCH=m
+CONFIG_DM_LOG_WRITES=m
+# CONFIG_TARGET_CORE is not set
+# CONFIG_FUSION is not set
+
+#
+# IEEE 1394 (FireWire) support
+#
+CONFIG_FIREWIRE=m
+CONFIG_FIREWIRE_OHCI=m
+CONFIG_FIREWIRE_SBP2=m
+CONFIG_FIREWIRE_NET=m
+CONFIG_FIREWIRE_NOSY=m
+# CONFIG_MACINTOSH_DRIVERS is not set
+CONFIG_NETDEVICES=y
+CONFIG_MII=m
+CONFIG_NET_CORE=y
+# CONFIG_BONDING is not set
+# CONFIG_DUMMY is not set
+# CONFIG_EQUALIZER is not set
+# CONFIG_NET_FC is not set
+# CONFIG_IFB is not set
+# CONFIG_NET_TEAM is not set
+# CONFIG_MACVLAN is not set
+# CONFIG_VXLAN is not set
+# CONFIG_GENEVE is not set
+# CONFIG_GTP is not set
+# CONFIG_MACSEC is not set
+# CONFIG_NETCONSOLE is not set
+# CONFIG_NETPOLL is not set
+# CONFIG_NET_POLL_CONTROLLER is not set
+CONFIG_TUN=m
+# CONFIG_TUN_VNET_CROSS_LE is not set
+# CONFIG_VETH is not set
+# CONFIG_VIRTIO_NET is not set
+# CONFIG_NLMON is not set
+CONFIG_SUNGEM_PHY=m
+# CONFIG_ARCNET is not set
+# CONFIG_ATM_DRIVERS is not set
+
+#
+# CAIF transport drivers
+#
+
+#
+# Distributed Switch Architecture drivers
+#
+CONFIG_ETHERNET=y
+CONFIG_MDIO=m
+CONFIG_NET_VENDOR_3COM=y
+CONFIG_PCMCIA_3C574=m
+CONFIG_PCMCIA_3C589=m
+CONFIG_VORTEX=m
+CONFIG_TYPHOON=m
+CONFIG_NET_VENDOR_ADAPTEC=y
+CONFIG_ADAPTEC_STARFIRE=m
+CONFIG_NET_VENDOR_AGERE=y
+# CONFIG_ET131X is not set
+CONFIG_NET_VENDOR_ALTEON=y
+CONFIG_ACENIC=m
+# CONFIG_ACENIC_OMIT_TIGON_I is not set
+CONFIG_ALTERA_TSE=m
+CONFIG_NET_VENDOR_AMAZON=y
+# CONFIG_ENA_ETHERNET is not set
+CONFIG_NET_VENDOR_AMD=y
+CONFIG_AMD8111_ETH=m
+CONFIG_PCNET32=m
+CONFIG_PCMCIA_NMCLAN=m
+CONFIG_NET_VENDOR_ARC=y
+CONFIG_NET_VENDOR_ATHEROS=y
+CONFIG_ATL2=m
+CONFIG_ATL1=m
+CONFIG_ATL1E=m
+CONFIG_ATL1C=m
+CONFIG_ALX=m
+CONFIG_NET_VENDOR_AURORA=y
+CONFIG_AURORA_NB8800=m
+CONFIG_NET_CADENCE=y
+CONFIG_MACB=m
+CONFIG_NET_VENDOR_BROADCOM=y
+CONFIG_B44=m
+CONFIG_B44_PCI_AUTOSELECT=y
+CONFIG_B44_PCICORE_AUTOSELECT=y
+CONFIG_B44_PCI=y
+CONFIG_BCMGENET=m
+CONFIG_BNX2=m
+CONFIG_CNIC=m
+CONFIG_TIGON3=m
+CONFIG_BNX2X=m
+CONFIG_BNX2X_SRIOV=y
+CONFIG_BNXT=m
+CONFIG_BNXT_SRIOV=y
+CONFIG_NET_VENDOR_BROCADE=y
+CONFIG_BNA=m
+CONFIG_NET_VENDOR_CAVIUM=y
+CONFIG_THUNDER_NIC_PF=m
+CONFIG_THUNDER_NIC_VF=m
+CONFIG_THUNDER_NIC_BGX=m
+CONFIG_THUNDER_NIC_RGX=m
+CONFIG_LIQUIDIO=m
+CONFIG_NET_VENDOR_CHELSIO=y
+CONFIG_CHELSIO_T1=m
+CONFIG_CHELSIO_T1_1G=y
+CONFIG_CHELSIO_T3=m
+CONFIG_CHELSIO_T4=m
+CONFIG_CHELSIO_T4VF=m
+CONFIG_CHELSIO_LIB=m
+CONFIG_NET_VENDOR_CISCO=y
+CONFIG_ENIC=m
+CONFIG_CX_ECAT=m
+CONFIG_DNET=m
+CONFIG_NET_VENDOR_DEC=y
+CONFIG_NET_TULIP=y
+CONFIG_DE2104X=m
+CONFIG_DE2104X_DSL=0
+CONFIG_TULIP=m
+# CONFIG_TULIP_MWI is not set
+CONFIG_TULIP_MMIO=y
+# CONFIG_TULIP_NAPI is not set
+CONFIG_DE4X5=m
+CONFIG_WINBOND_840=m
+CONFIG_DM9102=m
+CONFIG_ULI526X=m
+CONFIG_PCMCIA_XIRCOM=m
+CONFIG_NET_VENDOR_DLINK=y
+CONFIG_DL2K=m
+CONFIG_SUNDANCE=m
+# CONFIG_SUNDANCE_MMIO is not set
+CONFIG_NET_VENDOR_EMULEX=y
+CONFIG_BE2NET=m
+CONFIG_BE2NET_HWMON=y
+CONFIG_NET_VENDOR_EZCHIP=y
+CONFIG_NET_VENDOR_EXAR=y
+CONFIG_S2IO=m
+CONFIG_VXGE=m
+# CONFIG_VXGE_DEBUG_TRACE_ALL is not set
+CONFIG_NET_VENDOR_FUJITSU=y
+CONFIG_PCMCIA_FMVJ18X=m
+CONFIG_NET_VENDOR_HP=y
+CONFIG_HP100=m
+CONFIG_NET_VENDOR_INTEL=y
+CONFIG_E100=m
+CONFIG_E1000=m
+CONFIG_E1000E=m
+CONFIG_E1000E_HWTS=y
+CONFIG_IGB=m
+CONFIG_IGB_HWMON=y
+CONFIG_IGB_DCA=y
+CONFIG_IGBVF=m
+CONFIG_IXGB=m
+CONFIG_IXGBE=m
+CONFIG_IXGBE_HWMON=y
+CONFIG_IXGBE_DCA=y
+CONFIG_IXGBEVF=m
+CONFIG_I40E=m
+CONFIG_I40EVF=m
+CONFIG_FM10K=m
+CONFIG_NET_VENDOR_I825XX=y
+CONFIG_JME=m
+CONFIG_NET_VENDOR_MARVELL=y
+CONFIG_MVMDIO=m
+# CONFIG_MVNETA_BM is not set
+CONFIG_SKGE=m
+# CONFIG_SKGE_DEBUG is not set
+CONFIG_SKGE_GENESIS=y
+CONFIG_SKY2=m
+# CONFIG_SKY2_DEBUG is not set
+CONFIG_NET_VENDOR_MELLANOX=y
+CONFIG_MLX4_EN=m
+CONFIG_MLX4_CORE=m
+CONFIG_MLX4_DEBUG=y
+CONFIG_MLX5_CORE=m
+CONFIG_MLX5_CORE_EN=y
+CONFIG_MLXSW_CORE=m
+CONFIG_MLXSW_CORE_HWMON=y
+CONFIG_MLXSW_PCI=m
+CONFIG_NET_VENDOR_MICREL=y
+CONFIG_KS8842=m
+CONFIG_KS8851_MLL=m
+CONFIG_KSZ884X_PCI=m
+CONFIG_NET_VENDOR_MYRI=y
+CONFIG_MYRI10GE=m
+CONFIG_MYRI10GE_DCA=y
+CONFIG_FEALNX=m
+CONFIG_NET_VENDOR_NATSEMI=y
+CONFIG_NATSEMI=m
+CONFIG_NS83820=m
+CONFIG_NET_VENDOR_NETRONOME=y
+# CONFIG_NFP_NETVF is not set
+CONFIG_NET_VENDOR_8390=y
+CONFIG_PCMCIA_AXNET=m
+CONFIG_NE2K_PCI=m
+CONFIG_PCMCIA_PCNET=m
+CONFIG_NET_VENDOR_NVIDIA=y
+CONFIG_FORCEDETH=m
+CONFIG_NET_VENDOR_OKI=y
+CONFIG_ETHOC=m
+CONFIG_NET_PACKET_ENGINE=y
+CONFIG_HAMACHI=m
+CONFIG_YELLOWFIN=m
+CONFIG_NET_VENDOR_QLOGIC=y
+CONFIG_QLA3XXX=m
+CONFIG_QLCNIC=m
+CONFIG_QLCNIC_SRIOV=y
+CONFIG_QLCNIC_HWMON=y
+CONFIG_QLGE=m
+CONFIG_NETXEN_NIC=m
+CONFIG_QED=m
+CONFIG_QED_SRIOV=y
+CONFIG_QEDE=m
+CONFIG_NET_VENDOR_QUALCOMM=y
+# CONFIG_QCOM_EMAC is not set
+CONFIG_NET_VENDOR_REALTEK=y
+CONFIG_8139CP=m
+CONFIG_8139TOO=m
+CONFIG_8139TOO_PIO=y
+# CONFIG_8139TOO_TUNE_TWISTER is not set
+CONFIG_8139TOO_8129=y
+# CONFIG_8139_OLD_RX_RESET is not set
+CONFIG_R8169=m
+CONFIG_NET_VENDOR_RENESAS=y
+CONFIG_NET_VENDOR_RDC=y
+CONFIG_R6040=m
+CONFIG_NET_VENDOR_ROCKER=y
+CONFIG_NET_VENDOR_SAMSUNG=y
+CONFIG_SXGBE_ETH=m
+CONFIG_NET_VENDOR_SEEQ=y
+CONFIG_NET_VENDOR_SILAN=y
+CONFIG_SC92031=m
+CONFIG_NET_VENDOR_SIS=y
+CONFIG_SIS900=m
+CONFIG_SIS190=m
+CONFIG_SFC=m
+CONFIG_SFC_MCDI_MON=y
+CONFIG_SFC_SRIOV=y
+# CONFIG_SFC_MCDI_LOGGING is not set
+CONFIG_NET_VENDOR_SMSC=y
+CONFIG_PCMCIA_SMC91C92=m
+CONFIG_EPIC100=m
+CONFIG_SMSC911X=m
+# CONFIG_SMSC911X_ARCH_HOOKS is not set
+CONFIG_SMSC9420=m
+CONFIG_NET_VENDOR_STMICRO=y
+CONFIG_STMMAC_ETH=m
+CONFIG_STMMAC_PLATFORM=m
+CONFIG_DWMAC_GENERIC=m
+# CONFIG_STMMAC_PCI is not set
+CONFIG_NET_VENDOR_SUN=y
+CONFIG_HAPPYMEAL=m
+CONFIG_SUNGEM=m
+CONFIG_CASSINI=m
+CONFIG_NIU=m
+CONFIG_NET_VENDOR_SYNOPSYS=y
+CONFIG_NET_VENDOR_TEHUTI=y
+CONFIG_TEHUTI=m
+CONFIG_NET_VENDOR_TI=y
+CONFIG_TI_CPSW_ALE=m
+CONFIG_TLAN=m
+CONFIG_NET_VENDOR_VIA=y
+CONFIG_VIA_RHINE=m
+CONFIG_VIA_RHINE_MMIO=y
+CONFIG_VIA_VELOCITY=m
+CONFIG_NET_VENDOR_WIZNET=y
+CONFIG_WIZNET_W5100=m
+CONFIG_WIZNET_W5300=m
+# CONFIG_WIZNET_BUS_DIRECT is not set
+# CONFIG_WIZNET_BUS_INDIRECT is not set
+CONFIG_WIZNET_BUS_ANY=y
+CONFIG_NET_VENDOR_XIRCOM=y
+CONFIG_PCMCIA_XIRC2PS=m
+# CONFIG_FDDI is not set
+# CONFIG_HIPPI is not set
+# CONFIG_NET_SB1000 is not set
+CONFIG_PHYLIB=m
+CONFIG_SWPHY=y
+
+#
+# MDIO bus device drivers
+#
+# CONFIG_MDIO_BCM_UNIMAC is not set
+# CONFIG_MDIO_BITBANG is not set
+CONFIG_MDIO_CAVIUM=m
+# CONFIG_MDIO_OCTEON is not set
+CONFIG_MDIO_THUNDER=m
+
+#
+# MII PHY device drivers
+#
+# CONFIG_AMD_PHY is not set
+# CONFIG_AQUANTIA_PHY is not set
+# CONFIG_AT803X_PHY is not set
+CONFIG_BCM7XXX_PHY=m
+# CONFIG_BCM87XX_PHY is not set
+CONFIG_BCM_NET_PHYLIB=m
+# CONFIG_BROADCOM_PHY is not set
+# CONFIG_CICADA_PHY is not set
+# CONFIG_DAVICOM_PHY is not set
+# CONFIG_DP83848_PHY is not set
+# CONFIG_DP83867_PHY is not set
+CONFIG_FIXED_PHY=m
+# CONFIG_ICPLUS_PHY is not set
+# CONFIG_INTEL_XWAY_PHY is not set
+# CONFIG_LSI_ET1011C_PHY is not set
+# CONFIG_LXT_PHY is not set
+# CONFIG_MARVELL_PHY is not set
+# CONFIG_MICREL_PHY is not set
+# CONFIG_MICROCHIP_PHY is not set
+# CONFIG_MICROSEMI_PHY is not set
+# CONFIG_NATIONAL_PHY is not set
+# CONFIG_QSEMI_PHY is not set
+# CONFIG_REALTEK_PHY is not set
+CONFIG_SMSC_PHY=m
+# CONFIG_STE10XP is not set
+# CONFIG_TERANETICS_PHY is not set
+# CONFIG_VITESSE_PHY is not set
+# CONFIG_XILINX_GMII2RGMII is not set
+CONFIG_PPP=m
+# CONFIG_PPP_BSDCOMP is not set
+# CONFIG_PPP_DEFLATE is not set
+# CONFIG_PPP_FILTER is not set
+# CONFIG_PPP_MPPE is not set
+# CONFIG_PPP_MULTILINK is not set
+# CONFIG_PPPOATM is not set
+# CONFIG_PPPOE is not set
+# CONFIG_PPTP is not set
+# CONFIG_PPPOL2TP is not set
+# CONFIG_PPP_ASYNC is not set
+# CONFIG_PPP_SYNC_TTY is not set
+# CONFIG_SLIP is not set
+CONFIG_SLHC=m
+
+#
+# Host-side USB support is needed for USB Network Adapter support
+#
+# CONFIG_WLAN is not set
+
+#
+# Enable WiMAX (Networking options) to see the WiMAX drivers
+#
+# CONFIG_WAN is not set
+# CONFIG_IEEE802154_DRIVERS is not set
+# CONFIG_VMXNET3 is not set
+# CONFIG_FUJITSU_ES is not set
+# CONFIG_ISDN is not set
+# CONFIG_NVM is not set
+
+#
+# Input device support
+#
+CONFIG_INPUT=y
+CONFIG_INPUT_LEDS=y
+CONFIG_INPUT_FF_MEMLESS=y
+CONFIG_INPUT_POLLDEV=m
+CONFIG_INPUT_SPARSEKMAP=m
+CONFIG_INPUT_MATRIXKMAP=y
+
+#
+# Userland interfaces
+#
+# CONFIG_INPUT_MOUSEDEV is not set
+# CONFIG_INPUT_JOYDEV is not set
+CONFIG_INPUT_EVDEV=m
+# CONFIG_INPUT_EVBUG is not set
+
+#
+# Input Device Drivers
+#
+CONFIG_INPUT_KEYBOARD=y
+# CONFIG_KEYBOARD_ADP5588 is not set
+# CONFIG_KEYBOARD_ADP5589 is not set
+CONFIG_KEYBOARD_ATKBD=y
+# CONFIG_KEYBOARD_QT1070 is not set
+# CONFIG_KEYBOARD_QT2160 is not set
+# CONFIG_KEYBOARD_LKKBD is not set
+# CONFIG_KEYBOARD_GPIO is not set
+# CONFIG_KEYBOARD_GPIO_POLLED is not set
+# CONFIG_KEYBOARD_TCA6416 is not set
+# CONFIG_KEYBOARD_TCA8418 is not set
+# CONFIG_KEYBOARD_MATRIX is not set
+# CONFIG_KEYBOARD_LM8323 is not set
+# CONFIG_KEYBOARD_LM8333 is not set
+# CONFIG_KEYBOARD_MAX7359 is not set
+# CONFIG_KEYBOARD_MCS is not set
+# CONFIG_KEYBOARD_MPR121 is not set
+# CONFIG_KEYBOARD_NEWTON is not set
+# CONFIG_KEYBOARD_OPENCORES is not set
+CONFIG_KEYBOARD_SAMSUNG=y
+# CONFIG_KEYBOARD_STOWAWAY is not set
+# CONFIG_KEYBOARD_SUNKBD is not set
+CONFIG_KEYBOARD_XTKBD=y
+# CONFIG_KEYBOARD_CROS_EC is not set
+# CONFIG_INPUT_MOUSE is not set
+CONFIG_INPUT_JOYSTICK=y
+CONFIG_JOYSTICK_ANALOG=m
+CONFIG_JOYSTICK_A3D=m
+CONFIG_JOYSTICK_ADI=m
+CONFIG_JOYSTICK_COBRA=m
+CONFIG_JOYSTICK_GF2K=m
+CONFIG_JOYSTICK_GRIP=m
+CONFIG_JOYSTICK_GRIP_MP=m
+CONFIG_JOYSTICK_GUILLEMOT=m
+CONFIG_JOYSTICK_INTERACT=m
+CONFIG_JOYSTICK_SIDEWINDER=m
+CONFIG_JOYSTICK_TMDC=m
+CONFIG_JOYSTICK_IFORCE=m
+CONFIG_JOYSTICK_IFORCE_232=y
+CONFIG_JOYSTICK_WARRIOR=m
+CONFIG_JOYSTICK_MAGELLAN=m
+CONFIG_JOYSTICK_SPACEORB=m
+CONFIG_JOYSTICK_SPACEBALL=m
+CONFIG_JOYSTICK_STINGER=m
+CONFIG_JOYSTICK_TWIDJOY=m
+CONFIG_JOYSTICK_ZHENHUA=m
+CONFIG_JOYSTICK_AS5011=m
+CONFIG_JOYSTICK_JOYDUMP=m
+# CONFIG_INPUT_TABLET is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+# CONFIG_INPUT_MISC is not set
+# CONFIG_RMI4_CORE is not set
+
+#
+# Hardware I/O ports
+#
+CONFIG_SERIO=y
+CONFIG_ARCH_MIGHT_HAVE_PC_SERIO=y
+CONFIG_SERIO_I8042=y
+CONFIG_SERIO_SERPORT=m
+# CONFIG_SERIO_CT82C710 is not set
+# CONFIG_SERIO_PCIPS2 is not set
+CONFIG_SERIO_LIBPS2=y
+# CONFIG_SERIO_RAW is not set
+# CONFIG_SERIO_ALTERA_PS2 is not set
+# CONFIG_SERIO_PS2MULT is not set
+# CONFIG_SERIO_ARC_PS2 is not set
+# CONFIG_USERIO is not set
+CONFIG_GAMEPORT=y
+# CONFIG_GAMEPORT_NS558 is not set
+# CONFIG_GAMEPORT_L4 is not set
+# CONFIG_GAMEPORT_EMU10K1 is not set
+# CONFIG_GAMEPORT_FM801 is not set
+
+#
+# Character devices
+#
+CONFIG_TTY=y
+CONFIG_VT=y
+CONFIG_CONSOLE_TRANSLATIONS=y
+CONFIG_VT_CONSOLE=y
+CONFIG_HW_CONSOLE=y
+CONFIG_VT_HW_CONSOLE_BINDING=y
+CONFIG_UNIX98_PTYS=y
+CONFIG_LEGACY_PTYS=y
+CONFIG_LEGACY_PTY_COUNT=32
+CONFIG_SERIAL_NONSTANDARD=y
+# CONFIG_ROCKETPORT is not set
+# CONFIG_CYCLADES is not set
+# CONFIG_MOXA_INTELLIO is not set
+# CONFIG_MOXA_SMARTIO is not set
+# CONFIG_SYNCLINK is not set
+# CONFIG_SYNCLINKMP is not set
+# CONFIG_SYNCLINK_GT is not set
+# CONFIG_NOZOMI is not set
+# CONFIG_ISI is not set
+# CONFIG_N_HDLC is not set
+# CONFIG_N_GSM is not set
+# CONFIG_TRACE_SINK is not set
+CONFIG_DEVMEM=y
+CONFIG_DEVKMEM=y
+
+#
+# Serial drivers
+#
+CONFIG_SERIAL_EARLYCON=y
+CONFIG_SERIAL_8250=y
+# CONFIG_SERIAL_8250_DEPRECATED_OPTIONS is not set
+CONFIG_SERIAL_8250_PNP=y
+# CONFIG_SERIAL_8250_FINTEK is not set
+CONFIG_SERIAL_8250_CONSOLE=y
+CONFIG_SERIAL_8250_DMA=y
+CONFIG_SERIAL_8250_PCI=y
+CONFIG_SERIAL_8250_CS=m
+CONFIG_SERIAL_8250_NR_UARTS=4
+CONFIG_SERIAL_8250_RUNTIME_UARTS=4
+CONFIG_SERIAL_8250_EXTENDED=y
+CONFIG_SERIAL_8250_MANY_PORTS=y
+CONFIG_SERIAL_8250_SHARE_IRQ=y
+CONFIG_SERIAL_8250_DETECT_IRQ=y
+CONFIG_SERIAL_8250_RSA=y
+# CONFIG_SERIAL_8250_FSL is not set
+CONFIG_SERIAL_8250_DW=m
+CONFIG_SERIAL_8250_RT288X=y
+CONFIG_SERIAL_8250_LPSS=y
+CONFIG_SERIAL_8250_MID=m
+# CONFIG_SERIAL_8250_MOXA is not set
+
+#
+# Non-8250 serial port support
+#
+# CONFIG_SERIAL_UARTLITE is not set
+CONFIG_SERIAL_CORE=y
+CONFIG_SERIAL_CORE_CONSOLE=y
+# CONFIG_SERIAL_JSM is not set
+# CONFIG_SERIAL_SCCNXP is not set
+# CONFIG_SERIAL_SC16IS7XX is not set
+# CONFIG_SERIAL_ALTERA_JTAGUART is not set
+# CONFIG_SERIAL_ALTERA_UART is not set
+# CONFIG_SERIAL_ARC is not set
+# CONFIG_SERIAL_RP2 is not set
+# CONFIG_SERIAL_FSL_LPUART is not set
+# CONFIG_TTY_PRINTK is not set
+CONFIG_HVC_DRIVER=y
+CONFIG_VIRTIO_CONSOLE=y
+# CONFIG_IPMI_HANDLER is not set
+CONFIG_HW_RANDOM=y
+CONFIG_HW_RANDOM_TIMERIOMEM=m
+CONFIG_HW_RANDOM_INTEL=m
+CONFIG_HW_RANDOM_AMD=m
+CONFIG_HW_RANDOM_VIA=m
+CONFIG_HW_RANDOM_VIRTIO=y
+CONFIG_NVRAM=m
+# CONFIG_R3964 is not set
+# CONFIG_APPLICOM is not set
+
+#
+# PCMCIA character devices
+#
+CONFIG_SYNCLINK_CS=m
+CONFIG_CARDMAN_4000=m
+CONFIG_CARDMAN_4040=m
+CONFIG_IPWIRELESS=m
+# CONFIG_MWAVE is not set
+CONFIG_RAW_DRIVER=m
+CONFIG_MAX_RAW_DEVS=256
+# CONFIG_HPET is not set
+# CONFIG_HANGCHECK_TIMER is not set
+# CONFIG_TCG_TPM is not set
+# CONFIG_TELCLOCK is not set
+CONFIG_DEVPORT=y
+# CONFIG_XILLYBUS is not set
+
+#
+# I2C support
+#
+CONFIG_I2C=m
+CONFIG_I2C_BOARDINFO=y
+CONFIG_I2C_COMPAT=y
+CONFIG_I2C_CHARDEV=m
+CONFIG_I2C_MUX=m
+
+#
+# Multiplexer I2C Chip support
+#
+CONFIG_I2C_MUX_GPIO=m
+CONFIG_I2C_MUX_PCA9541=m
+CONFIG_I2C_MUX_PCA954x=m
+CONFIG_I2C_MUX_PINCTRL=m
+CONFIG_I2C_MUX_REG=m
+CONFIG_I2C_HELPER_AUTO=y
+CONFIG_I2C_SMBUS=m
+CONFIG_I2C_ALGOBIT=m
+CONFIG_I2C_ALGOPCA=m
+
+#
+# I2C Hardware Bus support
+#
+
+#
+# PC SMBus host controller drivers
+#
+CONFIG_I2C_ALI1535=m
+CONFIG_I2C_ALI1563=m
+CONFIG_I2C_ALI15X3=m
+CONFIG_I2C_AMD756=m
+CONFIG_I2C_AMD756_S4882=m
+CONFIG_I2C_AMD8111=m
+CONFIG_I2C_I801=m
+CONFIG_I2C_ISCH=m
+CONFIG_I2C_ISMT=m
+CONFIG_I2C_PIIX4=m
+CONFIG_I2C_NFORCE2=m
+CONFIG_I2C_NFORCE2_S4985=m
+CONFIG_I2C_SIS5595=m
+CONFIG_I2C_SIS630=m
+CONFIG_I2C_SIS96X=m
+CONFIG_I2C_VIA=m
+CONFIG_I2C_VIAPRO=m
+
+#
+# ACPI drivers
+#
+CONFIG_I2C_SCMI=m
+
+#
+# I2C system bus drivers (mostly embedded / system-on-chip)
+#
+# CONFIG_I2C_CBUS_GPIO is not set
+CONFIG_I2C_DESIGNWARE_CORE=m
+CONFIG_I2C_DESIGNWARE_PLATFORM=m
+CONFIG_I2C_DESIGNWARE_PCI=m
+# CONFIG_I2C_DESIGNWARE_BAYTRAIL is not set
+CONFIG_I2C_EMEV2=m
+CONFIG_I2C_GPIO=m
+CONFIG_I2C_OCORES=m
+CONFIG_I2C_PCA_PLATFORM=m
+# CONFIG_I2C_PXA_PCI is not set
+CONFIG_I2C_SIMTEC=m
+CONFIG_I2C_XILINX=m
+
+#
+# External I2C/SMBus adapter drivers
+#
+CONFIG_I2C_PARPORT_LIGHT=m
+CONFIG_I2C_TAOS_EVM=m
+
+#
+# Other I2C/SMBus bus drivers
+#
+CONFIG_I2C_CROS_EC_TUNNEL=m
+CONFIG_I2C_STUB=m
+CONFIG_I2C_SLAVE=y
+CONFIG_I2C_SLAVE_EEPROM=m
+# CONFIG_I2C_DEBUG_CORE is not set
+# CONFIG_I2C_DEBUG_ALGO is not set
+# CONFIG_I2C_DEBUG_BUS is not set
+# CONFIG_SPI is not set
+# CONFIG_SPMI is not set
+# CONFIG_HSI is not set
+
+#
+# PPS support
+#
+CONFIG_PPS=y
+# CONFIG_PPS_DEBUG is not set
+
+#
+# PPS clients support
+#
+# CONFIG_PPS_CLIENT_KTIMER is not set
+# CONFIG_PPS_CLIENT_LDISC is not set
+# CONFIG_PPS_CLIENT_GPIO is not set
+
+#
+# PPS generators support
+#
+
+#
+# PTP clock support
+#
+CONFIG_PTP_1588_CLOCK=y
+
+#
+# Enable PHYLIB and NETWORK_PHY_TIMESTAMPING to see the additional clocks.
+#
+CONFIG_PINCTRL=y
+
+#
+# Pin controllers
+#
+CONFIG_PINMUX=y
+CONFIG_PINCONF=y
+CONFIG_GENERIC_PINCONF=y
+# CONFIG_DEBUG_PINCTRL is not set
+CONFIG_PINCTRL_AMD=y
+CONFIG_PINCTRL_BAYTRAIL=y
+CONFIG_PINCTRL_CHERRYVIEW=m
+CONFIG_PINCTRL_INTEL=m
+CONFIG_PINCTRL_BROXTON=m
+CONFIG_PINCTRL_SUNRISEPOINT=m
+CONFIG_GPIOLIB=y
+CONFIG_GPIO_DEVRES=y
+CONFIG_GPIO_ACPI=y
+CONFIG_GPIOLIB_IRQCHIP=y
+# CONFIG_DEBUG_GPIO is not set
+CONFIG_GPIO_SYSFS=y
+CONFIG_GPIO_GENERIC=m
+CONFIG_GPIO_MAX730X=m
+
+#
+# Memory mapped GPIO drivers
+#
+# CONFIG_GPIO_AMDPT is not set
+CONFIG_GPIO_DWAPB=m
+CONFIG_GPIO_GENERIC_PLATFORM=m
+CONFIG_GPIO_ICH=m
+CONFIG_GPIO_LYNXPOINT=y
+# CONFIG_GPIO_MOCKUP is not set
+CONFIG_GPIO_VX855=m
+# CONFIG_GPIO_ZX is not set
+
+#
+# Port-mapped I/O GPIO drivers
+#
+CONFIG_GPIO_F7188X=m
+# CONFIG_GPIO_IT87 is not set
+CONFIG_GPIO_SCH=m
+CONFIG_GPIO_SCH311X=m
+
+#
+# I2C GPIO expanders
+#
+CONFIG_GPIO_ADP5588=m
+CONFIG_GPIO_MAX7300=m
+CONFIG_GPIO_MAX732X=m
+CONFIG_GPIO_PCA953X=m
+CONFIG_GPIO_PCF857X=m
+# CONFIG_GPIO_TPIC2810 is not set
+# CONFIG_GPIO_TS4900 is not set
+
+#
+# MFD GPIO expanders
+#
+CONFIG_GPIO_ARIZONA=m
+CONFIG_GPIO_JANZ_TTL=m
+CONFIG_GPIO_LP3943=m
+# CONFIG_GPIO_TPS65218 is not set
+CONFIG_GPIO_WM8994=m
+
+#
+# PCI GPIO expanders
+#
+CONFIG_GPIO_AMD8111=m
+# CONFIG_GPIO_BT8XX is not set
+CONFIG_GPIO_ML_IOH=m
+CONFIG_GPIO_RDC321X=m
+
+#
+# SPI or I2C GPIO expanders
+#
+CONFIG_W1=m
+CONFIG_W1_CON=y
+
+#
+# 1-wire Bus Masters
+#
+CONFIG_W1_MASTER_MATROX=m
+CONFIG_W1_MASTER_DS2482=m
+CONFIG_W1_MASTER_DS1WM=m
+CONFIG_W1_MASTER_GPIO=m
+
+#
+# 1-wire Slaves
+#
+CONFIG_W1_SLAVE_THERM=m
+CONFIG_W1_SLAVE_SMEM=m
+CONFIG_W1_SLAVE_DS2408=m
+# CONFIG_W1_SLAVE_DS2408_READBACK is not set
+CONFIG_W1_SLAVE_DS2413=m
+CONFIG_W1_SLAVE_DS2406=m
+CONFIG_W1_SLAVE_DS2423=m
+CONFIG_W1_SLAVE_DS2431=m
+CONFIG_W1_SLAVE_DS2433=m
+CONFIG_W1_SLAVE_DS2433_CRC=y
+CONFIG_W1_SLAVE_DS2760=m
+CONFIG_W1_SLAVE_DS2780=m
+CONFIG_W1_SLAVE_DS2781=m
+CONFIG_W1_SLAVE_DS28E04=m
+CONFIG_W1_SLAVE_BQ27000=m
+# CONFIG_POWER_AVS is not set
+# CONFIG_POWER_RESET is not set
+CONFIG_POWER_SUPPLY=y
+# CONFIG_POWER_SUPPLY_DEBUG is not set
+CONFIG_PDA_POWER=m
+CONFIG_TEST_POWER=m
+CONFIG_BATTERY_DS2760=m
+CONFIG_BATTERY_DS2780=m
+CONFIG_BATTERY_DS2781=m
+CONFIG_BATTERY_DS2782=m
+CONFIG_BATTERY_SBS=m
+CONFIG_BATTERY_BQ27XXX=m
+CONFIG_BATTERY_BQ27XXX_I2C=m
+CONFIG_BATTERY_MAX17040=m
+CONFIG_BATTERY_MAX17042=m
+CONFIG_CHARGER_PCF50633=m
+CONFIG_CHARGER_MAX8903=m
+CONFIG_CHARGER_LP8727=m
+CONFIG_CHARGER_GPIO=m
+# CONFIG_CHARGER_MANAGER is not set
+CONFIG_CHARGER_BQ2415X=m
+CONFIG_CHARGER_BQ24190=m
+CONFIG_CHARGER_BQ24257=m
+CONFIG_CHARGER_BQ24735=m
+CONFIG_CHARGER_BQ25890=m
+CONFIG_CHARGER_SMB347=m
+CONFIG_CHARGER_TPS65217=m
+CONFIG_BATTERY_GAUGE_LTC2941=m
+CONFIG_CHARGER_RT9455=m
+CONFIG_HWMON=m
+CONFIG_HWMON_VID=m
+# CONFIG_HWMON_DEBUG_CHIP is not set
+
+#
+# Native drivers
+#
+CONFIG_SENSORS_ABITUGURU=m
+CONFIG_SENSORS_ABITUGURU3=m
+CONFIG_SENSORS_AD7414=m
+CONFIG_SENSORS_AD7418=m
+CONFIG_SENSORS_ADM1021=m
+CONFIG_SENSORS_ADM1025=m
+CONFIG_SENSORS_ADM1026=m
+CONFIG_SENSORS_ADM1029=m
+CONFIG_SENSORS_ADM1031=m
+CONFIG_SENSORS_ADM9240=m
+CONFIG_SENSORS_ADT7X10=m
+CONFIG_SENSORS_ADT7410=m
+CONFIG_SENSORS_ADT7411=m
+CONFIG_SENSORS_ADT7462=m
+CONFIG_SENSORS_ADT7470=m
+CONFIG_SENSORS_ADT7475=m
+CONFIG_SENSORS_ASC7621=m
+CONFIG_SENSORS_K8TEMP=m
+CONFIG_SENSORS_K10TEMP=m
+CONFIG_SENSORS_FAM15H_POWER=m
+CONFIG_SENSORS_APPLESMC=m
+CONFIG_SENSORS_ASB100=m
+CONFIG_SENSORS_ATXP1=m
+CONFIG_SENSORS_DS620=m
+CONFIG_SENSORS_DS1621=m
+CONFIG_SENSORS_DELL_SMM=m
+CONFIG_SENSORS_I5K_AMB=m
+CONFIG_SENSORS_F71805F=m
+CONFIG_SENSORS_F71882FG=m
+CONFIG_SENSORS_F75375S=m
+CONFIG_SENSORS_MC13783_ADC=m
+CONFIG_SENSORS_FSCHMD=m
+CONFIG_SENSORS_GL518SM=m
+CONFIG_SENSORS_GL520SM=m
+CONFIG_SENSORS_G760A=m
+CONFIG_SENSORS_G762=m
+CONFIG_SENSORS_GPIO_FAN=m
+CONFIG_SENSORS_HIH6130=m
+CONFIG_SENSORS_I5500=m
+CONFIG_SENSORS_CORETEMP=m
+CONFIG_SENSORS_IT87=m
+CONFIG_SENSORS_JC42=m
+CONFIG_SENSORS_POWR1220=m
+CONFIG_SENSORS_LINEAGE=m
+CONFIG_SENSORS_LTC2945=m
+# CONFIG_SENSORS_LTC2990 is not set
+CONFIG_SENSORS_LTC4151=m
+CONFIG_SENSORS_LTC4215=m
+CONFIG_SENSORS_LTC4222=m
+CONFIG_SENSORS_LTC4245=m
+CONFIG_SENSORS_LTC4260=m
+CONFIG_SENSORS_LTC4261=m
+CONFIG_SENSORS_MAX16065=m
+CONFIG_SENSORS_MAX1619=m
+CONFIG_SENSORS_MAX1668=m
+CONFIG_SENSORS_MAX197=m
+CONFIG_SENSORS_MAX6639=m
+CONFIG_SENSORS_MAX6642=m
+CONFIG_SENSORS_MAX6650=m
+CONFIG_SENSORS_MAX6697=m
+CONFIG_SENSORS_MAX31790=m
+CONFIG_SENSORS_MCP3021=m
+CONFIG_SENSORS_MENF21BMC_HWMON=m
+CONFIG_SENSORS_LM63=m
+CONFIG_SENSORS_LM73=m
+CONFIG_SENSORS_LM75=m
+CONFIG_SENSORS_LM77=m
+CONFIG_SENSORS_LM78=m
+CONFIG_SENSORS_LM80=m
+CONFIG_SENSORS_LM83=m
+CONFIG_SENSORS_LM85=m
+CONFIG_SENSORS_LM87=m
+CONFIG_SENSORS_LM90=m
+CONFIG_SENSORS_LM92=m
+CONFIG_SENSORS_LM93=m
+CONFIG_SENSORS_LM95234=m
+CONFIG_SENSORS_LM95241=m
+CONFIG_SENSORS_LM95245=m
+CONFIG_SENSORS_PC87360=m
+CONFIG_SENSORS_PC87427=m
+CONFIG_SENSORS_NTC_THERMISTOR=m
+CONFIG_SENSORS_NCT6683=m
+CONFIG_SENSORS_NCT6775=m
+CONFIG_SENSORS_NCT7802=m
+CONFIG_SENSORS_NCT7904=m
+CONFIG_SENSORS_PCF8591=m
+CONFIG_PMBUS=m
+CONFIG_SENSORS_PMBUS=m
+CONFIG_SENSORS_ADM1275=m
+CONFIG_SENSORS_LM25066=m
+CONFIG_SENSORS_LTC2978=m
+CONFIG_SENSORS_LTC2978_REGULATOR=y
+# CONFIG_SENSORS_LTC3815 is not set
+CONFIG_SENSORS_MAX16064=m
+CONFIG_SENSORS_MAX20751=m
+CONFIG_SENSORS_MAX34440=m
+CONFIG_SENSORS_MAX8688=m
+CONFIG_SENSORS_TPS40422=m
+CONFIG_SENSORS_UCD9000=m
+CONFIG_SENSORS_UCD9200=m
+CONFIG_SENSORS_ZL6100=m
+CONFIG_SENSORS_SHT15=m
+CONFIG_SENSORS_SHT21=m
+# CONFIG_SENSORS_SHT3x is not set
+CONFIG_SENSORS_SHTC1=m
+CONFIG_SENSORS_SIS5595=m
+CONFIG_SENSORS_DME1737=m
+CONFIG_SENSORS_EMC1403=m
+CONFIG_SENSORS_EMC2103=m
+CONFIG_SENSORS_EMC6W201=m
+CONFIG_SENSORS_SMSC47M1=m
+CONFIG_SENSORS_SMSC47M192=m
+CONFIG_SENSORS_SMSC47B397=m
+# CONFIG_SENSORS_SCH56XX_COMMON is not set
+CONFIG_SENSORS_SMM665=m
+CONFIG_SENSORS_ADC128D818=m
+CONFIG_SENSORS_ADS1015=m
+CONFIG_SENSORS_ADS7828=m
+CONFIG_SENSORS_AMC6821=m
+CONFIG_SENSORS_INA209=m
+CONFIG_SENSORS_INA2XX=m
+# CONFIG_SENSORS_INA3221 is not set
+CONFIG_SENSORS_TC74=m
+CONFIG_SENSORS_THMC50=m
+CONFIG_SENSORS_TMP102=m
+CONFIG_SENSORS_TMP103=m
+CONFIG_SENSORS_TMP401=m
+CONFIG_SENSORS_TMP421=m
+CONFIG_SENSORS_VIA_CPUTEMP=m
+CONFIG_SENSORS_VIA686A=m
+CONFIG_SENSORS_VT1211=m
+CONFIG_SENSORS_VT8231=m
+CONFIG_SENSORS_W83781D=m
+CONFIG_SENSORS_W83791D=m
+CONFIG_SENSORS_W83792D=m
+CONFIG_SENSORS_W83793=m
+CONFIG_SENSORS_W83795=m
+# CONFIG_SENSORS_W83795_FANCTRL is not set
+CONFIG_SENSORS_W83L785TS=m
+CONFIG_SENSORS_W83L786NG=m
+CONFIG_SENSORS_W83627HF=m
+CONFIG_SENSORS_W83627EHF=m
+
+#
+# ACPI drivers
+#
+CONFIG_SENSORS_ACPI_POWER=m
+CONFIG_SENSORS_ATK0110=m
+CONFIG_THERMAL=y
+CONFIG_THERMAL_WRITABLE_TRIPS=y
+CONFIG_THERMAL_DEFAULT_GOV_STEP_WISE=y
+# CONFIG_THERMAL_DEFAULT_GOV_FAIR_SHARE is not set
+# CONFIG_THERMAL_DEFAULT_GOV_USER_SPACE is not set
+# CONFIG_THERMAL_DEFAULT_GOV_POWER_ALLOCATOR is not set
+CONFIG_THERMAL_GOV_FAIR_SHARE=y
+CONFIG_THERMAL_GOV_STEP_WISE=y
+CONFIG_THERMAL_GOV_BANG_BANG=y
+CONFIG_THERMAL_GOV_USER_SPACE=y
+CONFIG_THERMAL_GOV_POWER_ALLOCATOR=y
+CONFIG_THERMAL_EMULATION=y
+CONFIG_INTEL_POWERCLAMP=m
+CONFIG_X86_PKG_TEMP_THERMAL=m
+CONFIG_INTEL_SOC_DTS_IOSF_CORE=m
+CONFIG_INTEL_SOC_DTS_THERMAL=m
+
+#
+# ACPI INT340X thermal drivers
+#
+CONFIG_INT340X_THERMAL=m
+CONFIG_ACPI_THERMAL_REL=m
+# CONFIG_INT3406_THERMAL is not set
+CONFIG_INTEL_PCH_THERMAL=m
+# CONFIG_WATCHDOG is not set
+CONFIG_SSB_POSSIBLE=y
+
+#
+# Sonics Silicon Backplane
+#
+CONFIG_SSB=m
+CONFIG_SSB_SPROM=y
+CONFIG_SSB_PCIHOST_POSSIBLE=y
+CONFIG_SSB_PCIHOST=y
+# CONFIG_SSB_B43_PCI_BRIDGE is not set
+CONFIG_SSB_PCMCIAHOST_POSSIBLE=y
+CONFIG_SSB_PCMCIAHOST=y
+# CONFIG_SSB_SILENT is not set
+# CONFIG_SSB_DEBUG is not set
+CONFIG_SSB_DRIVER_PCICORE_POSSIBLE=y
+CONFIG_SSB_DRIVER_PCICORE=y
+# CONFIG_SSB_DRIVER_GPIO is not set
+CONFIG_BCMA_POSSIBLE=y
+
+#
+# Broadcom specific AMBA
+#
+CONFIG_BCMA=m
+CONFIG_BCMA_HOST_PCI_POSSIBLE=y
+CONFIG_BCMA_HOST_PCI=y
+# CONFIG_BCMA_HOST_SOC is not set
+CONFIG_BCMA_DRIVER_PCI=y
+# CONFIG_BCMA_DRIVER_GMAC_CMN is not set
+# CONFIG_BCMA_DRIVER_GPIO is not set
+# CONFIG_BCMA_DEBUG is not set
+
+#
+# Multifunction device drivers
+#
+CONFIG_MFD_CORE=y
+CONFIG_MFD_BCM590XX=m
+# CONFIG_MFD_AXP20X_I2C is not set
+CONFIG_MFD_CROS_EC=m
+CONFIG_MFD_CROS_EC_I2C=m
+# CONFIG_MFD_DA9062 is not set
+# CONFIG_MFD_DA9063 is not set
+# CONFIG_MFD_DA9150 is not set
+# CONFIG_MFD_EXYNOS_LPASS is not set
+CONFIG_MFD_MC13XXX=m
+CONFIG_MFD_MC13XXX_I2C=m
+CONFIG_HTC_PASIC3=m
+CONFIG_MFD_INTEL_QUARK_I2C_GPIO=m
+CONFIG_LPC_ICH=m
+CONFIG_LPC_SCH=m
+CONFIG_MFD_INTEL_LPSS=m
+CONFIG_MFD_INTEL_LPSS_ACPI=m
+CONFIG_MFD_INTEL_LPSS_PCI=m
+CONFIG_MFD_JANZ_CMODIO=m
+# CONFIG_MFD_KEMPLD is not set
+# CONFIG_MFD_88PM800 is not set
+# CONFIG_MFD_88PM805 is not set
+# CONFIG_MFD_MAX14577 is not set
+# CONFIG_MFD_MAX77693 is not set
+# CONFIG_MFD_MAX8907 is not set
+CONFIG_MFD_MT6397=m
+CONFIG_MFD_MENF21BMC=m
+CONFIG_MFD_RETU=m
+CONFIG_MFD_PCF50633=m
+CONFIG_PCF50633_ADC=m
+CONFIG_PCF50633_GPIO=m
+CONFIG_MFD_RDC321X=m
+CONFIG_MFD_RTSX_PCI=m
+# CONFIG_MFD_RT5033 is not set
+CONFIG_MFD_SI476X_CORE=m
+CONFIG_MFD_SM501=m
+# CONFIG_MFD_SM501_GPIO is not set
+CONFIG_MFD_SKY81452=m
+# CONFIG_ABX500_CORE is not set
+CONFIG_MFD_SYSCON=y
+CONFIG_MFD_TI_AM335X_TSCADC=m
+CONFIG_MFD_LP3943=m
+CONFIG_TPS6105X=m
+CONFIG_TPS65010=m
+CONFIG_TPS6507X=m
+# CONFIG_MFD_TPS65086 is not set
+CONFIG_MFD_TPS65217=m
+# CONFIG_MFD_TI_LP873X is not set
+CONFIG_MFD_TPS65218=m
+# CONFIG_MFD_TPS65912_I2C is not set
+CONFIG_MFD_WL1273_CORE=m
+CONFIG_MFD_LM3533=m
+# CONFIG_MFD_TMIO is not set
+CONFIG_MFD_VX855=m
+CONFIG_MFD_ARIZONA=y
+CONFIG_MFD_ARIZONA_I2C=m
+# CONFIG_MFD_CS47L24 is not set
+CONFIG_MFD_WM5102=y
+CONFIG_MFD_WM5110=y
+CONFIG_MFD_WM8997=y
+# CONFIG_MFD_WM8998 is not set
+CONFIG_MFD_WM8994=m
+CONFIG_REGULATOR=y
+# CONFIG_REGULATOR_DEBUG is not set
+CONFIG_REGULATOR_FIXED_VOLTAGE=m
+# CONFIG_REGULATOR_VIRTUAL_CONSUMER is not set
+CONFIG_REGULATOR_USERSPACE_CONSUMER=m
+CONFIG_REGULATOR_ACT8865=m
+CONFIG_REGULATOR_AD5398=m
+CONFIG_REGULATOR_ANATOP=m
+CONFIG_REGULATOR_BCM590XX=m
+CONFIG_REGULATOR_DA9210=m
+CONFIG_REGULATOR_DA9211=m
+CONFIG_REGULATOR_FAN53555=m
+CONFIG_REGULATOR_GPIO=m
+CONFIG_REGULATOR_ISL9305=m
+CONFIG_REGULATOR_ISL6271A=m
+CONFIG_REGULATOR_LP3971=m
+CONFIG_REGULATOR_LP3972=m
+CONFIG_REGULATOR_LP872X=m
+CONFIG_REGULATOR_LP8755=m
+CONFIG_REGULATOR_LTC3589=m
+# CONFIG_REGULATOR_LTC3676 is not set
+CONFIG_REGULATOR_MAX1586=m
+CONFIG_REGULATOR_MAX8649=m
+CONFIG_REGULATOR_MAX8660=m
+CONFIG_REGULATOR_MAX8952=m
+CONFIG_REGULATOR_MC13XXX_CORE=m
+CONFIG_REGULATOR_MC13783=m
+CONFIG_REGULATOR_MC13892=m
+CONFIG_REGULATOR_MT6311=m
+# CONFIG_REGULATOR_MT6323 is not set
+CONFIG_REGULATOR_MT6397=m
+CONFIG_REGULATOR_PCF50633=m
+CONFIG_REGULATOR_PFUZE100=m
+# CONFIG_REGULATOR_PV88060 is not set
+# CONFIG_REGULATOR_PV88080 is not set
+# CONFIG_REGULATOR_PV88090 is not set
+CONFIG_REGULATOR_SKY81452=m
+CONFIG_REGULATOR_TPS51632=m
+CONFIG_REGULATOR_TPS6105X=m
+CONFIG_REGULATOR_TPS62360=m
+CONFIG_REGULATOR_TPS65023=m
+CONFIG_REGULATOR_TPS6507X=m
+CONFIG_REGULATOR_TPS65217=m
+CONFIG_REGULATOR_WM8994=m
+# CONFIG_MEDIA_SUPPORT is not set
+
+#
+# Graphics support
+#
+# CONFIG_AGP is not set
+CONFIG_INTEL_GTT=m
+CONFIG_VGA_ARB=y
+CONFIG_VGA_ARB_MAX_GPUS=16
+# CONFIG_VGA_SWITCHEROO is not set
+CONFIG_DRM=m
+CONFIG_DRM_MIPI_DSI=y
+# CONFIG_DRM_DP_AUX_CHARDEV is not set
+CONFIG_DRM_KMS_HELPER=m
+CONFIG_DRM_KMS_FB_HELPER=y
+CONFIG_DRM_FBDEV_EMULATION=y
+CONFIG_DRM_LOAD_EDID_FIRMWARE=y
+CONFIG_DRM_TTM=m
+
+#
+# I2C encoder or helper chips
+#
+CONFIG_DRM_I2C_CH7006=m
+CONFIG_DRM_I2C_SIL164=m
+CONFIG_DRM_I2C_NXP_TDA998X=m
+# CONFIG_DRM_RADEON is not set
+# CONFIG_DRM_AMDGPU is not set
+
+#
+# ACP (Audio CoProcessor) Configuration
+#
+# CONFIG_DRM_NOUVEAU is not set
+CONFIG_DRM_I915=m
+# CONFIG_DRM_I915_PRELIMINARY_HW_SUPPORT is not set
+CONFIG_DRM_I915_USERPTR=y
+# CONFIG_DRM_I915_GVT is not set
+
+#
+# drm/i915 Debugging
+#
+# CONFIG_DRM_I915_WERROR is not set
+# CONFIG_DRM_I915_DEBUG is not set
+# CONFIG_DRM_VGEM is not set
+CONFIG_DRM_VMWGFX=m
+# CONFIG_DRM_VMWGFX_FBCON is not set
+CONFIG_DRM_GMA500=m
+CONFIG_DRM_GMA600=y
+CONFIG_DRM_GMA3600=y
+# CONFIG_DRM_AST is not set
+# CONFIG_DRM_MGAG200 is not set
+# CONFIG_DRM_CIRRUS_QEMU is not set
+# CONFIG_DRM_QXL is not set
+CONFIG_DRM_BOCHS=m
+# CONFIG_DRM_VIRTIO_GPU is not set
+CONFIG_DRM_PANEL=y
+
+#
+# Display Panels
+#
+CONFIG_DRM_BRIDGE=y
+
+#
+# Display Interface Bridges
+#
+# CONFIG_DRM_ANALOGIX_ANX78XX is not set
+# CONFIG_DRM_LEGACY is not set
+
+#
+# Frame buffer Devices
+#
+CONFIG_FB=y
+CONFIG_FIRMWARE_EDID=y
+CONFIG_FB_CMDLINE=y
+CONFIG_FB_NOTIFY=y
+CONFIG_FB_DDC=m
+CONFIG_FB_BOOT_VESA_SUPPORT=y
+CONFIG_FB_CFB_FILLRECT=y
+CONFIG_FB_CFB_COPYAREA=y
+CONFIG_FB_CFB_IMAGEBLIT=y
+# CONFIG_FB_CFB_REV_PIXELS_IN_BYTE is not set
+CONFIG_FB_SYS_FILLRECT=m
+CONFIG_FB_SYS_COPYAREA=m
+CONFIG_FB_SYS_IMAGEBLIT=m
+# CONFIG_FB_FOREIGN_ENDIAN is not set
+CONFIG_FB_SYS_FOPS=m
+CONFIG_FB_DEFERRED_IO=y
+CONFIG_FB_HECUBA=m
+CONFIG_FB_SVGALIB=m
+# CONFIG_FB_MACMODES is not set
+CONFIG_FB_BACKLIGHT=y
+CONFIG_FB_MODE_HELPERS=y
+CONFIG_FB_TILEBLITTING=y
+
+#
+# Frame buffer hardware drivers
+#
+CONFIG_FB_CIRRUS=m
+CONFIG_FB_PM2=m
+# CONFIG_FB_PM2_FIFO_DISCONNECT is not set
+CONFIG_FB_CYBER2000=m
+CONFIG_FB_CYBER2000_DDC=y
+CONFIG_FB_ARC=m
+# CONFIG_FB_ASILIANT is not set
+# CONFIG_FB_IMSTT is not set
+CONFIG_FB_VGA16=m
+# CONFIG_FB_UVESA is not set
+CONFIG_FB_VESA=y
+CONFIG_FB_N411=m
+CONFIG_FB_HGA=m
+CONFIG_FB_OPENCORES=m
+CONFIG_FB_S1D13XXX=m
+CONFIG_FB_NVIDIA=m
+CONFIG_FB_NVIDIA_I2C=y
+# CONFIG_FB_NVIDIA_DEBUG is not set
+CONFIG_FB_NVIDIA_BACKLIGHT=y
+CONFIG_FB_RIVA=m
+CONFIG_FB_RIVA_I2C=y
+# CONFIG_FB_RIVA_DEBUG is not set
+CONFIG_FB_RIVA_BACKLIGHT=y
+CONFIG_FB_I740=m
+CONFIG_FB_LE80578=m
+CONFIG_FB_CARILLO_RANCH=m
+CONFIG_FB_MATROX=m
+CONFIG_FB_MATROX_MILLENIUM=y
+CONFIG_FB_MATROX_MYSTIQUE=y
+CONFIG_FB_MATROX_G=y
+CONFIG_FB_MATROX_I2C=m
+CONFIG_FB_MATROX_MAVEN=m
+CONFIG_FB_RADEON=m
+CONFIG_FB_RADEON_I2C=y
+CONFIG_FB_RADEON_BACKLIGHT=y
+# CONFIG_FB_RADEON_DEBUG is not set
+CONFIG_FB_ATY128=m
+CONFIG_FB_ATY128_BACKLIGHT=y
+CONFIG_FB_ATY=m
+CONFIG_FB_ATY_CT=y
+CONFIG_FB_ATY_GENERIC_LCD=y
+CONFIG_FB_ATY_GX=y
+CONFIG_FB_ATY_BACKLIGHT=y
+# CONFIG_FB_S3 is not set
+# CONFIG_FB_SAVAGE is not set
+CONFIG_FB_SIS=m
+CONFIG_FB_SIS_300=y
+CONFIG_FB_SIS_315=y
+CONFIG_FB_VIA=m
+# CONFIG_FB_VIA_DIRECT_PROCFS is not set
+CONFIG_FB_VIA_X_COMPATIBILITY=y
+CONFIG_FB_NEOMAGIC=m
+CONFIG_FB_KYRO=m
+CONFIG_FB_3DFX=m
+# CONFIG_FB_3DFX_ACCEL is not set
+CONFIG_FB_3DFX_I2C=y
+CONFIG_FB_VOODOO1=m
+CONFIG_FB_VT8623=m
+CONFIG_FB_TRIDENT=m
+CONFIG_FB_ARK=m
+CONFIG_FB_PM3=m
+CONFIG_FB_CARMINE=m
+CONFIG_FB_CARMINE_DRAM_EVAL=y
+# CONFIG_CARMINE_DRAM_CUSTOM is not set
+# CONFIG_FB_SM501 is not set
+CONFIG_FB_IBM_GXT4500=m
+# CONFIG_FB_VIRTUAL is not set
+CONFIG_FB_METRONOME=m
+CONFIG_FB_MB862XX=m
+CONFIG_FB_MB862XX_PCI_GDC=y
+CONFIG_FB_MB862XX_I2C=y
+CONFIG_FB_BROADSHEET=m
+CONFIG_FB_AUO_K190X=m
+CONFIG_FB_AUO_K1900=m
+CONFIG_FB_AUO_K1901=m
+# CONFIG_FB_SIMPLE is not set
+CONFIG_FB_SM712=m
+CONFIG_BACKLIGHT_LCD_SUPPORT=y
+CONFIG_LCD_CLASS_DEVICE=m
+CONFIG_LCD_PLATFORM=m
+CONFIG_BACKLIGHT_CLASS_DEVICE=y
+CONFIG_BACKLIGHT_GENERIC=m
+CONFIG_BACKLIGHT_LM3533=m
+CONFIG_BACKLIGHT_CARILLO_RANCH=m
+CONFIG_BACKLIGHT_APPLE=m
+CONFIG_BACKLIGHT_PM8941_WLED=m
+CONFIG_BACKLIGHT_SAHARA=m
+CONFIG_BACKLIGHT_ADP8860=m
+CONFIG_BACKLIGHT_ADP8870=m
+CONFIG_BACKLIGHT_PCF50633=m
+CONFIG_BACKLIGHT_LM3639=m
+CONFIG_BACKLIGHT_SKY81452=m
+CONFIG_BACKLIGHT_TPS65217=m
+CONFIG_BACKLIGHT_GPIO=m
+CONFIG_BACKLIGHT_LV5207LP=m
+CONFIG_BACKLIGHT_BD6107=m
+CONFIG_VGASTATE=m
+CONFIG_HDMI=y
+
+#
+# Console display driver support
+#
+CONFIG_VGA_CONSOLE=y
+CONFIG_VGACON_SOFT_SCROLLBACK=y
+CONFIG_VGACON_SOFT_SCROLLBACK_SIZE=64
+CONFIG_DUMMY_CONSOLE=y
+CONFIG_DUMMY_CONSOLE_COLUMNS=80
+CONFIG_DUMMY_CONSOLE_ROWS=25
+CONFIG_FRAMEBUFFER_CONSOLE=y
+CONFIG_FRAMEBUFFER_CONSOLE_DETECT_PRIMARY=y
+CONFIG_FRAMEBUFFER_CONSOLE_ROTATION=y
+CONFIG_LOGO=y
+# CONFIG_LOGO_LINUX_MONO is not set
+# CONFIG_LOGO_LINUX_VGA16 is not set
+CONFIG_LOGO_LINUX_CLUT224=y
+# CONFIG_SOUND is not set
+
+#
+# HID support
+#
+CONFIG_HID=m
+CONFIG_HID_BATTERY_STRENGTH=y
+CONFIG_HIDRAW=y
+CONFIG_UHID=m
+CONFIG_HID_GENERIC=m
+
+#
+# Special HID drivers
+#
+CONFIG_HID_A4TECH=m
+CONFIG_HID_ACRUX=m
+CONFIG_HID_ACRUX_FF=y
+CONFIG_HID_APPLE=m
+# CONFIG_HID_ASUS is not set
+CONFIG_HID_AUREAL=m
+CONFIG_HID_BELKIN=m
+CONFIG_HID_CHERRY=m
+CONFIG_HID_CHICONY=m
+# CONFIG_HID_CMEDIA is not set
+CONFIG_HID_CYPRESS=m
+CONFIG_HID_DRAGONRISE=m
+CONFIG_DRAGONRISE_FF=y
+CONFIG_HID_EMS_FF=m
+CONFIG_HID_ELECOM=m
+CONFIG_HID_EZKEY=m
+CONFIG_HID_GEMBIRD=m
+CONFIG_HID_GFRM=m
+CONFIG_HID_KEYTOUCH=m
+CONFIG_HID_KYE=m
+CONFIG_HID_WALTOP=m
+CONFIG_HID_GYRATION=m
+CONFIG_HID_ICADE=m
+CONFIG_HID_TWINHAN=m
+CONFIG_HID_KENSINGTON=m
+CONFIG_HID_LCPOWER=m
+CONFIG_HID_LED=m
+CONFIG_HID_LENOVO=m
+CONFIG_HID_LOGITECH=m
+CONFIG_HID_LOGITECH_DJ=m
+CONFIG_HID_LOGITECH_HIDPP=m
+CONFIG_LOGITECH_FF=y
+CONFIG_LOGIRUMBLEPAD2_FF=y
+CONFIG_LOGIG940_FF=y
+CONFIG_LOGIWHEELS_FF=y
+CONFIG_HID_MAGICMOUSE=m
+CONFIG_HID_MICROSOFT=m
+CONFIG_HID_MONTEREY=m
+CONFIG_HID_MULTITOUCH=m
+CONFIG_HID_ORTEK=m
+CONFIG_HID_PANTHERLORD=m
+CONFIG_PANTHERLORD_FF=y
+CONFIG_HID_PETALYNX=m
+CONFIG_HID_PICOLCD=m
+CONFIG_HID_PICOLCD_FB=y
+CONFIG_HID_PICOLCD_BACKLIGHT=y
+CONFIG_HID_PICOLCD_LCD=y
+CONFIG_HID_PICOLCD_LEDS=y
+CONFIG_HID_PLANTRONICS=m
+CONFIG_HID_PRIMAX=m
+CONFIG_HID_SAITEK=m
+CONFIG_HID_SAMSUNG=m
+CONFIG_HID_SPEEDLINK=m
+CONFIG_HID_STEELSERIES=m
+CONFIG_HID_SUNPLUS=m
+CONFIG_HID_RMI=m
+CONFIG_HID_GREENASIA=m
+CONFIG_GREENASIA_FF=y
+CONFIG_HID_SMARTJOYPLUS=m
+CONFIG_SMARTJOYPLUS_FF=y
+CONFIG_HID_TIVO=m
+CONFIG_HID_TOPSEED=m
+CONFIG_HID_THINGM=m
+CONFIG_HID_THRUSTMASTER=m
+CONFIG_THRUSTMASTER_FF=y
+CONFIG_HID_WACOM=m
+CONFIG_HID_WIIMOTE=m
+CONFIG_HID_XINMO=m
+CONFIG_HID_ZEROPLUS=m
+CONFIG_ZEROPLUS_FF=y
+CONFIG_HID_ZYDACRON=m
+CONFIG_HID_SENSOR_HUB=m
+CONFIG_HID_SENSOR_CUSTOM_SENSOR=m
+# CONFIG_HID_ALPS is not set
+
+#
+# I2C HID support
+#
+CONFIG_I2C_HID=m
+
+#
+# Intel ISH HID support
+#
+# CONFIG_INTEL_ISH_HID is not set
+CONFIG_USB_OHCI_LITTLE_ENDIAN=y
+# CONFIG_USB_SUPPORT is not set
+# CONFIG_UWB is not set
+# CONFIG_MMC is not set
+# CONFIG_MEMSTICK is not set
+CONFIG_NEW_LEDS=y
+CONFIG_LEDS_CLASS=y
+CONFIG_LEDS_CLASS_FLASH=m
+
+#
+# LED drivers
+#
+CONFIG_LEDS_LM3530=m
+CONFIG_LEDS_LM3533=m
+CONFIG_LEDS_LM3642=m
+CONFIG_LEDS_PCA9532=m
+# CONFIG_LEDS_PCA9532_GPIO is not set
+CONFIG_LEDS_GPIO=m
+CONFIG_LEDS_LP3944=m
+# CONFIG_LEDS_LP3952 is not set
+CONFIG_LEDS_LP55XX_COMMON=m
+CONFIG_LEDS_LP5521=m
+CONFIG_LEDS_LP5523=m
+CONFIG_LEDS_LP5562=m
+CONFIG_LEDS_LP8501=m
+CONFIG_LEDS_LP8860=m
+CONFIG_LEDS_CLEVO_MAIL=m
+CONFIG_LEDS_PCA955X=m
+CONFIG_LEDS_PCA963X=m
+CONFIG_LEDS_REGULATOR=m
+CONFIG_LEDS_BD2802=m
+CONFIG_LEDS_INTEL_SS4200=m
+CONFIG_LEDS_LT3593=m
+CONFIG_LEDS_MC13783=m
+CONFIG_LEDS_TCA6507=m
+CONFIG_LEDS_TLC591XX=m
+CONFIG_LEDS_LM355x=m
+CONFIG_LEDS_MENF21BMC=m
+
+#
+# LED driver for blink(1) USB RGB LED is under Special HID drivers (HID_THINGM)
+#
+CONFIG_LEDS_BLINKM=m
+# CONFIG_LEDS_MLXCPLD is not set
+
+#
+# LED Triggers
+#
+CONFIG_LEDS_TRIGGERS=y
+CONFIG_LEDS_TRIGGER_TIMER=m
+CONFIG_LEDS_TRIGGER_ONESHOT=m
+# CONFIG_LEDS_TRIGGER_DISK is not set
+CONFIG_LEDS_TRIGGER_HEARTBEAT=m
+CONFIG_LEDS_TRIGGER_BACKLIGHT=m
+# CONFIG_LEDS_TRIGGER_CPU is not set
+CONFIG_LEDS_TRIGGER_GPIO=m
+CONFIG_LEDS_TRIGGER_DEFAULT_ON=m
+
+#
+# iptables trigger is under Netfilter config (LED target)
+#
+CONFIG_LEDS_TRIGGER_TRANSIENT=m
+CONFIG_LEDS_TRIGGER_CAMERA=m
+# CONFIG_LEDS_TRIGGER_PANIC is not set
+# CONFIG_ACCESSIBILITY is not set
+# CONFIG_INFINIBAND is not set
+CONFIG_EDAC_ATOMIC_SCRUB=y
+CONFIG_EDAC_SUPPORT=y
+# CONFIG_EDAC is not set
+CONFIG_RTC_LIB=y
+CONFIG_RTC_MC146818_LIB=y
+# CONFIG_RTC_CLASS is not set
+CONFIG_DMADEVICES=y
+# CONFIG_DMADEVICES_DEBUG is not set
+
+#
+# DMA Devices
+#
+CONFIG_DMA_ENGINE=y
+CONFIG_DMA_VIRTUAL_CHANNELS=m
+CONFIG_DMA_ACPI=y
+CONFIG_INTEL_IDMA64=m
+CONFIG_INTEL_IOATDMA=m
+# CONFIG_QCOM_HIDMA_MGMT is not set
+# CONFIG_QCOM_HIDMA is not set
+CONFIG_DW_DMAC_CORE=y
+CONFIG_DW_DMAC=m
+CONFIG_DW_DMAC_PCI=y
+CONFIG_HSU_DMA=m
+
+#
+# DMA Clients
+#
+# CONFIG_ASYNC_TX_DMA is not set
+CONFIG_DMATEST=m
+CONFIG_DMA_ENGINE_RAID=y
+
+#
+# DMABUF options
+#
+# CONFIG_SYNC_FILE is not set
+CONFIG_DCA=m
+# CONFIG_AUXDISPLAY is not set
+CONFIG_UIO=m
+CONFIG_UIO_CIF=m
+CONFIG_UIO_PDRV_GENIRQ=m
+CONFIG_UIO_DMEM_GENIRQ=m
+CONFIG_UIO_AEC=m
+CONFIG_UIO_SERCOS3=m
+CONFIG_UIO_PCI_GENERIC=m
+CONFIG_UIO_NETX=m
+CONFIG_UIO_PRUSS=m
+CONFIG_UIO_MF624=m
+# CONFIG_VIRT_DRIVERS is not set
+CONFIG_VIRTIO=y
+
+#
+# Virtio drivers
+#
+CONFIG_VIRTIO_PCI=y
+CONFIG_VIRTIO_PCI_LEGACY=y
+CONFIG_VIRTIO_BALLOON=y
+CONFIG_VIRTIO_INPUT=m
+CONFIG_VIRTIO_MMIO=y
+# CONFIG_VIRTIO_MMIO_CMDLINE_DEVICES is not set
+
+#
+# Microsoft Hyper-V guest support
+#
+# CONFIG_STAGING is not set
+# CONFIG_X86_PLATFORM_DEVICES is not set
+CONFIG_CHROME_PLATFORMS=y
+CONFIG_CHROMEOS_LAPTOP=m
+CONFIG_CHROMEOS_PSTORE=m
+CONFIG_CROS_EC_CHARDEV=m
+CONFIG_CROS_EC_LPC=m
+CONFIG_CROS_EC_PROTO=y
+# CONFIG_CROS_KBD_LED_BACKLIGHT is not set
+CONFIG_CLKDEV_LOOKUP=y
+CONFIG_HAVE_CLK_PREPARE=y
+CONFIG_COMMON_CLK=y
+
+#
+# Common Clock Framework
+#
+CONFIG_COMMON_CLK_SI5351=m
+CONFIG_COMMON_CLK_CDCE706=m
+# CONFIG_COMMON_CLK_CS2000_CP is not set
+# CONFIG_COMMON_CLK_NXP is not set
+# CONFIG_COMMON_CLK_PXA is not set
+# CONFIG_COMMON_CLK_PIC32 is not set
+# CONFIG_COMMON_CLK_MT8135 is not set
+# CONFIG_COMMON_CLK_MT8173 is not set
+
+#
+# Hardware Spinlock drivers
+#
+
+#
+# Clock Source drivers
+#
+CONFIG_CLKEVT_I8253=y
+CONFIG_I8253_LOCK=y
+CONFIG_CLKBLD_I8253=y
+# CONFIG_ATMEL_PIT is not set
+# CONFIG_SH_TIMER_CMT is not set
+# CONFIG_SH_TIMER_MTU2 is not set
+# CONFIG_SH_TIMER_TMU is not set
+# CONFIG_EM_TIMER_STI is not set
+# CONFIG_MAILBOX is not set
+# CONFIG_IOMMU_SUPPORT is not set
+
+#
+# Remoteproc drivers
+#
+CONFIG_REMOTEPROC=m
+CONFIG_STE_MODEM_RPROC=m
+
+#
+# Rpmsg drivers
+#
+
+#
+# SOC (System On Chip) specific Drivers
+#
+
+#
+# Broadcom SoC drivers
+#
+# CONFIG_SUNXI_SRAM is not set
+# CONFIG_SOC_TI is not set
+CONFIG_PM_DEVFREQ=y
+
+#
+# DEVFREQ Governors
+#
+CONFIG_DEVFREQ_GOV_SIMPLE_ONDEMAND=y
+CONFIG_DEVFREQ_GOV_PERFORMANCE=y
+CONFIG_DEVFREQ_GOV_POWERSAVE=y
+CONFIG_DEVFREQ_GOV_USERSPACE=y
+# CONFIG_DEVFREQ_GOV_PASSIVE is not set
+
+#
+# DEVFREQ Drivers
+#
+CONFIG_PM_DEVFREQ_EVENT=y
+# CONFIG_EXTCON is not set
+# CONFIG_MEMORY is not set
+# CONFIG_IIO is not set
+# CONFIG_NTB is not set
+# CONFIG_VME_BUS is not set
+# CONFIG_PWM is not set
+CONFIG_ARM_GIC_MAX_NR=1
+# CONFIG_IPACK_BUS is not set
+CONFIG_RESET_CONTROLLER=y
+# CONFIG_RESET_ATH79 is not set
+# CONFIG_RESET_BERLIN is not set
+# CONFIG_RESET_LPC18XX is not set
+# CONFIG_RESET_MESON is not set
+# CONFIG_RESET_PISTACHIO is not set
+# CONFIG_RESET_SOCFPGA is not set
+# CONFIG_RESET_STM32 is not set
+# CONFIG_RESET_SUNXI is not set
+# CONFIG_TI_SYSCON_RESET is not set
+# CONFIG_RESET_ZYNQ is not set
+# CONFIG_FMC is not set
+
+#
+# PHY Subsystem
+#
+CONFIG_GENERIC_PHY=y
+# CONFIG_PHY_PXA_28NM_HSIC is not set
+# CONFIG_PHY_PXA_28NM_USB2 is not set
+# CONFIG_BCM_KONA_USB2_PHY is not set
+# CONFIG_POWERCAP is not set
+# CONFIG_MCB is not set
+
+#
+# Performance monitor support
+#
+CONFIG_RAS=y
+# CONFIG_THUNDERBOLT is not set
+
+#
+# Android
+#
+# CONFIG_ANDROID is not set
+CONFIG_LIBNVDIMM=y
+CONFIG_BLK_DEV_PMEM=m
+CONFIG_ND_BLK=m
+CONFIG_ND_CLAIM=y
+CONFIG_ND_BTT=m
+CONFIG_BTT=y
+# CONFIG_DEV_DAX is not set
+CONFIG_NVMEM=m
+# CONFIG_STM is not set
+# CONFIG_INTEL_TH is not set
+
+#
+# FPGA Configuration Support
+#
+# CONFIG_FPGA is not set
+
+#
+# Firmware Drivers
+#
+# CONFIG_EDD is not set
+# CONFIG_FIRMWARE_MEMMAP is not set
+# CONFIG_DELL_RBU is not set
+# CONFIG_DCDBAS is not set
+# CONFIG_DMIID is not set
+# CONFIG_DMI_SYSFS is not set
+CONFIG_DMI_SCAN_MACHINE_NON_EFI_FALLBACK=y
+# CONFIG_ISCSI_IBFT_FIND is not set
+# CONFIG_FW_CFG_SYSFS is not set
+# CONFIG_GOOGLE_FIRMWARE is not set
+CONFIG_UEFI_CPER=y
+
+#
+# File systems
+#
+CONFIG_DCACHE_WORD_ACCESS=y
+CONFIG_EXT2_FS=y
+CONFIG_EXT2_FS_XATTR=y
+CONFIG_EXT2_FS_POSIX_ACL=y
+CONFIG_EXT2_FS_SECURITY=y
+CONFIG_EXT3_FS=y
+CONFIG_EXT3_FS_POSIX_ACL=y
+CONFIG_EXT3_FS_SECURITY=y
+CONFIG_EXT4_FS=y
+CONFIG_EXT4_FS_POSIX_ACL=y
+CONFIG_EXT4_FS_SECURITY=y
+CONFIG_EXT4_ENCRYPTION=y
+CONFIG_EXT4_FS_ENCRYPTION=y
+# CONFIG_EXT4_DEBUG is not set
+CONFIG_JBD2=y
+# CONFIG_JBD2_DEBUG is not set
+CONFIG_FS_MBCACHE=y
+# CONFIG_REISERFS_FS is not set
+# CONFIG_JFS_FS is not set
+# CONFIG_XFS_FS is not set
+# CONFIG_GFS2_FS is not set
+# CONFIG_OCFS2_FS is not set
+CONFIG_BTRFS_FS=y
+CONFIG_BTRFS_FS_POSIX_ACL=y
+# CONFIG_BTRFS_FS_CHECK_INTEGRITY is not set
+# CONFIG_BTRFS_FS_RUN_SANITY_TESTS is not set
+# CONFIG_BTRFS_DEBUG is not set
+# CONFIG_BTRFS_ASSERT is not set
+CONFIG_NILFS2_FS=m
+# CONFIG_F2FS_FS is not set
+# CONFIG_FS_DAX is not set
+CONFIG_FS_POSIX_ACL=y
+CONFIG_EXPORTFS=y
+# CONFIG_EXPORTFS_BLOCK_OPS is not set
+CONFIG_FILE_LOCKING=y
+CONFIG_MANDATORY_FILE_LOCKING=y
+CONFIG_FS_ENCRYPTION=y
+CONFIG_FSNOTIFY=y
+CONFIG_DNOTIFY=y
+CONFIG_INOTIFY_USER=y
+# CONFIG_FANOTIFY is not set
+CONFIG_QUOTA=y
+# CONFIG_QUOTA_NETLINK_INTERFACE is not set
+# CONFIG_PRINT_QUOTA_WARNING is not set
+# CONFIG_QUOTA_DEBUG is not set
+CONFIG_QUOTA_TREE=y
+# CONFIG_QFMT_V1 is not set
+CONFIG_QFMT_V2=y
+CONFIG_QUOTACTL=y
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+# CONFIG_OVERLAY_FS is not set
+
+#
+# Caches
+#
+CONFIG_FSCACHE=m
+# CONFIG_FSCACHE_STATS is not set
+# CONFIG_FSCACHE_HISTOGRAM is not set
+# CONFIG_FSCACHE_DEBUG is not set
+# CONFIG_FSCACHE_OBJECT_LIST is not set
+CONFIG_CACHEFILES=m
+# CONFIG_CACHEFILES_DEBUG is not set
+# CONFIG_CACHEFILES_HISTOGRAM is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+CONFIG_ISO9660_FS=y
+CONFIG_JOLIET=y
+CONFIG_ZISOFS=y
+CONFIG_UDF_FS=y
+CONFIG_UDF_NLS=y
+
+#
+# DOS/FAT/NT Filesystems
+#
+CONFIG_FAT_FS=y
+CONFIG_MSDOS_FS=y
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_CODEPAGE=437
+CONFIG_FAT_DEFAULT_IOCHARSET="iso8859-1"
+# CONFIG_FAT_DEFAULT_UTF8 is not set
+CONFIG_NTFS_FS=y
+# CONFIG_NTFS_DEBUG is not set
+CONFIG_NTFS_RW=y
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+CONFIG_PROC_KCORE=y
+CONFIG_PROC_SYSCTL=y
+CONFIG_PROC_PAGE_MONITOR=y
+CONFIG_PROC_CHILDREN=y
+CONFIG_KERNFS=y
+CONFIG_SYSFS=y
+CONFIG_TMPFS=y
+CONFIG_TMPFS_POSIX_ACL=y
+CONFIG_TMPFS_XATTR=y
+# CONFIG_HUGETLBFS is not set
+# CONFIG_HUGETLB_PAGE is not set
+CONFIG_ARCH_HAS_GIGANTIC_PAGE=y
+CONFIG_CONFIGFS_FS=y
+CONFIG_MISC_FILESYSTEMS=y
+# CONFIG_ORANGEFS_FS is not set
+CONFIG_ADFS_FS=m
+# CONFIG_ADFS_FS_RW is not set
+CONFIG_AFFS_FS=m
+CONFIG_ECRYPT_FS=m
+CONFIG_ECRYPT_FS_MESSAGING=y
+CONFIG_HFS_FS=m
+CONFIG_HFSPLUS_FS=m
+# CONFIG_HFSPLUS_FS_POSIX_ACL is not set
+CONFIG_BEFS_FS=m
+# CONFIG_BEFS_DEBUG is not set
+CONFIG_BFS_FS=m
+CONFIG_EFS_FS=m
+CONFIG_LOGFS=m
+CONFIG_CRAMFS=m
+CONFIG_SQUASHFS=m
+# CONFIG_SQUASHFS_FILE_CACHE is not set
+CONFIG_SQUASHFS_FILE_DIRECT=y
+# CONFIG_SQUASHFS_DECOMP_SINGLE is not set
+CONFIG_SQUASHFS_DECOMP_MULTI=y
+# CONFIG_SQUASHFS_DECOMP_MULTI_PERCPU is not set
+CONFIG_SQUASHFS_XATTR=y
+CONFIG_SQUASHFS_ZLIB=y
+CONFIG_SQUASHFS_LZ4=y
+CONFIG_SQUASHFS_LZO=y
+CONFIG_SQUASHFS_XZ=y
+# CONFIG_SQUASHFS_4K_DEVBLK_SIZE is not set
+CONFIG_SQUASHFS_EMBEDDED=y
+CONFIG_SQUASHFS_FRAGMENT_CACHE_SIZE=3
+CONFIG_VXFS_FS=m
+CONFIG_MINIX_FS=m
+CONFIG_OMFS_FS=m
+CONFIG_HPFS_FS=m
+CONFIG_QNX4FS_FS=m
+CONFIG_QNX6FS_FS=m
+# CONFIG_QNX6FS_DEBUG is not set
+CONFIG_ROMFS_FS=y
+CONFIG_ROMFS_BACKED_BY_BLOCK=y
+CONFIG_ROMFS_ON_BLOCK=y
+CONFIG_PSTORE=y
+CONFIG_PSTORE_ZLIB_COMPRESS=y
+# CONFIG_PSTORE_LZO_COMPRESS is not set
+# CONFIG_PSTORE_LZ4_COMPRESS is not set
+# CONFIG_PSTORE_CONSOLE is not set
+# CONFIG_PSTORE_PMSG is not set
+# CONFIG_PSTORE_FTRACE is not set
+CONFIG_PSTORE_RAM=m
+CONFIG_SYSV_FS=m
+CONFIG_UFS_FS=m
+# CONFIG_UFS_FS_WRITE is not set
+# CONFIG_UFS_DEBUG is not set
+CONFIG_EXOFS_FS=m
+# CONFIG_EXOFS_DEBUG is not set
+CONFIG_ORE=m
+CONFIG_NETWORK_FILESYSTEMS=y
+CONFIG_NFS_FS=y
+CONFIG_NFS_V2=y
+CONFIG_NFS_V3=y
+# CONFIG_NFS_V3_ACL is not set
+CONFIG_NFS_V4=y
+CONFIG_NFS_SWAP=y
+# CONFIG_NFS_V4_1 is not set
+# CONFIG_NFS_USE_LEGACY_DNS is not set
+CONFIG_NFS_USE_KERNEL_DNS=y
+CONFIG_NFSD=y
+CONFIG_NFSD_V3=y
+# CONFIG_NFSD_V3_ACL is not set
+CONFIG_NFSD_V4=y
+# CONFIG_NFSD_BLOCKLAYOUT is not set
+# CONFIG_NFSD_SCSILAYOUT is not set
+# CONFIG_NFSD_FLEXFILELAYOUT is not set
+# CONFIG_NFSD_V4_SECURITY_LABEL is not set
+# CONFIG_NFSD_FAULT_INJECTION is not set
+CONFIG_GRACE_PERIOD=y
+CONFIG_LOCKD=y
+CONFIG_LOCKD_V4=y
+CONFIG_NFS_COMMON=y
+CONFIG_SUNRPC=y
+CONFIG_SUNRPC_GSS=y
+CONFIG_SUNRPC_SWAP=y
+CONFIG_RPCSEC_GSS_KRB5=m
+# CONFIG_SUNRPC_DEBUG is not set
+CONFIG_CEPH_FS=m
+CONFIG_CEPH_FSCACHE=y
+CONFIG_CEPH_FS_POSIX_ACL=y
+CONFIG_CIFS=m
+# CONFIG_CIFS_STATS is not set
+CONFIG_CIFS_WEAK_PW_HASH=y
+# CONFIG_CIFS_UPCALL is not set
+# CONFIG_CIFS_XATTR is not set
+CONFIG_CIFS_DEBUG=y
+# CONFIG_CIFS_DEBUG2 is not set
+CONFIG_CIFS_DFS_UPCALL=y
+# CONFIG_CIFS_SMB2 is not set
+CONFIG_CIFS_FSCACHE=y
+CONFIG_NCP_FS=m
+CONFIG_NCPFS_PACKET_SIGNING=y
+CONFIG_NCPFS_IOCTL_LOCKING=y
+CONFIG_NCPFS_STRONG=y
+CONFIG_NCPFS_NFS_NS=y
+CONFIG_NCPFS_OS2_NS=y
+CONFIG_NCPFS_SMALLDOS=y
+CONFIG_NCPFS_NLS=y
+CONFIG_NCPFS_EXTRAS=y
+CONFIG_CODA_FS=m
+CONFIG_AFS_FS=m
+# CONFIG_AFS_DEBUG is not set
+# CONFIG_AFS_FSCACHE is not set
+CONFIG_NLS=y
+CONFIG_NLS_DEFAULT="utf8"
+CONFIG_NLS_CODEPAGE_437=y
+CONFIG_NLS_CODEPAGE_737=m
+CONFIG_NLS_CODEPAGE_775=m
+CONFIG_NLS_CODEPAGE_850=m
+CONFIG_NLS_CODEPAGE_852=m
+CONFIG_NLS_CODEPAGE_855=m
+CONFIG_NLS_CODEPAGE_857=m
+CONFIG_NLS_CODEPAGE_860=m
+CONFIG_NLS_CODEPAGE_861=m
+CONFIG_NLS_CODEPAGE_862=m
+CONFIG_NLS_CODEPAGE_863=m
+CONFIG_NLS_CODEPAGE_864=m
+CONFIG_NLS_CODEPAGE_865=m
+CONFIG_NLS_CODEPAGE_866=m
+CONFIG_NLS_CODEPAGE_869=m
+CONFIG_NLS_CODEPAGE_936=m
+CONFIG_NLS_CODEPAGE_950=m
+CONFIG_NLS_CODEPAGE_932=m
+CONFIG_NLS_CODEPAGE_949=m
+CONFIG_NLS_CODEPAGE_874=m
+CONFIG_NLS_ISO8859_8=m
+CONFIG_NLS_CODEPAGE_1250=m
+CONFIG_NLS_CODEPAGE_1251=m
+CONFIG_NLS_ASCII=m
+CONFIG_NLS_ISO8859_1=y
+CONFIG_NLS_ISO8859_2=m
+CONFIG_NLS_ISO8859_3=m
+CONFIG_NLS_ISO8859_4=m
+CONFIG_NLS_ISO8859_5=m
+CONFIG_NLS_ISO8859_6=m
+CONFIG_NLS_ISO8859_7=m
+CONFIG_NLS_ISO8859_9=m
+CONFIG_NLS_ISO8859_13=m
+CONFIG_NLS_ISO8859_14=m
+CONFIG_NLS_ISO8859_15=m
+CONFIG_NLS_KOI8_R=m
+CONFIG_NLS_KOI8_U=m
+CONFIG_NLS_MAC_ROMAN=m
+CONFIG_NLS_MAC_CELTIC=m
+CONFIG_NLS_MAC_CENTEURO=m
+CONFIG_NLS_MAC_CROATIAN=m
+CONFIG_NLS_MAC_CYRILLIC=m
+CONFIG_NLS_MAC_GAELIC=m
+CONFIG_NLS_MAC_GREEK=m
+CONFIG_NLS_MAC_ICELAND=m
+CONFIG_NLS_MAC_INUIT=m
+CONFIG_NLS_MAC_ROMANIAN=m
+CONFIG_NLS_MAC_TURKISH=m
+CONFIG_NLS_UTF8=y
+CONFIG_DLM=m
+# CONFIG_DLM_DEBUG is not set
+
+#
+# Kernel hacking
+#
+CONFIG_TRACE_IRQFLAGS_SUPPORT=y
+
+#
+# printk and dmesg options
+#
+CONFIG_PRINTK_TIME=y
+CONFIG_MESSAGE_LOGLEVEL_DEFAULT=4
+# CONFIG_BOOT_PRINTK_DELAY is not set
+# CONFIG_DYNAMIC_DEBUG is not set
+
+#
+# Compile-time checks and compiler options
+#
+# CONFIG_DEBUG_INFO is not set
+CONFIG_ENABLE_WARN_DEPRECATED=y
+CONFIG_ENABLE_MUST_CHECK=y
+CONFIG_FRAME_WARN=0
+CONFIG_STRIP_ASM_SYMS=y
+# CONFIG_READABLE_ASM is not set
+CONFIG_UNUSED_SYMBOLS=y
+# CONFIG_PAGE_OWNER is not set
+CONFIG_DEBUG_FS=y
+# CONFIG_HEADERS_CHECK is not set
+# CONFIG_DEBUG_SECTION_MISMATCH is not set
+CONFIG_SECTION_MISMATCH_WARN_ONLY=y
+CONFIG_ARCH_WANT_FRAME_POINTERS=y
+CONFIG_FRAME_POINTER=y
+# CONFIG_STACK_VALIDATION is not set
+# CONFIG_DEBUG_FORCE_WEAK_PER_CPU is not set
+CONFIG_MAGIC_SYSRQ=y
+CONFIG_MAGIC_SYSRQ_DEFAULT_ENABLE=0x1
+CONFIG_DEBUG_KERNEL=y
+
+#
+# Memory Debugging
+#
+# CONFIG_PAGE_EXTENSION is not set
+# CONFIG_DEBUG_PAGEALLOC is not set
+# CONFIG_PAGE_POISONING is not set
+# CONFIG_DEBUG_PAGE_REF is not set
+# CONFIG_DEBUG_OBJECTS is not set
+# CONFIG_SLUB_DEBUG_ON is not set
+# CONFIG_SLUB_STATS is not set
+CONFIG_HAVE_DEBUG_KMEMLEAK=y
+# CONFIG_DEBUG_KMEMLEAK is not set
+# CONFIG_DEBUG_STACK_USAGE is not set
+# CONFIG_DEBUG_VM is not set
+# CONFIG_DEBUG_VIRTUAL is not set
+CONFIG_DEBUG_MEMORY_INIT=y
+# CONFIG_DEBUG_PER_CPU_MAPS is not set
+CONFIG_HAVE_DEBUG_STACKOVERFLOW=y
+# CONFIG_DEBUG_STACKOVERFLOW is not set
+CONFIG_HAVE_ARCH_KMEMCHECK=y
+CONFIG_HAVE_ARCH_KASAN=y
+# CONFIG_KASAN is not set
+CONFIG_ARCH_HAS_KCOV=y
+# CONFIG_KCOV is not set
+# CONFIG_DEBUG_SHIRQ is not set
+
+#
+# Debug Lockups and Hangs
+#
+# CONFIG_LOCKUP_DETECTOR is not set
+# CONFIG_DETECT_HUNG_TASK is not set
+# CONFIG_WQ_WATCHDOG is not set
+# CONFIG_PANIC_ON_OOPS is not set
+CONFIG_PANIC_ON_OOPS_VALUE=0
+CONFIG_PANIC_TIMEOUT=0
+CONFIG_SCHED_DEBUG=y
+CONFIG_SCHED_INFO=y
+# CONFIG_SCHEDSTATS is not set
+# CONFIG_SCHED_STACK_END_CHECK is not set
+# CONFIG_DEBUG_TIMEKEEPING is not set
+# CONFIG_TIMER_STATS is not set
+
+#
+# Lock Debugging (spinlocks, mutexes, etc...)
+#
+# CONFIG_DEBUG_RT_MUTEXES is not set
+# CONFIG_DEBUG_SPINLOCK is not set
+# CONFIG_DEBUG_MUTEXES is not set
+# CONFIG_DEBUG_WW_MUTEX_SLOWPATH is not set
+# CONFIG_DEBUG_LOCK_ALLOC is not set
+# CONFIG_PROVE_LOCKING is not set
+# CONFIG_LOCK_STAT is not set
+# CONFIG_DEBUG_ATOMIC_SLEEP is not set
+# CONFIG_DEBUG_LOCKING_API_SELFTESTS is not set
+# CONFIG_LOCK_TORTURE_TEST is not set
+CONFIG_STACKTRACE=y
+# CONFIG_DEBUG_KOBJECT is not set
+CONFIG_DEBUG_BUGVERBOSE=y
+# CONFIG_DEBUG_LIST is not set
+# CONFIG_DEBUG_PI_LIST is not set
+# CONFIG_DEBUG_SG is not set
+# CONFIG_DEBUG_NOTIFIERS is not set
+# CONFIG_DEBUG_CREDENTIALS is not set
+
+#
+# RCU Debugging
+#
+# CONFIG_PROVE_RCU is not set
+# CONFIG_SPARSE_RCU_POINTER is not set
+# CONFIG_TORTURE_TEST is not set
+# CONFIG_RCU_PERF_TEST is not set
+# CONFIG_RCU_TORTURE_TEST is not set
+CONFIG_RCU_CPU_STALL_TIMEOUT=60
+# CONFIG_RCU_TRACE is not set
+# CONFIG_RCU_EQS_DEBUG is not set
+# CONFIG_DEBUG_WQ_FORCE_RR_CPU is not set
+# CONFIG_DEBUG_BLOCK_EXT_DEVT is not set
+# CONFIG_CPU_HOTPLUG_STATE_CONTROL is not set
+# CONFIG_NOTIFIER_ERROR_INJECTION is not set
+# CONFIG_FAULT_INJECTION is not set
+# CONFIG_LATENCYTOP is not set
+CONFIG_USER_STACKTRACE_SUPPORT=y
+CONFIG_NOP_TRACER=y
+CONFIG_HAVE_FUNCTION_TRACER=y
+CONFIG_HAVE_FUNCTION_GRAPH_TRACER=y
+CONFIG_HAVE_DYNAMIC_FTRACE=y
+CONFIG_HAVE_DYNAMIC_FTRACE_WITH_REGS=y
+CONFIG_HAVE_FTRACE_MCOUNT_RECORD=y
+CONFIG_HAVE_SYSCALL_TRACEPOINTS=y
+CONFIG_HAVE_FENTRY=y
+CONFIG_HAVE_C_RECORDMCOUNT=y
+CONFIG_TRACE_CLOCK=y
+CONFIG_RING_BUFFER=y
+CONFIG_EVENT_TRACING=y
+CONFIG_CONTEXT_SWITCH_TRACER=y
+CONFIG_TRACING=y
+CONFIG_GENERIC_TRACER=y
+CONFIG_TRACING_SUPPORT=y
+CONFIG_FTRACE=y
+CONFIG_FUNCTION_TRACER=y
+CONFIG_FUNCTION_GRAPH_TRACER=y
+# CONFIG_IRQSOFF_TRACER is not set
+# CONFIG_SCHED_TRACER is not set
+# CONFIG_HWLAT_TRACER is not set
+# CONFIG_FTRACE_SYSCALLS is not set
+# CONFIG_TRACER_SNAPSHOT is not set
+CONFIG_BRANCH_PROFILE_NONE=y
+# CONFIG_PROFILE_ANNOTATED_BRANCHES is not set
+# CONFIG_PROFILE_ALL_BRANCHES is not set
+# CONFIG_STACK_TRACER is not set
+CONFIG_BLK_DEV_IO_TRACE=y
+# CONFIG_UPROBE_EVENT is not set
+# CONFIG_PROBE_EVENTS is not set
+CONFIG_DYNAMIC_FTRACE=y
+CONFIG_DYNAMIC_FTRACE_WITH_REGS=y
+# CONFIG_FUNCTION_PROFILER is not set
+CONFIG_FTRACE_MCOUNT_RECORD=y
+# CONFIG_FTRACE_STARTUP_TEST is not set
+# CONFIG_MMIOTRACE is not set
+# CONFIG_HIST_TRIGGERS is not set
+# CONFIG_TRACEPOINT_BENCHMARK is not set
+CONFIG_RING_BUFFER_BENCHMARK=m
+# CONFIG_RING_BUFFER_STARTUP_TEST is not set
+# CONFIG_TRACE_ENUM_MAP_FILE is not set
+# CONFIG_TRACING_EVENTS_GPIO is not set
+
+#
+# Runtime Testing
+#
+# CONFIG_LKDTM is not set
+# CONFIG_TEST_LIST_SORT is not set
+# CONFIG_BACKTRACE_SELF_TEST is not set
+# CONFIG_RBTREE_TEST is not set
+# CONFIG_INTERVAL_TREE_TEST is not set
+# CONFIG_PERCPU_TEST is not set
+CONFIG_ATOMIC64_SELFTEST=y
+CONFIG_ASYNC_RAID6_TEST=m
+CONFIG_TEST_HEXDUMP=m
+# CONFIG_TEST_STRING_HELPERS is not set
+# CONFIG_TEST_KSTRTOX is not set
+# CONFIG_TEST_PRINTF is not set
+# CONFIG_TEST_BITMAP is not set
+# CONFIG_TEST_UUID is not set
+# CONFIG_TEST_RHASHTABLE is not set
+# CONFIG_TEST_HASH is not set
+# CONFIG_PROVIDE_OHCI1394_DMA_INIT is not set
+# CONFIG_DMA_API_DEBUG is not set
+# CONFIG_TEST_LKM is not set
+# CONFIG_TEST_USER_COPY is not set
+# CONFIG_TEST_BPF is not set
+# CONFIG_TEST_FIRMWARE is not set
+# CONFIG_TEST_UDELAY is not set
+CONFIG_MEMTEST=y
+# CONFIG_TEST_STATIC_KEYS is not set
+# CONFIG_SAMPLES is not set
+CONFIG_HAVE_ARCH_KGDB=y
+# CONFIG_KGDB is not set
+CONFIG_ARCH_HAS_UBSAN_SANITIZE_ALL=y
+# CONFIG_ARCH_WANTS_UBSAN_NO_NULL is not set
+# CONFIG_UBSAN is not set
+CONFIG_ARCH_HAS_DEVMEM_IS_ALLOWED=y
+CONFIG_STRICT_DEVMEM=y
+# CONFIG_IO_STRICT_DEVMEM is not set
+CONFIG_X86_VERBOSE_BOOTUP=y
+CONFIG_EARLY_PRINTK=y
+# CONFIG_EARLY_PRINTK_DBGP is not set
+# CONFIG_X86_PTDUMP_CORE is not set
+# CONFIG_X86_PTDUMP is not set
+CONFIG_DEBUG_RODATA_TEST=y
+# CONFIG_DEBUG_WX is not set
+# CONFIG_DEBUG_SET_MODULE_RONX is not set
+# CONFIG_DEBUG_NX_TEST is not set
+CONFIG_DOUBLEFAULT=y
+# CONFIG_DEBUG_TLBFLUSH is not set
+# CONFIG_IOMMU_DEBUG is not set
+# CONFIG_IOMMU_STRESS is not set
+CONFIG_HAVE_MMIOTRACE_SUPPORT=y
+CONFIG_IO_DELAY_TYPE_0X80=0
+CONFIG_IO_DELAY_TYPE_0XED=1
+CONFIG_IO_DELAY_TYPE_UDELAY=2
+CONFIG_IO_DELAY_TYPE_NONE=3
+CONFIG_IO_DELAY_0X80=y
+# CONFIG_IO_DELAY_0XED is not set
+# CONFIG_IO_DELAY_UDELAY is not set
+# CONFIG_IO_DELAY_NONE is not set
+CONFIG_DEFAULT_IO_DELAY_TYPE=0
+# CONFIG_DEBUG_BOOT_PARAMS is not set
+# CONFIG_CPA_DEBUG is not set
+# CONFIG_OPTIMIZE_INLINING is not set
+# CONFIG_DEBUG_ENTRY is not set
+# CONFIG_DEBUG_NMI_SELFTEST is not set
+# CONFIG_X86_DEBUG_FPU is not set
+# CONFIG_PUNIT_ATOM_DEBUG is not set
+
+#
+# Security options
+#
+CONFIG_KEYS=y
+# CONFIG_PERSISTENT_KEYRINGS is not set
+# CONFIG_BIG_KEYS is not set
+CONFIG_ENCRYPTED_KEYS=y
+# CONFIG_KEY_DH_OPERATIONS is not set
+CONFIG_SECURITY_DMESG_RESTRICT=y
+CONFIG_SECURITY=y
+CONFIG_SECURITYFS=y
+CONFIG_SECURITY_NETWORK=y
+CONFIG_SECURITY_NETWORK_XFRM=y
+# CONFIG_SECURITY_PATH is not set
+CONFIG_HAVE_HARDENED_USERCOPY_ALLOCATOR=y
+CONFIG_HAVE_ARCH_HARDENED_USERCOPY=y
+# CONFIG_HARDENED_USERCOPY is not set
+# CONFIG_SECURITY_SMACK is not set
+# CONFIG_SECURITY_TOMOYO is not set
+# CONFIG_SECURITY_APPARMOR is not set
+# CONFIG_SECURITY_LOADPIN is not set
+# CONFIG_SECURITY_YAMA is not set
+# CONFIG_INTEGRITY is not set
+CONFIG_DEFAULT_SECURITY_DAC=y
+CONFIG_DEFAULT_SECURITY=""
+CONFIG_XOR_BLOCKS=y
+CONFIG_ASYNC_CORE=y
+CONFIG_ASYNC_MEMCPY=y
+CONFIG_ASYNC_XOR=y
+CONFIG_ASYNC_PQ=y
+CONFIG_ASYNC_RAID6_RECOV=y
+CONFIG_CRYPTO=y
+
+#
+# Crypto core or helper
+#
+CONFIG_CRYPTO_ALGAPI=y
+CONFIG_CRYPTO_ALGAPI2=y
+CONFIG_CRYPTO_AEAD=y
+CONFIG_CRYPTO_AEAD2=y
+CONFIG_CRYPTO_BLKCIPHER=y
+CONFIG_CRYPTO_BLKCIPHER2=y
+CONFIG_CRYPTO_HASH=y
+CONFIG_CRYPTO_HASH2=y
+CONFIG_CRYPTO_RNG=y
+CONFIG_CRYPTO_RNG2=y
+CONFIG_CRYPTO_RNG_DEFAULT=y
+CONFIG_CRYPTO_AKCIPHER2=y
+CONFIG_CRYPTO_KPP2=y
+# CONFIG_CRYPTO_RSA is not set
+# CONFIG_CRYPTO_DH is not set
+# CONFIG_CRYPTO_ECDH is not set
+CONFIG_CRYPTO_MANAGER=y
+CONFIG_CRYPTO_MANAGER2=y
+# CONFIG_CRYPTO_USER is not set
+# CONFIG_CRYPTO_MANAGER_DISABLE_TESTS is not set
+CONFIG_CRYPTO_GF128MUL=y
+CONFIG_CRYPTO_NULL=y
+CONFIG_CRYPTO_NULL2=y
+# CONFIG_CRYPTO_PCRYPT is not set
+CONFIG_CRYPTO_WORKQUEUE=y
+# CONFIG_CRYPTO_CRYPTD is not set
+# CONFIG_CRYPTO_MCRYPTD is not set
+CONFIG_CRYPTO_AUTHENC=y
+# CONFIG_CRYPTO_TEST is not set
+
+#
+# Authenticated Encryption with Associated Data
+#
+CONFIG_CRYPTO_CCM=y
+CONFIG_CRYPTO_GCM=y
+# CONFIG_CRYPTO_CHACHA20POLY1305 is not set
+CONFIG_CRYPTO_SEQIV=y
+CONFIG_CRYPTO_ECHAINIV=m
+
+#
+# Block modes
+#
+CONFIG_CRYPTO_CBC=y
+CONFIG_CRYPTO_CTR=y
+CONFIG_CRYPTO_CTS=y
+CONFIG_CRYPTO_ECB=y
+# CONFIG_CRYPTO_LRW is not set
+# CONFIG_CRYPTO_PCBC is not set
+CONFIG_CRYPTO_XTS=y
+# CONFIG_CRYPTO_KEYWRAP is not set
+
+#
+# Hash modes
+#
+CONFIG_CRYPTO_CMAC=m
+CONFIG_CRYPTO_HMAC=y
+# CONFIG_CRYPTO_XCBC is not set
+# CONFIG_CRYPTO_VMAC is not set
+
+#
+# Digest
+#
+CONFIG_CRYPTO_CRC32C=y
+CONFIG_CRYPTO_CRC32C_INTEL=m
+CONFIG_CRYPTO_CRC32=m
+# CONFIG_CRYPTO_CRC32_PCLMUL is not set
+CONFIG_CRYPTO_CRCT10DIF=y
+# CONFIG_CRYPTO_CRCT10DIF_PCLMUL is not set
+CONFIG_CRYPTO_GHASH=y
+# CONFIG_CRYPTO_POLY1305 is not set
+# CONFIG_CRYPTO_POLY1305_X86_64 is not set
+CONFIG_CRYPTO_MD4=y
+CONFIG_CRYPTO_MD5=y
+CONFIG_CRYPTO_MICHAEL_MIC=y
+# CONFIG_CRYPTO_RMD128 is not set
+# CONFIG_CRYPTO_RMD160 is not set
+# CONFIG_CRYPTO_RMD256 is not set
+# CONFIG_CRYPTO_RMD320 is not set
+CONFIG_CRYPTO_SHA1=y
+# CONFIG_CRYPTO_SHA1_SSSE3 is not set
+# CONFIG_CRYPTO_SHA256_SSSE3 is not set
+# CONFIG_CRYPTO_SHA512_SSSE3 is not set
+# CONFIG_CRYPTO_SHA1_MB is not set
+# CONFIG_CRYPTO_SHA256_MB is not set
+# CONFIG_CRYPTO_SHA512_MB is not set
+CONFIG_CRYPTO_SHA256=y
+# CONFIG_CRYPTO_SHA512 is not set
+# CONFIG_CRYPTO_SHA3 is not set
+# CONFIG_CRYPTO_TGR192 is not set
+# CONFIG_CRYPTO_WP512 is not set
+# CONFIG_CRYPTO_GHASH_CLMUL_NI_INTEL is not set
+
+#
+# Ciphers
+#
+CONFIG_CRYPTO_AES=y
+# CONFIG_CRYPTO_AES_X86_64 is not set
+# CONFIG_CRYPTO_AES_NI_INTEL is not set
+# CONFIG_CRYPTO_ANUBIS is not set
+CONFIG_CRYPTO_ARC4=y
+# CONFIG_CRYPTO_BLOWFISH is not set
+# CONFIG_CRYPTO_BLOWFISH_X86_64 is not set
+# CONFIG_CRYPTO_CAMELLIA is not set
+# CONFIG_CRYPTO_CAMELLIA_X86_64 is not set
+# CONFIG_CRYPTO_CAMELLIA_AESNI_AVX_X86_64 is not set
+# CONFIG_CRYPTO_CAMELLIA_AESNI_AVX2_X86_64 is not set
+# CONFIG_CRYPTO_CAST5 is not set
+# CONFIG_CRYPTO_CAST5_AVX_X86_64 is not set
+# CONFIG_CRYPTO_CAST6 is not set
+# CONFIG_CRYPTO_CAST6_AVX_X86_64 is not set
+CONFIG_CRYPTO_DES=y
+# CONFIG_CRYPTO_DES3_EDE_X86_64 is not set
+# CONFIG_CRYPTO_FCRYPT is not set
+# CONFIG_CRYPTO_KHAZAD is not set
+# CONFIG_CRYPTO_SALSA20 is not set
+# CONFIG_CRYPTO_SALSA20_X86_64 is not set
+# CONFIG_CRYPTO_CHACHA20 is not set
+# CONFIG_CRYPTO_CHACHA20_X86_64 is not set
+# CONFIG_CRYPTO_SEED is not set
+# CONFIG_CRYPTO_SERPENT is not set
+# CONFIG_CRYPTO_SERPENT_SSE2_X86_64 is not set
+# CONFIG_CRYPTO_SERPENT_AVX_X86_64 is not set
+# CONFIG_CRYPTO_SERPENT_AVX2_X86_64 is not set
+# CONFIG_CRYPTO_TEA is not set
+# CONFIG_CRYPTO_TWOFISH is not set
+# CONFIG_CRYPTO_TWOFISH_X86_64 is not set
+# CONFIG_CRYPTO_TWOFISH_X86_64_3WAY is not set
+# CONFIG_CRYPTO_TWOFISH_AVX_X86_64 is not set
+
+#
+# Compression
+#
+CONFIG_CRYPTO_DEFLATE=y
+CONFIG_CRYPTO_LZO=y
+# CONFIG_CRYPTO_842 is not set
+# CONFIG_CRYPTO_LZ4 is not set
+# CONFIG_CRYPTO_LZ4HC is not set
+
+#
+# Random Number Generation
+#
+# CONFIG_CRYPTO_ANSI_CPRNG is not set
+CONFIG_CRYPTO_DRBG_MENU=y
+CONFIG_CRYPTO_DRBG_HMAC=y
+CONFIG_CRYPTO_DRBG_HASH=y
+CONFIG_CRYPTO_DRBG_CTR=y
+CONFIG_CRYPTO_DRBG=y
+CONFIG_CRYPTO_JITTERENTROPY=y
+# CONFIG_CRYPTO_USER_API_HASH is not set
+# CONFIG_CRYPTO_USER_API_SKCIPHER is not set
+# CONFIG_CRYPTO_USER_API_RNG is not set
+# CONFIG_CRYPTO_USER_API_AEAD is not set
+# CONFIG_CRYPTO_HW is not set
+# CONFIG_ASYMMETRIC_KEY_TYPE is not set
+
+#
+# Certificates for signature checking
+#
+CONFIG_HAVE_KVM=y
+CONFIG_VIRTUALIZATION=y
+# CONFIG_KVM is not set
+# CONFIG_VHOST_NET is not set
+# CONFIG_VHOST_VSOCK is not set
+# CONFIG_VHOST_CROSS_ENDIAN_LEGACY is not set
+CONFIG_BINARY_PRINTF=y
+
+#
+# Library routines
+#
+CONFIG_RAID6_PQ=y
+CONFIG_BITREVERSE=y
+# CONFIG_HAVE_ARCH_BITREVERSE is not set
+CONFIG_RATIONAL=y
+CONFIG_GENERIC_STRNCPY_FROM_USER=y
+CONFIG_GENERIC_STRNLEN_USER=y
+CONFIG_GENERIC_NET_UTILS=y
+CONFIG_GENERIC_FIND_FIRST_BIT=y
+CONFIG_GENERIC_PCI_IOMAP=y
+CONFIG_GENERIC_IOMAP=y
+CONFIG_GENERIC_IO=y
+CONFIG_ARCH_USE_CMPXCHG_LOCKREF=y
+CONFIG_ARCH_HAS_FAST_MULTIPLIER=y
+CONFIG_CRC_CCITT=m
+CONFIG_CRC16=y
+CONFIG_CRC_T10DIF=y
+CONFIG_CRC_ITU_T=y
+CONFIG_CRC32=y
+# CONFIG_CRC32_SELFTEST is not set
+CONFIG_CRC32_SLICEBY8=y
+# CONFIG_CRC32_SLICEBY4 is not set
+# CONFIG_CRC32_SARWATE is not set
+# CONFIG_CRC32_BIT is not set
+CONFIG_CRC7=m
+CONFIG_LIBCRC32C=y
+CONFIG_CRC8=m
+# CONFIG_AUDIT_ARCH_COMPAT_GENERIC is not set
+# CONFIG_RANDOM32_SELFTEST is not set
+CONFIG_ZLIB_INFLATE=y
+CONFIG_ZLIB_DEFLATE=y
+CONFIG_LZO_COMPRESS=y
+CONFIG_LZO_DECOMPRESS=y
+CONFIG_LZ4_DECOMPRESS=m
+CONFIG_XZ_DEC=y
+CONFIG_XZ_DEC_X86=y
+CONFIG_XZ_DEC_POWERPC=y
+CONFIG_XZ_DEC_IA64=y
+CONFIG_XZ_DEC_ARM=y
+CONFIG_XZ_DEC_ARMTHUMB=y
+CONFIG_XZ_DEC_SPARC=y
+CONFIG_XZ_DEC_BCJ=y
+# CONFIG_XZ_DEC_TEST is not set
+CONFIG_GENERIC_ALLOCATOR=y
+CONFIG_REED_SOLOMON=m
+CONFIG_REED_SOLOMON_ENC8=y
+CONFIG_REED_SOLOMON_DEC8=y
+CONFIG_TEXTSEARCH=y
+CONFIG_TEXTSEARCH_KMP=m
+CONFIG_TEXTSEARCH_BM=m
+CONFIG_TEXTSEARCH_FSM=m
+CONFIG_BTREE=y
+CONFIG_INTERVAL_TREE=y
+CONFIG_RADIX_TREE_MULTIORDER=y
+CONFIG_ASSOCIATIVE_ARRAY=y
+CONFIG_HAS_IOMEM=y
+CONFIG_HAS_IOPORT_MAP=y
+CONFIG_HAS_DMA=y
+CONFIG_CHECK_SIGNATURE=y
+CONFIG_CPU_RMAP=y
+CONFIG_DQL=y
+CONFIG_GLOB=y
+# CONFIG_GLOB_SELFTEST is not set
+CONFIG_NLATTR=y
+CONFIG_LRU_CACHE=m
+CONFIG_CORDIC=m
+# CONFIG_DDR is not set
+CONFIG_IRQ_POLL=y
+CONFIG_OID_REGISTRY=y
+CONFIG_FONT_SUPPORT=y
+CONFIG_FONTS=y
+CONFIG_FONT_8x8=y
+CONFIG_FONT_8x16=y
+# CONFIG_FONT_6x11 is not set
+# CONFIG_FONT_7x14 is not set
+# CONFIG_FONT_PEARL_8x8 is not set
+# CONFIG_FONT_ACORN_8x8 is not set
+# CONFIG_FONT_MINI_4x6 is not set
+# CONFIG_FONT_6x10 is not set
+CONFIG_FONT_SUN8x16=y
+# CONFIG_FONT_SUN12x22 is not set
+# CONFIG_FONT_10x18 is not set
+# CONFIG_SG_SPLIT is not set
+CONFIG_SG_POOL=y
+CONFIG_ARCH_HAS_SG_CHAIN=y
+CONFIG_ARCH_HAS_PMEM_API=y
+CONFIG_ARCH_HAS_MMIO_FLUSH=y
+CONFIG_SBITMAP=y
diff -uprN --new-file linux-4.9-rc2-original/include/linux/gmtp.h linux-4.9-rc2/include/linux/gmtp.h
--- linux-4.9-rc2-original/include/linux/gmtp.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/include/linux/gmtp.h	2016-12-01 16:51:04.671054634 -0300
@@ -0,0 +1,399 @@
+#ifndef LINUX_GMTP_H_
+#define LINUX_GMTP_H_
+
+#include <net/inet_sock.h>
+#include <net/inet_connection_sock.h>
+#include <net/tcp_states.h>
+#include <linux/types.h>
+#include <uapi/linux/gmtp.h>
+
+enum gmtp_state {
+	GMTP_OPEN	     = TCP_ESTABLISHED,
+	GMTP_REQUESTING	     = TCP_SYN_SENT,
+	GMTP_LISTEN	     = TCP_LISTEN,
+	GMTP_REQUEST_RECV    = TCP_SYN_RECV,
+	GMTP_ACTIVE_CLOSEREQ = TCP_FIN_WAIT1,
+	GMTP_PASSIVE_CLOSE   = TCP_CLOSE_WAIT, /* any node receiving a Close */
+	GMTP_CLOSING	     = TCP_CLOSING,
+	GMTP_TIME_WAIT	     = TCP_TIME_WAIT,
+	GMTP_CLOSED	     = TCP_CLOSE,
+	GMTP_DELEGATED	     = TCP_NEW_SYN_RECV,
+	GMTP_MAX_STATES
+};
+
+enum {
+	GMTPF_OPEN	      = TCPF_ESTABLISHED,
+	GMTPF_REQUESTING      = TCPF_SYN_SENT,
+	GMTPF_LISTEN	      = TCPF_LISTEN,
+	GMTPF_REQUEST_RECV	      = TCPF_SYN_RECV, //relay
+	GMTPF_ACTIVE_CLOSEREQ = TCPF_FIN_WAIT1,
+	GMTPF_PASSIVE_CLOSE   = TCPF_CLOSE_WAIT,
+	GMTPF_CLOSING	      = TCPF_CLOSING,
+	GMTPF_TIME_WAIT	      = TCPF_TIME_WAIT,
+	GMTPF_CLOSED	      = TCPF_CLOSE
+};
+
+
+enum gmtp_role {
+	GMTP_ROLE_UNDEFINED,
+	GMTP_ROLE_LISTEN,
+	GMTP_ROLE_CLIENT,
+	GMTP_ROLE_REPORTER,
+	GMTP_ROLE_SERVER,
+	GMTP_ROLE_RELAY
+};
+
+enum gmtp_sock_type {
+	GMTP_SOCK_TYPE_REGULAR,
+	GMTP_SOCK_TYPE_REPORTER,
+	GMTP_SOCK_TYPE_CONTROL_CHANNEL,
+	GMTP_SOCK_TYPE_DATA_CHANNEL
+};
+
+
+/*
+ * Number of loss intervals (RFC 4342, 8.6.1). The history size is one more than
+ * NINTERVAL, since the `open' interval I_0 is always stored as the first entry.
+ */
+#define NINTERVAL	8
+#define LIH_SIZE	(NINTERVAL + 1)
+
+/* Number of packets to wait after a missing packet (RFC 4342, 6.1) */
+#define MCC_NDUPACK 3
+
+/* GMTP-MCC receiver states */
+enum mcc_rx_states {
+	MCC_RSTATE_NO_DATA = 1,
+	MCC_RSTATE_DATA,
+};
+
+/**
+ * mcc_rx_hist  -  RX history structure for TFRC-based protocols
+ * @ring:		Packet history for RTT sampling and loss detection
+ * @loss_count:		Number of entries in circular history
+ * @loss_start:		Movable index (for loss detection)
+ * @rtt_sample_prev:	Used during RTT sampling, points to candidate entry
+ */
+struct mcc_rx_hist {
+	struct mcc_rx_hist_entry *ring[MCC_NDUPACK + 1];
+	u8			  loss_count:2,
+				  loss_start:2;
+#define rtt_sample_prev		  loss_start
+};
+
+/**
+ *  tfrc_loss_hist  -  Loss record database
+ *  @ring:	Circular queue managed in LIFO manner
+ *  @counter:	Current count of entries (can be more than %LIH_SIZE)
+ *  @i_mean:	Current Average Loss Interval [RFC 3448, 5.4]
+ */
+struct mcc_loss_hist {
+	struct mcc_loss_interval	*ring[LIH_SIZE];
+	u8				counter;
+	u32				i_mean;
+};
+
+/**
+ * struct gmtp_request_sock  -  represent GMTP-specific connection request
+ *
+ * @greq_inet_rsk: structure inherited from
+ *
+ * @iss: initial sequence number, sent on the first REQUEST (or register)
+ * @gss: greatest sequence number sent (for retransmitted REPLYS)
+ * @isr: initial sequence number received in the first REQUEST
+ * @gsr: greatest sequence number received (for retransmitted REQUEST(s))
+ *
+ **/
+struct gmtp_request_sock {
+	struct inet_request_sock greq_inet_rsk;
+
+	__u64			 iss;
+	__u64			 gss;
+	__u64			 isr;
+	__u64			 gsr;
+	enum gmtp_ucc_type	tx_ucc_type;
+	
+	__u8 flowname[GMTP_FLOWNAME_LEN];
+};
+
+static inline struct gmtp_request_sock *gmtp_rsk(const struct request_sock *req)
+{
+	return (struct gmtp_request_sock *)req;
+}
+
+/**
+ * struct gmtp_sock - GMTP socket state
+ *
+ * @flowname: name of the dataflow
+ * @relay_id: id of my relay (for clients)
+ * @iss: initial sequence number sent
+ * @isr: initial sequence number received
+ * @gss: greatest sequence number sent
+ * @gsr: greatest valid sequence number received
+ * @mss: current value of MSS (path MTU minus header sizes)
+ * @role: role of this sock, one of %gmtp_role
+ * @reporter: reporter of a client
+ * @rsock: socket connected to reporter
+ * @max_nclients: limit of clients in a reporter
+ * @nclients: number of clients of a reporter
+ * @req_stamp: time stamp of request sent
+ * @reply_stamp: time stamp of Register-Reply (or Request-Reply) sent
+ * @ack_rx_tstamp: timestamp of last received ACK (for keepalives)
+ * @ack_tx_tstamp: timestamp of last received ACK (for keepalives)
+ * @tx_rtt: RTT from sender to relays
+ * @server_timewait: server holds timewait state on close
+ * @rx_last_counter:	     Tracks window counter (RFC 4342, 8.1)
+ * @rx_state:		     Receiver state, one of %mcc_rx_states
+ * @rx_bytes_recv:	     Total sum of GMTP payload bytes
+ * @rx_x_recv:		     Receiver estimate of send rate (RFC 3448, sec. 4.3)
+ * @rx_max_rate:	Receiver max send rate calculated by TFRC Equation
+ * @rx_rtt:		RTT from receiver to sender (ms)
+ * @rx_avg_rtt:		Receiver estimate of RTT (average)
+ * @rx_tstamp_last_feedback: Time at which last feedback was sent
+ * @rx_hist:		     Packet history (loss detection + RTT sampling)
+ * @rx_li_hist:		     Loss Interval database
+ * @rx_s:		     Received packet size in bytes
+ * @rx_pinv:		     Inverse of Loss Event Rate (RFC 4342, sec. 8.5)
+ * @pkt_sent: Number of data packets sent
+ * @data_sent: Amount of data sent (bytes)
+ * @bytes_sent: Amount of data+headers sent (bytes)
+ * @tx_sample_len: Length of the sample window (used to infer 'instant' Tx Rate)
+ * @tx_time_sample: Elapsed time at sample window (jiffies)
+ * @tx_byte_sample: Bytes sent at sample window
+ * @tx_first_stamp: time stamp of first sent data packet (jiffies)
+ * @tx_last_stamp: time stamp of last sent data packet (jiffies)
+ * @tx_max_rate: Max TX rate (bytes/s). 0 == no limits.
+ * @tx_max_rate: Max UCC TX rate (bytes/s). Via GMTP-UCC. 0 == no limits.
+ * @tx_byte_budget: the amount of bytes that can be sent immediately.
+ * @tx_adj_budget: memory of last adjustment in TX rate.
+ */
+struct gmtp_sock {
+	/* inet_connection_sock has to be the first member of gmtp_sock */
+	struct inet_connection_sock gmtps_inet_connection;
+#define gmtps_syn_rtt 	gmtps_inet_connection.icsk_ack.lrcvtime
+
+	u8 				flowname[GMTP_FLOWNAME_LEN];
+	u8 				relay_id[GMTP_RELAY_ID_LEN];
+
+	u32				iss;
+	u32				isr;
+	u32				gss;
+	u32				gsr;
+	
+	u32				mss;
+
+	enum gmtp_sock_type		type:3;
+	enum gmtp_role			role:3;
+	struct gmtp_client		*myself;
+	struct sock 			*channel_sk;
+
+	u32				req_stamp;
+	u32				reply_stamp;
+	u32				ack_rx_tstamp;
+	u32				ack_tx_tstamp;
+
+	u8				server_timewait:1;
+
+	/** Rx variables */
+	__be32				ndp_count;
+	enum mcc_rx_states		rx_state:8;
+	u32				rx_bytes_recv;
+	u32				rx_x_recv;
+	__be32				rx_max_rate;
+	u32				rx_rtt;
+	u32				rx_avg_rtt;
+	ktime_t				rx_tstamp_last_feedback;
+	struct mcc_rx_hist		rx_hist;
+	struct mcc_loss_hist		rx_li_hist;
+	__u16				rx_s;
+#define rx_pinv				rx_li_hist.i_mean
+	u32 				rx_last_orig_tstamp;
+
+	/** Tx variables */
+	__be32				ndp_sent;
+	u32 				tx_rtt;
+	u32				tx_avg_rtt;
+	u32	 			tx_dpkts_sent;
+	u32				tx_data_sent;
+	u32				tx_bytes_sent;
+
+	u32	 			tx_sample_len;
+	unsigned long 			tx_time_sample; /* jiffies */
+	u32	 			tx_byte_sample;
+
+	unsigned long			tx_sample_rate;
+	unsigned long			tx_total_rate;
+
+	unsigned long			tx_first_stamp;  /* jiffies */
+	unsigned long 			tx_last_stamp;	/* jiffies */
+	unsigned long			tx_media_rate;
+	unsigned long			tx_max_rate;
+	unsigned long			tx_ucc_rate;
+	int 				tx_byte_budget;
+	int				tx_adj_budget;
+	enum gmtp_ucc_type		tx_ucc_type;
+
+	struct timer_list		xmit_timer;
+};
+
+struct gmtp_packet_info {
+	struct sock			*sk;
+	struct sk_buff			*skb;
+};
+
+static inline struct gmtp_sock *gmtp_sk(const struct sock *sk)
+{
+	return (struct gmtp_sock *)sk;
+}
+
+static inline const char *gmtp_role_name(const struct sock *sk)
+{
+	switch (gmtp_sk(sk)->role) {
+	case GMTP_ROLE_UNDEFINED: return "undefined";
+	case GMTP_ROLE_LISTEN:	  return "listen";
+	case GMTP_ROLE_SERVER:	  return "server";
+	case GMTP_ROLE_CLIENT:	  return "client";
+	case GMTP_ROLE_REPORTER:  return "client (reporter)";
+	case GMTP_ROLE_RELAY:	  return "relay";
+	}
+	return NULL;
+}
+
+static inline int gmtp_role_client(const struct sock *sk)
+{
+	return (gmtp_sk(sk)->role == GMTP_ROLE_CLIENT ||
+		gmtp_sk(sk)->role == GMTP_ROLE_REPORTER);
+}
+
+static inline struct gmtp_hdr *gmtp_hdr(const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr *)skb_transport_header(skb);
+}
+
+static inline struct gmtp_hdr *gmtp_zeroed_hdr(struct sk_buff *skb, int headlen)
+{
+	skb_push(skb, headlen);
+	skb_reset_transport_header(skb);
+	return memset(skb_transport_header(skb), 0, headlen);
+}
+
+static inline struct gmtp_hdr_data *gmtp_hdr_data(const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_data *)(skb_transport_header(skb) +
+						 sizeof(struct gmtp_hdr));
+}
+
+static inline struct gmtp_hdr_ack *gmtp_hdr_ack(const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_ack *)(skb_transport_header(skb) +
+						 sizeof(struct gmtp_hdr));
+}
+
+static inline struct gmtp_hdr_dataack *gmtp_hdr_dataack(const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_dataack *)(skb_transport_header(skb) +
+						 sizeof(struct gmtp_hdr));
+}
+
+static inline struct gmtp_hdr_feedback *gmtp_hdr_feedback(const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_feedback *)(skb_transport_header(skb)
+			+ sizeof(struct gmtp_hdr));
+}
+
+static inline struct gmtp_hdr_register_reply *gmtp_hdr_register_reply(
+		const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_register_reply *)(skb_transport_header(skb) +
+						 sizeof(struct gmtp_hdr));
+}
+
+static inline struct gmtp_hdr_register *gmtp_hdr_register(
+		const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_register *)(skb_transport_header(skb) +
+						 sizeof(struct gmtp_hdr));
+}
+
+static inline struct gmtp_hdr_route *gmtp_hdr_route(const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_route *)(skb_transport_header(skb) +
+						 sizeof(struct gmtp_hdr));
+}
+
+static inline struct gmtp_hdr_relay *gmtp_hdr_relay(const struct sk_buff *skb)
+{
+	__u8 *relay_list = NULL;
+	if(gmtp_hdr(skb)->type == GMTP_PKT_REGISTER_REPLY) {
+		relay_list = (__u8 *) gmtp_hdr_register_reply(skb)
+				+ sizeof(struct gmtp_hdr_register_reply);
+	} else if(gmtp_hdr(skb)->type == GMTP_PKT_ROUTE_NOTIFY) {
+		relay_list = (__u8 *) gmtp_hdr_route(skb)
+				+ sizeof(struct gmtp_hdr_route);
+	}
+	return (struct gmtp_hdr_relay *)relay_list;
+}
+
+static inline struct gmtp_hdr_reqnotify *gmtp_hdr_reqnotify(
+		const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_reqnotify *)(skb_transport_header(skb) +
+						 sizeof(struct gmtp_hdr));
+}
+
+static inline struct gmtp_hdr_elect_request *gmtp_hdr_elect_request(
+		const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_elect_request *)(skb_transport_header(skb) +
+						 sizeof(struct gmtp_hdr));
+}
+
+static inline struct gmtp_hdr_elect_response *gmtp_hdr_elect_response(
+		const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_elect_response *)(skb_transport_header(skb) +
+						 sizeof(struct gmtp_hdr));
+}
+
+static inline struct gmtp_hdr_delegate *gmtp_hdr_delegate(
+		const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_delegate *)(skb_transport_header(skb) +
+						 sizeof(struct gmtp_hdr));
+}
+
+static inline struct gmtp_hdr_reset *gmtp_hdr_reset(const struct sk_buff *skb)
+{
+	return (struct gmtp_hdr_reset *)(skb_transport_header(skb) +
+					 sizeof(struct gmtp_hdr));
+}
+
+static inline unsigned int __gmtp_hdr_len(const struct gmtp_hdr *gh)
+{
+	return sizeof(struct gmtp_hdr) + gmtp_packet_hdr_variable_len(gh->type);
+}
+
+static inline unsigned int gmtp_hdr_len(const struct sk_buff *skb)
+{
+	return __gmtp_hdr_len(gmtp_hdr(skb));
+}
+
+static inline __u8 *gmtp_data(const struct sk_buff *skb)
+{
+	return (__u8*) (skb_transport_header(skb) + gmtp_hdr_len(skb));
+}
+
+static inline __u32 gmtp_data_len(const struct sk_buff *skb)
+{
+	return (__u32)(skb_tail_pointer(skb) - gmtp_data(skb));
+}
+
+static inline int gmtp_data_hdr_len(void)
+{
+	return sizeof(struct gmtp_hdr)
+			+ gmtp_packet_hdr_variable_len(GMTP_PKT_DATA);
+}
+
+#endif /* LINUX_GMTP_H_ */
+
+
diff -uprN --new-file linux-4.9-rc2-original/include/linux/net.h linux-4.9-rc2/include/linux/net.h
--- linux-4.9-rc2-original/include/linux/net.h	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/include/linux/net.h	2016-12-02 02:40:52.639249546 -0300
@@ -68,6 +68,7 @@ enum sock_type {
 	SOCK_RDM	= 4,
 	SOCK_SEQPACKET	= 5,
 	SOCK_DCCP	= 6,
+    SOCK_GMTP   = 7,
 	SOCK_PACKET	= 10,
 };
 
diff -uprN --new-file linux-4.9-rc2-original/include/linux/netfilter.h linux-4.9-rc2/include/linux/netfilter.h
--- linux-4.9-rc2-original/include/linux/netfilter.h	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/include/linux/netfilter.h	2016-12-05 00:53:11.823554182 -0300
@@ -17,26 +17,26 @@
 #ifdef CONFIG_NETFILTER
 static inline int NF_DROP_GETERR(int verdict)
 {
-	return -(verdict >> NF_VERDICT_QBITS);
+    return -(verdict >> NF_VERDICT_QBITS);
 }
 
 static inline int nf_inet_addr_cmp(const union nf_inet_addr *a1,
-				   const union nf_inet_addr *a2)
+                   const union nf_inet_addr *a2)
 {
-	return a1->all[0] == a2->all[0] &&
-	       a1->all[1] == a2->all[1] &&
-	       a1->all[2] == a2->all[2] &&
-	       a1->all[3] == a2->all[3];
+    return a1->all[0] == a2->all[0] &&
+           a1->all[1] == a2->all[1] &&
+           a1->all[2] == a2->all[2] &&
+           a1->all[3] == a2->all[3];
 }
 
 static inline void nf_inet_addr_mask(const union nf_inet_addr *a1,
-				     union nf_inet_addr *result,
-				     const union nf_inet_addr *mask)
+                     union nf_inet_addr *result,
+                     const union nf_inet_addr *mask)
 {
-	result->all[0] = a1->all[0] & mask->all[0];
-	result->all[1] = a1->all[1] & mask->all[1];
-	result->all[2] = a1->all[2] & mask->all[2];
-	result->all[3] = a1->all[3] & mask->all[3];
+    result->all[0] = a1->all[0] & mask->all[0];
+    result->all[1] = a1->all[1] & mask->all[1];
+    result->all[2] = a1->all[2] & mask->all[2];
+    result->all[3] = a1->all[3] & mask->all[3];
 }
 
 int netfilter_init(void);
@@ -48,93 +48,93 @@ struct nf_hook_ops;
 struct sock;
 
 struct nf_hook_state {
-	unsigned int hook;
-	int thresh;
-	u_int8_t pf;
-	struct net_device *in;
-	struct net_device *out;
-	struct sock *sk;
-	struct net *net;
-	struct nf_hook_entry __rcu *hook_entries;
-	int (*okfn)(struct net *, struct sock *, struct sk_buff *);
+    unsigned int hook;
+    int thresh;
+    u_int8_t pf;
+    struct net_device *in;
+    struct net_device *out;
+    struct sock *sk;
+    struct net *net;
+    struct nf_hook_entry __rcu *hook_entries;
+    int (*okfn)(struct net *, struct sock *, struct sk_buff *);
 };
 
 typedef unsigned int nf_hookfn(void *priv,
-			       struct sk_buff *skb,
-			       const struct nf_hook_state *state);
+                   struct sk_buff *skb,
+                   const struct nf_hook_state *state);
 struct nf_hook_ops {
-	struct list_head	list;
+    struct list_head    list;
 
-	/* User fills in from here down. */
-	nf_hookfn		*hook;
-	struct net_device	*dev;
-	void			*priv;
-	u_int8_t		pf;
-	unsigned int		hooknum;
-	/* Hooks are ordered in ascending priority. */
-	int			priority;
+    /* User fills in from here down. */
+    nf_hookfn       *hook;
+    struct net_device   *dev;
+    void            *priv;
+    u_int8_t        pf;
+    unsigned int        hooknum;
+    /* Hooks are ordered in ascending priority. */
+    int         priority;
 };
 
 struct nf_hook_entry {
-	struct nf_hook_entry __rcu	*next;
-	struct nf_hook_ops		ops;
-	const struct nf_hook_ops	*orig_ops;
+    struct nf_hook_entry __rcu  *next;
+    struct nf_hook_ops      ops;
+    const struct nf_hook_ops    *orig_ops;
 };
 
 static inline void nf_hook_state_init(struct nf_hook_state *p,
-				      struct nf_hook_entry *hook_entry,
-				      unsigned int hook,
-				      int thresh, u_int8_t pf,
-				      struct net_device *indev,
-				      struct net_device *outdev,
-				      struct sock *sk,
-				      struct net *net,
-				      int (*okfn)(struct net *, struct sock *, struct sk_buff *))
-{
-	p->hook = hook;
-	p->thresh = thresh;
-	p->pf = pf;
-	p->in = indev;
-	p->out = outdev;
-	p->sk = sk;
-	p->net = net;
-	RCU_INIT_POINTER(p->hook_entries, hook_entry);
-	p->okfn = okfn;
+                      struct nf_hook_entry *hook_entry,
+                      unsigned int hook,
+                      int thresh, u_int8_t pf,
+                      struct net_device *indev,
+                      struct net_device *outdev,
+                      struct sock *sk,
+                      struct net *net,
+                      int (*okfn)(struct net *, struct sock *, struct sk_buff *))
+{
+    p->hook = hook;
+    p->thresh = thresh;
+    p->pf = pf;
+    p->in = indev;
+    p->out = outdev;
+    p->sk = sk;
+    p->net = net;
+    RCU_INIT_POINTER(p->hook_entries, hook_entry);
+    p->okfn = okfn;
 }
 
 
 
 struct nf_sockopt_ops {
-	struct list_head list;
+    struct list_head list;
 
-	u_int8_t pf;
+    u_int8_t pf;
 
-	/* Non-inclusive ranges: use 0/0/NULL to never get called. */
-	int set_optmin;
-	int set_optmax;
-	int (*set)(struct sock *sk, int optval, void __user *user, unsigned int len);
+    /* Non-inclusive ranges: use 0/0/NULL to never get called. */
+    int set_optmin;
+    int set_optmax;
+    int (*set)(struct sock *sk, int optval, void __user *user, unsigned int len);
 #ifdef CONFIG_COMPAT
-	int (*compat_set)(struct sock *sk, int optval,
-			void __user *user, unsigned int len);
+    int (*compat_set)(struct sock *sk, int optval,
+            void __user *user, unsigned int len);
 #endif
-	int get_optmin;
-	int get_optmax;
-	int (*get)(struct sock *sk, int optval, void __user *user, int *len);
+    int get_optmin;
+    int get_optmax;
+    int (*get)(struct sock *sk, int optval, void __user *user, int *len);
 #ifdef CONFIG_COMPAT
-	int (*compat_get)(struct sock *sk, int optval,
-			void __user *user, int *len);
+    int (*compat_get)(struct sock *sk, int optval,
+            void __user *user, int *len);
 #endif
-	/* Use the module struct to lock set/get code in place */
-	struct module *owner;
+    /* Use the module struct to lock set/get code in place */
+    struct module *owner;
 };
 
 /* Function to register/unregister hook points. */
 int nf_register_net_hook(struct net *net, const struct nf_hook_ops *ops);
 void nf_unregister_net_hook(struct net *net, const struct nf_hook_ops *ops);
 int nf_register_net_hooks(struct net *net, const struct nf_hook_ops *reg,
-			  unsigned int n);
+              unsigned int n);
 void nf_unregister_net_hooks(struct net *net, const struct nf_hook_ops *reg,
-			     unsigned int n);
+                 unsigned int n);
 
 int nf_register_hook(struct nf_hook_ops *reg);
 void nf_unregister_hook(struct nf_hook_ops *reg);
@@ -155,52 +155,52 @@ extern struct static_key nf_hooks_needed
 int nf_hook_slow(struct sk_buff *skb, struct nf_hook_state *state);
 
 /**
- *	nf_hook_thresh - call a netfilter hook
+ *  nf_hook_thresh - call a netfilter hook
  *
- *	Returns 1 if the hook has allowed the packet to pass.  The function
- *	okfn must be invoked by the caller in this case.  Any other return
- *	value indicates the packet has been consumed by the hook.
+ *  Returns 1 if the hook has allowed the packet to pass.  The function
+ *  okfn must be invoked by the caller in this case.  Any other return
+ *  value indicates the packet has been consumed by the hook.
  */
 static inline int nf_hook_thresh(u_int8_t pf, unsigned int hook,
-				 struct net *net,
-				 struct sock *sk,
-				 struct sk_buff *skb,
-				 struct net_device *indev,
-				 struct net_device *outdev,
-				 int (*okfn)(struct net *, struct sock *, struct sk_buff *),
-				 int thresh)
+                 struct net *net,
+                 struct sock *sk,
+                 struct sk_buff *skb,
+                 struct net_device *indev,
+                 struct net_device *outdev,
+                 int (*okfn)(struct net *, struct sock *, struct sk_buff *),
+                 int thresh)
 {
-	struct nf_hook_entry *hook_head;
-	int ret = 1;
+    struct nf_hook_entry *hook_head;
+    int ret = 1;
 
 #ifdef HAVE_JUMP_LABEL
-	if (__builtin_constant_p(pf) &&
-	    __builtin_constant_p(hook) &&
-	    !static_key_false(&nf_hooks_needed[pf][hook]))
-		return 1;
+    if (__builtin_constant_p(pf) &&
+        __builtin_constant_p(hook) &&
+        !static_key_false(&nf_hooks_needed[pf][hook]))
+        return 1;
 #endif
 
-	rcu_read_lock();
-	hook_head = rcu_dereference(net->nf.hooks[pf][hook]);
-	if (hook_head) {
-		struct nf_hook_state state;
-
-		nf_hook_state_init(&state, hook_head, hook, thresh,
-				   pf, indev, outdev, sk, net, okfn);
-
-		ret = nf_hook_slow(skb, &state);
-	}
-	rcu_read_unlock();
+    rcu_read_lock();
+    hook_head = rcu_dereference(net->nf.hooks[pf][hook]);
+    if (hook_head) {
+        struct nf_hook_state state;
+
+        nf_hook_state_init(&state, hook_head, hook, thresh,
+                   pf, indev, outdev, sk, net, okfn);
+
+        ret = nf_hook_slow(skb, &state);
+    }
+    rcu_read_unlock();
 
-	return ret;
+    return ret;
 }
 
 static inline int nf_hook(u_int8_t pf, unsigned int hook, struct net *net,
-			  struct sock *sk, struct sk_buff *skb,
-			  struct net_device *indev, struct net_device *outdev,
-			  int (*okfn)(struct net *, struct sock *, struct sk_buff *))
+              struct sock *sk, struct sk_buff *skb,
+              struct net_device *indev, struct net_device *outdev,
+              int (*okfn)(struct net *, struct sock *, struct sk_buff *))
 {
-	return nf_hook_thresh(pf, hook, net, sk, skb, indev, outdev, okfn, INT_MIN);
+    return nf_hook_thresh(pf, hook, net, sk, skb, indev, outdev, okfn, INT_MIN);
 }
                    
 /* Activate hook; either okfn or kfree_skb called, unless a hook
@@ -222,49 +222,49 @@ static inline int nf_hook(u_int8_t pf, u
 
 static inline int
 NF_HOOK_THRESH(uint8_t pf, unsigned int hook, struct net *net, struct sock *sk,
-	       struct sk_buff *skb, struct net_device *in,
-	       struct net_device *out,
-	       int (*okfn)(struct net *, struct sock *, struct sk_buff *),
-	       int thresh)
-{
-	int ret = nf_hook_thresh(pf, hook, net, sk, skb, in, out, okfn, thresh);
-	if (ret == 1)
-		ret = okfn(net, sk, skb);
-	return ret;
+           struct sk_buff *skb, struct net_device *in,
+           struct net_device *out,
+           int (*okfn)(struct net *, struct sock *, struct sk_buff *),
+           int thresh)
+{
+    int ret = nf_hook_thresh(pf, hook, net, sk, skb, in, out, okfn, thresh);
+    if (ret == 1)
+        ret = okfn(net, sk, skb);
+    return ret;
 }
 
 static inline int
 NF_HOOK_COND(uint8_t pf, unsigned int hook, struct net *net, struct sock *sk,
-	     struct sk_buff *skb, struct net_device *in, struct net_device *out,
-	     int (*okfn)(struct net *, struct sock *, struct sk_buff *),
-	     bool cond)
-{
-	int ret;
-
-	if (!cond ||
-	    ((ret = nf_hook_thresh(pf, hook, net, sk, skb, in, out, okfn, INT_MIN)) == 1))
-		ret = okfn(net, sk, skb);
-	return ret;
+         struct sk_buff *skb, struct net_device *in, struct net_device *out,
+         int (*okfn)(struct net *, struct sock *, struct sk_buff *),
+         bool cond)
+{
+    int ret;
+
+    if (!cond ||
+        ((ret = nf_hook_thresh(pf, hook, net, sk, skb, in, out, okfn, INT_MIN)) == 1))
+        ret = okfn(net, sk, skb);
+    return ret;
 }
 
 static inline int
 NF_HOOK(uint8_t pf, unsigned int hook, struct net *net, struct sock *sk, struct sk_buff *skb,
-	struct net_device *in, struct net_device *out,
-	int (*okfn)(struct net *, struct sock *, struct sk_buff *))
+    struct net_device *in, struct net_device *out,
+    int (*okfn)(struct net *, struct sock *, struct sk_buff *))
 {
-	return NF_HOOK_THRESH(pf, hook, net, sk, skb, in, out, okfn, INT_MIN);
+    return NF_HOOK_THRESH(pf, hook, net, sk, skb, in, out, okfn, INT_MIN);
 }
 
 /* Call setsockopt() */
 int nf_setsockopt(struct sock *sk, u_int8_t pf, int optval, char __user *opt,
-		  unsigned int len);
+          unsigned int len);
 int nf_getsockopt(struct sock *sk, u_int8_t pf, int optval, char __user *opt,
-		  int *len);
+          int *len);
 #ifdef CONFIG_COMPAT
 int compat_nf_setsockopt(struct sock *sk, u_int8_t pf, int optval,
-		char __user *opt, unsigned int len);
+        char __user *opt, unsigned int len);
 int compat_nf_getsockopt(struct sock *sk, u_int8_t pf, int optval,
-		char __user *opt, int *len);
+        char __user *opt, int *len);
 #endif
 
 /* Call this before modifying an existing packet: ensures it is
@@ -276,59 +276,59 @@ struct flowi;
 struct nf_queue_entry;
 
 struct nf_afinfo {
-	unsigned short	family;
-	__sum16		(*checksum)(struct sk_buff *skb, unsigned int hook,
-				    unsigned int dataoff, u_int8_t protocol);
-	__sum16		(*checksum_partial)(struct sk_buff *skb,
-					    unsigned int hook,
-					    unsigned int dataoff,
-					    unsigned int len,
-					    u_int8_t protocol);
-	int		(*route)(struct net *net, struct dst_entry **dst,
-				 struct flowi *fl, bool strict);
-	void		(*saveroute)(const struct sk_buff *skb,
-				     struct nf_queue_entry *entry);
-	int		(*reroute)(struct net *net, struct sk_buff *skb,
-				   const struct nf_queue_entry *entry);
-	int		route_key_size;
+    unsigned short  family;
+    __sum16     (*checksum)(struct sk_buff *skb, unsigned int hook,
+                    unsigned int dataoff, u_int8_t protocol);
+    __sum16     (*checksum_partial)(struct sk_buff *skb,
+                        unsigned int hook,
+                        unsigned int dataoff,
+                        unsigned int len,
+                        u_int8_t protocol);
+    int     (*route)(struct net *net, struct dst_entry **dst,
+                 struct flowi *fl, bool strict);
+    void        (*saveroute)(const struct sk_buff *skb,
+                     struct nf_queue_entry *entry);
+    int     (*reroute)(struct net *net, struct sk_buff *skb,
+                   const struct nf_queue_entry *entry);
+    int     route_key_size;
 };
 
 extern const struct nf_afinfo __rcu *nf_afinfo[NFPROTO_NUMPROTO];
 static inline const struct nf_afinfo *nf_get_afinfo(unsigned short family)
 {
-	return rcu_dereference(nf_afinfo[family]);
+    return rcu_dereference(nf_afinfo[family]);
 }
 
 static inline __sum16
 nf_checksum(struct sk_buff *skb, unsigned int hook, unsigned int dataoff,
-	    u_int8_t protocol, unsigned short family)
+        u_int8_t protocol, unsigned short family)
 {
-	const struct nf_afinfo *afinfo;
-	__sum16 csum = 0;
+    const struct nf_afinfo *afinfo;
+    __sum16 csum = 0;
 
-	rcu_read_lock();
-	afinfo = nf_get_afinfo(family);
-	if (afinfo)
-		csum = afinfo->checksum(skb, hook, dataoff, protocol);
-	rcu_read_unlock();
-	return csum;
+    rcu_read_lock();
+    afinfo = nf_get_afinfo(family);
+    if (afinfo)
+        csum = afinfo->checksum(skb, hook, dataoff, protocol);
+    rcu_read_unlock();
+    return csum;
 }
 
 static inline __sum16
 nf_checksum_partial(struct sk_buff *skb, unsigned int hook,
-		    unsigned int dataoff, unsigned int len,
-		    u_int8_t protocol, unsigned short family)
+            unsigned int dataoff, unsigned int len,
+            u_int8_t protocol, unsigned short family)
 {
-	const struct nf_afinfo *afinfo;
-	__sum16 csum = 0;
+    const struct nf_afinfo *afinfo;
+    __sum16 csum = 0;
 
-	rcu_read_lock();
-	afinfo = nf_get_afinfo(family);
-	if (afinfo)
-		csum = afinfo->checksum_partial(skb, hook, dataoff, len,
-						protocol);
-	rcu_read_unlock();
-	return csum;
+    rcu_read_lock();
+    afinfo = nf_get_afinfo(family);
+    if (afinfo)
+        csum = afinfo->checksum_partial(skb, hook, dataoff, len,
+                        protocol);
+    rcu_read_unlock();
+    return csum;
 }
 
 int nf_register_afinfo(const struct nf_afinfo *afinfo);
@@ -341,40 +341,40 @@ static inline void
 nf_nat_decode_session(struct sk_buff *skb, struct flowi *fl, u_int8_t family)
 {
 #ifdef CONFIG_NF_NAT_NEEDED
-	void (*decodefn)(struct sk_buff *, struct flowi *);
+    void (*decodefn)(struct sk_buff *, struct flowi *);
 
-	rcu_read_lock();
-	decodefn = rcu_dereference(nf_nat_decode_session_hook);
-	if (decodefn)
-		decodefn(skb, fl);
-	rcu_read_unlock();
+    rcu_read_lock();
+    decodefn = rcu_dereference(nf_nat_decode_session_hook);
+    if (decodefn)
+        decodefn(skb, fl);
+    rcu_read_unlock();
 #endif
 }
 
 #else /* !CONFIG_NETFILTER */
 static inline int
 NF_HOOK_COND(uint8_t pf, unsigned int hook, struct net *net, struct sock *sk,
-	     struct sk_buff *skb, struct net_device *in, struct net_device *out,
-	     int (*okfn)(struct net *, struct sock *, struct sk_buff *),
-	     bool cond)
+         struct sk_buff *skb, struct net_device *in, struct net_device *out,
+         int (*okfn)(struct net *, struct sock *, struct sk_buff *),
+         bool cond)
 {
-	return okfn(net, sk, skb);
+    return okfn(net, sk, skb);
 }
 
 static inline int
 NF_HOOK(uint8_t pf, unsigned int hook, struct net *net, struct sock *sk,
-	struct sk_buff *skb, struct net_device *in, struct net_device *out,
-	int (*okfn)(struct net *, struct sock *, struct sk_buff *))
+    struct sk_buff *skb, struct net_device *in, struct net_device *out,
+    int (*okfn)(struct net *, struct sock *, struct sk_buff *))
 {
-	return okfn(net, sk, skb);
+    return okfn(net, sk, skb);
 }
 
 static inline int nf_hook(u_int8_t pf, unsigned int hook, struct net *net,
-			  struct sock *sk, struct sk_buff *skb,
-			  struct net_device *indev, struct net_device *outdev,
-			  int (*okfn)(struct net *, struct sock *, struct sk_buff *))
+              struct sock *sk, struct sk_buff *skb,
+              struct net_device *indev, struct net_device *outdev,
+              int (*okfn)(struct net *, struct sock *, struct sk_buff *))
 {
-	return 1;
+    return 1;
 }
 struct flowi;
 static inline void
@@ -398,17 +398,17 @@ enum ip_conntrack_info;
 struct nlattr;
 
 struct nfnl_ct_hook {
-	struct nf_conn *(*get_ct)(const struct sk_buff *skb,
-				  enum ip_conntrack_info *ctinfo);
-	size_t (*build_size)(const struct nf_conn *ct);
-	int (*build)(struct sk_buff *skb, struct nf_conn *ct,
-		     enum ip_conntrack_info ctinfo,
-		     u_int16_t ct_attr, u_int16_t ct_info_attr);
-	int (*parse)(const struct nlattr *attr, struct nf_conn *ct);
-	int (*attach_expect)(const struct nlattr *attr, struct nf_conn *ct,
-			     u32 portid, u32 report);
-	void (*seq_adjust)(struct sk_buff *skb, struct nf_conn *ct,
-			   enum ip_conntrack_info ctinfo, s32 off);
+    struct nf_conn *(*get_ct)(const struct sk_buff *skb,
+                  enum ip_conntrack_info *ctinfo);
+    size_t (*build_size)(const struct nf_conn *ct);
+    int (*build)(struct sk_buff *skb, struct nf_conn *ct,
+             enum ip_conntrack_info ctinfo,
+             u_int16_t ct_attr, u_int16_t ct_info_attr);
+    int (*parse)(const struct nlattr *attr, struct nf_conn *ct);
+    int (*attach_expect)(const struct nlattr *attr, struct nf_conn *ct,
+                 u32 portid, u32 report);
+    void (*seq_adjust)(struct sk_buff *skb, struct nf_conn *ct,
+               enum ip_conntrack_info ctinfo, s32 off);
 };
 extern struct nfnl_ct_hook __rcu *nfnl_ct_hook;
 
diff -uprN --new-file linux-4.9-rc2-original/include/linux/socket.h linux-4.9-rc2/include/linux/socket.h
--- linux-4.9-rc2-original/include/linux/socket.h	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/include/linux/socket.h	2016-12-01 22:26:14.051787875 -0300
@@ -329,6 +329,7 @@ struct ucred {
 #define SOL_ALG		279
 #define SOL_NFC		280
 #define SOL_KCM		281
+#define SOL_GMTP	282
 
 /* IPX options */
 #define IPX_TYPE	1
diff -uprN --new-file linux-4.9-rc2-original/include/net/icmp.h linux-4.9-rc2/include/net/icmp.h
--- linux-4.9-rc2-original/include/net/icmp.h	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/include/net/icmp.h	2016-12-02 17:37:41.829847641 -0300
@@ -1,22 +1,22 @@
 /*
- * INET		An implementation of the TCP/IP protocol suite for the LINUX
- *		operating system.  INET is implemented using the  BSD Socket
- *		interface as the means of communication with the user level.
+ * INET     An implementation of the TCP/IP protocol suite for the LINUX
+ *      operating system.  INET is implemented using the  BSD Socket
+ *      interface as the means of communication with the user level.
  *
- *		Definitions for the ICMP module.
+ *      Definitions for the ICMP module.
  *
- * Version:	@(#)icmp.h	1.0.4	05/13/93
+ * Version: @(#)icmp.h  1.0.4   05/13/93
  *
- * Authors:	Ross Biro
- *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>
+ * Authors: Ross Biro
+ *      Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>
  *
- *		This program is free software; you can redistribute it and/or
- *		modify it under the terms of the GNU General Public License
- *		as published by the Free Software Foundation; either version
- *		2 of the License, or (at your option) any later version.
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
  */
 #ifndef _ICMP_H
-#define	_ICMP_H
+#define _ICMP_H
 
 #include <linux/icmp.h>
 
@@ -24,15 +24,15 @@
 #include <net/snmp.h>
 
 struct icmp_err {
-  int		errno;
-  unsigned int	fatal:1;
+  int       errno;
+  unsigned int  fatal:1;
 };
 
 extern const struct icmp_err icmp_err_convert[];
-#define ICMP_INC_STATS(net, field)	SNMP_INC_STATS((net)->mib.icmp_statistics, field)
-#define __ICMP_INC_STATS(net, field)	__SNMP_INC_STATS((net)->mib.icmp_statistics, field)
-#define ICMPMSGOUT_INC_STATS(net, field)	SNMP_INC_STATS_ATOMIC_LONG((net)->mib.icmpmsg_statistics, field+256)
-#define ICMPMSGIN_INC_STATS(net, field)		SNMP_INC_STATS_ATOMIC_LONG((net)->mib.icmpmsg_statistics, field)
+#define ICMP_INC_STATS(net, field)  SNMP_INC_STATS((net)->mib.icmp_statistics, field)
+#define __ICMP_INC_STATS(net, field)    __SNMP_INC_STATS((net)->mib.icmp_statistics, field)
+#define ICMPMSGOUT_INC_STATS(net, field)    SNMP_INC_STATS_ATOMIC_LONG((net)->mib.icmpmsg_statistics, field+256)
+#define ICMPMSGIN_INC_STATS(net, field)     SNMP_INC_STATS_ATOMIC_LONG((net)->mib.icmpmsg_statistics, field)
 
 struct dst_entry;
 struct net_proto_family;
@@ -45,4 +45,4 @@ void icmp_err(struct sk_buff *skb, u32 i
 int icmp_init(void);
 void icmp_out_count(struct net *net, unsigned char type);
 
-#endif	/* _ICMP_H */
+#endif  /* _ICMP_H */
diff -uprN --new-file linux-4.9-rc2-original/include/net/inet_connection_sock.h linux-4.9-rc2/include/net/inet_connection_sock.h
--- linux-4.9-rc2-original/include/net/inet_connection_sock.h	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/include/net/inet_connection_sock.h	2016-12-03 13:19:42.109862388 -0300
@@ -1,16 +1,16 @@
 /*
- * NET		Generic infrastructure for INET connection oriented protocols.
+ * NET      Generic infrastructure for INET connection oriented protocols.
  *
- *		Definitions for inet_connection_sock 
+ *      Definitions for inet_connection_sock 
  *
- * Authors:	Many people, see the TCP sources
+ * Authors: Many people, see the TCP sources
  *
- * 		From code originally in TCP
+ *      From code originally in TCP
  *
- *		This program is free software; you can redistribute it and/or
- *		modify it under the terms of the GNU General Public License
- *		as published by the Free Software Foundation; either version
- *		2 of the License, or (at your option) any later version.
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
  */
 #ifndef _INET_CONNECTION_SOCK_H
 #define _INET_CONNECTION_SOCK_H
@@ -36,154 +36,154 @@ struct tcp_congestion_ops;
  * (i.e. things that depend on the address family)
  */
 struct inet_connection_sock_af_ops {
-	int	    (*queue_xmit)(struct sock *sk, struct sk_buff *skb, struct flowi *fl);
-	void	    (*send_check)(struct sock *sk, struct sk_buff *skb);
-	int	    (*rebuild_header)(struct sock *sk);
-	void	    (*sk_rx_dst_set)(struct sock *sk, const struct sk_buff *skb);
-	int	    (*conn_request)(struct sock *sk, struct sk_buff *skb);
-	struct sock *(*syn_recv_sock)(const struct sock *sk, struct sk_buff *skb,
-				      struct request_sock *req,
-				      struct dst_entry *dst,
-				      struct request_sock *req_unhash,
-				      bool *own_req);
-	u16	    net_header_len;
-	u16	    net_frag_header_len;
-	u16	    sockaddr_len;
-	int	    (*setsockopt)(struct sock *sk, int level, int optname, 
-				  char __user *optval, unsigned int optlen);
-	int	    (*getsockopt)(struct sock *sk, int level, int optname, 
-				  char __user *optval, int __user *optlen);
+    int     (*queue_xmit)(struct sock *sk, struct sk_buff *skb, struct flowi *fl);
+    void        (*send_check)(struct sock *sk, struct sk_buff *skb);
+    int     (*rebuild_header)(struct sock *sk);
+    void        (*sk_rx_dst_set)(struct sock *sk, const struct sk_buff *skb);
+    int     (*conn_request)(struct sock *sk, struct sk_buff *skb);
+    struct sock *(*syn_recv_sock)(const struct sock *sk, struct sk_buff *skb,
+                      struct request_sock *req,
+                      struct dst_entry *dst,
+                      struct request_sock *req_unhash,
+                      bool *own_req);
+    u16     net_header_len;
+    u16     net_frag_header_len;
+    u16     sockaddr_len;
+    int     (*setsockopt)(struct sock *sk, int level, int optname, 
+                  char __user *optval, unsigned int optlen);
+    int     (*getsockopt)(struct sock *sk, int level, int optname, 
+                  char __user *optval, int __user *optlen);
 #ifdef CONFIG_COMPAT
-	int	    (*compat_setsockopt)(struct sock *sk,
-				int level, int optname,
-				char __user *optval, unsigned int optlen);
-	int	    (*compat_getsockopt)(struct sock *sk,
-				int level, int optname,
-				char __user *optval, int __user *optlen);
+    int     (*compat_setsockopt)(struct sock *sk,
+                int level, int optname,
+                char __user *optval, unsigned int optlen);
+    int     (*compat_getsockopt)(struct sock *sk,
+                int level, int optname,
+                char __user *optval, int __user *optlen);
 #endif
-	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
-	int	    (*bind_conflict)(const struct sock *sk,
-				     const struct inet_bind_bucket *tb, bool relax);
-	void	    (*mtu_reduced)(struct sock *sk);
+    void        (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
+    int     (*bind_conflict)(const struct sock *sk,
+                     const struct inet_bind_bucket *tb, bool relax);
+    void        (*mtu_reduced)(struct sock *sk);
 };
 
 /** inet_connection_sock - INET connection oriented sock
  *
- * @icsk_accept_queue:	   FIFO of established children 
- * @icsk_bind_hash:	   Bind node
- * @icsk_timeout:	   Timeout
+ * @icsk_accept_queue:     FIFO of established children 
+ * @icsk_bind_hash:    Bind node
+ * @icsk_timeout:      Timeout
  * @icsk_retransmit_timer: Resend (no ack)
- * @icsk_rto:		   Retransmit timeout
- * @icsk_pmtu_cookie	   Last pmtu seen by socket
- * @icsk_ca_ops		   Pluggable congestion control hook
- * @icsk_af_ops		   Operations which are AF_INET{4,6} specific
- * @icsk_ca_state:	   Congestion control state
- * @icsk_retransmits:	   Number of unrecovered [RTO] timeouts
- * @icsk_pending:	   Scheduled timer event
- * @icsk_backoff:	   Backoff
+ * @icsk_rto:          Retransmit timeout
+ * @icsk_pmtu_cookie       Last pmtu seen by socket
+ * @icsk_ca_ops        Pluggable congestion control hook
+ * @icsk_af_ops        Operations which are AF_INET{4,6} specific
+ * @icsk_ca_state:     Congestion control state
+ * @icsk_retransmits:      Number of unrecovered [RTO] timeouts
+ * @icsk_pending:      Scheduled timer event
+ * @icsk_backoff:      Backoff
  * @icsk_syn_retries:      Number of allowed SYN (or equivalent) retries
- * @icsk_probes_out:	   unanswered 0 window probes
- * @icsk_ext_hdr_len:	   Network protocol overhead (IP/IPv6 options)
- * @icsk_ack:		   Delayed ACK control data
- * @icsk_mtup;		   MTU probing control data
+ * @icsk_probes_out:       unanswered 0 window probes
+ * @icsk_ext_hdr_len:      Network protocol overhead (IP/IPv6 options)
+ * @icsk_ack:          Delayed ACK control data
+ * @icsk_mtup;         MTU probing control data
  */
 struct inet_connection_sock {
-	/* inet_sock has to be the first member! */
-	struct inet_sock	  icsk_inet;
-	struct request_sock_queue icsk_accept_queue;
-	struct inet_bind_bucket	  *icsk_bind_hash;
-	unsigned long		  icsk_timeout;
- 	struct timer_list	  icsk_retransmit_timer;
- 	struct timer_list	  icsk_delack_timer;
-	__u32			  icsk_rto;
-	__u32			  icsk_pmtu_cookie;
-	const struct tcp_congestion_ops *icsk_ca_ops;
-	const struct inet_connection_sock_af_ops *icsk_af_ops;
-	unsigned int		  (*icsk_sync_mss)(struct sock *sk, u32 pmtu);
-	__u8			  icsk_ca_state:6,
-				  icsk_ca_setsockopt:1,
-				  icsk_ca_dst_locked:1;
-	__u8			  icsk_retransmits;
-	__u8			  icsk_pending;
-	__u8			  icsk_backoff;
-	__u8			  icsk_syn_retries;
-	__u8			  icsk_probes_out;
-	__u16			  icsk_ext_hdr_len;
-	struct {
-		__u8		  pending;	 /* ACK is pending			   */
-		__u8		  quick;	 /* Scheduled number of quick acks	   */
-		__u8		  pingpong;	 /* The session is interactive		   */
-		__u8		  blocked;	 /* Delayed ACK was blocked by socket lock */
-		__u32		  ato;		 /* Predicted tick of soft clock	   */
-		unsigned long	  timeout;	 /* Currently scheduled timeout		   */
-		__u32		  lrcvtime;	 /* timestamp of last received data packet */
-		__u16		  last_seg_size; /* Size of last incoming segment	   */
-		__u16		  rcv_mss;	 /* MSS used for delayed ACK decisions	   */ 
-	} icsk_ack;
-	struct {
-		int		  enabled;
-
-		/* Range of MTUs to search */
-		int		  search_high;
-		int		  search_low;
-
-		/* Information on the current probe. */
-		int		  probe_size;
-
-		u32		  probe_timestamp;
-	} icsk_mtup;
-	u32			  icsk_user_timeout;
+    /* inet_sock has to be the first member! */
+    struct inet_sock      icsk_inet;
+    struct request_sock_queue icsk_accept_queue;
+    struct inet_bind_bucket   *icsk_bind_hash;
+    unsigned long         icsk_timeout;
+    struct timer_list     icsk_retransmit_timer;
+    struct timer_list     icsk_delack_timer;
+    __u32             icsk_rto;
+    __u32             icsk_pmtu_cookie;
+    const struct tcp_congestion_ops *icsk_ca_ops;
+    const struct inet_connection_sock_af_ops *icsk_af_ops;
+    unsigned int          (*icsk_sync_mss)(struct sock *sk, u32 pmtu);
+    __u8              icsk_ca_state:6,
+                    icsk_ca_setsockopt:1,
+                    icsk_ca_dst_locked:1;
+    __u8              icsk_retransmits;
+    __u8              icsk_pending;
+    __u8              icsk_backoff;
+    __u8              icsk_syn_retries;
+    __u8              icsk_probes_out;
+    __u16             icsk_ext_hdr_len;
+    struct {
+        __u8          pending;   /* ACK is pending             */
+        __u8          quick;     /* Scheduled number of quick acks     */
+        __u8          pingpong;  /* The session is interactive         */
+        __u8          blocked;   /* Delayed ACK was blocked by socket lock */
+        __u32         ato;       /* Predicted tick of soft clock       */
+        unsigned long     timeout;   /* Currently scheduled timeout        */
+        __u32         lrcvtime;  /* timestamp of last received data packet */
+        __u16         last_seg_size; /* Size of last incoming segment      */
+        __u16         rcv_mss;   /* MSS used for delayed ACK decisions     */ 
+    } icsk_ack;
+    struct {
+        int       enabled;
+
+        /* Range of MTUs to search */
+        int       search_high;
+        int       search_low;
+
+        /* Information on the current probe. */
+        int       probe_size;
+
+        u32       probe_timestamp;
+    } icsk_mtup;
+    u32           icsk_user_timeout;
 
-	u64			  icsk_ca_priv[88 / sizeof(u64)];
+    u64           icsk_ca_priv[88 / sizeof(u64)];
 #define ICSK_CA_PRIV_SIZE      (11 * sizeof(u64))
 };
 
-#define ICSK_TIME_RETRANS	1	/* Retransmit timer */
-#define ICSK_TIME_DACK		2	/* Delayed ack timer */
-#define ICSK_TIME_PROBE0	3	/* Zero window probe timer */
-#define ICSK_TIME_EARLY_RETRANS 4	/* Early retransmit timer */
-#define ICSK_TIME_LOSS_PROBE	5	/* Tail loss probe timer */
+#define ICSK_TIME_RETRANS   1   /* Retransmit timer */
+#define ICSK_TIME_DACK      2   /* Delayed ack timer */
+#define ICSK_TIME_PROBE0    3   /* Zero window probe timer */
+#define ICSK_TIME_EARLY_RETRANS 4   /* Early retransmit timer */
+#define ICSK_TIME_LOSS_PROBE    5   /* Tail loss probe timer */
 
 static inline struct inet_connection_sock *inet_csk(const struct sock *sk)
 {
-	return (struct inet_connection_sock *)sk;
+    return (struct inet_connection_sock *)sk;
 }
 
 static inline void *inet_csk_ca(const struct sock *sk)
 {
-	return (void *)inet_csk(sk)->icsk_ca_priv;
+    return (void *)inet_csk(sk)->icsk_ca_priv;
 }
 
 struct sock *inet_csk_clone_lock(const struct sock *sk,
-				 const struct request_sock *req,
-				 const gfp_t priority);
+                 const struct request_sock *req,
+                 const gfp_t priority);
 
 enum inet_csk_ack_state_t {
-	ICSK_ACK_SCHED	= 1,
-	ICSK_ACK_TIMER  = 2,
-	ICSK_ACK_PUSHED = 4,
-	ICSK_ACK_PUSHED2 = 8
+    ICSK_ACK_SCHED  = 1,
+    ICSK_ACK_TIMER  = 2,
+    ICSK_ACK_PUSHED = 4,
+    ICSK_ACK_PUSHED2 = 8
 };
 
 void inet_csk_init_xmit_timers(struct sock *sk,
-			       void (*retransmit_handler)(unsigned long),
-			       void (*delack_handler)(unsigned long),
-			       void (*keepalive_handler)(unsigned long));
+                   void (*retransmit_handler)(unsigned long),
+                   void (*delack_handler)(unsigned long),
+                   void (*keepalive_handler)(unsigned long));
 void inet_csk_clear_xmit_timers(struct sock *sk);
 
 static inline void inet_csk_schedule_ack(struct sock *sk)
 {
-	inet_csk(sk)->icsk_ack.pending |= ICSK_ACK_SCHED;
+    inet_csk(sk)->icsk_ack.pending |= ICSK_ACK_SCHED;
 }
 
 static inline int inet_csk_ack_scheduled(const struct sock *sk)
 {
-	return inet_csk(sk)->icsk_ack.pending & ICSK_ACK_SCHED;
+    return inet_csk(sk)->icsk_ack.pending & ICSK_ACK_SCHED;
 }
 
 static inline void inet_csk_delack_init(struct sock *sk)
 {
-	memset(&inet_csk(sk)->icsk_ack, 0, sizeof(inet_csk(sk)->icsk_ack));
+    memset(&inet_csk(sk)->icsk_ack, 0, sizeof(inet_csk(sk)->icsk_ack));
 }
 
 void inet_csk_delete_keepalive_timer(struct sock *sk);
@@ -195,63 +195,63 @@ extern const char inet_csk_timer_bug_msg
 
 static inline void inet_csk_clear_xmit_timer(struct sock *sk, const int what)
 {
-	struct inet_connection_sock *icsk = inet_csk(sk);
-	
-	if (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0) {
-		icsk->icsk_pending = 0;
+    struct inet_connection_sock *icsk = inet_csk(sk);
+    
+    if (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0) {
+        icsk->icsk_pending = 0;
 #ifdef INET_CSK_CLEAR_TIMERS
-		sk_stop_timer(sk, &icsk->icsk_retransmit_timer);
+        sk_stop_timer(sk, &icsk->icsk_retransmit_timer);
 #endif
-	} else if (what == ICSK_TIME_DACK) {
-		icsk->icsk_ack.blocked = icsk->icsk_ack.pending = 0;
+    } else if (what == ICSK_TIME_DACK) {
+        icsk->icsk_ack.blocked = icsk->icsk_ack.pending = 0;
 #ifdef INET_CSK_CLEAR_TIMERS
-		sk_stop_timer(sk, &icsk->icsk_delack_timer);
+        sk_stop_timer(sk, &icsk->icsk_delack_timer);
 #endif
-	}
+    }
 #ifdef INET_CSK_DEBUG
-	else {
-		pr_debug("%s", inet_csk_timer_bug_msg);
-	}
+    else {
+        pr_debug("%s", inet_csk_timer_bug_msg);
+    }
 #endif
 }
 
 /*
- *	Reset the retransmission timer
+ *  Reset the retransmission timer
  */
 static inline void inet_csk_reset_xmit_timer(struct sock *sk, const int what,
-					     unsigned long when,
-					     const unsigned long max_when)
+                         unsigned long when,
+                         const unsigned long max_when)
 {
-	struct inet_connection_sock *icsk = inet_csk(sk);
+    struct inet_connection_sock *icsk = inet_csk(sk);
 
-	if (when > max_when) {
+    if (when > max_when) {
 #ifdef INET_CSK_DEBUG
-		pr_debug("reset_xmit_timer: sk=%p %d when=0x%lx, caller=%p\n",
-			 sk, what, when, current_text_addr());
+        pr_debug("reset_xmit_timer: sk=%p %d when=0x%lx, caller=%p\n",
+             sk, what, when, current_text_addr());
 #endif
-		when = max_when;
-	}
+        when = max_when;
+    }
 
-	if (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0 ||
-	    what == ICSK_TIME_EARLY_RETRANS || what ==  ICSK_TIME_LOSS_PROBE) {
-		icsk->icsk_pending = what;
-		icsk->icsk_timeout = jiffies + when;
-		sk_reset_timer(sk, &icsk->icsk_retransmit_timer, icsk->icsk_timeout);
-	} else if (what == ICSK_TIME_DACK) {
-		icsk->icsk_ack.pending |= ICSK_ACK_TIMER;
-		icsk->icsk_ack.timeout = jiffies + when;
-		sk_reset_timer(sk, &icsk->icsk_delack_timer, icsk->icsk_ack.timeout);
-	}
+    if (what == ICSK_TIME_RETRANS || what == ICSK_TIME_PROBE0 ||
+        what == ICSK_TIME_EARLY_RETRANS || what ==  ICSK_TIME_LOSS_PROBE) {
+        icsk->icsk_pending = what;
+        icsk->icsk_timeout = jiffies + when;
+        sk_reset_timer(sk, &icsk->icsk_retransmit_timer, icsk->icsk_timeout);
+    } else if (what == ICSK_TIME_DACK) {
+        icsk->icsk_ack.pending |= ICSK_ACK_TIMER;
+        icsk->icsk_ack.timeout = jiffies + when;
+        sk_reset_timer(sk, &icsk->icsk_delack_timer, icsk->icsk_ack.timeout);
+    }
 #ifdef INET_CSK_DEBUG
-	else {
-		pr_debug("%s", inet_csk_timer_bug_msg);
-	}
+    else {
+        pr_debug("%s", inet_csk_timer_bug_msg);
+    }
 #endif
 }
 
 static inline unsigned long
 inet_csk_rto_backoff(const struct inet_connection_sock *icsk,
-		     unsigned long max_when)
+             unsigned long max_when)
 {
         u64 when = (u64)icsk->icsk_rto << icsk->icsk_backoff;
 
@@ -261,42 +261,42 @@ inet_csk_rto_backoff(const struct inet_c
 struct sock *inet_csk_accept(struct sock *sk, int flags, int *err);
 
 int inet_csk_bind_conflict(const struct sock *sk,
-			   const struct inet_bind_bucket *tb, bool relax);
+               const struct inet_bind_bucket *tb, bool relax);
 int inet_csk_get_port(struct sock *sk, unsigned short snum);
 
 struct dst_entry *inet_csk_route_req(const struct sock *sk, struct flowi4 *fl4,
-				     const struct request_sock *req);
+                     const struct request_sock *req);
 struct dst_entry *inet_csk_route_child_sock(const struct sock *sk,
-					    struct sock *newsk,
-					    const struct request_sock *req);
+                        struct sock *newsk,
+                        const struct request_sock *req);
 
 struct sock *inet_csk_reqsk_queue_add(struct sock *sk,
-				      struct request_sock *req,
-				      struct sock *child);
+                      struct request_sock *req,
+                      struct sock *child);
 void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,
-				   unsigned long timeout);
+                   unsigned long timeout);
 struct sock *inet_csk_complete_hashdance(struct sock *sk, struct sock *child,
-					 struct request_sock *req,
-					 bool own_req);
+                     struct request_sock *req,
+                     bool own_req);
 
 static inline void inet_csk_reqsk_queue_added(struct sock *sk)
 {
-	reqsk_queue_added(&inet_csk(sk)->icsk_accept_queue);
+    reqsk_queue_added(&inet_csk(sk)->icsk_accept_queue);
 }
 
 static inline int inet_csk_reqsk_queue_len(const struct sock *sk)
 {
-	return reqsk_queue_len(&inet_csk(sk)->icsk_accept_queue);
+    return reqsk_queue_len(&inet_csk(sk)->icsk_accept_queue);
 }
 
 static inline int inet_csk_reqsk_queue_young(const struct sock *sk)
 {
-	return reqsk_queue_len_young(&inet_csk(sk)->icsk_accept_queue);
+    return reqsk_queue_len_young(&inet_csk(sk)->icsk_accept_queue);
 }
 
 static inline int inet_csk_reqsk_queue_is_full(const struct sock *sk)
 {
-	return inet_csk_reqsk_queue_len(sk) >= sk->sk_max_ack_backlog;
+    return inet_csk_reqsk_queue_len(sk) >= sk->sk_max_ack_backlog;
 }
 
 void inet_csk_reqsk_queue_drop(struct sock *sk, struct request_sock *req);
@@ -310,8 +310,8 @@ void inet_csk_prepare_forced_close(struc
  */
 static inline unsigned int inet_csk_listen_poll(const struct sock *sk)
 {
-	return !reqsk_queue_empty(&inet_csk(sk)->icsk_accept_queue) ?
-			(POLLIN | POLLRDNORM) : 0;
+    return !reqsk_queue_empty(&inet_csk(sk)->icsk_accept_queue) ?
+            (POLLIN | POLLRDNORM) : 0;
 }
 
 int inet_csk_listen_start(struct sock *sk, int backlog);
@@ -320,9 +320,9 @@ void inet_csk_listen_stop(struct sock *s
 void inet_csk_addr2sockaddr(struct sock *sk, struct sockaddr *uaddr);
 
 int inet_csk_compat_getsockopt(struct sock *sk, int level, int optname,
-			       char __user *optval, int __user *optlen);
+                   char __user *optval, int __user *optlen);
 int inet_csk_compat_setsockopt(struct sock *sk, int level, int optname,
-			       char __user *optval, unsigned int optlen);
+                   char __user *optval, unsigned int optlen);
 
 struct dst_entry *inet_csk_update_pmtu(struct sock *sk, u32 mtu);
 #endif /* _INET_CONNECTION_SOCK_H */
diff -uprN --new-file linux-4.9-rc2-original/include/net/inet_hashtables.h linux-4.9-rc2/include/net/inet_hashtables.h
--- linux-4.9-rc2-original/include/net/inet_hashtables.h	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/include/net/inet_hashtables.h	2016-12-02 17:17:42.557840604 -0300
@@ -1,11 +1,11 @@
 /*
- * INET		An implementation of the TCP/IP protocol suite for the LINUX
- *		operating system.  INET is implemented using the BSD Socket
- *		interface as the means of communication with the user level.
+ * INET     An implementation of the TCP/IP protocol suite for the LINUX
+ *      operating system.  INET is implemented using the BSD Socket
+ *      interface as the means of communication with the user level.
  *
- * Authors:	Lotsa people, from code originally in tcp
+ * Authors: Lotsa people, from code originally in tcp
  *
- *	This program is free software; you can redistribute it and/or
+ *  This program is free software; you can redistribute it and/or
  *      modify it under the terms of the GNU General Public License
  *      as published by the Free Software Foundation; either version
  *      2 of the License, or (at your option) any later version.
@@ -40,21 +40,21 @@
  * but LISTEN ones.
  */
 struct inet_ehash_bucket {
-	struct hlist_nulls_head chain;
+    struct hlist_nulls_head chain;
 };
 
 /* There are a few simple rules, which allow for local port reuse by
  * an application.  In essence:
  *
- *	1) Sockets bound to different interfaces may share a local port.
- *	   Failing that, goto test 2.
- *	2) If all sockets have sk->sk_reuse set, and none of them are in
- *	   TCP_LISTEN state, the port may be shared.
- *	   Failing that, goto test 3.
- *	3) If all sockets are bound to a specific inet_sk(sk)->rcv_saddr local
- *	   address, and none of them are the same, the port may be
- *	   shared.
- *	   Failing this, the port cannot be shared.
+ *  1) Sockets bound to different interfaces may share a local port.
+ *     Failing that, goto test 2.
+ *  2) If all sockets have sk->sk_reuse set, and none of them are in
+ *     TCP_LISTEN state, the port may be shared.
+ *     Failing that, goto test 3.
+ *  3) If all sockets are bound to a specific inet_sk(sk)->rcv_saddr local
+ *     address, and none of them are the same, the port may be
+ *     shared.
+ *     Failing this, the port cannot be shared.
  *
  * The interesting point, is test #2.  This is what an FTP server does
  * all day.  To optimize this case we use a specific flag bit defined
@@ -72,126 +72,126 @@ struct inet_ehash_bucket {
  * must be walked for each data port opened by an ftp server.  Needless
  * to say, this does not scale at all.  With a couple thousand FTP
  * users logged onto your box, isn't it nice to know that new data
- * ports are created in O(1) time?  I thought so. ;-)	-DaveM
+ * ports are created in O(1) time?  I thought so. ;-)   -DaveM
  */
 struct inet_bind_bucket {
-	possible_net_t		ib_net;
-	unsigned short		port;
-	signed char		fastreuse;
-	signed char		fastreuseport;
-	kuid_t			fastuid;
-	int			num_owners;
-	struct hlist_node	node;
-	struct hlist_head	owners;
+    possible_net_t      ib_net;
+    unsigned short      port;
+    signed char     fastreuse;
+    signed char     fastreuseport;
+    kuid_t          fastuid;
+    int         num_owners;
+    struct hlist_node   node;
+    struct hlist_head   owners;
 };
 
 static inline struct net *ib_net(struct inet_bind_bucket *ib)
 {
-	return read_pnet(&ib->ib_net);
+    return read_pnet(&ib->ib_net);
 }
 
 #define inet_bind_bucket_for_each(tb, head) \
-	hlist_for_each_entry(tb, head, node)
+    hlist_for_each_entry(tb, head, node)
 
 struct inet_bind_hashbucket {
-	spinlock_t		lock;
-	struct hlist_head	chain;
+    spinlock_t      lock;
+    struct hlist_head   chain;
 };
 
 /*
  * Sockets can be hashed in established or listening table
  */
 struct inet_listen_hashbucket {
-	spinlock_t		lock;
-	struct hlist_head	head;
+    spinlock_t      lock;
+    struct hlist_head   head;
 };
 
 /* This is for listening sockets, thus all sockets which possess wildcards. */
-#define INET_LHTABLE_SIZE	32	/* Yes, really, this is all you need. */
+#define INET_LHTABLE_SIZE   32  /* Yes, really, this is all you need. */
 
 struct inet_hashinfo {
-	/* This is for sockets with full identity only.  Sockets here will
-	 * always be without wildcards and will have the following invariant:
-	 *
-	 *          TCP_ESTABLISHED <= sk->sk_state < TCP_CLOSE
-	 *
-	 */
-	struct inet_ehash_bucket	*ehash;
-	spinlock_t			*ehash_locks;
-	unsigned int			ehash_mask;
-	unsigned int			ehash_locks_mask;
-
-	/* Ok, let's try this, I give up, we do need a local binding
-	 * TCP hash as well as the others for fast bind/connect.
-	 */
-	struct inet_bind_hashbucket	*bhash;
-
-	unsigned int			bhash_size;
-	/* 4 bytes hole on 64 bit */
-
-	struct kmem_cache		*bind_bucket_cachep;
-
-	/* All the above members are written once at bootup and
-	 * never written again _or_ are predominantly read-access.
-	 *
-	 * Now align to a new cache line as all the following members
-	 * might be often dirty.
-	 */
-	/* All sockets in TCP_LISTEN state will be in here.  This is the only
-	 * table where wildcard'd TCP sockets can exist.  Hash function here
-	 * is just local port number.
-	 */
-	struct inet_listen_hashbucket	listening_hash[INET_LHTABLE_SIZE]
-					____cacheline_aligned_in_smp;
+    /* This is for sockets with full identity only.  Sockets here will
+     * always be without wildcards and will have the following invariant:
+     *
+     *          TCP_ESTABLISHED <= sk->sk_state < TCP_CLOSE
+     *
+     */
+    struct inet_ehash_bucket    *ehash;
+    spinlock_t          *ehash_locks;
+    unsigned int            ehash_mask;
+    unsigned int            ehash_locks_mask;
+
+    /* Ok, let's try this, I give up, we do need a local binding
+     * TCP hash as well as the others for fast bind/connect.
+     */
+    struct inet_bind_hashbucket *bhash;
+
+    unsigned int            bhash_size;
+    /* 4 bytes hole on 64 bit */
+
+    struct kmem_cache       *bind_bucket_cachep;
+
+    /* All the above members are written once at bootup and
+     * never written again _or_ are predominantly read-access.
+     *
+     * Now align to a new cache line as all the following members
+     * might be often dirty.
+     */
+    /* All sockets in TCP_LISTEN state will be in here.  This is the only
+     * table where wildcard'd TCP sockets can exist.  Hash function here
+     * is just local port number.
+     */
+    struct inet_listen_hashbucket   listening_hash[INET_LHTABLE_SIZE]
+                    ____cacheline_aligned_in_smp;
 };
 
 static inline struct inet_ehash_bucket *inet_ehash_bucket(
-	struct inet_hashinfo *hashinfo,
-	unsigned int hash)
+    struct inet_hashinfo *hashinfo,
+    unsigned int hash)
 {
-	return &hashinfo->ehash[hash & hashinfo->ehash_mask];
+    return &hashinfo->ehash[hash & hashinfo->ehash_mask];
 }
 
 static inline spinlock_t *inet_ehash_lockp(
-	struct inet_hashinfo *hashinfo,
-	unsigned int hash)
+    struct inet_hashinfo *hashinfo,
+    unsigned int hash)
 {
-	return &hashinfo->ehash_locks[hash & hashinfo->ehash_locks_mask];
+    return &hashinfo->ehash_locks[hash & hashinfo->ehash_locks_mask];
 }
 
 int inet_ehash_locks_alloc(struct inet_hashinfo *hashinfo);
 
 static inline void inet_ehash_locks_free(struct inet_hashinfo *hashinfo)
 {
-	kvfree(hashinfo->ehash_locks);
-	hashinfo->ehash_locks = NULL;
+    kvfree(hashinfo->ehash_locks);
+    hashinfo->ehash_locks = NULL;
 }
 
 struct inet_bind_bucket *
 inet_bind_bucket_create(struct kmem_cache *cachep, struct net *net,
-			struct inet_bind_hashbucket *head,
-			const unsigned short snum);
+            struct inet_bind_hashbucket *head,
+            const unsigned short snum);
 void inet_bind_bucket_destroy(struct kmem_cache *cachep,
-			      struct inet_bind_bucket *tb);
+                  struct inet_bind_bucket *tb);
 
 static inline u32 inet_bhashfn(const struct net *net, const __u16 lport,
-			       const u32 bhash_size)
+                   const u32 bhash_size)
 {
-	return (lport + net_hash_mix(net)) & (bhash_size - 1);
+    return (lport + net_hash_mix(net)) & (bhash_size - 1);
 }
 
 void inet_bind_hash(struct sock *sk, struct inet_bind_bucket *tb,
-		    const unsigned short snum);
+            const unsigned short snum);
 
 /* These can have wildcards, don't try too hard. */
 static inline u32 inet_lhashfn(const struct net *net, const unsigned short num)
 {
-	return (num + net_hash_mix(net)) & (INET_LHTABLE_SIZE - 1);
+    return (num + net_hash_mix(net)) & (INET_LHTABLE_SIZE - 1);
 }
 
 static inline int inet_sk_listen_hashfn(const struct sock *sk)
 {
-	return inet_lhashfn(sock_net(sk), inet_sk(sk)->inet_num);
+    return inet_lhashfn(sock_net(sk), inet_sk(sk)->inet_num);
 }
 
 /* Caller must disable local BH processing. */
@@ -204,28 +204,28 @@ void inet_hashinfo_init(struct inet_hash
 bool inet_ehash_insert(struct sock *sk, struct sock *osk);
 bool inet_ehash_nolisten(struct sock *sk, struct sock *osk);
 int __inet_hash(struct sock *sk, struct sock *osk,
-		int (*saddr_same)(const struct sock *sk1,
-				  const struct sock *sk2,
-				  bool match_wildcard));
+        int (*saddr_same)(const struct sock *sk1,
+                  const struct sock *sk2,
+                  bool match_wildcard));
 int inet_hash(struct sock *sk);
 void inet_unhash(struct sock *sk);
 
 struct sock *__inet_lookup_listener(struct net *net,
-				    struct inet_hashinfo *hashinfo,
-				    struct sk_buff *skb, int doff,
-				    const __be32 saddr, const __be16 sport,
-				    const __be32 daddr,
-				    const unsigned short hnum,
-				    const int dif);
+                    struct inet_hashinfo *hashinfo,
+                    struct sk_buff *skb, int doff,
+                    const __be32 saddr, const __be16 sport,
+                    const __be32 daddr,
+                    const unsigned short hnum,
+                    const int dif);
 
 static inline struct sock *inet_lookup_listener(struct net *net,
-		struct inet_hashinfo *hashinfo,
-		struct sk_buff *skb, int doff,
-		__be32 saddr, __be16 sport,
-		__be32 daddr, __be16 dport, int dif)
+        struct inet_hashinfo *hashinfo,
+        struct sk_buff *skb, int doff,
+        __be32 saddr, __be16 sport,
+        __be32 daddr, __be16 dport, int dif)
 {
-	return __inet_lookup_listener(net, hashinfo, skb, doff, saddr, sport,
-				      daddr, ntohs(dport), dif);
+    return __inet_lookup_listener(net, hashinfo, skb, doff, saddr, sport,
+                      daddr, ntohs(dport), dif);
 }
 
 /* Socket demux engine toys. */
@@ -239,148 +239,148 @@ static inline struct sock *inet_lookup_l
 */
 #ifdef __BIG_ENDIAN
 #define INET_COMBINED_PORTS(__sport, __dport) \
-	((__force __portpair)(((__force __u32)(__be16)(__sport) << 16) | (__u32)(__dport)))
+    ((__force __portpair)(((__force __u32)(__be16)(__sport) << 16) | (__u32)(__dport)))
 #else /* __LITTLE_ENDIAN */
 #define INET_COMBINED_PORTS(__sport, __dport) \
-	((__force __portpair)(((__u32)(__dport) << 16) | (__force __u32)(__be16)(__sport)))
+    ((__force __portpair)(((__u32)(__dport) << 16) | (__force __u32)(__be16)(__sport)))
 #endif
 
 #if (BITS_PER_LONG == 64)
 #ifdef __BIG_ENDIAN
 #define INET_ADDR_COOKIE(__name, __saddr, __daddr) \
-	const __addrpair __name = (__force __addrpair) ( \
-				   (((__force __u64)(__be32)(__saddr)) << 32) | \
-				   ((__force __u64)(__be32)(__daddr)))
+    const __addrpair __name = (__force __addrpair) ( \
+                   (((__force __u64)(__be32)(__saddr)) << 32) | \
+                   ((__force __u64)(__be32)(__daddr)))
 #else /* __LITTLE_ENDIAN */
 #define INET_ADDR_COOKIE(__name, __saddr, __daddr) \
-	const __addrpair __name = (__force __addrpair) ( \
-				   (((__force __u64)(__be32)(__daddr)) << 32) | \
-				   ((__force __u64)(__be32)(__saddr)))
+    const __addrpair __name = (__force __addrpair) ( \
+                   (((__force __u64)(__be32)(__daddr)) << 32) | \
+                   ((__force __u64)(__be32)(__saddr)))
 #endif /* __BIG_ENDIAN */
-#define INET_MATCH(__sk, __net, __cookie, __saddr, __daddr, __ports, __dif)	\
-	(((__sk)->sk_portpair == (__ports))			&&	\
-	 ((__sk)->sk_addrpair == (__cookie))			&&	\
-	 (!(__sk)->sk_bound_dev_if	||				\
-	   ((__sk)->sk_bound_dev_if == (__dif))) 		&& 	\
-	 net_eq(sock_net(__sk), (__net)))
+#define INET_MATCH(__sk, __net, __cookie, __saddr, __daddr, __ports, __dif) \
+    (((__sk)->sk_portpair == (__ports))         &&  \
+     ((__sk)->sk_addrpair == (__cookie))            &&  \
+     (!(__sk)->sk_bound_dev_if  ||              \
+       ((__sk)->sk_bound_dev_if == (__dif)))        &&  \
+     net_eq(sock_net(__sk), (__net)))
 #else /* 32-bit arch */
 #define INET_ADDR_COOKIE(__name, __saddr, __daddr) \
-	const int __name __deprecated __attribute__((unused))
+    const int __name __deprecated __attribute__((unused))
 
 #define INET_MATCH(__sk, __net, __cookie, __saddr, __daddr, __ports, __dif) \
-	(((__sk)->sk_portpair == (__ports))		&&		\
-	 ((__sk)->sk_daddr	== (__saddr))		&&		\
-	 ((__sk)->sk_rcv_saddr	== (__daddr))		&&		\
-	 (!(__sk)->sk_bound_dev_if	||				\
-	   ((__sk)->sk_bound_dev_if == (__dif))) 	&&		\
-	 net_eq(sock_net(__sk), (__net)))
+    (((__sk)->sk_portpair == (__ports))     &&      \
+     ((__sk)->sk_daddr  == (__saddr))       &&      \
+     ((__sk)->sk_rcv_saddr  == (__daddr))       &&      \
+     (!(__sk)->sk_bound_dev_if  ||              \
+       ((__sk)->sk_bound_dev_if == (__dif)))    &&      \
+     net_eq(sock_net(__sk), (__net)))
 #endif /* 64-bit arch */
 
 /* Sockets in TCP_CLOSE state are _always_ taken out of the hash, so we need
  * not check it for lookups anymore, thanks Alexey. -DaveM
  */
 struct sock *__inet_lookup_established(struct net *net,
-				       struct inet_hashinfo *hashinfo,
-				       const __be32 saddr, const __be16 sport,
-				       const __be32 daddr, const u16 hnum,
-				       const int dif);
+                       struct inet_hashinfo *hashinfo,
+                       const __be32 saddr, const __be16 sport,
+                       const __be32 daddr, const u16 hnum,
+                       const int dif);
 
 static inline struct sock *
-	inet_lookup_established(struct net *net, struct inet_hashinfo *hashinfo,
-				const __be32 saddr, const __be16 sport,
-				const __be32 daddr, const __be16 dport,
-				const int dif)
+    inet_lookup_established(struct net *net, struct inet_hashinfo *hashinfo,
+                const __be32 saddr, const __be16 sport,
+                const __be32 daddr, const __be16 dport,
+                const int dif)
 {
-	return __inet_lookup_established(net, hashinfo, saddr, sport, daddr,
-					 ntohs(dport), dif);
+    return __inet_lookup_established(net, hashinfo, saddr, sport, daddr,
+                     ntohs(dport), dif);
 }
 
 static inline struct sock *__inet_lookup(struct net *net,
-					 struct inet_hashinfo *hashinfo,
-					 struct sk_buff *skb, int doff,
-					 const __be32 saddr, const __be16 sport,
-					 const __be32 daddr, const __be16 dport,
-					 const int dif,
-					 bool *refcounted)
-{
-	u16 hnum = ntohs(dport);
-	struct sock *sk;
-
-	sk = __inet_lookup_established(net, hashinfo, saddr, sport,
-				       daddr, hnum, dif);
-	*refcounted = true;
-	if (sk)
-		return sk;
-	*refcounted = false;
-	return __inet_lookup_listener(net, hashinfo, skb, doff, saddr,
-				      sport, daddr, hnum, dif);
+                     struct inet_hashinfo *hashinfo,
+                     struct sk_buff *skb, int doff,
+                     const __be32 saddr, const __be16 sport,
+                     const __be32 daddr, const __be16 dport,
+                     const int dif,
+                     bool *refcounted)
+{
+    u16 hnum = ntohs(dport);
+    struct sock *sk;
+
+    sk = __inet_lookup_established(net, hashinfo, saddr, sport,
+                       daddr, hnum, dif);
+    *refcounted = true;
+    if (sk)
+        return sk;
+    *refcounted = false;
+    return __inet_lookup_listener(net, hashinfo, skb, doff, saddr,
+                      sport, daddr, hnum, dif);
 }
 
 static inline struct sock *inet_lookup(struct net *net,
-				       struct inet_hashinfo *hashinfo,
-				       struct sk_buff *skb, int doff,
-				       const __be32 saddr, const __be16 sport,
-				       const __be32 daddr, const __be16 dport,
-				       const int dif)
-{
-	struct sock *sk;
-	bool refcounted;
-
-	sk = __inet_lookup(net, hashinfo, skb, doff, saddr, sport, daddr,
-			   dport, dif, &refcounted);
-
-	if (sk && !refcounted && !atomic_inc_not_zero(&sk->sk_refcnt))
-		sk = NULL;
-	return sk;
+                       struct inet_hashinfo *hashinfo,
+                       struct sk_buff *skb, int doff,
+                       const __be32 saddr, const __be16 sport,
+                       const __be32 daddr, const __be16 dport,
+                       const int dif)
+{
+    struct sock *sk;
+    bool refcounted;
+
+    sk = __inet_lookup(net, hashinfo, skb, doff, saddr, sport, daddr,
+               dport, dif, &refcounted);
+
+    if (sk && !refcounted && !atomic_inc_not_zero(&sk->sk_refcnt))
+        sk = NULL;
+    return sk;
 }
 
 static inline struct sock *__inet_lookup_skb(struct inet_hashinfo *hashinfo,
-					     struct sk_buff *skb,
-					     int doff,
-					     const __be16 sport,
-					     const __be16 dport,
-					     bool *refcounted)
-{
-	struct sock *sk = skb_steal_sock(skb);
-	const struct iphdr *iph = ip_hdr(skb);
-
-	*refcounted = true;
-	if (sk)
-		return sk;
-
-	return __inet_lookup(dev_net(skb_dst(skb)->dev), hashinfo, skb,
-			     doff, iph->saddr, sport,
-			     iph->daddr, dport, inet_iif(skb),
-			     refcounted);
+                         struct sk_buff *skb,
+                         int doff,
+                         const __be16 sport,
+                         const __be16 dport,
+                         bool *refcounted)
+{
+    struct sock *sk = skb_steal_sock(skb);
+    const struct iphdr *iph = ip_hdr(skb);
+
+    *refcounted = true;
+    if (sk)
+        return sk;
+
+    return __inet_lookup(dev_net(skb_dst(skb)->dev), hashinfo, skb,
+                 doff, iph->saddr, sport,
+                 iph->daddr, dport, inet_iif(skb),
+                 refcounted);
 }
 
 u32 sk_ehashfn(const struct sock *sk);
 u32 inet6_ehashfn(const struct net *net,
-		  const struct in6_addr *laddr, const u16 lport,
-		  const struct in6_addr *faddr, const __be16 fport);
+          const struct in6_addr *laddr, const u16 lport,
+          const struct in6_addr *faddr, const __be16 fport);
 
 static inline void sk_daddr_set(struct sock *sk, __be32 addr)
 {
-	sk->sk_daddr = addr; /* alias of inet_daddr */
+    sk->sk_daddr = addr; /* alias of inet_daddr */
 #if IS_ENABLED(CONFIG_IPV6)
-	ipv6_addr_set_v4mapped(addr, &sk->sk_v6_daddr);
+    ipv6_addr_set_v4mapped(addr, &sk->sk_v6_daddr);
 #endif
 }
 
 static inline void sk_rcv_saddr_set(struct sock *sk, __be32 addr)
 {
-	sk->sk_rcv_saddr = addr; /* alias of inet_rcv_saddr */
+    sk->sk_rcv_saddr = addr; /* alias of inet_rcv_saddr */
 #if IS_ENABLED(CONFIG_IPV6)
-	ipv6_addr_set_v4mapped(addr, &sk->sk_v6_rcv_saddr);
+    ipv6_addr_set_v4mapped(addr, &sk->sk_v6_rcv_saddr);
 #endif
 }
 
 int __inet_hash_connect(struct inet_timewait_death_row *death_row,
-			struct sock *sk, u32 port_offset,
-			int (*check_established)(struct inet_timewait_death_row *,
-						 struct sock *, __u16,
-						 struct inet_timewait_sock **));
+            struct sock *sk, u32 port_offset,
+            int (*check_established)(struct inet_timewait_death_row *,
+                         struct sock *, __u16,
+                         struct inet_timewait_sock **));
 
 int inet_hash_connect(struct inet_timewait_death_row *death_row,
-		      struct sock *sk);
+              struct sock *sk);
 #endif /* _INET_HASHTABLES_H */
diff -uprN --new-file linux-4.9-rc2-original/include/net/net_namespace.h linux-4.9-rc2/include/net/net_namespace.h
--- linux-4.9-rc2-original/include/net/net_namespace.h	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/include/net/net_namespace.h	2016-12-03 04:24:08.411087536 -0300
@@ -19,6 +19,7 @@
 #include <net/netns/ieee802154_6lowpan.h>
 #include <net/netns/sctp.h>
 #include <net/netns/dccp.h>
+#include <net/netns/gmtp.h>
 #include <net/netns/netfilter.h>
 #include <net/netns/x_tables.h>
 #if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
@@ -45,104 +46,107 @@ struct netns_ipvs;
 #define NETDEV_HASHENTRIES (1 << NETDEV_HASHBITS)
 
 struct net {
-	atomic_t		passive;	/* To decided when the network
-						 * namespace should be freed.
-						 */
-	atomic_t		count;		/* To decided when the network
-						 *  namespace should be shut down.
-						 */
-	spinlock_t		rules_mod_lock;
-
-	atomic64_t		cookie_gen;
-
-	struct list_head	list;		/* list of network namespaces */
-	struct list_head	cleanup_list;	/* namespaces on death row */
-	struct list_head	exit_list;	/* Use only net_mutex */
-
-	struct user_namespace   *user_ns;	/* Owning user namespace */
-	struct ucounts		*ucounts;
-	spinlock_t		nsid_lock;
-	struct idr		netns_ids;
+    atomic_t        passive;    /* To decided when the network
+                         * namespace should be freed.
+                         */
+    atomic_t        count;      /* To decided when the network
+                         *  namespace should be shut down.
+                         */
+    spinlock_t      rules_mod_lock;
+
+    atomic64_t      cookie_gen;
+
+    struct list_head    list;       /* list of network namespaces */
+    struct list_head    cleanup_list;   /* namespaces on death row */
+    struct list_head    exit_list;  /* Use only net_mutex */
+
+    struct user_namespace   *user_ns;   /* Owning user namespace */
+    struct ucounts      *ucounts;
+    spinlock_t      nsid_lock;
+    struct idr      netns_ids;
 
-	struct ns_common	ns;
+    struct ns_common    ns;
 
-	struct proc_dir_entry 	*proc_net;
-	struct proc_dir_entry 	*proc_net_stat;
+    struct proc_dir_entry   *proc_net;
+    struct proc_dir_entry   *proc_net_stat;
 
 #ifdef CONFIG_SYSCTL
-	struct ctl_table_set	sysctls;
+    struct ctl_table_set    sysctls;
 #endif
 
-	struct sock 		*rtnl;			/* rtnetlink socket */
-	struct sock		*genl_sock;
+    struct sock         *rtnl;          /* rtnetlink socket */
+    struct sock     *genl_sock;
 
-	struct list_head 	dev_base_head;
-	struct hlist_head 	*dev_name_head;
-	struct hlist_head	*dev_index_head;
-	unsigned int		dev_base_seq;	/* protected by rtnl_mutex */
-	int			ifindex;
-	unsigned int		dev_unreg_count;
+    struct list_head    dev_base_head;
+    struct hlist_head   *dev_name_head;
+    struct hlist_head   *dev_index_head;
+    unsigned int        dev_base_seq;   /* protected by rtnl_mutex */
+    int         ifindex;
+    unsigned int        dev_unreg_count;
 
-	/* core fib_rules */
-	struct list_head	rules_ops;
+    /* core fib_rules */
+    struct list_head    rules_ops;
 
 
-	struct net_device       *loopback_dev;          /* The loopback */
-	struct netns_core	core;
-	struct netns_mib	mib;
-	struct netns_packet	packet;
-	struct netns_unix	unx;
-	struct netns_ipv4	ipv4;
+    struct net_device       *loopback_dev;          /* The loopback */
+    struct netns_core   core;
+    struct netns_mib    mib;
+    struct netns_packet packet;
+    struct netns_unix   unx;
+    struct netns_ipv4   ipv4;
 #if IS_ENABLED(CONFIG_IPV6)
-	struct netns_ipv6	ipv6;
+    struct netns_ipv6   ipv6;
 #endif
 #if IS_ENABLED(CONFIG_IEEE802154_6LOWPAN)
-	struct netns_ieee802154_lowpan	ieee802154_lowpan;
-#endif
-#if defined(CONFIG_IP_SCTP) || defined(CONFIG_IP_SCTP_MODULE)
-	struct netns_sctp	sctp;
+    struct netns_ieee802154_lowpan  ieee802154_lowpan;
 #endif
 #if defined(CONFIG_IP_DCCP) || defined(CONFIG_IP_DCCP_MODULE)
-	struct netns_dccp	dccp;
+    struct netns_dccp dccp;
+#endif
+#if defined(CONFIG_IP_SCTP) || defined(CONFIG_IP_SCTP_MODULE)
+    struct netns_sctp sctp;
 #endif
+// #if defined(CONFIG_IP_GMTP) || defined(CONFIG_IP_GMTP_MODULE)
+    struct netns_gmtp gmtp;
+// #endif
 #ifdef CONFIG_NETFILTER
-	struct netns_nf		nf;
-	struct netns_xt		xt;
+    struct netns_nf     nf;
+    struct netns_xt     xt;
 #if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
-	struct netns_ct		ct;
+    struct netns_ct     ct;
 #endif
 #if defined(CONFIG_NF_TABLES) || defined(CONFIG_NF_TABLES_MODULE)
-	struct netns_nftables	nft;
+    struct netns_nftables   nft;
 #endif
 #if IS_ENABLED(CONFIG_NF_DEFRAG_IPV6)
-	struct netns_nf_frag	nf_frag;
+    struct netns_nf_frag    nf_frag;
 #endif
-	struct sock		*nfnl;
-	struct sock		*nfnl_stash;
+    struct sock     *nfnl;
+    struct sock     *nfnl_stash;
 #if IS_ENABLED(CONFIG_NETFILTER_NETLINK_ACCT)
-	struct list_head        nfnl_acct_list;
+    struct list_head        nfnl_acct_list;
 #endif
 #if IS_ENABLED(CONFIG_NF_CT_NETLINK_TIMEOUT)
-	struct list_head	nfct_timeout_list;
+    struct list_head    nfct_timeout_list;
 #endif
 #endif
 #ifdef CONFIG_WEXT_CORE
-	struct sk_buff_head	wext_nlevents;
+    struct sk_buff_head wext_nlevents;
 #endif
-	struct net_generic __rcu	*gen;
+    struct net_generic __rcu    *gen;
 
-	/* Note : following structs are cache line aligned */
+    /* Note : following structs are cache line aligned */
 #ifdef CONFIG_XFRM
-	struct netns_xfrm	xfrm;
+    struct netns_xfrm   xfrm;
 #endif
 #if IS_ENABLED(CONFIG_IP_VS)
-	struct netns_ipvs	*ipvs;
+    struct netns_ipvs   *ipvs;
 #endif
 #if IS_ENABLED(CONFIG_MPLS)
-	struct netns_mpls	mpls;
+    struct netns_mpls   mpls;
 #endif
-	struct sock		*diag_nlsk;
-	atomic_t		fnhe_genid;
+    struct sock     *diag_nlsk;
+    atomic_t        fnhe_genid;
 };
 
 #include <linux/seq_file_net.h>
@@ -152,17 +156,17 @@ extern struct net init_net;
 
 #ifdef CONFIG_NET_NS
 struct net *copy_net_ns(unsigned long flags, struct user_namespace *user_ns,
-			struct net *old_net);
+            struct net *old_net);
 
 #else /* CONFIG_NET_NS */
 #include <linux/sched.h>
 #include <linux/nsproxy.h>
 static inline struct net *copy_net_ns(unsigned long flags,
-	struct user_namespace *user_ns, struct net *old_net)
+    struct user_namespace *user_ns, struct net *old_net)
 {
-	if (flags & CLONE_NEWNET)
-		return ERR_PTR(-EINVAL);
-	return old_net;
+    if (flags & CLONE_NEWNET)
+        return ERR_PTR(-EINVAL);
+    return old_net;
 }
 #endif /* CONFIG_NET_NS */
 
@@ -185,32 +189,32 @@ void __put_net(struct net *net);
 
 static inline struct net *get_net(struct net *net)
 {
-	atomic_inc(&net->count);
-	return net;
+    atomic_inc(&net->count);
+    return net;
 }
 
 static inline struct net *maybe_get_net(struct net *net)
 {
-	/* Used when we know struct net exists but we
-	 * aren't guaranteed a previous reference count
-	 * exists.  If the reference count is zero this
-	 * function fails and returns NULL.
-	 */
-	if (!atomic_inc_not_zero(&net->count))
-		net = NULL;
-	return net;
+    /* Used when we know struct net exists but we
+     * aren't guaranteed a previous reference count
+     * exists.  If the reference count is zero this
+     * function fails and returns NULL.
+     */
+    if (!atomic_inc_not_zero(&net->count))
+        net = NULL;
+    return net;
 }
 
 static inline void put_net(struct net *net)
 {
-	if (atomic_dec_and_test(&net->count))
-		__put_net(net);
+    if (atomic_dec_and_test(&net->count))
+        __put_net(net);
 }
 
 static inline
 int net_eq(const struct net *net1, const struct net *net2)
 {
-	return net1 == net2;
+    return net1 == net2;
 }
 
 void net_drop_ns(void *);
@@ -219,7 +223,7 @@ void net_drop_ns(void *);
 
 static inline struct net *get_net(struct net *net)
 {
-	return net;
+    return net;
 }
 
 static inline void put_net(struct net *net)
@@ -228,13 +232,13 @@ static inline void put_net(struct net *n
 
 static inline struct net *maybe_get_net(struct net *net)
 {
-	return net;
+    return net;
 }
 
 static inline
 int net_eq(const struct net *net1, const struct net *net2)
 {
-	return 1;
+    return 1;
 }
 
 #define net_drop_ns NULL
@@ -243,31 +247,31 @@ int net_eq(const struct net *net1, const
 
 typedef struct {
 #ifdef CONFIG_NET_NS
-	struct net *net;
+    struct net *net;
 #endif
 } possible_net_t;
 
 static inline void write_pnet(possible_net_t *pnet, struct net *net)
 {
 #ifdef CONFIG_NET_NS
-	pnet->net = net;
+    pnet->net = net;
 #endif
 }
 
 static inline struct net *read_pnet(const possible_net_t *pnet)
 {
 #ifdef CONFIG_NET_NS
-	return pnet->net;
+    return pnet->net;
 #else
-	return &init_net;
+    return &init_net;
 #endif
 }
 
-#define for_each_net(VAR)				\
-	list_for_each_entry(VAR, &net_namespace_list, list)
+#define for_each_net(VAR)               \
+    list_for_each_entry(VAR, &net_namespace_list, list)
 
-#define for_each_net_rcu(VAR)				\
-	list_for_each_entry_rcu(VAR, &net_namespace_list, list)
+#define for_each_net_rcu(VAR)               \
+    list_for_each_entry_rcu(VAR, &net_namespace_list, list)
 
 #ifdef CONFIG_NET_NS
 #define __net_init
@@ -275,10 +279,10 @@ static inline struct net *read_pnet(cons
 #define __net_initdata
 #define __net_initconst
 #else
-#define __net_init	__init
-#define __net_exit	__ref
-#define __net_initdata	__initdata
-#define __net_initconst	__initconst
+#define __net_init  __init
+#define __net_exit  __ref
+#define __net_initdata  __initdata
+#define __net_initconst __initconst
 #endif
 
 int peernet2id_alloc(struct net *net, struct net *peer);
@@ -287,12 +291,12 @@ bool peernet_has_id(struct net *net, str
 struct net *get_net_ns_by_id(struct net *net, int id);
 
 struct pernet_operations {
-	struct list_head list;
-	int (*init)(struct net *net);
-	void (*exit)(struct net *net);
-	void (*exit_batch)(struct list_head *net_exit_list);
-	int *id;
-	size_t size;
+    struct list_head list;
+    int (*init)(struct net *net);
+    void (*exit)(struct net *net);
+    void (*exit_batch)(struct list_head *net_exit_list);
+    int *id;
+    size_t size;
 };
 
 /*
@@ -325,14 +329,14 @@ struct ctl_table_header;
 #ifdef CONFIG_SYSCTL
 int net_sysctl_init(void);
 struct ctl_table_header *register_net_sysctl(struct net *net, const char *path,
-					     struct ctl_table *table);
+                         struct ctl_table *table);
 void unregister_net_sysctl_table(struct ctl_table_header *header);
 #else
 static inline int net_sysctl_init(void) { return 0; }
 static inline struct ctl_table_header *register_net_sysctl(struct net *net,
-	const char *path, struct ctl_table *table)
+    const char *path, struct ctl_table *table)
 {
-	return NULL;
+    return NULL;
 }
 static inline void unregister_net_sysctl_table(struct ctl_table_header *header)
 {
@@ -341,44 +345,44 @@ static inline void unregister_net_sysctl
 
 static inline int rt_genid_ipv4(struct net *net)
 {
-	return atomic_read(&net->ipv4.rt_genid);
+    return atomic_read(&net->ipv4.rt_genid);
 }
 
 static inline void rt_genid_bump_ipv4(struct net *net)
 {
-	atomic_inc(&net->ipv4.rt_genid);
+    atomic_inc(&net->ipv4.rt_genid);
 }
 
 extern void (*__fib6_flush_trees)(struct net *net);
 static inline void rt_genid_bump_ipv6(struct net *net)
 {
-	if (__fib6_flush_trees)
-		__fib6_flush_trees(net);
+    if (__fib6_flush_trees)
+        __fib6_flush_trees(net);
 }
 
 #if IS_ENABLED(CONFIG_IEEE802154_6LOWPAN)
 static inline struct netns_ieee802154_lowpan *
 net_ieee802154_lowpan(struct net *net)
 {
-	return &net->ieee802154_lowpan;
+    return &net->ieee802154_lowpan;
 }
 #endif
 
 /* For callers who don't really care about whether it's IPv4 or IPv6 */
 static inline void rt_genid_bump_all(struct net *net)
 {
-	rt_genid_bump_ipv4(net);
-	rt_genid_bump_ipv6(net);
+    rt_genid_bump_ipv4(net);
+    rt_genid_bump_ipv6(net);
 }
 
 static inline int fnhe_genid(struct net *net)
 {
-	return atomic_read(&net->fnhe_genid);
+    return atomic_read(&net->fnhe_genid);
 }
 
 static inline void fnhe_genid_bump(struct net *net)
 {
-	atomic_inc(&net->fnhe_genid);
+    atomic_inc(&net->fnhe_genid);
 }
 
 #endif /* __NET_NET_NAMESPACE_H */
diff -uprN --new-file linux-4.9-rc2-original/include/net/netns/gmtp.h linux-4.9-rc2/include/net/netns/gmtp.h
--- linux-4.9-rc2-original/include/net/netns/gmtp.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/include/net/netns/gmtp.h	2016-12-01 18:35:58.059913731 -0300
@@ -0,0 +1,11 @@
+#ifndef __NETNS_GMTP_H__
+#define __NETNS_GMTP_H__
+
+struct sock;
+
+struct netns_gmtp {
+	struct sock *v4_ctl_sk;
+	struct sock *v6_ctl_sk;
+};
+
+#endif
diff -uprN --new-file linux-4.9-rc2-original/include/net/request_sock.h linux-4.9-rc2/include/net/request_sock.h
--- linux-4.9-rc2-original/include/net/request_sock.h	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/include/net/request_sock.h	2016-12-02 16:10:17.700408281 -0300
@@ -1,16 +1,16 @@
 /*
- * NET		Generic infrastructure for Network protocols.
+ * NET      Generic infrastructure for Network protocols.
  *
- *		Definitions for request_sock 
+ *      Definitions for request_sock 
  *
- * Authors:	Arnaldo Carvalho de Melo <acme@conectiva.com.br>
+ * Authors: Arnaldo Carvalho de Melo <acme@conectiva.com.br>
  *
- * 		From code originally in include/net/tcp.h
+ *      From code originally in include/net/tcp.h
  *
- *		This program is free software; you can redistribute it and/or
- *		modify it under the terms of the GNU General Public License
- *		as published by the Free Software Foundation; either version
- *		2 of the License, or (at your option) any later version.
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
  */
 #ifndef _REQUEST_SOCK_H
 #define _REQUEST_SOCK_H
@@ -28,18 +28,18 @@ struct dst_entry;
 struct proto;
 
 struct request_sock_ops {
-	int		family;
-	int		obj_size;
-	struct kmem_cache	*slab;
-	char		*slab_name;
-	int		(*rtx_syn_ack)(const struct sock *sk,
-				       struct request_sock *req);
-	void		(*send_ack)(const struct sock *sk, struct sk_buff *skb,
-				    struct request_sock *req);
-	void		(*send_reset)(const struct sock *sk,
-				      struct sk_buff *skb);
-	void		(*destructor)(struct request_sock *req);
-	void		(*syn_ack_timeout)(const struct request_sock *req);
+    int     family;
+    int     obj_size;
+    struct kmem_cache   *slab;
+    char *slab_name;
+    int (*rtx_syn_ack)(const struct sock *sk,
+                       struct request_sock *req);
+    void (*send_ack)(const struct sock *sk, struct sk_buff *skb,
+                    struct request_sock *req);
+    void (*send_reset)(const struct sock *sk,
+                      struct sk_buff *skb);
+    void (*destructor)(struct request_sock *req);
+    void (*syn_ack_timeout)(const struct request_sock *req);
 };
 
 int inet_rtx_syn_ack(const struct sock *parent, struct request_sock *req);
@@ -47,110 +47,110 @@ int inet_rtx_syn_ack(const struct sock *
 /* struct request_sock - mini sock to represent a connection request
  */
 struct request_sock {
-	struct sock_common		__req_common;
-#define rsk_refcnt			__req_common.skc_refcnt
-#define rsk_hash			__req_common.skc_hash
-#define rsk_listener			__req_common.skc_listener
-#define rsk_window_clamp		__req_common.skc_window_clamp
-#define rsk_rcv_wnd			__req_common.skc_rcv_wnd
-
-	struct request_sock		*dl_next;
-	u16				mss;
-	u8				num_retrans; /* number of retransmits */
-	u8				cookie_ts:1; /* syncookie: encode tcpopts in timestamp */
-	u8				num_timeout:7; /* number of timeouts */
-	u32				ts_recent;
-	struct timer_list		rsk_timer;
-	const struct request_sock_ops	*rsk_ops;
-	struct sock			*sk;
-	u32				*saved_syn;
-	u32				secid;
-	u32				peer_secid;
+    struct sock_common      __req_common;
+#define rsk_refcnt          __req_common.skc_refcnt
+#define rsk_hash            __req_common.skc_hash
+#define rsk_listener            __req_common.skc_listener
+#define rsk_window_clamp        __req_common.skc_window_clamp
+#define rsk_rcv_wnd         __req_common.skc_rcv_wnd
+
+    struct request_sock     *dl_next;
+    u16             mss;
+    u8              num_retrans; /* number of retransmits */
+    u8              cookie_ts:1; /* syncookie: encode tcpopts in timestamp */
+    u8              num_timeout:7; /* number of timeouts */
+    u32             ts_recent;
+    struct timer_list       rsk_timer;
+    const struct request_sock_ops   *rsk_ops;
+    struct sock         *sk;
+    u32             *saved_syn;
+    u32             secid;
+    u32             peer_secid;
 };
 
 static inline struct request_sock *inet_reqsk(const struct sock *sk)
 {
-	return (struct request_sock *)sk;
+    return (struct request_sock *)sk;
 }
 
 static inline struct sock *req_to_sk(struct request_sock *req)
 {
-	return (struct sock *)req;
+    return (struct sock *)req;
 }
 
 static inline struct request_sock *
 reqsk_alloc(const struct request_sock_ops *ops, struct sock *sk_listener,
-	    bool attach_listener)
+        bool attach_listener)
 {
-	struct request_sock *req;
+    struct request_sock *req;
 
-	req = kmem_cache_alloc(ops->slab, GFP_ATOMIC | __GFP_NOWARN);
-	if (!req)
-		return NULL;
-	req->rsk_listener = NULL;
-	if (attach_listener) {
-		if (unlikely(!atomic_inc_not_zero(&sk_listener->sk_refcnt))) {
-			kmem_cache_free(ops->slab, req);
-			return NULL;
-		}
-		req->rsk_listener = sk_listener;
-	}
-	req->rsk_ops = ops;
-	req_to_sk(req)->sk_prot = sk_listener->sk_prot;
-	sk_node_init(&req_to_sk(req)->sk_node);
-	sk_tx_queue_clear(req_to_sk(req));
-	req->saved_syn = NULL;
-	atomic_set(&req->rsk_refcnt, 0);
+    req = kmem_cache_alloc(ops->slab, GFP_ATOMIC | __GFP_NOWARN);
+    if (!req)
+        return NULL;
+    req->rsk_listener = NULL;
+    if (attach_listener) {
+        if (unlikely(!atomic_inc_not_zero(&sk_listener->sk_refcnt))) {
+            kmem_cache_free(ops->slab, req);
+            return NULL;
+        }
+        req->rsk_listener = sk_listener;
+    }
+    req->rsk_ops = ops;
+    req_to_sk(req)->sk_prot = sk_listener->sk_prot;
+    sk_node_init(&req_to_sk(req)->sk_node);
+    sk_tx_queue_clear(req_to_sk(req));
+    req->saved_syn = NULL;
+    atomic_set(&req->rsk_refcnt, 0);
 
-	return req;
+    return req;
 }
 
 static inline void reqsk_free(struct request_sock *req)
 {
-	/* temporary debugging */
-	WARN_ON_ONCE(atomic_read(&req->rsk_refcnt) != 0);
+    /* temporary debugging */
+    WARN_ON_ONCE(atomic_read(&req->rsk_refcnt) != 0);
 
-	req->rsk_ops->destructor(req);
-	if (req->rsk_listener)
-		sock_put(req->rsk_listener);
-	kfree(req->saved_syn);
-	kmem_cache_free(req->rsk_ops->slab, req);
+    req->rsk_ops->destructor(req);
+    if (req->rsk_listener)
+        sock_put(req->rsk_listener);
+    kfree(req->saved_syn);
+    kmem_cache_free(req->rsk_ops->slab, req);
 }
 
 static inline void reqsk_put(struct request_sock *req)
 {
-	if (atomic_dec_and_test(&req->rsk_refcnt))
-		reqsk_free(req);
+    if (atomic_dec_and_test(&req->rsk_refcnt))
+        reqsk_free(req);
 }
 
 extern int sysctl_max_syn_backlog;
 
 /*
  * For a TCP Fast Open listener -
- *	lock - protects the access to all the reqsk, which is co-owned by
- *		the listener and the child socket.
- *	qlen - pending TFO requests (still in TCP_SYN_RECV).
- *	max_qlen - max TFO reqs allowed before TFO is disabled.
- *
- *	XXX (TFO) - ideally these fields can be made as part of "listen_sock"
- *	structure above. But there is some implementation difficulty due to
- *	listen_sock being part of request_sock_queue hence will be freed when
- *	a listener is stopped. But TFO related fields may continue to be
- *	accessed even after a listener is closed, until its sk_refcnt drops
- *	to 0 implying no more outstanding TFO reqs. One solution is to keep
- *	listen_opt around until	sk_refcnt drops to 0. But there is some other
- *	complexity that needs to be resolved. E.g., a listener can be disabled
- *	temporarily through shutdown()->tcp_disconnect(), and re-enabled later.
+ *  lock - protects the access to all the reqsk, which is co-owned by
+ *      the listener and the child socket.
+ *  qlen - pending TFO requests (still in TCP_SYN_RECV).
+ *  max_qlen - max TFO reqs allowed before TFO is disabled.
+ *
+ *  XXX (TFO) - ideally these fields can be made as part of "listen_sock"
+ *  structure above. But there is some implementation difficulty due to
+ *  listen_sock being part of request_sock_queue hence will be freed when
+ *  a listener is stopped. But TFO related fields may continue to be
+ *  accessed even after a listener is closed, until its sk_refcnt drops
+ *  to 0 implying no more outstanding TFO reqs. One solution is to keep
+ *  listen_opt around until sk_refcnt drops to 0. But there is some other
+ *  complexity that needs to be resolved. E.g., a listener can be disabled
+ *  temporarily through shutdown()->tcp_disconnect(), and re-enabled later.
  */
 struct fastopen_queue {
-	struct request_sock	*rskq_rst_head; /* Keep track of past TFO */
-	struct request_sock	*rskq_rst_tail; /* requests that caused RST.
-						 * This is part of the defense
-						 * against spoofing attack.
-						 */
-	spinlock_t	lock;
-	int		qlen;		/* # of pending (TCP_SYN_RECV) reqs */
-	int		max_qlen;	/* != 0 iff TFO is currently enabled */
+    struct request_sock *rskq_rst_head; /* Keep track of past TFO */
+    struct request_sock *rskq_rst_tail; /* requests that caused RST.
+                         * This is part of the defense
+                         * against spoofing attack.
+                         */
+    spinlock_t  lock;
+    int     qlen;       /* # of pending (TCP_SYN_RECV) reqs */
+    int     max_qlen;   /* != 0 iff TFO is currently enabled */
 };
 
 /** struct request_sock_queue - queue of request_socks
@@ -161,69 +161,69 @@ struct fastopen_queue {
  *
  */
 struct request_sock_queue {
-	spinlock_t		rskq_lock;
-	u8			rskq_defer_accept;
+    spinlock_t      rskq_lock;
+    u8          rskq_defer_accept;
 
-	u32			synflood_warned;
-	atomic_t		qlen;
-	atomic_t		young;
-
-	struct request_sock	*rskq_accept_head;
-	struct request_sock	*rskq_accept_tail;
-	struct fastopen_queue	fastopenq;  /* Check max_qlen != 0 to determine
-					     * if TFO is enabled.
-					     */
+    u32         synflood_warned;
+    atomic_t        qlen;
+    atomic_t        young;
+
+    struct request_sock *rskq_accept_head;
+    struct request_sock *rskq_accept_tail;
+    struct fastopen_queue   fastopenq;  /* Check max_qlen != 0 to determine
+                         * if TFO is enabled.
+                         */
 };
 
 void reqsk_queue_alloc(struct request_sock_queue *queue);
 
 void reqsk_fastopen_remove(struct sock *sk, struct request_sock *req,
-			   bool reset);
+               bool reset);
 
 static inline bool reqsk_queue_empty(const struct request_sock_queue *queue)
 {
-	return queue->rskq_accept_head == NULL;
+    return queue->rskq_accept_head == NULL;
 }
 
 static inline struct request_sock *reqsk_queue_remove(struct request_sock_queue *queue,
-						      struct sock *parent)
+                              struct sock *parent)
 {
-	struct request_sock *req;
+    struct request_sock *req;
 
-	spin_lock_bh(&queue->rskq_lock);
-	req = queue->rskq_accept_head;
-	if (req) {
-		sk_acceptq_removed(parent);
-		queue->rskq_accept_head = req->dl_next;
-		if (queue->rskq_accept_head == NULL)
-			queue->rskq_accept_tail = NULL;
-	}
-	spin_unlock_bh(&queue->rskq_lock);
-	return req;
+    spin_lock_bh(&queue->rskq_lock);
+    req = queue->rskq_accept_head;
+    if (req) {
+        sk_acceptq_removed(parent);
+        queue->rskq_accept_head = req->dl_next;
+        if (queue->rskq_accept_head == NULL)
+            queue->rskq_accept_tail = NULL;
+    }
+    spin_unlock_bh(&queue->rskq_lock);
+    return req;
 }
 
 static inline void reqsk_queue_removed(struct request_sock_queue *queue,
-				       const struct request_sock *req)
+                       const struct request_sock *req)
 {
-	if (req->num_timeout == 0)
-		atomic_dec(&queue->young);
-	atomic_dec(&queue->qlen);
+    if (req->num_timeout == 0)
+        atomic_dec(&queue->young);
+    atomic_dec(&queue->qlen);
 }
 
 static inline void reqsk_queue_added(struct request_sock_queue *queue)
 {
-	atomic_inc(&queue->young);
-	atomic_inc(&queue->qlen);
+    atomic_inc(&queue->young);
+    atomic_inc(&queue->qlen);
 }
 
 static inline int reqsk_queue_len(const struct request_sock_queue *queue)
 {
-	return atomic_read(&queue->qlen);
+    return atomic_read(&queue->qlen);
 }
 
 static inline int reqsk_queue_len_young(const struct request_sock_queue *queue)
 {
-	return atomic_read(&queue->young);
+    return atomic_read(&queue->young);
 }
 
 #endif /* _REQUEST_SOCK_H */
diff -uprN --new-file linux-4.9-rc2-original/include/net/secure_seq.h linux-4.9-rc2/include/net/secure_seq.h
--- linux-4.9-rc2-original/include/net/secure_seq.h	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/include/net/secure_seq.h	2016-12-13 22:07:01.128057345 -0300
@@ -5,14 +5,16 @@
 
 u32 secure_ipv4_port_ephemeral(__be32 saddr, __be32 daddr, __be16 dport);
 u32 secure_ipv6_port_ephemeral(const __be32 *saddr, const __be32 *daddr,
-			       __be16 dport);
+                   __be16 dport);
 __u32 secure_tcp_sequence_number(__be32 saddr, __be32 daddr,
-				 __be16 sport, __be16 dport);
+                 __be16 sport, __be16 dport);
 __u32 secure_tcpv6_sequence_number(const __be32 *saddr, const __be32 *daddr,
-				   __be16 sport, __be16 dport);
+                   __be16 sport, __be16 dport);
 u64 secure_dccp_sequence_number(__be32 saddr, __be32 daddr,
-				__be16 sport, __be16 dport);
+                __be16 sport, __be16 dport);
+__u32 secure_gmtp_sequence_number(__be32 saddr, __be32 daddr,
+                __be16 sport, __be16 dport);
 u64 secure_dccpv6_sequence_number(__be32 *saddr, __be32 *daddr,
-				  __be16 sport, __be16 dport);
+                  __be16 sport, __be16 dport);
 
 #endif /* _NET_SECURE_SEQ */
diff -uprN --new-file linux-4.9-rc2-original/include/uapi/linux/gmtp.h linux-4.9-rc2/include/uapi/linux/gmtp.h
--- linux-4.9-rc2-original/include/uapi/linux/gmtp.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/include/uapi/linux/gmtp.h	2016-12-01 16:52:21.504094089 -0300
@@ -0,0 +1,375 @@
+#ifndef UAPI_LINUX_GMTP_H
+#define UAPI_LINUX_GMTP_H
+
+#include <linux/types.h>
+
+#define GMTP_VERSION (1)
+#define GMTP_FLOWNAME_LEN (16) /* bytes */
+#define GMTP_FLOWNAME_STR_LEN ((GMTP_FLOWNAME_LEN * 2) + 1)
+
+#define GMTP_RELAY_ID_LEN (16) /* bytes */
+
+#define GMTP_REPORTER_DEFAULT_PROPORTION (6)
+
+
+/**
+ * MSS: 1444
+ *
+ * GMTP fixed header: 36
+ * GMTP Ack Header: 0
+ * ----------------------
+ *
+ * GMTP Register-Reply header:
+ * 1444 - 36 = 1408
+ * ---------------------
+ * Register-Reply->nrelays: 8
+ * Register-Reply->relay_list 1400
+ *
+ * 1400/20 = 70 (-1 (ucc_type))
+ *
+ */
+#define GMTP_MAX_RELAY_NUM 69
+
+/**
+ * GMTP packet header
+ *
+ *  0                   1                   2                   3
+ *  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+ *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ *  | V.|   Type  |     Header Length   |       Server RTT      |P|R|
+ *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ *  |          Source Port          |       Destination Port        |
+ *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ *  |                         Sequence Number                       |
+ *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ *  |                        Transmission Rate                      |
+ *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ *  |            Data Flow Name - part 1 of 4 (128 bits)            .
+ *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ *  .                 Data Flow Name - part 2 of 4                  .
+ *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ *  .                 Data Flow Name - part 3 of 4                  .
+ *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ *  .                 Data Flow Name - part 4 of 4                  |
+ *  +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
+ *  |                                                               |
+ *  |              Variable part (depends of 'type')                |
+ *  |             Max Length = (2^11-1) => 2047 bytes               |
+ *  |                                                               |
+ *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ *
+ * struct gmtp_hdr - generic part of GMTP packet header
+ *
+ * @version: protocol version
+ * @type: packet type
+ * @hdrlen: header length (bytes)
+ * @server_rtt: server RTT
+ * @pull:  'P' (Pull) field
+ * @relay:  'R' (Relay) field. It is activated when a relay send packets
+ * @res: reserved to future <- [DEPRECATED]
+ * @sport: source port
+ * @dport: destiny port
+ * @seq: sequence number
+ * @transm_r: transmission rate
+ * @flowname: data flow name
+ */
+struct gmtp_hdr {
+	__u8 	version:2;
+	__u8 	type:5;
+	__be16 	hdrlen:11;
+	__be16 	server_rtt:12;
+	__u8 	pull:1;
+	__u8 	relay:1;
+	__be16 	sport; //source port
+	__be16 	dport; //dest port
+	__be32 	seq;
+	__be32 	transm_r;
+	__u8 	flowname[GMTP_FLOWNAME_LEN]; //128 bits
+};
+
+/**
+ * struct gmtp_hdr_data - Data packets
+ * @tstamp: time stamp of sent data packet
+ */
+struct gmtp_hdr_data {
+	__be32 tstamp;
+};
+
+/**
+ * struct gmtp_hdr_ack - ACK packets
+ * @orig_tstamp: time stamp of original received packet
+ * @wait: time wait from reception of packet to ack send
+ *
+ * The receiver will calculate RTT: now - (orig + wait)
+ */
+struct gmtp_hdr_ack {
+	__be32 orig_tstamp;
+};
+
+/**
+ * struct gmtp_hdr_dataack - DATAACK packets
+ */
+struct gmtp_hdr_dataack {
+	struct gmtp_hdr_data	data_hdr;
+	struct gmtp_hdr_ack	ack_hdr;
+};
+
+/**
+ * struct gmtp_hdr_feedback - Data packets
+ * @tstamp: time stamp of feedback packet
+ * @nclients: active clients at reporter
+ *
+ */
+struct gmtp_hdr_feedback {
+	__be32 	orig_tstamp;
+	__u8	nclients;
+};
+
+/**
+ * struct gmtp_hdr_reset - Unconditionally shut down a connection
+ *
+ * @reset_code - one of %gmtp_reset_codes
+ * @reset_data - the Data of reset
+ */
+struct gmtp_hdr_reset {
+	__u8	reset_code,
+		reset_data[3];
+};
+
+/**
+ * struct gmtp_hdr_register - Register from relays
+ *
+ * @relay_id: unique id of relay
+ */
+struct gmtp_hdr_register {
+	__u8 			relay_id[GMTP_RELAY_ID_LEN];
+};
+
+
+/**
+ * struct gmtp_hdr_relay - Store data of a single relay in GMTP headers
+ *
+ * @relay_id: unique id of relay
+ * @relay_ip: IP address of relay
+ */
+struct gmtp_hdr_relay {
+	__u8 			relay_id[GMTP_RELAY_ID_LEN];
+	__be32 			relay_ip;
+};
+
+/**
+ * struct gmtp_hdr_register_reply - Register reply from servers
+ *
+ * @ucc_type: type of UCC
+ * @nrelays: 	number of relays
+ * @relay_list:	list of relays in path
+ */
+struct gmtp_hdr_register_reply {
+	__u8			ucc_type:2;
+	__u8 			nrelays;
+
+	/* Relays will add their id and ip addr */
+	/*struct gmtp_hdr_relay 	relay_list[GMTP_MAX_RELAY_NUM];*/
+};
+
+/**
+ * struct gmtp_hdr_route_notify - RouteNotify to servers
+ *
+ * @ucc_type: type of UCC
+ * @nrelays: number of relays
+ * @relay_list - list of relays in path
+ */
+struct gmtp_hdr_route {
+	__u8			ucc_type:2;
+	__u8 			nrelays;
+
+	/* Relays will add their id and ip addr */
+	/*struct gmtp_hdr_relay 	relay_list[GMTP_MAX_RELAY_NUM];*/
+};
+
+/**
+ * struct gmtp_hdr_reqnotify - RequestNotify to clients
+ *
+ * @rn_code: One of gmtp_reqnotify_error_code
+ * @mcst_addr: multicast channel address
+ * @mcst_port: multicast channel port
+ * @relay_id: Relay ID
+ * @reporter_addr: reporter IP address
+ * @reporter_port: reporter port
+ * @max_nclients: max amount of clients connected to a reporter
+ */
+struct gmtp_hdr_reqnotify {
+	__u8			rn_code:2;
+	__be32			mcst_addr;
+	__be16  		mcst_port;
+	__u8 			relay_id[GMTP_RELAY_ID_LEN];
+	__be32			reporter_addr;
+	__be16  		reporter_port;
+	__u8 			max_nclients;
+};
+
+enum gmtp_reqnotify_error_code {
+	GMTP_REQNOTIFY_CODE_OK = 0,
+	GMTP_REQNOTIFY_CODE_WAIT,
+	GMTP_REQNOTIFY_CODE_ERROR,
+	GMTP_REQNOTIFY_MAX_CODES
+};
+
+/**
+ * struct gmtp_hdr_elect_request - Elect request to reporters
+ *
+ * @relay_id: relay from where request come from
+ * @max_nclients: Max number of clients of a reporter
+ */
+struct gmtp_hdr_elect_request {
+	__u8 			relay_id[GMTP_RELAY_ID_LEN];
+	__u8 			max_nclients;
+};
+
+/**
+ * struct gmtp_hdr_elect_request - Elect request to reporters
+ *
+ * @elect_code: One of %gmtp_ack_codes
+ */
+struct gmtp_hdr_elect_response {
+	__u8 	elect_code:2;
+};
+
+enum gmtp_elect_codes {
+	GMTP_ELECT_ACCEPT = 0,
+	GMTP_ELECT_REJECT,
+	GMTP_ELECT_AUTO,
+	GMTP_ELECT_MAX_CODES
+};
+
+/**
+ * struct gmtp_hdr_delegate - Delegate register/request to a relay
+ *
+ * @elect_code: One of %gmtp_ack_codes
+ */
+struct gmtp_hdr_delegate {
+	struct gmtp_hdr_relay relay;
+	__be16 relay_port;
+};
+
+/**
+ * see www.gmtp-protocol.org
+ */
+enum gmtp_pkt_type {
+	GMTP_PKT_REQUEST = 0,
+	GMTP_PKT_REQUESTNOTIFY,
+	GMTP_PKT_RESPONSE,
+	GMTP_PKT_REGISTER,
+	GMTP_PKT_REGISTER_REPLY,
+	GMTP_PKT_ROUTE_NOTIFY,
+	GMTP_PKT_RELAYQUERY,
+	GMTP_PKT_RELAYQUERY_REPLY,
+	GMTP_PKT_DATA,
+	GMTP_PKT_ACK,
+	GMTP_PKT_DATAACK,
+	GMTP_PKT_MEDIADESC,
+	GMTP_PKT_DATAPULL_REQUEST,
+	GMTP_PKT_DATAPULL_RESPONSE,
+	GMTP_PKT_ELECT_REQUEST,
+	GMTP_PKT_ELECT_RESPONSE,
+	GMTP_PKT_CLOSE,
+	GMTP_PKT_RESET,
+
+	GMTP_PKT_FEEDBACK,
+	GMTP_PKT_DELEGATE,
+	GMTP_PKT_DELEGATE_REPLY,
+
+	GMTP_PKT_INVALID,
+	GMTP_PKT_MAX_STATES
+};
+
+#define GMTP_NR_PKT_TYPES GMTP_PKT_INVALID
+
+enum gmtp_reset_codes {
+	GMTP_RESET_CODE_UNSPECIFIED = 0,
+	GMTP_RESET_CODE_CLOSED,
+	GMTP_RESET_CODE_ABORTED,
+	GMTP_RESET_CODE_NO_CONNECTION,
+	GMTP_RESET_CODE_PACKET_ERROR,
+	GMTP_RESET_CODE_MANDATORY_ERROR,
+	GMTP_RESET_CODE_CONNECTION_REFUSED,
+	GMTP_RESET_CODE_BAD_FLOWNAME,
+	GMTP_RESET_CODE_TOO_BUSY,
+	GMTP_RESET_CODE_AGGRESSION_PENALTY,
+
+	GMTP_MAX_RESET_CODES		/* Leave at the end!  */
+};
+
+static inline unsigned int gmtp_packet_hdr_variable_len(const __u8 type)
+{
+	unsigned int len = 0;
+	switch(type)
+	{
+	case GMTP_PKT_DATA:
+		len = sizeof(struct gmtp_hdr_data);
+		break;
+	case GMTP_PKT_DATAACK:
+		len = sizeof(struct gmtp_hdr_dataack);
+		break;
+	case GMTP_PKT_ACK:
+		len = sizeof(struct gmtp_hdr_ack);
+		break;
+	case GMTP_PKT_FEEDBACK:
+		len = sizeof(struct gmtp_hdr_feedback);
+		break;
+	case GMTP_PKT_REGISTER:
+		len = sizeof(struct gmtp_hdr_register);
+		break;
+	case GMTP_PKT_REGISTER_REPLY:
+		len = sizeof(struct gmtp_hdr_register_reply);
+		break;
+	case GMTP_PKT_ROUTE_NOTIFY:
+		len = sizeof(struct gmtp_hdr_route);
+		break;
+	case GMTP_PKT_REQUESTNOTIFY:
+		len = sizeof(struct gmtp_hdr_reqnotify);
+		break;
+	case GMTP_PKT_ELECT_REQUEST:
+		len = sizeof(struct gmtp_hdr_elect_request);
+		break;
+	case GMTP_PKT_ELECT_RESPONSE:
+		len = sizeof(struct gmtp_hdr_elect_response);
+		break;
+	case GMTP_PKT_DELEGATE:
+	case GMTP_PKT_DELEGATE_REPLY:
+		len = sizeof(struct gmtp_hdr_delegate);
+		break;
+	case GMTP_PKT_RESET:
+		len = sizeof(struct gmtp_hdr_reset);
+		break;
+	}
+	
+	return len;
+}
+
+enum gmtp_ucc_type {
+	GMTP_DELAY_UCC = 0,
+	GMTP_MEDIA_ADAPT_UCC,
+
+	GMTP_MAX_UCC_TYPES
+};
+
+/* GMTP socket options */
+enum gmtp_sockopt_codes {
+	GMTP_SOCKOPT_FLOWNAME = 1,
+	GMTP_SOCKOPT_MEDIA_RATE,
+	GMTP_SOCKOPT_MAX_TX_RATE,
+	GMTP_SOCKOPT_UCC_TX_RATE,
+	GMTP_SOCKOPT_GET_CUR_MSS,
+	GMTP_SOCKOPT_SERVER_RTT,
+	GMTP_SOCKOPT_SERVER_TIMEWAIT,
+	GMTP_SOCKOPT_PULL,
+	GMTP_SOCKOPT_ROLE_RELAY,
+	GMTP_SOCKOPT_RELAY_ENABLED,
+	GMTP_SOCKOPT_NDP_RCV,
+	GMTP_SOCKOPT_NDP_SENT,
+	GMTP_SOCKOPT_UCC_TYPE
+};
+
+
+#endif /* UAPI_LINUX_GMTP_H */
diff -uprN --new-file linux-4.9-rc2-original/include/uapi/linux/in.h linux-4.9-rc2/include/uapi/linux/in.h
--- linux-4.9-rc2-original/include/uapi/linux/in.h	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/include/uapi/linux/in.h	2016-12-02 17:36:26.694786959 -0300
@@ -1,19 +1,19 @@
 /*
- * INET		An implementation of the TCP/IP protocol suite for the LINUX
- *		operating system.  INET is implemented using the  BSD Socket
- *		interface as the means of communication with the user level.
+ * INET     An implementation of the TCP/IP protocol suite for the LINUX
+ *      operating system.  INET is implemented using the  BSD Socket
+ *      interface as the means of communication with the user level.
  *
- *		Definitions of the Internet Protocol.
+ *      Definitions of the Internet Protocol.
  *
- * Version:	@(#)in.h	1.0.1	04/21/93
+ * Version: @(#)in.h    1.0.1   04/21/93
  *
- * Authors:	Original taken from the GNU Project <netinet/in.h> file.
- *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>
+ * Authors: Original taken from the GNU Project <netinet/in.h> file.
+ *      Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>
  *
- *		This program is free software; you can redistribute it and/or
- *		modify it under the terms of the GNU General Public License
- *		as published by the Free Software Foundation; either version
- *		2 of the License, or (at your option) any later version.
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
  */
 #ifndef _UAPI_LINUX_IN_H
 #define _UAPI_LINUX_IN_H
@@ -25,56 +25,58 @@
 #if __UAPI_DEF_IN_IPPROTO
 /* Standard well-defined IP protocols.  */
 enum {
-  IPPROTO_IP = 0,		/* Dummy protocol for TCP		*/
-#define IPPROTO_IP		IPPROTO_IP
-  IPPROTO_ICMP = 1,		/* Internet Control Message Protocol	*/
-#define IPPROTO_ICMP		IPPROTO_ICMP
-  IPPROTO_IGMP = 2,		/* Internet Group Management Protocol	*/
-#define IPPROTO_IGMP		IPPROTO_IGMP
-  IPPROTO_IPIP = 4,		/* IPIP tunnels (older KA9Q tunnels use 94) */
-#define IPPROTO_IPIP		IPPROTO_IPIP
-  IPPROTO_TCP = 6,		/* Transmission Control Protocol	*/
-#define IPPROTO_TCP		IPPROTO_TCP
-  IPPROTO_EGP = 8,		/* Exterior Gateway Protocol		*/
-#define IPPROTO_EGP		IPPROTO_EGP
-  IPPROTO_PUP = 12,		/* PUP protocol				*/
-#define IPPROTO_PUP		IPPROTO_PUP
-  IPPROTO_UDP = 17,		/* User Datagram Protocol		*/
-#define IPPROTO_UDP		IPPROTO_UDP
-  IPPROTO_IDP = 22,		/* XNS IDP protocol			*/
-#define IPPROTO_IDP		IPPROTO_IDP
-  IPPROTO_TP = 29,		/* SO Transport Protocol Class 4	*/
-#define IPPROTO_TP		IPPROTO_TP
-  IPPROTO_DCCP = 33,		/* Datagram Congestion Control Protocol */
-#define IPPROTO_DCCP		IPPROTO_DCCP
-  IPPROTO_IPV6 = 41,		/* IPv6-in-IPv4 tunnelling		*/
-#define IPPROTO_IPV6		IPPROTO_IPV6
-  IPPROTO_RSVP = 46,		/* RSVP Protocol			*/
-#define IPPROTO_RSVP		IPPROTO_RSVP
-  IPPROTO_GRE = 47,		/* Cisco GRE tunnels (rfc 1701,1702)	*/
-#define IPPROTO_GRE		IPPROTO_GRE
-  IPPROTO_ESP = 50,		/* Encapsulation Security Payload protocol */
-#define IPPROTO_ESP		IPPROTO_ESP
-  IPPROTO_AH = 51,		/* Authentication Header protocol	*/
-#define IPPROTO_AH		IPPROTO_AH
-  IPPROTO_MTP = 92,		/* Multicast Transport Protocol		*/
-#define IPPROTO_MTP		IPPROTO_MTP
-  IPPROTO_BEETPH = 94,		/* IP option pseudo header for BEET	*/
-#define IPPROTO_BEETPH		IPPROTO_BEETPH
-  IPPROTO_ENCAP = 98,		/* Encapsulation Header			*/
-#define IPPROTO_ENCAP		IPPROTO_ENCAP
-  IPPROTO_PIM = 103,		/* Protocol Independent Multicast	*/
-#define IPPROTO_PIM		IPPROTO_PIM
-  IPPROTO_COMP = 108,		/* Compression Header Protocol		*/
-#define IPPROTO_COMP		IPPROTO_COMP
-  IPPROTO_SCTP = 132,		/* Stream Control Transport Protocol	*/
-#define IPPROTO_SCTP		IPPROTO_SCTP
-  IPPROTO_UDPLITE = 136,	/* UDP-Lite (RFC 3828)			*/
-#define IPPROTO_UDPLITE		IPPROTO_UDPLITE
-  IPPROTO_MPLS = 137,		/* MPLS in IP (RFC 4023)		*/
-#define IPPROTO_MPLS		IPPROTO_MPLS
-  IPPROTO_RAW = 255,		/* Raw IP packets			*/
-#define IPPROTO_RAW		IPPROTO_RAW
+  IPPROTO_IP = 0,       /* Dummy protocol for TCP       */
+#define IPPROTO_IP      IPPROTO_IP
+  IPPROTO_ICMP = 1,     /* Internet Control Message Protocol    */
+#define IPPROTO_ICMP        IPPROTO_ICMP
+  IPPROTO_IGMP = 2,     /* Internet Group Management Protocol   */
+#define IPPROTO_IGMP        IPPROTO_IGMP
+  IPPROTO_IPIP = 4,     /* IPIP tunnels (older KA9Q tunnels use 94) */
+#define IPPROTO_IPIP        IPPROTO_IPIP
+  IPPROTO_TCP = 6,      /* Transmission Control Protocol    */
+#define IPPROTO_TCP     IPPROTO_TCP
+  IPPROTO_EGP = 8,      /* Exterior Gateway Protocol        */
+#define IPPROTO_EGP     IPPROTO_EGP
+  IPPROTO_PUP = 12,     /* PUP protocol             */
+#define IPPROTO_PUP     IPPROTO_PUP
+  IPPROTO_UDP = 17,     /* User Datagram Protocol       */
+#define IPPROTO_UDP     IPPROTO_UDP
+  IPPROTO_IDP = 22,     /* XNS IDP protocol         */
+#define IPPROTO_IDP     IPPROTO_IDP
+  IPPROTO_TP = 29,      /* SO Transport Protocol Class 4    */
+#define IPPROTO_TP      IPPROTO_TP
+  IPPROTO_DCCP = 33,        /* Datagram Congestion Control Protocol */
+#define IPPROTO_DCCP        IPPROTO_DCCP
+  IPPROTO_IPV6 = 41,        /* IPv6-in-IPv4 tunnelling      */
+#define IPPROTO_IPV6        IPPROTO_IPV6
+  IPPROTO_RSVP = 46,        /* RSVP Protocol            */
+#define IPPROTO_RSVP        IPPROTO_RSVP
+  IPPROTO_GRE = 47,     /* Cisco GRE tunnels (rfc 1701,1702)    */
+#define IPPROTO_GRE     IPPROTO_GRE
+  IPPROTO_ESP = 50,     /* Encapsulation Security Payload protocol */
+#define IPPROTO_ESP     IPPROTO_ESP
+  IPPROTO_AH = 51,      /* Authentication Header protocol   */
+#define IPPROTO_AH      IPPROTO_AH
+  IPPROTO_MTP = 92,     /* Multicast Transport Protocol     */
+#define IPPROTO_MTP     IPPROTO_MTP
+  IPPROTO_BEETPH = 94,      /* IP option pseudo header for BEET */
+#define IPPROTO_BEETPH      IPPROTO_BEETPH
+  IPPROTO_ENCAP = 98,       /* Encapsulation Header         */
+#define IPPROTO_ENCAP       IPPROTO_ENCAP
+  IPPROTO_PIM = 103,        /* Protocol Independent Multicast   */
+#define IPPROTO_PIM     IPPROTO_PIM
+  IPPROTO_COMP = 108,       /* Compression Header Protocol      */
+#define IPPROTO_COMP        IPPROTO_COMP
+  IPPROTO_SCTP = 132,       /* Stream Control Transport Protocol    */
+#define IPPROTO_SCTP        IPPROTO_SCTP
+  IPPROTO_UDPLITE = 136,    /* UDP-Lite (RFC 3828)          */
+#define IPPROTO_UDPLITE     IPPROTO_UDPLITE
+  IPPROTO_MPLS = 137,       /* MPLS in IP (RFC 4023)        */
+#define IPPROTO_MPLS        IPPROTO_MPLS
+  IPPROTO_GMTP = 254,    /* Global Media Transmission Protocol (GMTP)  */
+#define IPPROTO_GMTP    IPPROTO_GMTP
+  IPPROTO_RAW = 255,        /* Raw IP packets           */
+#define IPPROTO_RAW     IPPROTO_RAW
   IPPROTO_MAX
 };
 #endif
@@ -82,32 +84,32 @@ enum {
 #if __UAPI_DEF_IN_ADDR
 /* Internet address. */
 struct in_addr {
-	__be32	s_addr;
+    __be32  s_addr;
 };
 #endif
 
-#define IP_TOS		1
-#define IP_TTL		2
-#define IP_HDRINCL	3
-#define IP_OPTIONS	4
-#define IP_ROUTER_ALERT	5
-#define IP_RECVOPTS	6
-#define IP_RETOPTS	7
-#define IP_PKTINFO	8
-#define IP_PKTOPTIONS	9
-#define IP_MTU_DISCOVER	10
-#define IP_RECVERR	11
-#define IP_RECVTTL	12
-#define	IP_RECVTOS	13
-#define IP_MTU		14
-#define IP_FREEBIND	15
-#define IP_IPSEC_POLICY	16
-#define IP_XFRM_POLICY	17
-#define IP_PASSSEC	18
-#define IP_TRANSPARENT	19
+#define IP_TOS      1
+#define IP_TTL      2
+#define IP_HDRINCL  3
+#define IP_OPTIONS  4
+#define IP_ROUTER_ALERT 5
+#define IP_RECVOPTS 6
+#define IP_RETOPTS  7
+#define IP_PKTINFO  8
+#define IP_PKTOPTIONS   9
+#define IP_MTU_DISCOVER 10
+#define IP_RECVERR  11
+#define IP_RECVTTL  12
+#define IP_RECVTOS  13
+#define IP_MTU      14
+#define IP_FREEBIND 15
+#define IP_IPSEC_POLICY 16
+#define IP_XFRM_POLICY  17
+#define IP_PASSSEC  18
+#define IP_TRANSPARENT  19
 
 /* BSD compatibility */
-#define IP_RECVRETOPTS	IP_RETOPTS
+#define IP_RECVRETOPTS  IP_RETOPTS
 
 /* TProxy original addresses */
 #define IP_ORIGDSTADDR       20
@@ -115,46 +117,46 @@ struct in_addr {
 
 #define IP_MINTTL       21
 #define IP_NODEFRAG     22
-#define IP_CHECKSUM	23
-#define IP_BIND_ADDRESS_NO_PORT	24
+#define IP_CHECKSUM 23
+#define IP_BIND_ADDRESS_NO_PORT 24
 
 /* IP_MTU_DISCOVER values */
-#define IP_PMTUDISC_DONT		0	/* Never send DF frames */
-#define IP_PMTUDISC_WANT		1	/* Use per route hints	*/
-#define IP_PMTUDISC_DO			2	/* Always DF		*/
-#define IP_PMTUDISC_PROBE		3       /* Ignore dst pmtu      */
+#define IP_PMTUDISC_DONT        0   /* Never send DF frames */
+#define IP_PMTUDISC_WANT        1   /* Use per route hints  */
+#define IP_PMTUDISC_DO          2   /* Always DF        */
+#define IP_PMTUDISC_PROBE       3       /* Ignore dst pmtu      */
 /* Always use interface mtu (ignores dst pmtu) but don't set DF flag.
  * Also incoming ICMP frag_needed notifications will be ignored on
  * this socket to prevent accepting spoofed ones.
  */
-#define IP_PMTUDISC_INTERFACE		4
+#define IP_PMTUDISC_INTERFACE       4
 /* weaker version of IP_PMTUDISC_INTERFACE, which allos packets to get
  * fragmented if they exeed the interface mtu
  */
-#define IP_PMTUDISC_OMIT		5
+#define IP_PMTUDISC_OMIT        5
 
-#define IP_MULTICAST_IF			32
-#define IP_MULTICAST_TTL 		33
-#define IP_MULTICAST_LOOP 		34
-#define IP_ADD_MEMBERSHIP		35
-#define IP_DROP_MEMBERSHIP		36
-#define IP_UNBLOCK_SOURCE		37
-#define IP_BLOCK_SOURCE			38
-#define IP_ADD_SOURCE_MEMBERSHIP	39
-#define IP_DROP_SOURCE_MEMBERSHIP	40
-#define IP_MSFILTER			41
-#define MCAST_JOIN_GROUP		42
-#define MCAST_BLOCK_SOURCE		43
-#define MCAST_UNBLOCK_SOURCE		44
-#define MCAST_LEAVE_GROUP		45
-#define MCAST_JOIN_SOURCE_GROUP		46
-#define MCAST_LEAVE_SOURCE_GROUP	47
-#define MCAST_MSFILTER			48
-#define IP_MULTICAST_ALL		49
-#define IP_UNICAST_IF			50
+#define IP_MULTICAST_IF         32
+#define IP_MULTICAST_TTL        33
+#define IP_MULTICAST_LOOP       34
+#define IP_ADD_MEMBERSHIP       35
+#define IP_DROP_MEMBERSHIP      36
+#define IP_UNBLOCK_SOURCE       37
+#define IP_BLOCK_SOURCE         38
+#define IP_ADD_SOURCE_MEMBERSHIP    39
+#define IP_DROP_SOURCE_MEMBERSHIP   40
+#define IP_MSFILTER         41
+#define MCAST_JOIN_GROUP        42
+#define MCAST_BLOCK_SOURCE      43
+#define MCAST_UNBLOCK_SOURCE        44
+#define MCAST_LEAVE_GROUP       45
+#define MCAST_JOIN_SOURCE_GROUP     46
+#define MCAST_LEAVE_SOURCE_GROUP    47
+#define MCAST_MSFILTER          48
+#define IP_MULTICAST_ALL        49
+#define IP_UNICAST_IF           50
 
-#define MCAST_EXCLUDE	0
-#define MCAST_INCLUDE	1
+#define MCAST_EXCLUDE   0
+#define MCAST_INCLUDE   1
 
 /* These need to appear somewhere around here */
 #define IP_DEFAULT_MULTICAST_TTL        1
@@ -164,79 +166,79 @@ struct in_addr {
 
 #if __UAPI_DEF_IP_MREQ
 struct ip_mreq  {
-	struct in_addr imr_multiaddr;	/* IP multicast address of group */
-	struct in_addr imr_interface;	/* local IP address of interface */
+    struct in_addr imr_multiaddr;   /* IP multicast address of group */
+    struct in_addr imr_interface;   /* local IP address of interface */
 };
 
 struct ip_mreqn {
-	struct in_addr	imr_multiaddr;		/* IP multicast address of group */
-	struct in_addr	imr_address;		/* local IP address of interface */
-	int		imr_ifindex;		/* Interface index */
+    struct in_addr  imr_multiaddr;      /* IP multicast address of group */
+    struct in_addr  imr_address;        /* local IP address of interface */
+    int     imr_ifindex;        /* Interface index */
 };
 
 struct ip_mreq_source {
-	__be32		imr_multiaddr;
-	__be32		imr_interface;
-	__be32		imr_sourceaddr;
+    __be32      imr_multiaddr;
+    __be32      imr_interface;
+    __be32      imr_sourceaddr;
 };
 
 struct ip_msfilter {
-	__be32		imsf_multiaddr;
-	__be32		imsf_interface;
-	__u32		imsf_fmode;
-	__u32		imsf_numsrc;
-	__be32		imsf_slist[1];
+    __be32      imsf_multiaddr;
+    __be32      imsf_interface;
+    __u32       imsf_fmode;
+    __u32       imsf_numsrc;
+    __be32      imsf_slist[1];
 };
 
 #define IP_MSFILTER_SIZE(numsrc) \
-	(sizeof(struct ip_msfilter) - sizeof(__u32) \
-	+ (numsrc) * sizeof(__u32))
+    (sizeof(struct ip_msfilter) - sizeof(__u32) \
+    + (numsrc) * sizeof(__u32))
 
 struct group_req {
-	__u32				 gr_interface;	/* interface index */
-	struct __kernel_sockaddr_storage gr_group;	/* group address */
+    __u32                gr_interface;  /* interface index */
+    struct __kernel_sockaddr_storage gr_group;  /* group address */
 };
 
 struct group_source_req {
-	__u32				 gsr_interface;	/* interface index */
-	struct __kernel_sockaddr_storage gsr_group;	/* group address */
-	struct __kernel_sockaddr_storage gsr_source;	/* source address */
+    __u32                gsr_interface; /* interface index */
+    struct __kernel_sockaddr_storage gsr_group; /* group address */
+    struct __kernel_sockaddr_storage gsr_source;    /* source address */
 };
 
 struct group_filter {
-	__u32				 gf_interface;	/* interface index */
-	struct __kernel_sockaddr_storage gf_group;	/* multicast address */
-	__u32				 gf_fmode;	/* filter mode */
-	__u32				 gf_numsrc;	/* number of sources */
-	struct __kernel_sockaddr_storage gf_slist[1];	/* interface index */
+    __u32                gf_interface;  /* interface index */
+    struct __kernel_sockaddr_storage gf_group;  /* multicast address */
+    __u32                gf_fmode;  /* filter mode */
+    __u32                gf_numsrc; /* number of sources */
+    struct __kernel_sockaddr_storage gf_slist[1];   /* interface index */
 };
 
 #define GROUP_FILTER_SIZE(numsrc) \
-	(sizeof(struct group_filter) - sizeof(struct __kernel_sockaddr_storage) \
-	+ (numsrc) * sizeof(struct __kernel_sockaddr_storage))
+    (sizeof(struct group_filter) - sizeof(struct __kernel_sockaddr_storage) \
+    + (numsrc) * sizeof(struct __kernel_sockaddr_storage))
 #endif
 
 #if __UAPI_DEF_IN_PKTINFO
 struct in_pktinfo {
-	int		ipi_ifindex;
-	struct in_addr	ipi_spec_dst;
-	struct in_addr	ipi_addr;
+    int     ipi_ifindex;
+    struct in_addr  ipi_spec_dst;
+    struct in_addr  ipi_addr;
 };
 #endif
 
 /* Structure describing an Internet (IP) socket address. */
 #if  __UAPI_DEF_SOCKADDR_IN
-#define __SOCK_SIZE__	16		/* sizeof(struct sockaddr)	*/
+#define __SOCK_SIZE__   16      /* sizeof(struct sockaddr)  */
 struct sockaddr_in {
-  __kernel_sa_family_t	sin_family;	/* Address family		*/
-  __be16		sin_port;	/* Port number			*/
-  struct in_addr	sin_addr;	/* Internet address		*/
+  __kernel_sa_family_t  sin_family; /* Address family       */
+  __be16        sin_port;   /* Port number          */
+  struct in_addr    sin_addr;   /* Internet address     */
 
   /* Pad to size of `struct sockaddr'. */
-  unsigned char		__pad[__SOCK_SIZE__ - sizeof(short int) -
-			sizeof(unsigned short int) - sizeof(struct in_addr)];
+  unsigned char     __pad[__SOCK_SIZE__ - sizeof(short int) -
+            sizeof(unsigned short int) - sizeof(struct in_addr)];
 };
-#define sin_zero	__pad		/* for BSD UNIX comp. -FvK	*/
+#define sin_zero    __pad       /* for BSD UNIX comp. -FvK  */
 #endif
 
 #if __UAPI_DEF_IN_CLASS
@@ -245,51 +247,51 @@ struct sockaddr_in {
  * On subnets, host and network parts are found according
  * to the subnet mask, not these masks.
  */
-#define	IN_CLASSA(a)		((((long int) (a)) & 0x80000000) == 0)
-#define	IN_CLASSA_NET		0xff000000
-#define	IN_CLASSA_NSHIFT	24
-#define	IN_CLASSA_HOST		(0xffffffff & ~IN_CLASSA_NET)
-#define	IN_CLASSA_MAX		128
-
-#define	IN_CLASSB(a)		((((long int) (a)) & 0xc0000000) == 0x80000000)
-#define	IN_CLASSB_NET		0xffff0000
-#define	IN_CLASSB_NSHIFT	16
-#define	IN_CLASSB_HOST		(0xffffffff & ~IN_CLASSB_NET)
-#define	IN_CLASSB_MAX		65536
-
-#define	IN_CLASSC(a)		((((long int) (a)) & 0xe0000000) == 0xc0000000)
-#define	IN_CLASSC_NET		0xffffff00
-#define	IN_CLASSC_NSHIFT	8
-#define	IN_CLASSC_HOST		(0xffffffff & ~IN_CLASSC_NET)
-
-#define	IN_CLASSD(a)		((((long int) (a)) & 0xf0000000) == 0xe0000000)
-#define	IN_MULTICAST(a)		IN_CLASSD(a)
-#define IN_MULTICAST_NET	0xF0000000
+#define IN_CLASSA(a)        ((((long int) (a)) & 0x80000000) == 0)
+#define IN_CLASSA_NET       0xff000000
+#define IN_CLASSA_NSHIFT    24
+#define IN_CLASSA_HOST      (0xffffffff & ~IN_CLASSA_NET)
+#define IN_CLASSA_MAX       128
+
+#define IN_CLASSB(a)        ((((long int) (a)) & 0xc0000000) == 0x80000000)
+#define IN_CLASSB_NET       0xffff0000
+#define IN_CLASSB_NSHIFT    16
+#define IN_CLASSB_HOST      (0xffffffff & ~IN_CLASSB_NET)
+#define IN_CLASSB_MAX       65536
+
+#define IN_CLASSC(a)        ((((long int) (a)) & 0xe0000000) == 0xc0000000)
+#define IN_CLASSC_NET       0xffffff00
+#define IN_CLASSC_NSHIFT    8
+#define IN_CLASSC_HOST      (0xffffffff & ~IN_CLASSC_NET)
+
+#define IN_CLASSD(a)        ((((long int) (a)) & 0xf0000000) == 0xe0000000)
+#define IN_MULTICAST(a)     IN_CLASSD(a)
+#define IN_MULTICAST_NET    0xF0000000
 
-#define	IN_EXPERIMENTAL(a)	((((long int) (a)) & 0xf0000000) == 0xf0000000)
-#define	IN_BADCLASS(a)		IN_EXPERIMENTAL((a))
+#define IN_EXPERIMENTAL(a)  ((((long int) (a)) & 0xf0000000) == 0xf0000000)
+#define IN_BADCLASS(a)      IN_EXPERIMENTAL((a))
 
 /* Address to accept any incoming messages. */
-#define	INADDR_ANY		((unsigned long int) 0x00000000)
+#define INADDR_ANY      ((unsigned long int) 0x00000000)
 
 /* Address to send to all hosts. */
-#define	INADDR_BROADCAST	((unsigned long int) 0xffffffff)
+#define INADDR_BROADCAST    ((unsigned long int) 0xffffffff)
 
 /* Address indicating an error return. */
-#define	INADDR_NONE		((unsigned long int) 0xffffffff)
+#define INADDR_NONE     ((unsigned long int) 0xffffffff)
 
 /* Network number for local host loopback. */
-#define	IN_LOOPBACKNET		127
+#define IN_LOOPBACKNET      127
 
 /* Address to loopback in software to local host.  */
-#define	INADDR_LOOPBACK		0x7f000001	/* 127.0.0.1   */
-#define	IN_LOOPBACK(a)		((((long int) (a)) & 0xff000000) == 0x7f000000)
+#define INADDR_LOOPBACK     0x7f000001  /* 127.0.0.1   */
+#define IN_LOOPBACK(a)      ((((long int) (a)) & 0xff000000) == 0x7f000000)
 
 /* Defines for Multicast INADDR */
-#define INADDR_UNSPEC_GROUP   	0xe0000000U	/* 224.0.0.0   */
-#define INADDR_ALLHOSTS_GROUP 	0xe0000001U	/* 224.0.0.1   */
-#define INADDR_ALLRTRS_GROUP    0xe0000002U	/* 224.0.0.2 */
-#define INADDR_MAX_LOCAL_GROUP  0xe00000ffU	/* 224.0.0.255 */
+#define INADDR_UNSPEC_GROUP     0xe0000000U /* 224.0.0.0   */
+#define INADDR_ALLHOSTS_GROUP   0xe0000001U /* 224.0.0.1   */
+#define INADDR_ALLRTRS_GROUP    0xe0000002U /* 224.0.0.2 */
+#define INADDR_MAX_LOCAL_GROUP  0xe00000ffU /* 224.0.0.255 */
 #endif
 
 /* <asm/byteorder.h> contains the htonl type stuff.. */
diff -uprN --new-file linux-4.9-rc2-original/net/Kconfig linux-4.9-rc2/net/Kconfig
--- linux-4.9-rc2-original/net/Kconfig	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/net/Kconfig	2016-12-01 18:24:40.006390567 -0300
@@ -209,6 +209,7 @@ source "net/dccp/Kconfig"
 source "net/sctp/Kconfig"
 source "net/rds/Kconfig"
 source "net/tipc/Kconfig"
+source "net/gmtp/Kconfig"
 source "net/atm/Kconfig"
 source "net/l2tp/Kconfig"
 source "net/802/Kconfig"
diff -uprN --new-file linux-4.9-rc2-original/net/Makefile linux-4.9-rc2/net/Makefile
--- linux-4.9-rc2-original/net/Makefile	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/net/Makefile	2016-12-01 18:32:50.195262363 -0300
@@ -44,6 +44,7 @@ ifneq ($(CONFIG_VLAN_8021Q),)
 obj-y				+= 8021q/
 endif
 obj-$(CONFIG_IP_DCCP)		+= dccp/
+obj-$(CONFIG_GMTP)		+= gmtp/
 obj-$(CONFIG_IP_SCTP)		+= sctp/
 obj-$(CONFIG_RDS)		+= rds/
 obj-$(CONFIG_WIRELESS)		+= wireless/
diff -uprN --new-file linux-4.9-rc2-original/net/core/secure_seq.c linux-4.9-rc2/net/core/secure_seq.c
--- linux-4.9-rc2-original/net/core/secure_seq.c	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/net/core/secure_seq.c	2016-12-13 22:04:35.060883436 -0300
@@ -171,3 +171,22 @@ u64 secure_dccpv6_sequence_number(__be32
 EXPORT_SYMBOL(secure_dccpv6_sequence_number);
 #endif
 #endif
+
+/*#if IS_ENABLED(CONFIG_IP_GMTP)*/
+__u32 secure_gmtp_sequence_number(__be32 saddr, __be32 daddr,
+				 __be16 sport, __be16 dport)
+{
+	u32 hash[MD5_DIGEST_WORDS];
+
+	net_secret_init();
+	hash[0] = (__force u32)saddr;
+	hash[1] = (__force u32)daddr;
+	hash[2] = ((__force u16)sport << 16) + (__force u16)dport;
+	hash[3] = net_secret[15];
+
+	md5_transform(hash, net_secret);
+
+	return seq_scale(hash[0]);
+}
+EXPORT_SYMBOL(secure_gmtp_sequence_number);
+/*#endif */
diff -uprN --new-file linux-4.9-rc2-original/net/dccp/ipv4.c linux-4.9-rc2/net/dccp/ipv4.c
--- linux-4.9-rc2-original/net/dccp/ipv4.c	2016-10-23 21:10:14.000000000 -0300
+++ linux-4.9-rc2/net/dccp/ipv4.c	2016-12-03 13:26:29.311771663 -0300
@@ -4,10 +4,10 @@
  *  An implementation of the DCCP protocol
  *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>
  *
- *	This program is free software; you can redistribute it and/or
- *	modify it under the terms of the GNU General Public License
- *	as published by the Free Software Foundation; either version
- *	2 of the License, or (at your option) any later version.
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version
+ *  2 of the License, or (at your option) any later version.
  */
 
 #include <linux/dccp.h>
@@ -41,103 +41,103 @@
 
 int dccp_v4_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)
 {
-	const struct sockaddr_in *usin = (struct sockaddr_in *)uaddr;
-	struct inet_sock *inet = inet_sk(sk);
-	struct dccp_sock *dp = dccp_sk(sk);
-	__be16 orig_sport, orig_dport;
-	__be32 daddr, nexthop;
-	struct flowi4 *fl4;
-	struct rtable *rt;
-	int err;
-	struct ip_options_rcu *inet_opt;
-
-	dp->dccps_role = DCCP_ROLE_CLIENT;
-
-	if (addr_len < sizeof(struct sockaddr_in))
-		return -EINVAL;
-
-	if (usin->sin_family != AF_INET)
-		return -EAFNOSUPPORT;
-
-	nexthop = daddr = usin->sin_addr.s_addr;
-
-	inet_opt = rcu_dereference_protected(inet->inet_opt,
-					     lockdep_sock_is_held(sk));
-	if (inet_opt != NULL && inet_opt->opt.srr) {
-		if (daddr == 0)
-			return -EINVAL;
-		nexthop = inet_opt->opt.faddr;
-	}
-
-	orig_sport = inet->inet_sport;
-	orig_dport = usin->sin_port;
-	fl4 = &inet->cork.fl.u.ip4;
-	rt = ip_route_connect(fl4, nexthop, inet->inet_saddr,
-			      RT_CONN_FLAGS(sk), sk->sk_bound_dev_if,
-			      IPPROTO_DCCP,
-			      orig_sport, orig_dport, sk);
-	if (IS_ERR(rt))
-		return PTR_ERR(rt);
-
-	if (rt->rt_flags & (RTCF_MULTICAST | RTCF_BROADCAST)) {
-		ip_rt_put(rt);
-		return -ENETUNREACH;
-	}
-
-	if (inet_opt == NULL || !inet_opt->opt.srr)
-		daddr = fl4->daddr;
-
-	if (inet->inet_saddr == 0)
-		inet->inet_saddr = fl4->saddr;
-	sk_rcv_saddr_set(sk, inet->inet_saddr);
-	inet->inet_dport = usin->sin_port;
-	sk_daddr_set(sk, daddr);
-
-	inet_csk(sk)->icsk_ext_hdr_len = 0;
-	if (inet_opt)
-		inet_csk(sk)->icsk_ext_hdr_len = inet_opt->opt.optlen;
-	/*
-	 * Socket identity is still unknown (sport may be zero).
-	 * However we set state to DCCP_REQUESTING and not releasing socket
-	 * lock select source port, enter ourselves into the hash tables and
-	 * complete initialization after this.
-	 */
-	dccp_set_state(sk, DCCP_REQUESTING);
-	err = inet_hash_connect(&dccp_death_row, sk);
-	if (err != 0)
-		goto failure;
-
-	rt = ip_route_newports(fl4, rt, orig_sport, orig_dport,
-			       inet->inet_sport, inet->inet_dport, sk);
-	if (IS_ERR(rt)) {
-		err = PTR_ERR(rt);
-		rt = NULL;
-		goto failure;
-	}
-	/* OK, now commit destination to socket.  */
-	sk_setup_caps(sk, &rt->dst);
-
-	dp->dccps_iss = secure_dccp_sequence_number(inet->inet_saddr,
-						    inet->inet_daddr,
-						    inet->inet_sport,
-						    inet->inet_dport);
-	inet->inet_id = dp->dccps_iss ^ jiffies;
-
-	err = dccp_connect(sk);
-	rt = NULL;
-	if (err != 0)
-		goto failure;
+    const struct sockaddr_in *usin = (struct sockaddr_in *)uaddr;
+    struct inet_sock *inet = inet_sk(sk);
+    struct dccp_sock *dp = dccp_sk(sk);
+    __be16 orig_sport, orig_dport;
+    __be32 daddr, nexthop;
+    struct flowi4 *fl4;
+    struct rtable *rt;
+    int err;
+    struct ip_options_rcu *inet_opt;
+
+    dp->dccps_role = DCCP_ROLE_CLIENT;
+
+    if (addr_len < sizeof(struct sockaddr_in))
+        return -EINVAL;
+
+    if (usin->sin_family != AF_INET)
+        return -EAFNOSUPPORT;
+
+    nexthop = daddr = usin->sin_addr.s_addr;
+
+    inet_opt = rcu_dereference_protected(inet->inet_opt,
+                         lockdep_sock_is_held(sk));
+    if (inet_opt != NULL && inet_opt->opt.srr) {
+        if (daddr == 0)
+            return -EINVAL;
+        nexthop = inet_opt->opt.faddr;
+    }
+
+    orig_sport = inet->inet_sport;
+    orig_dport = usin->sin_port;
+    fl4 = &inet->cork.fl.u.ip4;
+    rt = ip_route_connect(fl4, nexthop, inet->inet_saddr,
+                  RT_CONN_FLAGS(sk), sk->sk_bound_dev_if,
+                  IPPROTO_DCCP,
+                  orig_sport, orig_dport, sk);
+    if (IS_ERR(rt))
+        return PTR_ERR(rt);
+
+    if (rt->rt_flags & (RTCF_MULTICAST | RTCF_BROADCAST)) {
+        ip_rt_put(rt);
+        return -ENETUNREACH;
+    }
+
+    if (inet_opt == NULL || !inet_opt->opt.srr)
+        daddr = fl4->daddr;
+
+    if (inet->inet_saddr == 0)
+        inet->inet_saddr = fl4->saddr;
+    sk_rcv_saddr_set(sk, inet->inet_saddr);
+    inet->inet_dport = usin->sin_port;
+    sk_daddr_set(sk, daddr);
+
+    inet_csk(sk)->icsk_ext_hdr_len = 0;
+    if (inet_opt)
+        inet_csk(sk)->icsk_ext_hdr_len = inet_opt->opt.optlen;
+    /*
+     * Socket identity is still unknown (sport may be zero).
+     * However we set state to DCCP_REQUESTING and not releasing socket
+     * lock select source port, enter ourselves into the hash tables and
+     * complete initialization after this.
+     */
+    dccp_set_state(sk, DCCP_REQUESTING);
+    err = inet_hash_connect(&dccp_death_row, sk);
+    if (err != 0)
+        goto failure;
+
+    rt = ip_route_newports(fl4, rt, orig_sport, orig_dport,
+                   inet->inet_sport, inet->inet_dport, sk);
+    if (IS_ERR(rt)) {
+        err = PTR_ERR(rt);
+        rt = NULL;
+        goto failure;
+    }
+    /* OK, now commit destination to socket.  */
+    sk_setup_caps(sk, &rt->dst);
+
+    dp->dccps_iss = secure_dccp_sequence_number(inet->inet_saddr,
+                            inet->inet_daddr,
+                            inet->inet_sport,
+                            inet->inet_dport);
+    inet->inet_id = dp->dccps_iss ^ jiffies;
+
+    err = dccp_connect(sk);
+    rt = NULL;
+    if (err != 0)
+        goto failure;
 out:
-	return err;
+    return err;
 failure:
-	/*
-	 * This unhashes the socket and releases the local port, if necessary.
-	 */
-	dccp_set_state(sk, DCCP_CLOSED);
-	ip_rt_put(rt);
-	sk->sk_route_caps = 0;
-	inet->inet_dport = 0;
-	goto out;
+    /*
+     * This unhashes the socket and releases the local port, if necessary.
+     */
+    dccp_set_state(sk, DCCP_CLOSED);
+    ip_rt_put(rt);
+    sk->sk_route_caps = 0;
+    inet->inet_dport = 0;
+    goto out;
 }
 EXPORT_SYMBOL_GPL(dccp_v4_connect);
 
@@ -145,77 +145,77 @@ EXPORT_SYMBOL_GPL(dccp_v4_connect);
  * This routine does path mtu discovery as defined in RFC1191.
  */
 static inline void dccp_do_pmtu_discovery(struct sock *sk,
-					  const struct iphdr *iph,
-					  u32 mtu)
+                      const struct iphdr *iph,
+                      u32 mtu)
 {
-	struct dst_entry *dst;
-	const struct inet_sock *inet = inet_sk(sk);
-	const struct dccp_sock *dp = dccp_sk(sk);
-
-	/* We are not interested in DCCP_LISTEN and request_socks (RESPONSEs
-	 * send out by Linux are always < 576bytes so they should go through
-	 * unfragmented).
-	 */
-	if (sk->sk_state == DCCP_LISTEN)
-		return;
-
-	dst = inet_csk_update_pmtu(sk, mtu);
-	if (!dst)
-		return;
-
-	/* Something is about to be wrong... Remember soft error
-	 * for the case, if this connection will not able to recover.
-	 */
-	if (mtu < dst_mtu(dst) && ip_dont_fragment(sk, dst))
-		sk->sk_err_soft = EMSGSIZE;
-
-	mtu = dst_mtu(dst);
-
-	if (inet->pmtudisc != IP_PMTUDISC_DONT &&
-	    ip_sk_accept_pmtu(sk) &&
-	    inet_csk(sk)->icsk_pmtu_cookie > mtu) {
-		dccp_sync_mss(sk, mtu);
-
-		/*
-		 * From RFC 4340, sec. 14.1:
-		 *
-		 *	DCCP-Sync packets are the best choice for upward
-		 *	probing, since DCCP-Sync probes do not risk application
-		 *	data loss.
-		 */
-		dccp_send_sync(sk, dp->dccps_gsr, DCCP_PKT_SYNC);
-	} /* else let the usual retransmit timer handle it */
+    struct dst_entry *dst;
+    const struct inet_sock *inet = inet_sk(sk);
+    const struct dccp_sock *dp = dccp_sk(sk);
+
+    /* We are not interested in DCCP_LISTEN and request_socks (RESPONSEs
+     * send out by Linux are always < 576bytes so they should go through
+     * unfragmented).
+     */
+    if (sk->sk_state == DCCP_LISTEN)
+        return;
+
+    dst = inet_csk_update_pmtu(sk, mtu);
+    if (!dst)
+        return;
+
+    /* Something is about to be wrong... Remember soft error
+     * for the case, if this connection will not able to recover.
+     */
+    if (mtu < dst_mtu(dst) && ip_dont_fragment(sk, dst))
+        sk->sk_err_soft = EMSGSIZE;
+
+    mtu = dst_mtu(dst);
+
+    if (inet->pmtudisc != IP_PMTUDISC_DONT &&
+        ip_sk_accept_pmtu(sk) &&
+        inet_csk(sk)->icsk_pmtu_cookie > mtu) {
+        dccp_sync_mss(sk, mtu);
+
+        /*
+         * From RFC 4340, sec. 14.1:
+         *
+         *  DCCP-Sync packets are the best choice for upward
+         *  probing, since DCCP-Sync probes do not risk application
+         *  data loss.
+         */
+        dccp_send_sync(sk, dp->dccps_gsr, DCCP_PKT_SYNC);
+    } /* else let the usual retransmit timer handle it */
 }
 
 static void dccp_do_redirect(struct sk_buff *skb, struct sock *sk)
 {
-	struct dst_entry *dst = __sk_dst_check(sk, 0);
+    struct dst_entry *dst = __sk_dst_check(sk, 0);
 
-	if (dst)
-		dst->ops->redirect(dst, sk, skb);
+    if (dst)
+        dst->ops->redirect(dst, sk, skb);
 }
 
 void dccp_req_err(struct sock *sk, u64 seq)
-	{
-	struct request_sock *req = inet_reqsk(sk);
-	struct net *net = sock_net(sk);
-
-	/*
-	 * ICMPs are not backlogged, hence we cannot get an established
-	 * socket here.
-	 */
-	if (!between48(seq, dccp_rsk(req)->dreq_iss, dccp_rsk(req)->dreq_gss)) {
-		__NET_INC_STATS(net, LINUX_MIB_OUTOFWINDOWICMPS);
-	} else {
-		/*
-		 * Still in RESPOND, just remove it silently.
-		 * There is no good way to pass the error to the newly
-		 * created socket, and POSIX does not want network
-		 * errors returned from accept().
-		 */
-		inet_csk_reqsk_queue_drop(req->rsk_listener, req);
-	}
-	reqsk_put(req);
+    {
+    struct request_sock *req = inet_reqsk(sk);
+    struct net *net = sock_net(sk);
+
+    /*
+     * ICMPs are not backlogged, hence we cannot get an established
+     * socket here.
+     */
+    if (!between48(seq, dccp_rsk(req)->dreq_iss, dccp_rsk(req)->dreq_gss)) {
+        __NET_INC_STATS(net, LINUX_MIB_OUTOFWINDOWICMPS);
+    } else {
+        /*
+         * Still in RESPOND, just remove it silently.
+         * There is no good way to pass the error to the newly
+         * created socket, and POSIX does not want network
+         * errors returned from accept().
+         */
+        inet_csk_reqsk_queue_drop(req->rsk_listener, req);
+    }
+    reqsk_put(req);
 }
 EXPORT_SYMBOL(dccp_req_err);
 
@@ -233,153 +233,153 @@ EXPORT_SYMBOL(dccp_req_err);
  */
 static void dccp_v4_err(struct sk_buff *skb, u32 info)
 {
-	const struct iphdr *iph = (struct iphdr *)skb->data;
-	const u8 offset = iph->ihl << 2;
-	const struct dccp_hdr *dh = (struct dccp_hdr *)(skb->data + offset);
-	struct dccp_sock *dp;
-	struct inet_sock *inet;
-	const int type = icmp_hdr(skb)->type;
-	const int code = icmp_hdr(skb)->code;
-	struct sock *sk;
-	__u64 seq;
-	int err;
-	struct net *net = dev_net(skb->dev);
-
-	if (skb->len < offset + sizeof(*dh) ||
-	    skb->len < offset + __dccp_basic_hdr_len(dh)) {
-		__ICMP_INC_STATS(net, ICMP_MIB_INERRORS);
-		return;
-	}
-
-	sk = __inet_lookup_established(net, &dccp_hashinfo,
-				       iph->daddr, dh->dccph_dport,
-				       iph->saddr, ntohs(dh->dccph_sport),
-				       inet_iif(skb));
-	if (!sk) {
-		__ICMP_INC_STATS(net, ICMP_MIB_INERRORS);
-		return;
-	}
-
-	if (sk->sk_state == DCCP_TIME_WAIT) {
-		inet_twsk_put(inet_twsk(sk));
-		return;
-	}
-	seq = dccp_hdr_seq(dh);
-	if (sk->sk_state == DCCP_NEW_SYN_RECV)
-		return dccp_req_err(sk, seq);
-
-	bh_lock_sock(sk);
-	/* If too many ICMPs get dropped on busy
-	 * servers this needs to be solved differently.
-	 */
-	if (sock_owned_by_user(sk))
-		__NET_INC_STATS(net, LINUX_MIB_LOCKDROPPEDICMPS);
-
-	if (sk->sk_state == DCCP_CLOSED)
-		goto out;
-
-	dp = dccp_sk(sk);
-	if ((1 << sk->sk_state) & ~(DCCPF_REQUESTING | DCCPF_LISTEN) &&
-	    !between48(seq, dp->dccps_awl, dp->dccps_awh)) {
-		__NET_INC_STATS(net, LINUX_MIB_OUTOFWINDOWICMPS);
-		goto out;
-	}
-
-	switch (type) {
-	case ICMP_REDIRECT:
-		dccp_do_redirect(skb, sk);
-		goto out;
-	case ICMP_SOURCE_QUENCH:
-		/* Just silently ignore these. */
-		goto out;
-	case ICMP_PARAMETERPROB:
-		err = EPROTO;
-		break;
-	case ICMP_DEST_UNREACH:
-		if (code > NR_ICMP_UNREACH)
-			goto out;
-
-		if (code == ICMP_FRAG_NEEDED) { /* PMTU discovery (RFC1191) */
-			if (!sock_owned_by_user(sk))
-				dccp_do_pmtu_discovery(sk, iph, info);
-			goto out;
-		}
-
-		err = icmp_err_convert[code].errno;
-		break;
-	case ICMP_TIME_EXCEEDED:
-		err = EHOSTUNREACH;
-		break;
-	default:
-		goto out;
-	}
-
-	switch (sk->sk_state) {
-	case DCCP_REQUESTING:
-	case DCCP_RESPOND:
-		if (!sock_owned_by_user(sk)) {
-			__DCCP_INC_STATS(DCCP_MIB_ATTEMPTFAILS);
-			sk->sk_err = err;
-
-			sk->sk_error_report(sk);
-
-			dccp_done(sk);
-		} else
-			sk->sk_err_soft = err;
-		goto out;
-	}
-
-	/* If we've already connected we will keep trying
-	 * until we time out, or the user gives up.
-	 *
-	 * rfc1122 4.2.3.9 allows to consider as hard errors
-	 * only PROTO_UNREACH and PORT_UNREACH (well, FRAG_FAILED too,
-	 * but it is obsoleted by pmtu discovery).
-	 *
-	 * Note, that in modern internet, where routing is unreliable
-	 * and in each dark corner broken firewalls sit, sending random
-	 * errors ordered by their masters even this two messages finally lose
-	 * their original sense (even Linux sends invalid PORT_UNREACHs)
-	 *
-	 * Now we are in compliance with RFCs.
-	 *							--ANK (980905)
-	 */
-
-	inet = inet_sk(sk);
-	if (!sock_owned_by_user(sk) && inet->recverr) {
-		sk->sk_err = err;
-		sk->sk_error_report(sk);
-	} else /* Only an error on timeout */
-		sk->sk_err_soft = err;
+    const struct iphdr *iph = (struct iphdr *)skb->data;
+    const u8 offset = iph->ihl << 2;
+    const struct dccp_hdr *dh = (struct dccp_hdr *)(skb->data + offset);
+    struct dccp_sock *dp;
+    struct inet_sock *inet;
+    const int type = icmp_hdr(skb)->type;
+    const int code = icmp_hdr(skb)->code;
+    struct sock *sk;
+    __u64 seq;
+    int err;
+    struct net *net = dev_net(skb->dev);
+
+    if (skb->len < offset + sizeof(*dh) ||
+        skb->len < offset + __dccp_basic_hdr_len(dh)) {
+        __ICMP_INC_STATS(net, ICMP_MIB_INERRORS);
+        return;
+    }
+
+    sk = __inet_lookup_established(net, &dccp_hashinfo,
+                       iph->daddr, dh->dccph_dport,
+                       iph->saddr, ntohs(dh->dccph_sport),
+                       inet_iif(skb));
+    if (!sk) {
+        __ICMP_INC_STATS(net, ICMP_MIB_INERRORS);
+        return;
+    }
+
+    if (sk->sk_state == DCCP_TIME_WAIT) {
+        inet_twsk_put(inet_twsk(sk));
+        return;
+    }
+    seq = dccp_hdr_seq(dh);
+    if (sk->sk_state == DCCP_NEW_SYN_RECV)
+        return dccp_req_err(sk, seq);
+
+    bh_lock_sock(sk);
+    /* If too many ICMPs get dropped on busy
+     * servers this needs to be solved differently.
+     */
+    if (sock_owned_by_user(sk))
+        __NET_INC_STATS(net, LINUX_MIB_LOCKDROPPEDICMPS);
+
+    if (sk->sk_state == DCCP_CLOSED)
+        goto out;
+
+    dp = dccp_sk(sk);
+    if ((1 << sk->sk_state) & ~(DCCPF_REQUESTING | DCCPF_LISTEN) &&
+        !between48(seq, dp->dccps_awl, dp->dccps_awh)) {
+        __NET_INC_STATS(net, LINUX_MIB_OUTOFWINDOWICMPS);
+        goto out;
+    }
+
+    switch (type) {
+    case ICMP_REDIRECT:
+        dccp_do_redirect(skb, sk);
+        goto out;
+    case ICMP_SOURCE_QUENCH:
+        /* Just silently ignore these. */
+        goto out;
+    case ICMP_PARAMETERPROB:
+        err = EPROTO;
+        break;
+    case ICMP_DEST_UNREACH:
+        if (code > NR_ICMP_UNREACH)
+            goto out;
+
+        if (code == ICMP_FRAG_NEEDED) { /* PMTU discovery (RFC1191) */
+            if (!sock_owned_by_user(sk))
+                dccp_do_pmtu_discovery(sk, iph, info);
+            goto out;
+        }
+
+        err = icmp_err_convert[code].errno;
+        break;
+    case ICMP_TIME_EXCEEDED:
+        err = EHOSTUNREACH;
+        break;
+    default:
+        goto out;
+    }
+
+    switch (sk->sk_state) {
+    case DCCP_REQUESTING:
+    case DCCP_RESPOND:
+        if (!sock_owned_by_user(sk)) {
+            __DCCP_INC_STATS(DCCP_MIB_ATTEMPTFAILS);
+            sk->sk_err = err;
+
+            sk->sk_error_report(sk);
+
+            dccp_done(sk);
+        } else
+            sk->sk_err_soft = err;
+        goto out;
+    }
+
+    /* If we've already connected we will keep trying
+     * until we time out, or the user gives up.
+     *
+     * rfc1122 4.2.3.9 allows to consider as hard errors
+     * only PROTO_UNREACH and PORT_UNREACH (well, FRAG_FAILED too,
+     * but it is obsoleted by pmtu discovery).
+     *
+     * Note, that in modern internet, where routing is unreliable
+     * and in each dark corner broken firewalls sit, sending random
+     * errors ordered by their masters even this two messages finally lose
+     * their original sense (even Linux sends invalid PORT_UNREACHs)
+     *
+     * Now we are in compliance with RFCs.
+     *                          --ANK (980905)
+     */
+
+    inet = inet_sk(sk);
+    if (!sock_owned_by_user(sk) && inet->recverr) {
+        sk->sk_err = err;
+        sk->sk_error_report(sk);
+    } else /* Only an error on timeout */
+        sk->sk_err_soft = err;
 out:
-	bh_unlock_sock(sk);
-	sock_put(sk);
+    bh_unlock_sock(sk);
+    sock_put(sk);
 }
 
 static inline __sum16 dccp_v4_csum_finish(struct sk_buff *skb,
-				      __be32 src, __be32 dst)
+                      __be32 src, __be32 dst)
 {
-	return csum_tcpudp_magic(src, dst, skb->len, IPPROTO_DCCP, skb->csum);
+    return csum_tcpudp_magic(src, dst, skb->len, IPPROTO_DCCP, skb->csum);
 }
 
 void dccp_v4_send_check(struct sock *sk, struct sk_buff *skb)
 {
-	const struct inet_sock *inet = inet_sk(sk);
-	struct dccp_hdr *dh = dccp_hdr(skb);
+    const struct inet_sock *inet = inet_sk(sk);
+    struct dccp_hdr *dh = dccp_hdr(skb);
 
-	dccp_csum_outgoing(skb);
-	dh->dccph_checksum = dccp_v4_csum_finish(skb,
-						 inet->inet_saddr,
-						 inet->inet_daddr);
+    dccp_csum_outgoing(skb);
+    dh->dccph_checksum = dccp_v4_csum_finish(skb,
+                         inet->inet_saddr,
+                         inet->inet_daddr);
 }
 EXPORT_SYMBOL_GPL(dccp_v4_send_check);
 
 static inline u64 dccp_v4_init_sequence(const struct sk_buff *skb)
 {
-	return secure_dccp_sequence_number(ip_hdr(skb)->daddr,
-					   ip_hdr(skb)->saddr,
-					   dccp_hdr(skb)->dccph_dport,
-					   dccp_hdr(skb)->dccph_sport);
+    return secure_dccp_sequence_number(ip_hdr(skb)->daddr,
+                       ip_hdr(skb)->saddr,
+                       dccp_hdr(skb)->dccph_dport,
+                       dccp_hdr(skb)->dccph_sport);
 }
 
 /*
@@ -389,163 +389,163 @@ static inline u64 dccp_v4_init_sequence(
  * This is the equivalent of TCP's tcp_v4_syn_recv_sock
  */
 struct sock *dccp_v4_request_recv_sock(const struct sock *sk,
-				       struct sk_buff *skb,
-				       struct request_sock *req,
-				       struct dst_entry *dst,
-				       struct request_sock *req_unhash,
-				       bool *own_req)
-{
-	struct inet_request_sock *ireq;
-	struct inet_sock *newinet;
-	struct sock *newsk;
-
-	if (sk_acceptq_is_full(sk))
-		goto exit_overflow;
-
-	newsk = dccp_create_openreq_child(sk, req, skb);
-	if (newsk == NULL)
-		goto exit_nonewsk;
-
-	newinet		   = inet_sk(newsk);
-	ireq		   = inet_rsk(req);
-	sk_daddr_set(newsk, ireq->ir_rmt_addr);
-	sk_rcv_saddr_set(newsk, ireq->ir_loc_addr);
-	newinet->inet_saddr	= ireq->ir_loc_addr;
-	newinet->inet_opt	= ireq->opt;
-	ireq->opt	   = NULL;
-	newinet->mc_index  = inet_iif(skb);
-	newinet->mc_ttl	   = ip_hdr(skb)->ttl;
-	newinet->inet_id   = jiffies;
-
-	if (dst == NULL && (dst = inet_csk_route_child_sock(sk, newsk, req)) == NULL)
-		goto put_and_exit;
-
-	sk_setup_caps(newsk, dst);
-
-	dccp_sync_mss(newsk, dst_mtu(dst));
-
-	if (__inet_inherit_port(sk, newsk) < 0)
-		goto put_and_exit;
-	*own_req = inet_ehash_nolisten(newsk, req_to_sk(req_unhash));
+                       struct sk_buff *skb,
+                       struct request_sock *req,
+                       struct dst_entry *dst,
+                       struct request_sock *req_unhash,
+                       bool *own_req)
+{
+    struct inet_request_sock *ireq;
+    struct inet_sock *newinet;
+    struct sock *newsk;
+
+    if (sk_acceptq_is_full(sk))
+        goto exit_overflow;
+
+    newsk = dccp_create_openreq_child(sk, req, skb);
+    if (newsk == NULL)
+        goto exit_nonewsk;
+
+    newinet        = inet_sk(newsk);
+    ireq           = inet_rsk(req);
+    sk_daddr_set(newsk, ireq->ir_rmt_addr);
+    sk_rcv_saddr_set(newsk, ireq->ir_loc_addr);
+    newinet->inet_saddr = ireq->ir_loc_addr;
+    newinet->inet_opt   = ireq->opt;
+    ireq->opt      = NULL;
+    newinet->mc_index  = inet_iif(skb);
+    newinet->mc_ttl    = ip_hdr(skb)->ttl;
+    newinet->inet_id   = jiffies;
+
+    if (dst == NULL && (dst = inet_csk_route_child_sock(sk, newsk, req)) == NULL)
+        goto put_and_exit;
+
+    sk_setup_caps(newsk, dst);
+
+    dccp_sync_mss(newsk, dst_mtu(dst));
+
+    if (__inet_inherit_port(sk, newsk) < 0)
+        goto put_and_exit;
+    *own_req = inet_ehash_nolisten(newsk, req_to_sk(req_unhash));
 
-	return newsk;
+    return newsk;
 
 exit_overflow:
-	__NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS);
+    __NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS);
 exit_nonewsk:
-	dst_release(dst);
+    dst_release(dst);
 exit:
-	__NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENDROPS);
-	return NULL;
+    __NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENDROPS);
+    return NULL;
 put_and_exit:
-	inet_csk_prepare_forced_close(newsk);
-	dccp_done(newsk);
-	goto exit;
+    inet_csk_prepare_forced_close(newsk);
+    dccp_done(newsk);
+    goto exit;
 }
 EXPORT_SYMBOL_GPL(dccp_v4_request_recv_sock);
 
 static struct dst_entry* dccp_v4_route_skb(struct net *net, struct sock *sk,
-					   struct sk_buff *skb)
+                       struct sk_buff *skb)
 {
-	struct rtable *rt;
-	const struct iphdr *iph = ip_hdr(skb);
-	struct flowi4 fl4 = {
-		.flowi4_oif = inet_iif(skb),
-		.daddr = iph->saddr,
-		.saddr = iph->daddr,
-		.flowi4_tos = RT_CONN_FLAGS(sk),
-		.flowi4_proto = sk->sk_protocol,
-		.fl4_sport = dccp_hdr(skb)->dccph_dport,
-		.fl4_dport = dccp_hdr(skb)->dccph_sport,
-	};
-
-	security_skb_classify_flow(skb, flowi4_to_flowi(&fl4));
-	rt = ip_route_output_flow(net, &fl4, sk);
-	if (IS_ERR(rt)) {
-		IP_INC_STATS(net, IPSTATS_MIB_OUTNOROUTES);
-		return NULL;
-	}
+    struct rtable *rt;
+    const struct iphdr *iph = ip_hdr(skb);
+    struct flowi4 fl4 = {
+        .flowi4_oif = inet_iif(skb),
+        .daddr = iph->saddr,
+        .saddr = iph->daddr,
+        .flowi4_tos = RT_CONN_FLAGS(sk),
+        .flowi4_proto = sk->sk_protocol,
+        .fl4_sport = dccp_hdr(skb)->dccph_dport,
+        .fl4_dport = dccp_hdr(skb)->dccph_sport,
+    };
+
+    security_skb_classify_flow(skb, flowi4_to_flowi(&fl4));
+    rt = ip_route_output_flow(net, &fl4, sk);
+    if (IS_ERR(rt)) {
+        IP_INC_STATS(net, IPSTATS_MIB_OUTNOROUTES);
+        return NULL;
+    }
 
-	return &rt->dst;
+    return &rt->dst;
 }
 
 static int dccp_v4_send_response(const struct sock *sk, struct request_sock *req)
 {
-	int err = -1;
-	struct sk_buff *skb;
-	struct dst_entry *dst;
-	struct flowi4 fl4;
-
-	dst = inet_csk_route_req(sk, &fl4, req);
-	if (dst == NULL)
-		goto out;
-
-	skb = dccp_make_response(sk, dst, req);
-	if (skb != NULL) {
-		const struct inet_request_sock *ireq = inet_rsk(req);
-		struct dccp_hdr *dh = dccp_hdr(skb);
-
-		dh->dccph_checksum = dccp_v4_csum_finish(skb, ireq->ir_loc_addr,
-							      ireq->ir_rmt_addr);
-		err = ip_build_and_send_pkt(skb, sk, ireq->ir_loc_addr,
-					    ireq->ir_rmt_addr,
-					    ireq->opt);
-		err = net_xmit_eval(err);
-	}
+    int err = -1;
+    struct sk_buff *skb;
+    struct dst_entry *dst;
+    struct flowi4 fl4;
+
+    dst = inet_csk_route_req(sk, &fl4, req);
+    if (dst == NULL)
+        goto out;
+
+    skb = dccp_make_response(sk, dst, req);
+    if (skb != NULL) {
+        const struct inet_request_sock *ireq = inet_rsk(req);
+        struct dccp_hdr *dh = dccp_hdr(skb);
+
+        dh->dccph_checksum = dccp_v4_csum_finish(skb, ireq->ir_loc_addr,
+                                  ireq->ir_rmt_addr);
+        err = ip_build_and_send_pkt(skb, sk, ireq->ir_loc_addr,
+                        ireq->ir_rmt_addr,
+                        ireq->opt);
+        err = net_xmit_eval(err);
+    }
 
 out:
-	dst_release(dst);
-	return err;
+    dst_release(dst);
+    return err;
 }
 
 static void dccp_v4_ctl_send_reset(const struct sock *sk, struct sk_buff *rxskb)
 {
-	int err;
-	const struct iphdr *rxiph;
-	struct sk_buff *skb;
-	struct dst_entry *dst;
-	struct net *net = dev_net(skb_dst(rxskb)->dev);
-	struct sock *ctl_sk = net->dccp.v4_ctl_sk;
-
-	/* Never send a reset in response to a reset. */
-	if (dccp_hdr(rxskb)->dccph_type == DCCP_PKT_RESET)
-		return;
-
-	if (skb_rtable(rxskb)->rt_type != RTN_LOCAL)
-		return;
-
-	dst = dccp_v4_route_skb(net, ctl_sk, rxskb);
-	if (dst == NULL)
-		return;
-
-	skb = dccp_ctl_make_reset(ctl_sk, rxskb);
-	if (skb == NULL)
-		goto out;
-
-	rxiph = ip_hdr(rxskb);
-	dccp_hdr(skb)->dccph_checksum = dccp_v4_csum_finish(skb, rxiph->saddr,
-								 rxiph->daddr);
-	skb_dst_set(skb, dst_clone(dst));
-
-	local_bh_disable();
-	bh_lock_sock(ctl_sk);
-	err = ip_build_and_send_pkt(skb, ctl_sk,
-				    rxiph->daddr, rxiph->saddr, NULL);
-	bh_unlock_sock(ctl_sk);
-
-	if (net_xmit_eval(err) == 0) {
-		__DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
-		__DCCP_INC_STATS(DCCP_MIB_OUTRSTS);
-	}
-	local_bh_enable();
+    int err;
+    const struct iphdr *rxiph;
+    struct sk_buff *skb;
+    struct dst_entry *dst;
+    struct net *net = dev_net(skb_dst(rxskb)->dev);
+    struct sock *ctl_sk = net->dccp.v4_ctl_sk;
+
+    /* Never send a reset in response to a reset. */
+    if (dccp_hdr(rxskb)->dccph_type == DCCP_PKT_RESET)
+        return;
+
+    if (skb_rtable(rxskb)->rt_type != RTN_LOCAL)
+        return;
+
+    dst = dccp_v4_route_skb(net, ctl_sk, rxskb);
+    if (dst == NULL)
+        return;
+
+    skb = dccp_ctl_make_reset(ctl_sk, rxskb);
+    if (skb == NULL)
+        goto out;
+
+    rxiph = ip_hdr(rxskb);
+    dccp_hdr(skb)->dccph_checksum = dccp_v4_csum_finish(skb, rxiph->saddr,
+                                 rxiph->daddr);
+    skb_dst_set(skb, dst_clone(dst));
+
+    local_bh_disable();
+    bh_lock_sock(ctl_sk);
+    err = ip_build_and_send_pkt(skb, ctl_sk,
+                    rxiph->daddr, rxiph->saddr, NULL);
+    bh_unlock_sock(ctl_sk);
+
+    if (net_xmit_eval(err) == 0) {
+        __DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
+        __DCCP_INC_STATS(DCCP_MIB_OUTRSTS);
+    }
+    local_bh_enable();
 out:
-	dst_release(dst);
+    dst_release(dst);
 }
 
 static void dccp_v4_reqsk_destructor(struct request_sock *req)
 {
-	dccp_feat_list_purge(&dccp_rsk(req)->dreq_featneg);
-	kfree(inet_rsk(req)->opt);
+    dccp_feat_list_purge(&dccp_rsk(req)->dreq_featneg);
+    kfree(inet_rsk(req)->opt);
 }
 
 void dccp_syn_ack_timeout(const struct request_sock *req)
@@ -554,509 +554,509 @@ void dccp_syn_ack_timeout(const struct r
 EXPORT_SYMBOL(dccp_syn_ack_timeout);
 
 static struct request_sock_ops dccp_request_sock_ops __read_mostly = {
-	.family		= PF_INET,
-	.obj_size	= sizeof(struct dccp_request_sock),
-	.rtx_syn_ack	= dccp_v4_send_response,
-	.send_ack	= dccp_reqsk_send_ack,
-	.destructor	= dccp_v4_reqsk_destructor,
-	.send_reset	= dccp_v4_ctl_send_reset,
-	.syn_ack_timeout = dccp_syn_ack_timeout,
+    .family     = PF_INET,
+    .obj_size   = sizeof(struct dccp_request_sock),
+    .rtx_syn_ack    = dccp_v4_send_response,
+    .send_ack   = dccp_reqsk_send_ack,
+    .destructor = dccp_v4_reqsk_destructor,
+    .send_reset = dccp_v4_ctl_send_reset,
+    .syn_ack_timeout = dccp_syn_ack_timeout,
 };
 
 int dccp_v4_conn_request(struct sock *sk, struct sk_buff *skb)
 {
-	struct inet_request_sock *ireq;
-	struct request_sock *req;
-	struct dccp_request_sock *dreq;
-	const __be32 service = dccp_hdr_request(skb)->dccph_req_service;
-	struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
-
-	/* Never answer to DCCP_PKT_REQUESTs send to broadcast or multicast */
-	if (skb_rtable(skb)->rt_flags & (RTCF_BROADCAST | RTCF_MULTICAST))
-		return 0;	/* discard, don't send a reset here */
-
-	if (dccp_bad_service_code(sk, service)) {
-		dcb->dccpd_reset_code = DCCP_RESET_CODE_BAD_SERVICE_CODE;
-		goto drop;
-	}
-	/*
-	 * TW buckets are converted to open requests without
-	 * limitations, they conserve resources and peer is
-	 * evidently real one.
-	 */
-	dcb->dccpd_reset_code = DCCP_RESET_CODE_TOO_BUSY;
-	if (inet_csk_reqsk_queue_is_full(sk))
-		goto drop;
-
-	/*
-	 * Accept backlog is full. If we have already queued enough
-	 * of warm entries in syn queue, drop request. It is better than
-	 * clogging syn queue with openreqs with exponentially increasing
-	 * timeout.
-	 */
-	if (sk_acceptq_is_full(sk) && inet_csk_reqsk_queue_young(sk) > 1)
-		goto drop;
-
-	req = inet_reqsk_alloc(&dccp_request_sock_ops, sk, true);
-	if (req == NULL)
-		goto drop;
-
-	if (dccp_reqsk_init(req, dccp_sk(sk), skb))
-		goto drop_and_free;
-
-	dreq = dccp_rsk(req);
-	if (dccp_parse_options(sk, dreq, skb))
-		goto drop_and_free;
-
-	if (security_inet_conn_request(sk, skb, req))
-		goto drop_and_free;
-
-	ireq = inet_rsk(req);
-	sk_rcv_saddr_set(req_to_sk(req), ip_hdr(skb)->daddr);
-	sk_daddr_set(req_to_sk(req), ip_hdr(skb)->saddr);
-	ireq->ireq_family = AF_INET;
-	ireq->ir_iif = sk->sk_bound_dev_if;
-
-	/*
-	 * Step 3: Process LISTEN state
-	 *
-	 * Set S.ISR, S.GSR, S.SWL, S.SWH from packet or Init Cookie
-	 *
-	 * Setting S.SWL/S.SWH to is deferred to dccp_create_openreq_child().
-	 */
-	dreq->dreq_isr	   = dcb->dccpd_seq;
-	dreq->dreq_gsr	   = dreq->dreq_isr;
-	dreq->dreq_iss	   = dccp_v4_init_sequence(skb);
-	dreq->dreq_gss     = dreq->dreq_iss;
-	dreq->dreq_service = service;
+    struct inet_request_sock *ireq;
+    struct request_sock *req;
+    struct dccp_request_sock *dreq;
+    const __be32 service = dccp_hdr_request(skb)->dccph_req_service;
+    struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
+
+    /* Never answer to DCCP_PKT_REQUESTs send to broadcast or multicast */
+    if (skb_rtable(skb)->rt_flags & (RTCF_BROADCAST | RTCF_MULTICAST))
+        return 0;   /* discard, don't send a reset here */
+
+    if (dccp_bad_service_code(sk, service)) {
+        dcb->dccpd_reset_code = DCCP_RESET_CODE_BAD_SERVICE_CODE;
+        goto drop;
+    }
+    /*
+     * TW buckets are converted to open requests without
+     * limitations, they conserve resources and peer is
+     * evidently real one.
+     */
+    dcb->dccpd_reset_code = DCCP_RESET_CODE_TOO_BUSY;
+    if (inet_csk_reqsk_queue_is_full(sk))
+        goto drop;
+
+    /*
+     * Accept backlog is full. If we have already queued enough
+     * of warm entries in syn queue, drop request. It is better than
+     * clogging syn queue with openreqs with exponentially increasing
+     * timeout.
+     */
+    if (sk_acceptq_is_full(sk) && inet_csk_reqsk_queue_young(sk) > 1)
+        goto drop;
+
+    req = inet_reqsk_alloc(&dccp_request_sock_ops, sk, true);
+    if (req == NULL)
+        goto drop;
+
+    if (dccp_reqsk_init(req, dccp_sk(sk), skb))
+        goto drop_and_free;
+
+    dreq = dccp_rsk(req);
+    if (dccp_parse_options(sk, dreq, skb))
+        goto drop_and_free;
+
+    if (security_inet_conn_request(sk, skb, req))
+        goto drop_and_free;
+
+    ireq = inet_rsk(req);
+    sk_rcv_saddr_set(req_to_sk(req), ip_hdr(skb)->daddr);
+    sk_daddr_set(req_to_sk(req), ip_hdr(skb)->saddr);
+    ireq->ireq_family = AF_INET;
+    ireq->ir_iif = sk->sk_bound_dev_if;
+
+    /*
+     * Step 3: Process LISTEN state
+     *
+     * Set S.ISR, S.GSR, S.SWL, S.SWH from packet or Init Cookie
+     *
+     * Setting S.SWL/S.SWH to is deferred to dccp_create_openreq_child().
+     */
+    dreq->dreq_isr     = dcb->dccpd_seq;
+    dreq->dreq_gsr     = dreq->dreq_isr;
+    dreq->dreq_iss     = dccp_v4_init_sequence(skb);
+    dreq->dreq_gss     = dreq->dreq_iss;
+    dreq->dreq_service = service;
 
-	if (dccp_v4_send_response(sk, req))
-		goto drop_and_free;
+    if (dccp_v4_send_response(sk, req))
+        goto drop_and_free;
 
-	inet_csk_reqsk_queue_hash_add(sk, req, DCCP_TIMEOUT_INIT);
-	return 0;
+    inet_csk_reqsk_queue_hash_add(sk, req, DCCP_TIMEOUT_INIT);
+    return 0;
 
 drop_and_free:
-	reqsk_free(req);
+    reqsk_free(req);
 drop:
-	__DCCP_INC_STATS(DCCP_MIB_ATTEMPTFAILS);
-	return -1;
+    __DCCP_INC_STATS(DCCP_MIB_ATTEMPTFAILS);
+    return -1;
 }
 EXPORT_SYMBOL_GPL(dccp_v4_conn_request);
 
 int dccp_v4_do_rcv(struct sock *sk, struct sk_buff *skb)
 {
-	struct dccp_hdr *dh = dccp_hdr(skb);
+    struct dccp_hdr *dh = dccp_hdr(skb);
 
-	if (sk->sk_state == DCCP_OPEN) { /* Fast path */
-		if (dccp_rcv_established(sk, skb, dh, skb->len))
-			goto reset;
-		return 0;
-	}
-
-	/*
-	 *  Step 3: Process LISTEN state
-	 *	 If P.type == Request or P contains a valid Init Cookie option,
-	 *	      (* Must scan the packet's options to check for Init
-	 *		 Cookies.  Only Init Cookies are processed here,
-	 *		 however; other options are processed in Step 8.  This
-	 *		 scan need only be performed if the endpoint uses Init
-	 *		 Cookies *)
-	 *	      (* Generate a new socket and switch to that socket *)
-	 *	      Set S := new socket for this port pair
-	 *	      S.state = RESPOND
-	 *	      Choose S.ISS (initial seqno) or set from Init Cookies
-	 *	      Initialize S.GAR := S.ISS
-	 *	      Set S.ISR, S.GSR, S.SWL, S.SWH from packet or Init Cookies
-	 *	      Continue with S.state == RESPOND
-	 *	      (* A Response packet will be generated in Step 11 *)
-	 *	 Otherwise,
-	 *	      Generate Reset(No Connection) unless P.type == Reset
-	 *	      Drop packet and return
-	 *
-	 * NOTE: the check for the packet types is done in
-	 *	 dccp_rcv_state_process
-	 */
-
-	if (dccp_rcv_state_process(sk, skb, dh, skb->len))
-		goto reset;
-	return 0;
+    if (sk->sk_state == DCCP_OPEN) { /* Fast path */
+        if (dccp_rcv_established(sk, skb, dh, skb->len))
+            goto reset;
+        return 0;
+    }
+
+    /*
+     *  Step 3: Process LISTEN state
+     *   If P.type == Request or P contains a valid Init Cookie option,
+     *        (* Must scan the packet's options to check for Init
+     *       Cookies.  Only Init Cookies are processed here,
+     *       however; other options are processed in Step 8.  This
+     *       scan need only be performed if the endpoint uses Init
+     *       Cookies *)
+     *        (* Generate a new socket and switch to that socket *)
+     *        Set S := new socket for this port pair
+     *        S.state = RESPOND
+     *        Choose S.ISS (initial seqno) or set from Init Cookies
+     *        Initialize S.GAR := S.ISS
+     *        Set S.ISR, S.GSR, S.SWL, S.SWH from packet or Init Cookies
+     *        Continue with S.state == RESPOND
+     *        (* A Response packet will be generated in Step 11 *)
+     *   Otherwise,
+     *        Generate Reset(No Connection) unless P.type == Reset
+     *        Drop packet and return
+     *
+     * NOTE: the check for the packet types is done in
+     *   dccp_rcv_state_process
+     */
+
+    if (dccp_rcv_state_process(sk, skb, dh, skb->len))
+        goto reset;
+    return 0;
 
 reset:
-	dccp_v4_ctl_send_reset(sk, skb);
-	kfree_skb(skb);
-	return 0;
+    dccp_v4_ctl_send_reset(sk, skb);
+    kfree_skb(skb);
+    return 0;
 }
 EXPORT_SYMBOL_GPL(dccp_v4_do_rcv);
 
 /**
- *	dccp_invalid_packet  -  check for malformed packets
- *	Implements RFC 4340, 8.5:  Step 1: Check header basics
- *	Packets that fail these checks are ignored and do not receive Resets.
+ *  dccp_invalid_packet  -  check for malformed packets
+ *  Implements RFC 4340, 8.5:  Step 1: Check header basics
+ *  Packets that fail these checks are ignored and do not receive Resets.
  */
 int dccp_invalid_packet(struct sk_buff *skb)
 {
-	const struct dccp_hdr *dh;
-	unsigned int cscov;
+    const struct dccp_hdr *dh;
+    unsigned int cscov;
 
-	if (skb->pkt_type != PACKET_HOST)
-		return 1;
+    if (skb->pkt_type != PACKET_HOST)
+        return 1;
 
-	/* If the packet is shorter than 12 bytes, drop packet and return */
-	if (!pskb_may_pull(skb, sizeof(struct dccp_hdr))) {
-		DCCP_WARN("pskb_may_pull failed\n");
-		return 1;
-	}
-
-	dh = dccp_hdr(skb);
-
-	/* If P.type is not understood, drop packet and return */
-	if (dh->dccph_type >= DCCP_PKT_INVALID) {
-		DCCP_WARN("invalid packet type\n");
-		return 1;
-	}
-
-	/*
-	 * If P.Data Offset is too small for packet type, drop packet and return
-	 */
-	if (dh->dccph_doff < dccp_hdr_len(skb) / sizeof(u32)) {
-		DCCP_WARN("P.Data Offset(%u) too small\n", dh->dccph_doff);
-		return 1;
-	}
-	/*
-	 * If P.Data Offset is too too large for packet, drop packet and return
-	 */
-	if (!pskb_may_pull(skb, dh->dccph_doff * sizeof(u32))) {
-		DCCP_WARN("P.Data Offset(%u) too large\n", dh->dccph_doff);
-		return 1;
-	}
-
-	/*
-	 * If P.type is not Data, Ack, or DataAck and P.X == 0 (the packet
-	 * has short sequence numbers), drop packet and return
-	 */
-	if ((dh->dccph_type < DCCP_PKT_DATA    ||
-	    dh->dccph_type > DCCP_PKT_DATAACK) && dh->dccph_x == 0)  {
-		DCCP_WARN("P.type (%s) not Data || [Data]Ack, while P.X == 0\n",
-			  dccp_packet_name(dh->dccph_type));
-		return 1;
-	}
-
-	/*
-	 * If P.CsCov is too large for the packet size, drop packet and return.
-	 * This must come _before_ checksumming (not as RFC 4340 suggests).
-	 */
-	cscov = dccp_csum_coverage(skb);
-	if (cscov > skb->len) {
-		DCCP_WARN("P.CsCov %u exceeds packet length %d\n",
-			  dh->dccph_cscov, skb->len);
-		return 1;
-	}
-
-	/* If header checksum is incorrect, drop packet and return.
-	 * (This step is completed in the AF-dependent functions.) */
-	skb->csum = skb_checksum(skb, 0, cscov, 0);
+    /* If the packet is shorter than 12 bytes, drop packet and return */
+    if (!pskb_may_pull(skb, sizeof(struct dccp_hdr))) {
+        DCCP_WARN("pskb_may_pull failed\n");
+        return 1;
+    }
+
+    dh = dccp_hdr(skb);
+
+    /* If P.type is not understood, drop packet and return */
+    if (dh->dccph_type >= DCCP_PKT_INVALID) {
+        DCCP_WARN("invalid packet type\n");
+        return 1;
+    }
+
+    /*
+     * If P.Data Offset is too small for packet type, drop packet and return
+     */
+    if (dh->dccph_doff < dccp_hdr_len(skb) / sizeof(u32)) {
+        DCCP_WARN("P.Data Offset(%u) too small\n", dh->dccph_doff);
+        return 1;
+    }
+    /*
+     * If P.Data Offset is too too large for packet, drop packet and return
+     */
+    if (!pskb_may_pull(skb, dh->dccph_doff * sizeof(u32))) {
+        DCCP_WARN("P.Data Offset(%u) too large\n", dh->dccph_doff);
+        return 1;
+    }
+
+    /*
+     * If P.type is not Data, Ack, or DataAck and P.X == 0 (the packet
+     * has short sequence numbers), drop packet and return
+     */
+    if ((dh->dccph_type < DCCP_PKT_DATA    ||
+        dh->dccph_type > DCCP_PKT_DATAACK) && dh->dccph_x == 0)  {
+        DCCP_WARN("P.type (%s) not Data || [Data]Ack, while P.X == 0\n",
+              dccp_packet_name(dh->dccph_type));
+        return 1;
+    }
+
+    /*
+     * If P.CsCov is too large for the packet size, drop packet and return.
+     * This must come _before_ checksumming (not as RFC 4340 suggests).
+     */
+    cscov = dccp_csum_coverage(skb);
+    if (cscov > skb->len) {
+        DCCP_WARN("P.CsCov %u exceeds packet length %d\n",
+              dh->dccph_cscov, skb->len);
+        return 1;
+    }
+
+    /* If header checksum is incorrect, drop packet and return.
+     * (This step is completed in the AF-dependent functions.) */
+    skb->csum = skb_checksum(skb, 0, cscov, 0);
 
-	return 0;
+    return 0;
 }
 EXPORT_SYMBOL_GPL(dccp_invalid_packet);
 
 /* this is called when real data arrives */
 static int dccp_v4_rcv(struct sk_buff *skb)
 {
-	const struct dccp_hdr *dh;
-	const struct iphdr *iph;
-	bool refcounted;
-	struct sock *sk;
-	int min_cov;
-
-	/* Step 1: Check header basics */
-
-	if (dccp_invalid_packet(skb))
-		goto discard_it;
-
-	iph = ip_hdr(skb);
-	/* Step 1: If header checksum is incorrect, drop packet and return */
-	if (dccp_v4_csum_finish(skb, iph->saddr, iph->daddr)) {
-		DCCP_WARN("dropped packet with invalid checksum\n");
-		goto discard_it;
-	}
-
-	dh = dccp_hdr(skb);
-
-	DCCP_SKB_CB(skb)->dccpd_seq  = dccp_hdr_seq(dh);
-	DCCP_SKB_CB(skb)->dccpd_type = dh->dccph_type;
-
-	dccp_pr_debug("%8.8s src=%pI4@%-5d dst=%pI4@%-5d seq=%llu",
-		      dccp_packet_name(dh->dccph_type),
-		      &iph->saddr, ntohs(dh->dccph_sport),
-		      &iph->daddr, ntohs(dh->dccph_dport),
-		      (unsigned long long) DCCP_SKB_CB(skb)->dccpd_seq);
-
-	if (dccp_packet_without_ack(skb)) {
-		DCCP_SKB_CB(skb)->dccpd_ack_seq = DCCP_PKT_WITHOUT_ACK_SEQ;
-		dccp_pr_debug_cat("\n");
-	} else {
-		DCCP_SKB_CB(skb)->dccpd_ack_seq = dccp_hdr_ack_seq(skb);
-		dccp_pr_debug_cat(", ack=%llu\n", (unsigned long long)
-				  DCCP_SKB_CB(skb)->dccpd_ack_seq);
-	}
+    const struct dccp_hdr *dh;
+    const struct iphdr *iph;
+    bool refcounted;
+    struct sock *sk;
+    int min_cov;
+
+    /* Step 1: Check header basics */
+
+    if (dccp_invalid_packet(skb))
+        goto discard_it;
+
+    iph = ip_hdr(skb);
+    /* Step 1: If header checksum is incorrect, drop packet and return */
+    if (dccp_v4_csum_finish(skb, iph->saddr, iph->daddr)) {
+        DCCP_WARN("dropped packet with invalid checksum\n");
+        goto discard_it;
+    }
+
+    dh = dccp_hdr(skb);
+
+    DCCP_SKB_CB(skb)->dccpd_seq  = dccp_hdr_seq(dh);
+    DCCP_SKB_CB(skb)->dccpd_type = dh->dccph_type;
+
+    dccp_pr_debug("%8.8s src=%pI4@%-5d dst=%pI4@%-5d seq=%llu",
+              dccp_packet_name(dh->dccph_type),
+              &iph->saddr, ntohs(dh->dccph_sport),
+              &iph->daddr, ntohs(dh->dccph_dport),
+              (unsigned long long) DCCP_SKB_CB(skb)->dccpd_seq);
+
+    if (dccp_packet_without_ack(skb)) {
+        DCCP_SKB_CB(skb)->dccpd_ack_seq = DCCP_PKT_WITHOUT_ACK_SEQ;
+        dccp_pr_debug_cat("\n");
+    } else {
+        DCCP_SKB_CB(skb)->dccpd_ack_seq = dccp_hdr_ack_seq(skb);
+        dccp_pr_debug_cat(", ack=%llu\n", (unsigned long long)
+                  DCCP_SKB_CB(skb)->dccpd_ack_seq);
+    }
 
 lookup:
-	sk = __inet_lookup_skb(&dccp_hashinfo, skb, __dccp_hdr_len(dh),
-			       dh->dccph_sport, dh->dccph_dport, &refcounted);
-	if (!sk) {
-		dccp_pr_debug("failed to look up flow ID in table and "
-			      "get corresponding socket\n");
-		goto no_dccp_socket;
-	}
-
-	/*
-	 * Step 2:
-	 *	... or S.state == TIMEWAIT,
-	 *		Generate Reset(No Connection) unless P.type == Reset
-	 *		Drop packet and return
-	 */
-	if (sk->sk_state == DCCP_TIME_WAIT) {
-		dccp_pr_debug("sk->sk_state == DCCP_TIME_WAIT: do_time_wait\n");
-		inet_twsk_put(inet_twsk(sk));
-		goto no_dccp_socket;
-	}
-
-	if (sk->sk_state == DCCP_NEW_SYN_RECV) {
-		struct request_sock *req = inet_reqsk(sk);
-		struct sock *nsk;
-
-		sk = req->rsk_listener;
-		if (unlikely(sk->sk_state != DCCP_LISTEN)) {
-			inet_csk_reqsk_queue_drop_and_put(sk, req);
-			goto lookup;
-		}
-		sock_hold(sk);
-		refcounted = true;
-		nsk = dccp_check_req(sk, skb, req);
-		if (!nsk) {
-			reqsk_put(req);
-			goto discard_and_relse;
-		}
-		if (nsk == sk) {
-			reqsk_put(req);
-		} else if (dccp_child_process(sk, nsk, skb)) {
-			dccp_v4_ctl_send_reset(sk, skb);
-			goto discard_and_relse;
-		} else {
-			sock_put(sk);
-			return 0;
-		}
-	}
-	/*
-	 * RFC 4340, sec. 9.2.1: Minimum Checksum Coverage
-	 *	o if MinCsCov = 0, only packets with CsCov = 0 are accepted
-	 *	o if MinCsCov > 0, also accept packets with CsCov >= MinCsCov
-	 */
-	min_cov = dccp_sk(sk)->dccps_pcrlen;
-	if (dh->dccph_cscov && (min_cov == 0 || dh->dccph_cscov < min_cov))  {
-		dccp_pr_debug("Packet CsCov %d does not satisfy MinCsCov %d\n",
-			      dh->dccph_cscov, min_cov);
-		/* FIXME: "Such packets SHOULD be reported using Data Dropped
-		 *         options (Section 11.7) with Drop Code 0, Protocol
-		 *         Constraints."                                     */
-		goto discard_and_relse;
-	}
-
-	if (!xfrm4_policy_check(sk, XFRM_POLICY_IN, skb))
-		goto discard_and_relse;
-	nf_reset(skb);
+    sk = __inet_lookup_skb(&dccp_hashinfo, skb, __dccp_hdr_len(dh),
+                   dh->dccph_sport, dh->dccph_dport, &refcounted);
+    if (!sk) {
+        dccp_pr_debug("failed to look up flow ID in table and "
+                  "get corresponding socket\n");
+        goto no_dccp_socket;
+    }
+
+    /*
+     * Step 2:
+     *  ... or S.state == TIMEWAIT,
+     *      Generate Reset(No Connection) unless P.type == Reset
+     *      Drop packet and return
+     */
+    if (sk->sk_state == DCCP_TIME_WAIT) {
+        dccp_pr_debug("sk->sk_state == DCCP_TIME_WAIT: do_time_wait\n");
+        inet_twsk_put(inet_twsk(sk));
+        goto no_dccp_socket;
+    }
+
+    if (sk->sk_state == DCCP_NEW_SYN_RECV) {
+        struct request_sock *req = inet_reqsk(sk);
+        struct sock *nsk;
+
+        sk = req->rsk_listener;
+        if (unlikely(sk->sk_state != DCCP_LISTEN)) {
+            inet_csk_reqsk_queue_drop_and_put(sk, req);
+            goto lookup;
+        }
+        sock_hold(sk);
+        refcounted = true;
+        nsk = dccp_check_req(sk, skb, req);
+        if (!nsk) {
+            reqsk_put(req);
+            goto discard_and_relse;
+        }
+        if (nsk == sk) {
+            reqsk_put(req);
+        } else if (dccp_child_process(sk, nsk, skb)) {
+            dccp_v4_ctl_send_reset(sk, skb);
+            goto discard_and_relse;
+        } else {
+            sock_put(sk);
+            return 0;
+        }
+    }
+    /*
+     * RFC 4340, sec. 9.2.1: Minimum Checksum Coverage
+     *  o if MinCsCov = 0, only packets with CsCov = 0 are accepted
+     *  o if MinCsCov > 0, also accept packets with CsCov >= MinCsCov
+     */
+    min_cov = dccp_sk(sk)->dccps_pcrlen;
+    if (dh->dccph_cscov && (min_cov == 0 || dh->dccph_cscov < min_cov))  {
+        dccp_pr_debug("Packet CsCov %d does not satisfy MinCsCov %d\n",
+                  dh->dccph_cscov, min_cov);
+        /* FIXME: "Such packets SHOULD be reported using Data Dropped
+         *         options (Section 11.7) with Drop Code 0, Protocol
+         *         Constraints."                                     */
+        goto discard_and_relse;
+    }
+
+    if (!xfrm4_policy_check(sk, XFRM_POLICY_IN, skb))
+        goto discard_and_relse;
+    nf_reset(skb);
 
-	return __sk_receive_skb(sk, skb, 1, dh->dccph_doff * 4);
+    return __sk_receive_skb(sk, skb, 1, dh->dccph_doff * 4);
 
 no_dccp_socket:
-	if (!xfrm4_policy_check(NULL, XFRM_POLICY_IN, skb))
-		goto discard_it;
-	/*
-	 * Step 2:
-	 *	If no socket ...
-	 *		Generate Reset(No Connection) unless P.type == Reset
-	 *		Drop packet and return
-	 */
-	if (dh->dccph_type != DCCP_PKT_RESET) {
-		DCCP_SKB_CB(skb)->dccpd_reset_code =
-					DCCP_RESET_CODE_NO_CONNECTION;
-		dccp_v4_ctl_send_reset(sk, skb);
-	}
+    if (!xfrm4_policy_check(NULL, XFRM_POLICY_IN, skb))
+        goto discard_it;
+    /*
+     * Step 2:
+     *  If no socket ...
+     *      Generate Reset(No Connection) unless P.type == Reset
+     *      Drop packet and return
+     */
+    if (dh->dccph_type != DCCP_PKT_RESET) {
+        DCCP_SKB_CB(skb)->dccpd_reset_code =
+                    DCCP_RESET_CODE_NO_CONNECTION;
+        dccp_v4_ctl_send_reset(sk, skb);
+    }
 
 discard_it:
-	kfree_skb(skb);
-	return 0;
+    kfree_skb(skb);
+    return 0;
 
 discard_and_relse:
-	if (refcounted)
-		sock_put(sk);
-	goto discard_it;
+    if (refcounted)
+        sock_put(sk);
+    goto discard_it;
 }
 
 static const struct inet_connection_sock_af_ops dccp_ipv4_af_ops = {
-	.queue_xmit	   = ip_queue_xmit,
-	.send_check	   = dccp_v4_send_check,
-	.rebuild_header	   = inet_sk_rebuild_header,
-	.conn_request	   = dccp_v4_conn_request,
-	.syn_recv_sock	   = dccp_v4_request_recv_sock,
-	.net_header_len	   = sizeof(struct iphdr),
-	.setsockopt	   = ip_setsockopt,
-	.getsockopt	   = ip_getsockopt,
-	.addr2sockaddr	   = inet_csk_addr2sockaddr,
-	.sockaddr_len	   = sizeof(struct sockaddr_in),
-	.bind_conflict	   = inet_csk_bind_conflict,
+    .queue_xmit    = ip_queue_xmit,
+    .send_check    = dccp_v4_send_check,
+    .rebuild_header    = inet_sk_rebuild_header,
+    .conn_request      = dccp_v4_conn_request,
+    .syn_recv_sock     = dccp_v4_request_recv_sock,
+    .net_header_len    = sizeof(struct iphdr),
+    .setsockopt    = ip_setsockopt,
+    .getsockopt    = ip_getsockopt,
+    .addr2sockaddr     = inet_csk_addr2sockaddr,
+    .sockaddr_len      = sizeof(struct sockaddr_in),
+    .bind_conflict     = inet_csk_bind_conflict,
 #ifdef CONFIG_COMPAT
-	.compat_setsockopt = compat_ip_setsockopt,
-	.compat_getsockopt = compat_ip_getsockopt,
+    .compat_setsockopt = compat_ip_setsockopt,
+    .compat_getsockopt = compat_ip_getsockopt,
 #endif
 };
 
 static int dccp_v4_init_sock(struct sock *sk)
 {
-	static __u8 dccp_v4_ctl_sock_initialized;
-	int err = dccp_init_sock(sk, dccp_v4_ctl_sock_initialized);
+    static __u8 dccp_v4_ctl_sock_initialized;
+    int err = dccp_init_sock(sk, dccp_v4_ctl_sock_initialized);
 
-	if (err == 0) {
-		if (unlikely(!dccp_v4_ctl_sock_initialized))
-			dccp_v4_ctl_sock_initialized = 1;
-		inet_csk(sk)->icsk_af_ops = &dccp_ipv4_af_ops;
-	}
+    if (err == 0) {
+        if (unlikely(!dccp_v4_ctl_sock_initialized))
+            dccp_v4_ctl_sock_initialized = 1;
+        inet_csk(sk)->icsk_af_ops = &dccp_ipv4_af_ops;
+    }
 
-	return err;
+    return err;
 }
 
 static struct timewait_sock_ops dccp_timewait_sock_ops = {
-	.twsk_obj_size	= sizeof(struct inet_timewait_sock),
+    .twsk_obj_size  = sizeof(struct inet_timewait_sock),
 };
 
 static struct proto dccp_v4_prot = {
-	.name			= "DCCP",
-	.owner			= THIS_MODULE,
-	.close			= dccp_close,
-	.connect		= dccp_v4_connect,
-	.disconnect		= dccp_disconnect,
-	.ioctl			= dccp_ioctl,
-	.init			= dccp_v4_init_sock,
-	.setsockopt		= dccp_setsockopt,
-	.getsockopt		= dccp_getsockopt,
-	.sendmsg		= dccp_sendmsg,
-	.recvmsg		= dccp_recvmsg,
-	.backlog_rcv		= dccp_v4_do_rcv,
-	.hash			= inet_hash,
-	.unhash			= inet_unhash,
-	.accept			= inet_csk_accept,
-	.get_port		= inet_csk_get_port,
-	.shutdown		= dccp_shutdown,
-	.destroy		= dccp_destroy_sock,
-	.orphan_count		= &dccp_orphan_count,
-	.max_header		= MAX_DCCP_HEADER,
-	.obj_size		= sizeof(struct dccp_sock),
-	.slab_flags		= SLAB_DESTROY_BY_RCU,
-	.rsk_prot		= &dccp_request_sock_ops,
-	.twsk_prot		= &dccp_timewait_sock_ops,
-	.h.hashinfo		= &dccp_hashinfo,
+    .name           = "DCCP",
+    .owner          = THIS_MODULE,
+    .close          = dccp_close,
+    .connect        = dccp_v4_connect,
+    .disconnect     = dccp_disconnect,
+    .ioctl          = dccp_ioctl,
+    .init           = dccp_v4_init_sock,
+    .setsockopt     = dccp_setsockopt,
+    .getsockopt     = dccp_getsockopt,
+    .sendmsg        = dccp_sendmsg,
+    .recvmsg        = dccp_recvmsg,
+    .backlog_rcv        = dccp_v4_do_rcv,
+    .hash           = inet_hash,
+    .unhash         = inet_unhash,
+    .accept         = inet_csk_accept,
+    .get_port       = inet_csk_get_port,
+    .shutdown       = dccp_shutdown,
+    .destroy        = dccp_destroy_sock,
+    .orphan_count       = &dccp_orphan_count,
+    .max_header     = MAX_DCCP_HEADER,
+    .obj_size       = sizeof(struct dccp_sock),
+    .slab_flags     = SLAB_DESTROY_BY_RCU,
+    .rsk_prot       = &dccp_request_sock_ops,
+    .twsk_prot      = &dccp_timewait_sock_ops,
+    .h.hashinfo     = &dccp_hashinfo,
 #ifdef CONFIG_COMPAT
-	.compat_setsockopt	= compat_dccp_setsockopt,
-	.compat_getsockopt	= compat_dccp_getsockopt,
+    .compat_setsockopt  = compat_dccp_setsockopt,
+    .compat_getsockopt  = compat_dccp_getsockopt,
 #endif
 };
 
 static const struct net_protocol dccp_v4_protocol = {
-	.handler	= dccp_v4_rcv,
-	.err_handler	= dccp_v4_err,
-	.no_policy	= 1,
-	.netns_ok	= 1,
-	.icmp_strict_tag_validation = 1,
+    .handler    = dccp_v4_rcv,
+    .err_handler    = dccp_v4_err,
+    .no_policy  = 1,
+    .netns_ok   = 1,
+    .icmp_strict_tag_validation = 1,
 };
 
 static const struct proto_ops inet_dccp_ops = {
-	.family		   = PF_INET,
-	.owner		   = THIS_MODULE,
-	.release	   = inet_release,
-	.bind		   = inet_bind,
-	.connect	   = inet_stream_connect,
-	.socketpair	   = sock_no_socketpair,
-	.accept		   = inet_accept,
-	.getname	   = inet_getname,
-	/* FIXME: work on tcp_poll to rename it to inet_csk_poll */
-	.poll		   = dccp_poll,
-	.ioctl		   = inet_ioctl,
-	/* FIXME: work on inet_listen to rename it to sock_common_listen */
-	.listen		   = inet_dccp_listen,
-	.shutdown	   = inet_shutdown,
-	.setsockopt	   = sock_common_setsockopt,
-	.getsockopt	   = sock_common_getsockopt,
-	.sendmsg	   = inet_sendmsg,
-	.recvmsg	   = sock_common_recvmsg,
-	.mmap		   = sock_no_mmap,
-	.sendpage	   = sock_no_sendpage,
+    .family        = PF_INET,
+    .owner         = THIS_MODULE,
+    .release       = inet_release,
+    .bind          = inet_bind,
+    .connect       = inet_stream_connect,
+    .socketpair    = sock_no_socketpair,
+    .accept        = inet_accept,
+    .getname       = inet_getname,
+    /* FIXME: work on tcp_poll to rename it to inet_csk_poll */
+    .poll          = dccp_poll,
+    .ioctl         = inet_ioctl,
+    /* FIXME: work on inet_listen to rename it to sock_common_listen */
+    .listen        = inet_dccp_listen,
+    .shutdown      = inet_shutdown,
+    .setsockopt    = sock_common_setsockopt,
+    .getsockopt    = sock_common_getsockopt,
+    .sendmsg       = inet_sendmsg,
+    .recvmsg       = sock_common_recvmsg,
+    .mmap          = sock_no_mmap,
+    .sendpage      = sock_no_sendpage,
 #ifdef CONFIG_COMPAT
-	.compat_setsockopt = compat_sock_common_setsockopt,
-	.compat_getsockopt = compat_sock_common_getsockopt,
+    .compat_setsockopt = compat_sock_common_setsockopt,
+    .compat_getsockopt = compat_sock_common_getsockopt,
 #endif
 };
 
 static struct inet_protosw dccp_v4_protosw = {
-	.type		= SOCK_DCCP,
-	.protocol	= IPPROTO_DCCP,
-	.prot		= &dccp_v4_prot,
-	.ops		= &inet_dccp_ops,
-	.flags		= INET_PROTOSW_ICSK,
+    .type       = SOCK_DCCP,
+    .protocol   = IPPROTO_DCCP,
+    .prot       = &dccp_v4_prot,
+    .ops        = &inet_dccp_ops,
+    .flags      = INET_PROTOSW_ICSK,
 };
 
 static int __net_init dccp_v4_init_net(struct net *net)
 {
-	if (dccp_hashinfo.bhash == NULL)
-		return -ESOCKTNOSUPPORT;
+    if (dccp_hashinfo.bhash == NULL)
+        return -ESOCKTNOSUPPORT;
 
-	return inet_ctl_sock_create(&net->dccp.v4_ctl_sk, PF_INET,
-				    SOCK_DCCP, IPPROTO_DCCP, net);
+    return inet_ctl_sock_create(&net->dccp.v4_ctl_sk, PF_INET,
+                    SOCK_DCCP, IPPROTO_DCCP, net);
 }
 
 static void __net_exit dccp_v4_exit_net(struct net *net)
 {
-	inet_ctl_sock_destroy(net->dccp.v4_ctl_sk);
+    inet_ctl_sock_destroy(net->dccp.v4_ctl_sk);
 }
 
 static struct pernet_operations dccp_v4_ops = {
-	.init	= dccp_v4_init_net,
-	.exit	= dccp_v4_exit_net,
+    .init   = dccp_v4_init_net,
+    .exit   = dccp_v4_exit_net,
 };
 
 static int __init dccp_v4_init(void)
 {
-	int err = proto_register(&dccp_v4_prot, 1);
+    int err = proto_register(&dccp_v4_prot, 1);
 
-	if (err != 0)
-		goto out;
+    if (err != 0)
+        goto out;
 
-	err = inet_add_protocol(&dccp_v4_protocol, IPPROTO_DCCP);
-	if (err != 0)
-		goto out_proto_unregister;
+    err = inet_add_protocol(&dccp_v4_protocol, IPPROTO_DCCP);
+    if (err != 0)
+        goto out_proto_unregister;
 
-	inet_register_protosw(&dccp_v4_protosw);
+    inet_register_protosw(&dccp_v4_protosw);
 
-	err = register_pernet_subsys(&dccp_v4_ops);
-	if (err)
-		goto out_destroy_ctl_sock;
+    err = register_pernet_subsys(&dccp_v4_ops);
+    if (err)
+        goto out_destroy_ctl_sock;
 out:
-	return err;
+    return err;
 out_destroy_ctl_sock:
-	inet_unregister_protosw(&dccp_v4_protosw);
-	inet_del_protocol(&dccp_v4_protocol, IPPROTO_DCCP);
+    inet_unregister_protosw(&dccp_v4_protosw);
+    inet_del_protocol(&dccp_v4_protocol, IPPROTO_DCCP);
 out_proto_unregister:
-	proto_unregister(&dccp_v4_prot);
-	goto out;
+    proto_unregister(&dccp_v4_prot);
+    goto out;
 }
 
 static void __exit dccp_v4_exit(void)
 {
-	unregister_pernet_subsys(&dccp_v4_ops);
-	inet_unregister_protosw(&dccp_v4_protosw);
-	inet_del_protocol(&dccp_v4_protocol, IPPROTO_DCCP);
-	proto_unregister(&dccp_v4_prot);
+    unregister_pernet_subsys(&dccp_v4_ops);
+    inet_unregister_protosw(&dccp_v4_protosw);
+    inet_del_protocol(&dccp_v4_protocol, IPPROTO_DCCP);
+    proto_unregister(&dccp_v4_prot);
 }
 
 module_init(dccp_v4_init);
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/.gitignore linux-4.9-rc2/net/gmtp/.gitignore
--- linux-4.9-rc2-original/net/gmtp/.gitignore	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/.gitignore	2016-12-01 16:50:35.505419255 -0300
@@ -0,0 +1,2 @@
+/.settings/
+doc/*
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/Kconfig linux-4.9-rc2/net/gmtp/Kconfig
--- linux-4.9-rc2-original/net/gmtp/Kconfig	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/Kconfig	2016-12-01 16:50:35.505419255 -0300
@@ -0,0 +1,11 @@
+menuconfig GMTP
+	tristate "The GMTP Protocol"
+	depends on INET
+    default y
+
+if GMTP
+
+source "net/gmtp/gmtp-inter/Kconfig"
+
+endif
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/Makefile linux-4.9-rc2/net/gmtp/Makefile
--- linux-4.9-rc2-original/net/gmtp/Makefile	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/Makefile	2016-12-01 16:50:35.506419242 -0300
@@ -0,0 +1,9 @@
+obj-$(CONFIG_GMTP) += gmtp.o gmtp_ipv4.o
+
+gmtp-y += hash/hash.o hash/client.o hash/hash_client.o hash/hash_server.o
+gmtp-y += input.o minisocks.o output.o sockopt.o proto.o timer.o
+gmtp-y +=  mcc/mcc_proto.o mcc/mcc_input.o mcc/mcc_equation.o mcc/packet_history.o mcc/loss_interval.o 
+
+gmtp_ipv4-y := ipv4.o
+
+obj-$(CONFIG_GMTP_INTER) += gmtp-inter/
\ No newline at end of file
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/Kconfig linux-4.9-rc2/net/gmtp/gmtp-inter/Kconfig
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/Kconfig	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/Kconfig	2016-12-01 16:50:35.551418679 -0300
@@ -0,0 +1,9 @@
+menu "GMTP-Inter Configuration"
+
+config GMTP_INTER
+	bool "Activate GMTP-Inter"
+    default y if (GMTP = y)
+	---help---
+	  Enable GMTP-Inter.
+endmenu
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/Makefile linux-4.9-rc2/net/gmtp/gmtp-inter/Makefile
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/Makefile	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/Makefile	2016-12-01 16:50:35.552418667 -0300
@@ -0,0 +1,3 @@
+obj-$(CONFIG_GMTP_INTER)  += gmtp_inter.o
+
+gmtp_inter-y += ucc.o mcc-inter.o relay.o hash-inter.o build.o output-inter.o input-inter.o gmtp-inter.o
\ No newline at end of file
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/build.c linux-4.9-rc2/net/gmtp/gmtp-inter/build.c
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/build.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/build.c	2016-12-01 16:50:35.527418980 -0300
@@ -0,0 +1,612 @@
+/*
+ * build.c
+ *
+ *  Created on: 27/05/2015
+ *      Author: wendell
+ */
+
+#include <linux/phy.h>
+#include <linux/etherdevice.h>
+#include <net/ip.h>
+#include <net/sch_generic.h>
+#include <linux/kernel.h>
+
+#include <uapi/linux/gmtp.h>
+#include <linux/gmtp.h>
+#include "../gmtp.h"
+
+#include "gmtp-inter.h"
+
+struct gmtp_hdr *gmtp_inter_make_route_hdr(struct sk_buff *skb)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	__u8 *transport_header;
+
+	struct gmtp_hdr *gh_cpy;
+	struct gmtp_hdr_route *gh_rn;
+	struct gmtp_hdr_register_reply *gh_reply = gmtp_hdr_register_reply(skb);
+
+	int gmtp_hdr_len = sizeof(struct gmtp_hdr) +
+			sizeof(struct gmtp_hdr_route) +
+			(gh_reply->nrelays * sizeof(struct gmtp_hdr_relay));
+
+	gmtp_pr_func();
+
+	transport_header = kmalloc(gmtp_hdr_len, gfp_any());
+	memset(transport_header, 0, gmtp_hdr_len);
+
+	gh_cpy = (struct gmtp_hdr *) transport_header;
+	memcpy(gh_cpy, gh, gmtp_hdr_len /*sizeof(struct gmtp_hdr)*/);
+
+	gh_cpy->version = GMTP_VERSION;
+	gh_cpy->type = GMTP_PKT_ROUTE_NOTIFY;
+	gh_cpy->hdrlen = gmtp_hdr_len;
+	pr_info("Original gh->transm_r: %u B/s\n", gh->transm_r);
+	/*gh_cpy->transm_r = entry->transm_r;*/
+	gh_cpy->relay = 1;
+	gh_cpy->dport = gh->sport;
+	gh_cpy->sport = gh->dport;
+
+	return gh_cpy;
+}
+
+struct gmtp_hdr *gmtp_inter_make_request_notify_hdr(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry, __be16 new_sport,
+		__be16 new_dport, struct gmtp_client *my_reporter,
+		__u8 max_nclients, __u8 code)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	__u8 *transport_header;
+
+	struct gmtp_hdr *gh_cpy;
+	struct gmtp_hdr_reqnotify *gh_rnotify;
+
+	int gmtp_hdr_len = sizeof(struct gmtp_hdr)
+			+ sizeof(struct gmtp_hdr_reqnotify);
+
+	transport_header = kmalloc(gmtp_hdr_len, gfp_any());
+	memset(transport_header, 0, gmtp_hdr_len);
+
+	gh_cpy = (struct gmtp_hdr *)transport_header;
+	memcpy(gh_cpy, gh, sizeof(struct gmtp_hdr));
+
+	gh_cpy->version = GMTP_VERSION;
+	gh_cpy->type = GMTP_PKT_REQUESTNOTIFY;
+	gh_cpy->hdrlen = gmtp_hdr_len;
+	gh_cpy->relay = 1;
+	gh_cpy->sport = new_sport;
+	gh_cpy->dport = new_dport;
+
+	gh_rnotify = (struct gmtp_hdr_reqnotify*)(transport_header
+			+ sizeof(struct gmtp_hdr));
+
+	gh_rnotify->rn_code = code;
+	gh_rnotify->mcst_addr = entry->channel_addr;
+	gh_rnotify->mcst_port = entry->channel_port;
+	memcpy(gh_rnotify->relay_id, gmtp_info->relay_id, GMTP_RELAY_ID_LEN);
+
+	if(my_reporter != NULL) {
+		gh_rnotify->reporter_addr = my_reporter->addr;
+		gh_rnotify->reporter_port = my_reporter->port;
+		gh_rnotify->max_nclients = max_nclients;
+		my_reporter->nclients++;
+	}
+
+	pr_info("ReqNotify => Ch: %pI4@%-5d | Code: %u | max_nclients: %u\n",
+					&gh_rnotify->mcst_addr,
+					ntohs(gh_rnotify->mcst_port),
+					gh_rnotify->rn_code,
+					gh_rnotify->max_nclients);
+
+	pr_info("Reporter: %pI4@%-5d\n", &gh_rnotify->reporter_addr,
+			ntohs(gh_rnotify->reporter_port));
+
+	return gh_cpy;
+}
+
+
+int gmtp_inter_make_request_notify(struct sk_buff *skb, __be32 new_saddr,
+		__be16 new_sport, __be32 new_daddr, __be16 new_dport,
+		struct gmtp_client *reporter, __u8 max_nclients, __u8 code)
+{
+	int ret = NF_ACCEPT;
+
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_inter_entry *entry;
+	unsigned int skb_len = skb->len;
+	struct gmtp_hdr *new_gh;
+	int gmtp_hdr_len = sizeof(struct gmtp_hdr)
+			+ sizeof(struct gmtp_hdr_reqnotify);
+
+	gmtp_pr_func();
+
+	entry = gmtp_inter_lookup_media(gmtp_inter.hashtable, gh->flowname);
+	if(entry == NULL) {
+		gmtp_print_warning("Failed to lookup media info in table...");
+		goto fail;
+	}
+
+	/* Delete REQUEST or REGISTER-REPLY specific header */
+	skb_trim(skb, (skb_len - gmtp_packet_hdr_variable_len(gh->type)));
+
+	new_gh = kmalloc(gmtp_hdr_len, GFP_ATOMIC);
+	new_gh = gmtp_inter_make_request_notify_hdr(skb, entry, new_sport,
+			new_dport, reporter, max_nclients, code);
+
+	skb_put(skb, sizeof(struct gmtp_hdr_reqnotify));
+	memcpy(gh, new_gh, gmtp_hdr_len);
+
+	iph->saddr = new_saddr;
+	iph->daddr = new_daddr;
+	iph->tot_len = htons(skb->len);
+	ip_send_check(iph);
+
+	return ret;
+
+fail:
+	ret = NF_DROP;
+	return ret;
+}
+
+struct gmtp_hdr *gmtp_inter_make_register_reply_hdr(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry, __be16 new_sport,
+		__be16 new_dport)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_hdr *gh_cpy;
+	struct gmtp_hdr_register_reply *gh_reply;
+	__u8 *transport_header;
+
+	int gmtp_hdr_len = sizeof(struct gmtp_hdr)
+			+ sizeof(struct gmtp_hdr_register_reply);
+
+	gmtp_pr_func();
+
+	transport_header = kmalloc(gmtp_hdr_len, gfp_any());
+	memset(transport_header, 0, gmtp_hdr_len);
+
+	gh_cpy = (struct gmtp_hdr *)transport_header;
+	memcpy(gh_cpy, gh, sizeof(struct gmtp_hdr));
+
+	gh_cpy->version = GMTP_VERSION;
+	gh_cpy->type = GMTP_PKT_REGISTER_REPLY;
+	gh_cpy->hdrlen = gmtp_hdr_len;
+	gh_cpy->transm_r = entry->transm_r;
+	gh_cpy->server_rtt = entry->server_rtt;
+	gh_cpy->relay = 1;
+	gh_cpy->sport = new_sport;
+	gh_cpy->dport = new_dport;
+
+	gh_reply = (struct gmtp_hdr_register_reply*)(transport_header
+				+ sizeof(struct gmtp_hdr));
+	gh_reply->ucc_type = entry->ucc_type;
+
+	return gh_cpy;
+}
+EXPORT_SYMBOL_GPL(gmtp_inter_make_register_reply_hdr);
+
+int gmtp_inter_make_delegate_reply(struct sk_buff *skb, struct gmtp_relay *relay,
+		struct gmtp_inter_entry *entry)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+	struct ethhdr *eth = eth_hdr(skb);
+	struct gmtp_hdr_delegate *ghd;
+	unsigned int skb_len = skb->len;
+	int gmtp_hdr_len = sizeof(struct gmtp_hdr)
+			+ sizeof(struct gmtp_hdr_delegate);
+
+	/* Delete ACK specific header */
+	skb_trim(skb, (skb_len - gmtp_packet_hdr_variable_len(gh->type)));
+
+	gh->type = GMTP_PKT_DELEGATE_REPLY;
+	gh->hdrlen = gmtp_hdr_len;
+	gh->sport = entry->my_port;
+
+	ghd = (struct gmtp_hdr_delegate*)skb_put(skb,
+			sizeof(struct gmtp_hdr_delegate));
+	memcpy(ghd->relay.relay_id, relay->relay_id, GMTP_RELAY_ID_LEN);
+	ghd->relay.relay_ip = relay->addr;
+	ghd->relay_port = relay->port;
+
+	iph->saddr = entry->my_addr;
+	iph->tot_len = htons(skb->len);
+	ip_send_check(iph);
+
+	ether_addr_copy(eth->h_source, entry->dev_in->dev_addr);
+
+	return NF_ACCEPT;
+}
+
+struct gmtp_hdr *gmtp_inter_make_reset_hdr(struct sk_buff *skb, __u8 code)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	__u8 *transport_header;
+
+	struct gmtp_hdr *gh_cpy;
+	struct gmtp_hdr_reset *gh_reset;
+
+	int gmtp_hdr_len = sizeof(struct gmtp_hdr)
+			+ sizeof(struct gmtp_hdr_reset);
+
+	gmtp_pr_func();
+
+	transport_header = kmalloc(gmtp_hdr_len, gfp_any());
+	memset(transport_header, 0, gmtp_hdr_len);
+
+	gh_cpy = (struct gmtp_hdr *)transport_header;
+	memcpy(gh_cpy, gh, sizeof(struct gmtp_hdr));
+
+	gh_cpy->type = GMTP_PKT_RESET;
+	gh_cpy->hdrlen = gmtp_hdr_len;
+	gh_cpy->relay = 1;
+	swap(gh_cpy->sport, gh_cpy->dport);
+
+	gh_reset = (struct gmtp_hdr_reset*)(transport_header
+			+ sizeof(struct gmtp_hdr));
+
+	gh_reset->reset_code = code;
+
+	switch (gh_reset->reset_code) {
+	case GMTP_RESET_CODE_PACKET_ERROR:
+		gh_reset->reset_data[0] = gh->type;
+		break;
+	default:
+		break;
+	}
+
+	return gh_cpy;
+}
+
+
+int gmtp_inter_make_reset(struct sk_buff *skb, struct gmtp_hdr *gh_reset)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+	int gmtp_hdr_len = sizeof(struct gmtp_hdr)
+			+ sizeof(struct gmtp_hdr_reset);
+
+	gmtp_pr_func();
+
+	skb_put(skb, sizeof(struct gmtp_hdr_reset));
+	memcpy(gh, gh_reset, gmtp_hdr_len);
+
+	swap(iph->saddr, iph->daddr);
+	iph->tot_len = htons(skb->len);
+	ip_send_check(iph);
+
+	return NF_ACCEPT;
+}
+
+
+struct gmtp_hdr *gmtp_inter_make_close_hdr(struct sk_buff *skb)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	__u8 *transport_header;
+
+	struct gmtp_hdr *gh_cpy;
+
+	int gmtp_hdr_len = sizeof(struct gmtp_hdr);
+
+	gmtp_pr_func();
+
+	transport_header = kmalloc(gmtp_hdr_len, gfp_any());
+	memset(transport_header, 0, gmtp_hdr_len);
+
+	gh_cpy = (struct gmtp_hdr *)transport_header;
+	memcpy(gh_cpy, gh, gmtp_hdr_len);
+
+	gh_cpy->type = GMTP_PKT_CLOSE;
+	gh_cpy->hdrlen = gmtp_hdr_len;
+	gh_cpy->relay = 1;
+
+	pr_info("%s (%u)\n", gmtp_packet_name(gh_cpy->type), gh_cpy->type);
+
+	return gh_cpy;
+}
+
+/*
+ * Add an ip header to a skbuff and send it out.
+ * Based on netpoll_send_udp(...) (netpoll.c)
+ */
+struct sk_buff *gmtp_inter_build_pkt_len(struct sk_buff *skb_src, __be32 saddr,
+		__be32 daddr, struct gmtp_hdr *gh_ref, int data_len,
+		enum gmtp_inter_direction direction)
+{
+	struct net_device *dev = skb_src->dev;
+	struct ethhdr *eth_src = eth_hdr(skb_src);
+	struct iphdr *iph_src = ip_hdr(skb_src);
+	struct sk_buff *skb;
+
+	struct ethhdr *eth;
+	struct iphdr *iph;
+	struct gmtp_hdr *gh;
+	int total_len, ip_len, gmtp_len;
+
+	if(eth_src == NULL) {
+		gmtp_print_warning("eth_src is NULL!");
+		return NULL;
+	}
+
+	gmtp_len = data_len + gh_ref->hdrlen;
+	ip_len = gmtp_len + sizeof(*iph_src);
+	total_len = ip_len + LL_RESERVED_SPACE(dev);
+
+	skb = alloc_skb(GMTP_MAX_HDR_LEN, GFP_ATOMIC);
+	if(skb == NULL) {
+		gmtp_print_warning("skb is null");
+		return NULL;
+	}
+
+	skb_reserve(skb, GMTP_MAX_HDR_LEN);
+
+	/* Build GMTP data */
+	if(data_len > 0) {
+		unsigned char *data = skb_push(skb, data_len);
+		skb_reset_transport_header(skb);
+		memcpy(data, gmtp_data(skb_src), data_len);
+	}
+
+	/* Build GMTP header */
+	skb_push(skb, gh_ref->hdrlen);
+	skb_reset_transport_header(skb);
+	gh = gmtp_hdr(skb);
+	memcpy(gh, gh_ref, gh_ref->hdrlen);
+
+	/* Build the IP header. */
+	skb_push(skb, sizeof(*iph));
+	skb_reset_network_header(skb);
+	iph = ip_hdr(skb);
+
+	/* iph->version = 4; iph->ihl = 5; */
+	put_unaligned(0x45, (unsigned char *)iph);
+	iph->tos      = 0;
+	iph->frag_off = 0;
+	iph->ttl      = 64;
+	iph->protocol = IPPROTO_GMTP;
+	put_unaligned(saddr, &(iph->saddr));
+	put_unaligned(daddr, &(iph->daddr));
+	put_unaligned(htons(skb->len), &(iph->tot_len));
+	ip_send_check(iph);
+
+	eth = (struct ethhdr *) skb_push(skb, ETH_HLEN);
+	skb_reset_mac_header(skb);
+	skb->protocol = eth->h_proto = htons(ETH_P_IP);
+
+	ether_addr_copy(eth->h_source, dev->dev_addr);
+	switch(direction) {
+	case GMTP_INTER_FORWARD:
+		ether_addr_copy(eth->h_dest, eth_src->h_dest);
+		break;
+	case GMTP_INTER_BACKWARD:
+		ether_addr_copy(eth->h_dest, eth_src->h_source);
+		break;
+	case GMTP_INTER_LOCAL:
+		ether_addr_copy(eth->h_dest, eth->h_source);
+		ether_addr_copy(eth->h_source, eth_src->h_dest);
+		break;
+	}
+	skb->dev = dev;
+
+	return skb;
+}
+
+struct sk_buff *gmtp_inter_build_pkt(struct sk_buff *skb_src, __be32 saddr,
+		__be32 daddr, struct gmtp_hdr *gh_ref,
+		enum gmtp_inter_direction direction)
+{
+	int data_len = 0;
+
+	if(gh_ref->type == GMTP_PKT_DATA)
+		data_len = gmtp_data_len(skb_src);
+
+	return gmtp_inter_build_pkt_len(skb_src, saddr, daddr, gh_ref, data_len,
+			direction);
+}
+
+void gmtp_inter_send_pkt(struct sk_buff *skb)
+{
+	int err = dev_queue_xmit(skb);
+	if(err)
+		gmtp_pr_error("Error %d trying send packet (%p)", err, skb);
+}
+
+void gmtp_inter_build_and_send_pkt(struct sk_buff *skb_src, __be32 saddr,
+		__be32 daddr, struct gmtp_hdr *gh_ref,
+		enum gmtp_inter_direction direction)
+{
+	struct sk_buff *skb = gmtp_inter_build_pkt(skb_src, saddr, daddr,
+			gh_ref, direction);
+
+	if(skb != NULL)
+		gmtp_inter_send_pkt(skb);
+}
+
+void gmtp_inter_build_and_send_pkt_len(struct sk_buff *skb_src, __be32 saddr,
+		__be32 daddr, struct gmtp_hdr *gh_ref, int data_len,
+		enum gmtp_inter_direction direction)
+{
+	struct sk_buff *skb = gmtp_inter_build_pkt_len(skb_src, saddr, daddr,
+			gh_ref, data_len, direction);
+
+	if(skb != NULL)
+		gmtp_inter_send_pkt(skb);
+}
+
+void gmtp_inter_build_and_send_skb(struct sk_buff *skb,
+		enum gmtp_inter_direction direction)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+	gmtp_inter_build_and_send_pkt(skb, iph->saddr, iph->daddr, gh, direction);
+}
+
+void gmtp_copy_hdr(struct sk_buff *skb, struct sk_buff *src_skb)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_hdr *gh_src = gmtp_hdr(src_skb);
+
+	if(gh->type == gh_src->type)
+		memcpy(gh, gh_src, gh_src->hdrlen);
+}
+
+int gmtp_inter_make_register(struct sk_buff *skb)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr_register *gr;
+	unsigned int skb_len = skb->len;
+	int gmtp_hdr_len = sizeof(struct gmtp_hdr)
+			+ sizeof(struct gmtp_hdr_register);
+
+	/* Delete ACK specific header */
+	skb_trim(skb, (skb_len - gmtp_packet_hdr_variable_len(gh->type)));
+
+	gh->type = GMTP_PKT_REGISTER;
+	gh->hdrlen = gmtp_hdr_len;
+
+	gr = (struct gmtp_hdr_register*)skb_put(skb,
+			sizeof(struct gmtp_hdr_register));
+	memcpy(gr->relay_id, gmtp_info->relay_id, GMTP_RELAY_ID_LEN);
+
+	iph->ttl = 64;
+	iph->tot_len = htons(skb->len);
+	ip_send_check(iph);
+
+	return NF_ACCEPT;
+}
+
+struct sk_buff *gmtp_inter_build_register(struct gmtp_inter_entry *entry)
+{
+	struct sk_buff *skb = alloc_skb(GMTP_MAX_HDR_LEN, GFP_ATOMIC);
+
+	struct ethhdr *eth;
+	struct iphdr *iph;
+	struct gmtp_hdr *gh;
+	struct gmtp_hdr_register *gr;
+
+	struct net_device *dev_entry = entry->dev_in;
+	int total_len, ip_len = 0;
+	int gmtp_hdr_len = sizeof(struct gmtp_hdr)
+					+ sizeof(struct gmtp_hdr_register);
+
+	ip_len = gmtp_hdr_len + sizeof(struct iphdr);
+	total_len = ip_len + LL_RESERVED_SPACE(dev_entry);
+	skb_reserve(skb, total_len);
+
+	gh = gmtp_zeroed_hdr(skb, gmtp_hdr_len);
+
+	gh->version = GMTP_VERSION;
+	gh->type = GMTP_PKT_REGISTER;
+	gh->hdrlen = gmtp_hdr_len;
+	gh->relay = 1;
+	gh->seq = entry->seq;
+	gh->dport = entry->media_port;
+	gh->sport = entry->my_port;
+	gh->server_rtt = entry->server_rtt;
+	gh->transm_r = min(gmtp_inter.ucc_rx, entry->rcv_tx_rate);
+	memcpy(gh->flowname, entry->flowname, GMTP_FLOWNAME_LEN);
+
+	gr = (struct gmtp_hdr_register*) gh + sizeof(struct gmtp_hdr);
+	memcpy(gr->relay_id, gmtp_info->relay_id, GMTP_RELAY_ID_LEN);
+
+	/* Build the IP header. */
+	skb_push(skb, sizeof(struct iphdr));
+	skb_reset_network_header(skb);
+	iph = ip_hdr(skb);
+
+	/* iph->version = 4; iph->ihl = 5; */
+	put_unaligned(0x45, (unsigned char *)iph);
+	iph->tos = 0;
+	iph->frag_off = 0;
+	iph->ttl = 64;
+	iph->protocol = IPPROTO_GMTP;
+
+	put_unaligned(entry->my_addr, &(iph->saddr));
+	put_unaligned(entry->server_addr, &(iph->daddr));
+	put_unaligned(htons(skb->len), &(iph->tot_len));
+	ip_send_check(iph);
+
+	skb_push(skb, ETH_HLEN);
+	skb_reset_mac_header(skb);
+	eth = eth_hdr(skb);
+	skb->protocol = eth->h_proto = htons(ETH_P_IP);
+
+	ether_addr_copy(eth->h_source, dev_entry->dev_addr);
+	ether_addr_copy(eth->h_dest, entry->server_mac_addr);
+
+	skb->dev = dev_entry;
+
+	return skb;
+}
+
+struct sk_buff *gmtp_inter_build_ack(struct gmtp_inter_entry *entry)
+{
+	struct sk_buff *skb = alloc_skb(GMTP_MAX_HDR_LEN, GFP_ATOMIC);
+
+	struct ethhdr *eth;
+	struct iphdr *iph;
+	struct gmtp_hdr *gh;
+	struct gmtp_hdr_ack *gack;
+
+	struct net_device *dev_entry = NULL;
+	int gmtp_hdr_len = sizeof(struct gmtp_hdr) + sizeof(struct gmtp_hdr_ack);
+	int total_len, ip_len = 0;
+
+	dev_entry = entry->dev_in;
+
+	ip_len = gmtp_hdr_len + sizeof(struct iphdr);
+	total_len = ip_len + LL_RESERVED_SPACE(dev_entry);
+	skb_reserve(skb, total_len);
+
+	gh = gmtp_zeroed_hdr(skb, gmtp_hdr_len);
+
+	gh->version = GMTP_VERSION;
+	gh->type = GMTP_PKT_ACK;
+	gh->hdrlen = gmtp_hdr_len;
+	gh->relay = 1;
+	gh->seq = entry->seq;
+	gh->dport = entry->media_port;
+	gh->sport = entry->my_port;
+	gh->server_rtt = entry->server_rtt;
+	gh->transm_r = min(gmtp_inter.ucc_rx, entry->rcv_tx_rate);
+	/*gh->transm_r = min(gmtp_inter.ucc_rx, entry->required_tx*3);*/
+	/*gh->transm_r = 100000;*/
+	memcpy(gh->flowname, entry->flowname, GMTP_FLOWNAME_LEN);
+
+	gack = gmtp_hdr_ack(skb);
+	gack->orig_tstamp = entry->last_data_tstamp;
+
+	/* Build the IP header. */
+	skb_push(skb, sizeof(struct iphdr));
+	skb_reset_network_header(skb);
+	iph = ip_hdr(skb);
+
+	/* iph->version = 4; iph->ihl = 5; */
+	put_unaligned(0x45, (unsigned char *)iph);
+	iph->tos = 0;
+	iph->frag_off = 0;
+	iph->ttl = 64;
+	iph->protocol = IPPROTO_GMTP;
+
+	put_unaligned(entry->my_addr, &(iph->saddr));
+	put_unaligned(entry->server_addr, &(iph->daddr));
+	put_unaligned(htons(skb->len), &(iph->tot_len));
+	ip_send_check(iph);
+
+	/*print_gmtp_packet(iph, gh);*/
+
+	skb_push(skb, ETH_HLEN);
+	skb_reset_mac_header(skb);
+	eth = eth_hdr(skb);
+	skb->protocol = eth->h_proto = htons(ETH_P_IP);
+
+	ether_addr_copy(eth->h_source, dev_entry->dev_addr);
+	ether_addr_copy(eth->h_dest, entry->server_mac_addr);
+
+	skb->dev = dev_entry;
+	return skb;
+}
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/gmtp-inter.c linux-4.9-rc2/net/gmtp/gmtp-inter/gmtp-inter.c
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/gmtp-inter.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/gmtp-inter.c	2016-12-13 21:39:42.075548321 -0300
@@ -0,0 +1,488 @@
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+#include <linux/skbuff.h>
+#include <linux/ip.h>
+#include <linux/inet.h>
+#include <linux/inetdevice.h>
+#include <linux/err.h>
+#include <linux/if.h>
+#include <linux/ioctl.h>
+#include <linux/rtnetlink.h>
+
+#include <net/sock.h>
+#include <net/sch_generic.h>
+
+#include <uapi/linux/gen_stats.h>
+#include <uapi/linux/types.h>
+
+#include <uapi/linux/gmtp.h>
+#include <linux/gmtp.h>
+#include "../gmtp.h"
+
+#include "gmtp-inter.h"
+#include "mcc-inter.h"
+#include "ucc.h"
+
+/****
+static struct nf_hook_ops nfho_pre_routing;
+static struct nf_hook_ops nfho_local_in;
+static struct nf_hook_ops nfho_local_out;
+static struct nf_hook_ops nfho_post_routing;
+****/
+
+struct gmtp_inter gmtp_inter;
+
+__be32 get_mcst_v4_addr(void)
+{
+    __be32 mcst_addr;
+    unsigned char *base_channel = "\xe0\xc0\x00\x00"; /* 224.192.0.0 */
+    unsigned char *channel = kmalloc(4 * sizeof(unsigned char), GFP_KERNEL);
+
+    gmtp_print_function();
+
+    if(channel == NULL) {
+        gmtp_pr_error("NULL channel: Cannot assign requested address");
+        return -EADDRNOTAVAIL;
+    }
+    memcpy(channel, base_channel, 4 * sizeof(unsigned char));
+
+    channel[3] += gmtp_inter.mcst[3]++;
+
+    /**
+     * From: base_channel (224.192. 0 . 0 )
+     * to:   max_channel  (239.255.255.255)
+     *                     L0  L1  L2  L3
+     */
+    if(gmtp_inter.mcst[3] > 255) {  /* L3 starts with 1 */
+        gmtp_inter.mcst[3] = 0;
+        gmtp_inter.mcst[2]++;
+    }
+    if(gmtp_inter.mcst[2] > 255) {
+        gmtp_inter.mcst[2] = 0;
+        gmtp_inter.mcst[1]++;
+    }
+    if(gmtp_inter.mcst[1] > 63) { /* 255 - 192 */
+        gmtp_inter.mcst[1] = 0;
+        gmtp_inter.mcst[0]++;
+    }
+    if(gmtp_inter.mcst[0] > 15) {  /* 239 - 224 */
+        int i;
+        for(i = 0; i < 4; ++i)
+            pr_info("gmtp_inter.mcst[%d] = %u\n", i,
+                    gmtp_inter.mcst[i]);
+        gmtp_pr_error("Cannot assign requested multicast address");
+        return -EADDRNOTAVAIL;
+    }
+    channel[2] += gmtp_inter.mcst[2];
+    channel[1] += gmtp_inter.mcst[1];
+    channel[0] += gmtp_inter.mcst[0];
+
+    mcst_addr = *(unsigned int *)channel;
+    gmtp_print_debug("Channel addr: %pI4", &mcst_addr);
+    return mcst_addr;
+}
+EXPORT_SYMBOL_GPL(get_mcst_v4_addr);
+
+void gmtp_buffer_add(struct gmtp_inter_entry *info, struct sk_buff *newskb)
+{
+    skb_queue_tail(info->buffer, skb_copy(newskb, GFP_ATOMIC));
+    info->buffer_len += newskb->len + ETH_HLEN;
+}
+
+void gmtp_ucc_buffer_add(struct sk_buff *newskb)
+{
+    if(newskb != NULL) {
+        gmtp_inter.buffer_len += skblen(newskb);
+        gmtp_inter.total_bytes_rx += skblen(newskb);
+        gmtp_inter.ucc_bytes += skblen(newskb);
+    }
+}
+
+struct sk_buff *gmtp_buffer_dequeue(struct gmtp_inter_entry *info)
+{
+    struct sk_buff *skb = skb_dequeue(info->buffer);
+    if(skb != NULL) {
+        info->buffer_len -= (skb->len + ETH_HLEN);
+    }
+    return skb;
+}
+
+void gmtp_ucc_buffer_dequeue(struct sk_buff *newskb)
+{
+    if(newskb != NULL) {
+        gmtp_inter.buffer_len -= skblen(newskb);
+        if(gmtp_inter.buffer_len < 0)
+            gmtp_inter.buffer_len = 0;
+    }
+}
+
+
+unsigned int hook_func_pre_routing(unsigned int hooknum, struct sk_buff *skb,
+        const struct net_device *in, const struct net_device *out,
+        int (*okfn)(struct sk_buff *))
+{
+    int ret = NF_ACCEPT;
+    struct iphdr *iph = ip_hdr(skb);
+
+    gmtp_ucc_buffer_add(skb);
+
+    /*if(skb->dev != NULL) {
+        struct netdev_rx_queue *rx = skb->dev->_rx;
+        pr_info("skb->dev->ingress_queue3: %p\n", rx);
+        if(rx != NULL) {
+            pr_info("in->ingress_queue->qdisc: %p\n", ndq->qdisc);
+            if(ndq->qdisc != NULL) {
+                pr_info("q.qlen: %u\n", ndq->qdisc->q.qlen);
+                pr_info("qstats.qlen: %u\n",
+                        ndq->qdisc->qstats.qlen);
+                pr_info("qstats.drops: %u\n",
+                        ndq->qdisc->qstats.drops);
+                pr_info("qstats.overlimits: %u\n",
+                        ndq->qdisc->qstats.overlimits);
+            }
+        }
+    }*/
+
+    /*int i;
+    for(i = 0; i < NR_CPUS; i++) {
+        struct softnet_data *queue;
+        queue = &per_cpu(softnet_data, i);
+
+        struct sk_buff_head *input = &queue->input_pkt_queue;
+        struct sk_buff_head *process = &queue->process_queue;
+
+        pr_info("input_queue: %u\n", input->qlen);
+        pr_info("process_queue: %u\n", process->qlen);
+        pr_info("processed: %u\n", queue->processed);
+        pr_info("time_squeeze: %u\n", queue->time_squeeze);
+        pr_info("cpu_collision: %u\n", queue->cpu_collision);
+        pr_info("received_rps: %u\n", queue->received_rps);
+        pr_info("dropped: %u\n", queue->dropped);
+    }*/
+
+    if(gmtp_info->relay_enabled == 0)
+        return ret;
+
+    if(iph->protocol == IPPROTO_GMTP) {
+
+        struct gmtp_hdr *gh = gmtp_hdr(skb);
+        struct gmtp_inter_entry *entry;
+        struct gmtp_relay *relay;
+
+        if(gh->type == GMTP_PKT_REQUEST) {
+            if(gmtp_local_ip(iph->saddr)
+                    && iph->saddr != iph->daddr) {
+                goto out;
+            }
+
+            if(iph->ttl == 1) {
+                print_packet(skb, true);
+                print_gmtp_packet(iph, gh);
+                ret = gmtp_inter_request_rcv(skb);
+                goto out;
+            }
+        }
+
+        entry = gmtp_inter_lookup_media(gmtp_inter.hashtable,
+                gh->flowname);
+        if(entry == NULL)
+            goto out;
+
+        switch(gh->type) {
+        case GMTP_PKT_REGISTER:
+            if(!gmtp_local_ip(iph->daddr))
+                ret = gmtp_inter_register_rcv(skb);
+            break;
+        case GMTP_PKT_REGISTER_REPLY:
+            ret = gmtp_inter_register_reply_rcv(skb, entry,
+                    GMTP_INTER_BACKWARD);
+            break;
+        case GMTP_PKT_ROUTE_NOTIFY:
+            ret = gmtp_inter_route_rcv(skb, entry);
+            break;
+        case GMTP_PKT_ACK:
+            ret = gmtp_inter_ack_rcv(skb, entry);
+            break;
+        case GMTP_PKT_FEEDBACK:
+            ret = gmtp_inter_feedback_rcv(skb, entry);
+            break;
+        case GMTP_PKT_DELEGATE:
+            ret = gmtp_inter_delegate_rcv(skb, entry);
+            break;
+        default:
+            relay = gmtp_get_relay(&entry->relays->list,
+                    iph->daddr, gh->dport);
+            if(!gmtp_local_ip(iph->daddr) && (relay == NULL))
+                goto out;
+        }
+
+        switch(gh->type) {
+        case GMTP_PKT_DATA:
+            ret = gmtp_inter_data_rcv(skb, entry);
+            break;
+        case GMTP_PKT_ELECT_RESPONSE:
+            ret = gmtp_inter_elect_resp_rcv(skb, entry);
+            break;
+        case GMTP_PKT_RESET:
+        case GMTP_PKT_CLOSE:
+            ret = gmtp_inter_close_rcv(skb, entry, true);
+            break;
+        }
+
+    }
+
+out:
+    if(ret == NF_DROP)
+        gmtp_ucc_buffer_dequeue(skb);
+
+    return ret;
+}
+
+
+unsigned int hook_func_local_in(unsigned int hooknum, struct sk_buff *skb,
+        const struct net_device *in, const struct net_device *out,
+        int (*okfn)(struct sk_buff *))
+{
+    int ret = NF_ACCEPT;
+    struct iphdr *iph = ip_hdr(skb);
+
+    if(gmtp_info->relay_enabled == 0)
+        goto in;
+
+    if(iph->protocol == IPPROTO_GMTP) {
+
+        struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+        struct gmtp_inter_entry *entry = gmtp_inter_lookup_media(
+                gmtp_inter.hashtable, gh->flowname);
+        if(entry == NULL)
+            goto in;
+
+        if(!gmtp_inter_lookup_media(gmtp_inter.hashtable, gh->flowname))
+            goto in;
+
+        switch(gh->type) {
+        case GMTP_PKT_REGISTER:
+            /* Here. We need to trick the server,
+            to avoid data packets destined to 'lo' */
+            ret = gmtp_inter_register_local_in(skb, entry);
+            break;
+        }
+    }
+
+in:
+    /*gmtp_ucc_buffer_dequeue(skb);*/
+    return ret;
+}
+
+unsigned int hook_func_local_out(unsigned int hooknum, struct sk_buff *skb,
+        const struct net_device *in, const struct net_device *out,
+        int (*okfn)(struct sk_buff *))
+{
+    int ret = NF_ACCEPT;
+    struct iphdr *iph = ip_hdr(skb);
+
+    if(gmtp_info->relay_enabled == 0)
+        return ret;
+
+    if(iph->protocol == IPPROTO_GMTP) {
+
+        struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+        struct gmtp_inter_entry *entry = gmtp_inter_lookup_media(
+                gmtp_inter.hashtable, gh->flowname);
+        if(entry == NULL)
+            return NF_ACCEPT;
+
+        switch(gh->type) {
+        case GMTP_PKT_RESET:
+        case GMTP_PKT_CLOSE:
+            ret = gmtp_inter_close_rcv(skb, entry, false);
+            break;
+        }
+    }
+
+    return ret;
+}
+
+static int gmtp_inter_has_clients(struct sk_buff *skb,
+        struct gmtp_inter_entry *entry)
+{
+    struct iphdr *iph = ip_hdr(skb);
+    struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+    struct gmtp_relay *relay = gmtp_get_relay(&entry->relays->list,
+            iph->daddr, gh->dport);
+    // struct gmtp_reporter *reporter = gmtp_get_client(&entry->clients->list,
+    //         iph->daddr, gh->dport);
+    struct gmtp_client *reporter = gmtp_get_client(&entry->clients->list,
+             iph->daddr, gh->dport);
+
+    if(relay == NULL && reporter == NULL)
+        return 1;
+    return 0;
+}
+
+unsigned int hook_func_post_routing(unsigned int hooknum, struct sk_buff *skb,
+        const struct net_device *in, const struct net_device *out,
+        int (*okfn)(struct sk_buff *))
+{
+    int ret = NF_ACCEPT;
+    struct iphdr *iph = ip_hdr(skb);
+
+    if(gmtp_info->relay_enabled == 0)
+        goto out;
+
+    if(iph->protocol == IPPROTO_GMTP) {
+
+        struct gmtp_hdr *gh = gmtp_hdr(skb);
+        struct gmtp_inter_entry *entry;
+
+        entry = gmtp_inter_lookup_media(gmtp_inter.hashtable,
+                gh->flowname);
+        if(entry == NULL)
+            return NF_ACCEPT;
+
+        if(gh->type == GMTP_PKT_DATA) {
+            if(!gmtp_local_ip(iph->daddr) ||
+                GMTP_SKB_CB(skb)->jumped) {
+                if(gmtp_inter_has_clients(skb, entry))
+                    goto out;
+            }
+        }
+
+        switch(gh->type) {
+        case GMTP_PKT_REGISTER:
+            ret = gmtp_inter_register_out(skb, entry);
+            break;
+        case GMTP_PKT_REGISTER_REPLY:
+            ret = gmtp_inter_register_reply_out(skb, entry);
+            break;
+        case GMTP_PKT_DATA:
+            if(gmtp_local_ip(iph->daddr)
+                    || GMTP_SKB_CB(skb)->jumped) {
+                ret = gmtp_inter_data_out(skb, entry);
+            }
+            break;
+        case GMTP_PKT_ACK:
+            ret = gmtp_inter_ack_out(skb, entry);
+            break;
+        case GMTP_PKT_RESET:
+        case GMTP_PKT_CLOSE:
+            ret = gmtp_inter_close_out(skb, entry);
+            break;
+        }
+    }
+
+out:
+    return ret;
+}
+
+static void register_hooks(void)
+{
+    /****
+    nfho_pre_routing.hook = hook_func_pre_routing;
+    nfho_pre_routing.hooknum = NF_INET_PRE_ROUTING;
+    nfho_pre_routing.pf = PF_INET;
+    nfho_pre_routing.priority = NF_IP_PRI_FIRST;
+    nf_register_hook(&nfho_pre_routing);
+
+    nfho_local_in.hook = hook_func_local_in;
+    nfho_local_in.hooknum = NF_INET_LOCAL_IN;
+    nfho_local_in.pf = PF_INET;
+    nfho_local_in.priority = NF_IP_PRI_FIRST;
+    nf_register_hook(&nfho_local_in);
+
+    nfho_local_out.hook = hook_func_local_out;
+    nfho_local_out.hooknum = NF_INET_LOCAL_OUT;
+    nfho_local_out.pf = PF_INET;
+    nfho_local_out.priority = NF_IP_PRI_FIRST;
+    nf_register_hook(&nfho_local_out);
+
+    nfho_post_routing.hook = hook_func_post_routing;
+    nfho_post_routing.hooknum = NF_INET_POST_ROUTING;
+    nfho_post_routing.pf = PF_INET;
+    nfho_post_routing.priority = NF_IP_PRI_FIRST;
+    nf_register_hook(&nfho_post_routing);
+    ****/
+}
+
+int init_module()
+{
+    int ret = 0;
+
+    gmtp_pr_func();
+    gmtp_print_debug("Starting GMTP-Inter");
+
+    if(gmtp_info == NULL) {
+        gmtp_print_error("gmtp_info is NULL...");
+        ret = -ENOBUFS;
+        goto out;
+    }
+
+    gmtp_inter.capacity = CAPACITY_DEFAULT;
+    gmtp_inter.buffer_len = 0;
+    gmtp_inter.kreporter = GMTP_REPORTER_DEFAULT_PROPORTION - 1;
+
+    /* TODO Why initial rx per flow is 5% of capacity of channel? */
+    gmtp_inter.ucc_rx = DIV_ROUND_CLOSEST(gmtp_inter.capacity * 10, 100);
+
+    gmtp_inter.total_bytes_rx = 0;
+    gmtp_inter.total_rx = 0;
+    gmtp_inter.ucc_bytes = 0;
+    gmtp_inter.ucc_rx_tstamp = 0;
+    gmtp_inter.rx_rate_wnd = 100;
+    memset(&gmtp_inter.mcst, 0, 4 * sizeof(unsigned char));
+
+    gmtp_inter.hashtable = gmtp_inter_create_hashtable(64);
+    if(gmtp_inter.hashtable == NULL) {
+        gmtp_print_error("Cannot create hashtable...");
+        ret = -ENOMEM;
+        goto out;
+    }
+
+    gmtp_info->relay_enabled = 1; /* Enabling gmtp-inter */
+
+    gmtp_inter.h_user = INT_MAX; /* TODO Make it user defined */
+    gmtp_inter.worst_rtt = GMTP_MIN_RTT_MS;
+
+    pr_info("Configuring GMTP-UCC timer...\n");
+    setup_timer(&gmtp_inter.gmtp_ucc_timer, gmtp_ucc_equation_callback, 0);
+    mod_timer(&gmtp_inter.gmtp_ucc_timer, jiffies + 1);
+
+    register_hooks();
+
+out:
+    return ret;
+}
+
+static void unregister_hooks(void)
+{
+    /****
+    nf_unregister_hook(&nfho_pre_routing);
+    nf_unregister_hook(&nfho_local_in);
+    nf_unregister_hook(&nfho_post_routing);
+    ****/
+}
+
+void cleanup_module()
+{
+    gmtp_pr_func();
+    gmtp_print_debug("Finishing GMTP-inter");
+
+    gmtp_info->relay_enabled = 0;
+    kfree_gmtp_inter_hashtable(gmtp_inter.hashtable);
+
+    unregister_hooks();
+    del_timer(&gmtp_inter.gmtp_ucc_timer);
+}
+
+module_init(init_module);
+module_exit(cleanup_module);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Mrio Andr Menezes <mariomenezescosta@gmail.com>");
+MODULE_AUTHOR("Wendell Silva Soares <wss@ic.ufal.br>");
+MODULE_DESCRIPTION("GMTP - Global Media Transmission Protocol");
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/gmtp-inter.h linux-4.9-rc2/net/gmtp/gmtp-inter/gmtp-inter.h
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/gmtp-inter.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/gmtp-inter.h	2016-12-01 16:50:35.541418804 -0300
@@ -0,0 +1,213 @@
+ /* gmtp-inter.h
+ *
+ *  Created on: 17/02/2015
+ *      Author: wendell
+ */
+
+#ifndef GMTP_INTER_H_
+#define GMTP_INTER_H_
+
+#include <linux/types.h>
+#include <linux/skbuff.h>
+#include <linux/spinlock.h>
+#include <uapi/linux/ip.h>
+
+#include <linux/gmtp.h>
+#include <uapi/linux/gmtp.h>
+#include "../gmtp.h"
+
+#include "ucc.h"
+#include "hash-inter.h"
+
+#define H_USER 	1024
+
+#define CAPACITY_DEFAULT 1250000 /* B/s => 10 Mbps */
+
+extern const char *gmtp_packet_name(const __u8);
+extern const char *gmtp_state_name(const int);
+extern void flowname_str(__u8* str, const __u8* flowname);
+extern void print_gmtp_packet(const struct iphdr *iph, const struct gmtp_hdr *gh);
+extern void print_packet(struct sk_buff *skb, bool in);
+extern unsigned char *gmtp_build_md5(unsigned char *buf);
+extern unsigned char *gmtp_build_relay_id(void);
+extern __be32 gmtp_dev_ip(struct net_device *dev);
+extern bool gmtp_local_ip(__be32 ip);
+extern void gmtp_add_relayid(struct sk_buff *skb);
+extern struct gmtp_hashtable* server_hashtable;
+
+/**
+ * TODO Negotiate buffer size with server
+ * TODO Make kreporter configurable
+ *
+ * struct gmtp_inter - GMTP-inter state variables
+ *
+ * @buffer_len: relay buffer occupation (total)
+ * @capacity: channel capacity of transmission (bytes/s)
+ * @total_bytes_rx: total data bytes received
+ * @total_rx: Current total RX rate (bytes/s)
+ * @ucc_rx: Current per flow max RX (bytes/s)
+ * @ucc_bytes: bytes received since last GMTP-UCC execution
+ * @ucc_rx_tstamp: time stamp of last GMTP-UCC execution
+ * @rx_rate_wnd: size of window to calculate rx rates
+ * @h: Current H_0 in RCP equation
+ * @last_rtt: Last RTT received in all flows
+ *
+ * @mcst: control of granted multicast addresses
+ * @kreporter: number of clients per reporter.
+ *
+ * @hashtable: GMTP-inter relay table
+ */
+struct gmtp_inter {
+	int 			capacity;
+	int			buffer_len;
+
+	unsigned int 		total_bytes_rx;
+
+	unsigned int 		total_rx;
+	int 			ucc_rx;
+	unsigned int        	ucc_bytes;
+	unsigned long  		ucc_rx_tstamp;
+	unsigned int 		rx_rate_wnd;
+	int			h_user;
+	unsigned int		worst_rtt;
+
+	unsigned char		mcst[4];
+
+	unsigned char		kreporter;
+
+	struct timer_list 	gmtp_ucc_timer;
+
+	struct gmtp_inter_hashtable *hashtable;
+};
+
+extern struct gmtp_inter gmtp_inter;
+
+#define skblen(skb) (((*skb).len) + ETH_HLEN)
+
+enum gmtp_inter_direction {
+	GMTP_INTER_FORWARD = 0,
+	GMTP_INTER_BACKWARD,
+	GMTP_INTER_LOCAL
+};
+
+/** gmtp-inter.c */
+__be32 get_mcst_v4_addr(void);
+void gmtp_buffer_add(struct gmtp_inter_entry *info, struct sk_buff *newsk);
+struct sk_buff *gmtp_buffer_dequeue(struct gmtp_inter_entry *info);
+void gmtp_ucc_buffer_add(struct sk_buff *newskb);
+void gmtp_ucc_buffer_dequeue(struct sk_buff *newskb);
+__be32 gmtp_inter_device_ip(struct net_device *dev);
+void gmtp_timer_callback(void);
+bool gmtp_local_ip(__be32 ip);
+
+/** input.c */
+int gmtp_inter_register_rcv(struct sk_buff *skb);
+struct gmtp_client *jump_over_gmtp_intra(struct sk_buff *skb,
+		struct list_head *list_head);
+int gmtp_inter_request_rcv(struct sk_buff *skb);
+int gmtp_inter_register_local_in(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry);
+int gmtp_inter_register_reply_rcv(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry,
+		enum gmtp_inter_direction direction);
+int gmtp_inter_ack_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry);
+int gmtp_inter_route_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry);
+int gmtp_inter_data_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry);
+int gmtp_inter_feedback_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry);
+int gmtp_inter_delegate_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry);
+int gmtp_inter_elect_resp_rcv(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry);
+int gmtp_inter_close_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry,
+		bool in);
+
+/** Output.c */
+int gmtp_inter_register_out(struct sk_buff *skb, struct gmtp_inter_entry *entry);
+int gmtp_inter_register_reply_out(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry);
+int gmtp_inter_request_notify_out(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry);
+int gmtp_inter_ack_out(struct sk_buff *skb, struct gmtp_inter_entry *entry);
+int gmtp_inter_data_out(struct sk_buff *skb, struct gmtp_inter_entry *entry);
+int gmtp_inter_close_out(struct sk_buff *skb, struct gmtp_inter_entry *entry);
+
+/** build.c */
+struct sk_buff *gmtp_inter_build_pkt_len(struct sk_buff *skb_src, __be32 saddr,
+		__be32 daddr, struct gmtp_hdr *gh_ref, int data_len,
+		enum gmtp_inter_direction direction);
+struct sk_buff *gmtp_inter_build_pkt(struct sk_buff *skb_src, __be32 saddr,
+		__be32 daddr, struct gmtp_hdr *gh_ref,
+		enum gmtp_inter_direction direction);
+void gmtp_inter_send_pkt(struct sk_buff *skb);
+struct gmtp_hdr *gmtp_inter_make_route_hdr(struct sk_buff *skb);
+
+int gmtp_inter_make_register(struct sk_buff *skb);
+struct gmtp_hdr *gmtp_inter_make_request_notify_hdr(struct sk_buff *skb,
+		struct gmtp_inter_entry *media_info, __be16 new_sport,
+		__be16 new_dport, struct gmtp_client *reporter,
+		__u8 max_nclients, __u8 error_code);
+
+int gmtp_inter_make_request_notify(struct sk_buff *skb, __be32 new_saddr,
+		__be16 new_sport, __be32 new_daddr, __be16 new_dport,
+		struct gmtp_client *reporter, __u8 max_nclients,
+		__u8 error_code);
+struct gmtp_hdr *gmtp_inter_make_register_reply_hdr(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry, __be16 new_sport,
+		__be16 new_dport);
+
+int gmtp_inter_make_delegate_reply(struct sk_buff *skb, struct gmtp_relay *relay,
+		struct gmtp_inter_entry *entry);
+
+struct gmtp_hdr *gmtp_inter_make_reset_hdr(struct sk_buff *skb, __u8 code);
+int gmtp_inter_make_reset(struct sk_buff *skb, struct gmtp_hdr *gh_reset);
+struct gmtp_hdr *gmtp_inter_make_close_hdr(struct sk_buff *skb);
+void gmtp_inter_build_and_send_pkt(struct sk_buff *skb_src, __be32 saddr,
+		__be32 daddr, struct gmtp_hdr *gh_ref,
+		enum gmtp_inter_direction direction);
+void gmtp_inter_build_and_send_pkt_len(struct sk_buff *skb_src, __be32 saddr,
+		__be32 daddr, struct gmtp_hdr *gh_ref, int data_len,
+		enum gmtp_inter_direction direction);
+void gmtp_inter_build_and_send_skb(struct sk_buff *skb,
+		enum gmtp_inter_direction direction);
+void gmtp_copy_hdr(struct sk_buff *skb, struct sk_buff *src_skb);
+struct gmtp_hdr *gmtp_inter_make_ack_hdr(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry, __be32 tstamp);
+int gmtp_inter_make_ack_from_feedback(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry);
+struct sk_buff *gmtp_inter_build_register(struct gmtp_inter_entry *entry);
+struct sk_buff *gmtp_inter_build_ack(struct gmtp_inter_entry *entry);
+
+/**
+ * A very ugly delayer, to GMTP-inter...
+ *
+ * If we use schedule(), we get this error:  'BUG: scheduling while atomic'
+ *
+ * We cannot use schedule(), because hook functions are atomic,
+ * and sleeping in kernel code is not allowed in atomic context.
+ *
+ * Calling cond_resched(), kernel call schedule() where it's possible...
+ * In NS-3 we call schedule_timeout(1L) (1 jiffy)
+ */
+static inline void gmtp_inter_wait_ms(unsigned int delay)
+{
+	unsigned int timeout = jiffies_to_msecs(jiffies) + delay;
+	while(jiffies_to_msecs(jiffies) < timeout) {
+		/*cond_resched(); *//* Do nothing, just wait... */
+		schedule_timeout(1L);
+	}
+}
+
+static inline unsigned long ktime_to_jiffies(ktime_t value)
+{
+	struct timespec ts = ktime_to_timespec(value);
+
+	return timespec_to_jiffies(&ts);
+}
+
+static inline void jiffies_to_ktime(const unsigned long jiffies, ktime_t *value)
+{
+	struct timespec ts;
+	jiffies_to_timespec(jiffies, &ts);
+	*value = timespec_to_ktime(ts);
+}
+
+#endif /* GMTP_INTER_H_ */
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/hash-inter.c linux-4.9-rc2/net/gmtp/gmtp-inter/hash-inter.c
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/hash-inter.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/hash-inter.c	2016-12-01 16:50:35.570418442 -0300
@@ -0,0 +1,253 @@
+/*
+ * hash-inter.c
+ *
+ *  Created on: 27/02/2015
+ *      Author: wendell
+ */
+
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/list.h>
+#include <linux/timer.h>
+
+#include "gmtp-inter.h"
+#include "hash-inter.h"
+#include "mcc-inter.h"
+#include "ucc.h"
+
+struct gmtp_inter_hashtable *gmtp_inter_create_hashtable(unsigned int size)
+{
+	int i;
+	struct gmtp_inter_hashtable *ht;
+
+	gmtp_pr_func();
+	gmtp_pr_info("Size of gmtp_inter_hashtable = %d", size);
+
+	if(size < 1)
+		return NULL;
+
+	ht = kmalloc(sizeof(struct gmtp_inter_hashtable), GFP_KERNEL);
+	if(ht == NULL)
+		return NULL;
+
+	ht->table = kmalloc(sizeof(struct gmtp_inter_entry*) *size, GFP_KERNEL);
+	if(ht->table == NULL)
+		return NULL;
+
+	for(i = 0; i < size; ++i)
+		ht->table[i] = NULL;
+
+	ht->size = size;
+
+	return ht;
+}
+
+unsigned int gmtp_inter_hash(struct gmtp_inter_hashtable *hashtable,
+		const __u8 *flowname)
+{
+	unsigned int hashval;
+	int i;
+
+	if(hashtable == NULL)
+		return -EINVAL;
+
+	if(flowname == NULL)
+		return -ENOKEY;
+
+	hashval = 0;
+
+	for(i=0; i<GMTP_FLOWNAME_LEN; ++i)
+		hashval = flowname[i] + (hashval << 5) - hashval;
+
+	return hashval % hashtable->size;
+}
+
+struct gmtp_inter_entry *gmtp_inter_lookup_media(
+		struct gmtp_inter_hashtable *hashtable, const __u8 *media)
+{
+	struct gmtp_inter_entry *entry;
+	unsigned int hashval;
+
+	hashval = gmtp_inter_hash(hashtable, media);
+
+	/* Error */
+	if(hashval < 0)
+		return NULL;
+
+	for(entry = hashtable->table[hashval]; entry != NULL;
+			entry = entry->next)
+		if(memcmp(media, entry->flowname, GMTP_FLOWNAME_LEN) == 0)
+			return entry;
+
+	return NULL;
+}
+
+void __gmtp_inter_build_info(struct gmtp_inter_entry *info)
+{
+	if(unlikely(info == NULL))
+		return;
+
+	info->total_bytes = 0;
+	info->last_rx_tstamp = 0;
+	info->rcv_tx_rate = UINT_MAX;
+
+	info->nfeedbacks = 0;
+	info->sum_feedbacks = 0;
+	info->recent_bytes = UINT_MAX;
+	info->recent_rx_tstamp = 0;
+	info->current_rx = 0;
+	info->required_tx = 0;
+	info->data_pkt_out = 0;
+	info->server_rtt = 64;
+	info->transm_r = UINT_MAX;
+
+	info->clients = kmalloc(sizeof(struct gmtp_client), GFP_KERNEL);
+	INIT_LIST_HEAD(&info->clients->list);
+	info->nclients = 0;
+
+	info->buffer = kmalloc(sizeof(struct sk_buff_head), GFP_KERNEL);
+	skb_queue_head_init(info->buffer);
+	info->buffer_len = 0;
+	/*gmtp_set_buffer_limits(info, 40);*/
+	gmtp_set_buffer_limits(info, 40);
+
+	setup_timer(&info->mcc_timer, mcc_timer_callback, (unsigned long) info);
+}
+
+void gmtp_inter_build_info(struct gmtp_inter_entry *info, unsigned int bmin)
+{
+	if(likely(info != NULL)) {
+		gmtp_set_buffer_limits(info, bmin);
+		__gmtp_inter_build_info(info);
+	}
+}
+
+int gmtp_inter_add_entry(struct gmtp_inter_hashtable *hashtable, __u8 *flowname,
+		__be32 server_addr, __be32 *relay, __be16 media_port,
+		__be32 channel_addr, __be16 channel_port)
+{
+	struct gmtp_inter_entry *new_entry;
+	struct gmtp_inter_entry *current_entry;
+	unsigned int hashval;
+
+	gmtp_print_function();
+
+	hashval = gmtp_inter_hash(hashtable, flowname);
+
+	/* Error */
+	if(hashval < 0)
+		return hashval;
+
+	new_entry = kmalloc(sizeof(struct gmtp_inter_entry), GFP_KERNEL);
+	if(new_entry == NULL)
+		return 1;
+
+	current_entry = gmtp_inter_lookup_media(hashtable, flowname);
+	if(current_entry != NULL)
+		return 2; /* TODO Media already being transmitted by other
+								server? */
+	gmtp_inter_build_info(new_entry, 5);
+
+	memcpy(new_entry->flowname, flowname, GMTP_FLOWNAME_LEN);
+	new_entry->server_addr = server_addr;
+
+	new_entry->relays = kmalloc(sizeof(struct gmtp_relay), GFP_KERNEL);
+	INIT_LIST_HEAD(&new_entry->relays->list);
+	new_entry->nrelays = 0;
+
+	new_entry->media_port = media_port;
+	new_entry->channel_addr = channel_addr;
+	new_entry->channel_port = channel_port;
+	new_entry->state = GMTP_INTER_WAITING_REGISTER_REPLY;
+	new_entry->next = hashtable->table[hashval];
+	hashtable->table[hashval] = new_entry;
+	setup_timer(&new_entry->ack_timer, gmtp_inter_ack_timer_callback,
+			(unsigned long ) new_entry);
+	setup_timer(&new_entry->register_timer,
+			gmtp_inter_register_timer_callback,
+			(unsigned long ) new_entry);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(gmtp_inter_add_entry);
+
+void gmtp_inter_del_clients(struct gmtp_inter_entry *entry)
+{
+	struct gmtp_client *client, *temp;
+
+	gmtp_pr_func();
+
+	list_for_each_entry_safe(client, temp, &entry->clients->list, list)
+	{
+		list_del(&client->list);
+		kfree(client);
+	}
+}
+
+struct gmtp_inter_entry *gmtp_inter_del_entry(
+		struct gmtp_inter_hashtable *hashtable, __u8 *media)
+{
+	struct gmtp_inter_entry *previous_entry;
+	struct gmtp_inter_entry *current_entry;
+	int hashval;
+
+	gmtp_print_function();
+
+	hashval = gmtp_inter_hash(hashtable, media);
+	if(hashval < 0)
+		return NULL;
+
+	previous_entry = NULL;
+	current_entry = hashtable->table[hashval];
+
+	while(current_entry != NULL
+			&& memcmp(media, current_entry->flowname,
+					GMTP_FLOWNAME_LEN) != 0) {
+		previous_entry = current_entry;
+		current_entry = current_entry->next;
+	}
+
+	if(current_entry == NULL) {
+		gmtp_print_debug("Media entry not found at %d", hashval);
+		return hashtable->table[hashval];
+	}
+
+	/* Remove the last entry of list */
+	if(previous_entry == NULL)
+		hashtable->table[hashval] = current_entry->next;
+	else  /* The list keeps another media with same hash value */
+		previous_entry->next = current_entry->next;
+
+	gmtp_inter_del_clients(current_entry);
+	skb_queue_purge(current_entry->buffer);
+	del_timer_sync(&current_entry->mcc_timer);
+	del_timer_sync(&current_entry->ack_timer);
+	kfree(current_entry);
+
+	gmtp_print_debug("Media entry removed successfully!");
+	return hashtable->table[hashval];
+}
+
+void kfree_gmtp_inter_hashtable(struct gmtp_inter_hashtable *hashtable)
+{
+	int i;
+	struct gmtp_inter_entry *list, *temp;
+
+	gmtp_print_function();
+
+	if(hashtable == NULL)
+		return;
+
+	for(i = 0; i < hashtable->size; ++i) {
+		list = hashtable->table[i];
+		while(list != NULL) {
+			temp = list;
+			list = list->next;
+			gmtp_inter_del_entry(hashtable, temp->flowname);
+		}
+	}
+
+	kfree(hashtable->table);
+	kfree(hashtable);
+}
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/hash-inter.h linux-4.9-rc2/net/gmtp/gmtp-inter/hash-inter.h
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/hash-inter.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/hash-inter.h	2016-12-04 02:55:46.301493153 -0300
@@ -0,0 +1,201 @@
+/*
+ * hash-inter.h
+ *
+ *  Created on: 03/05/2015
+ *      Author: wendell
+ */
+
+#ifndef HASH_INTER_H_
+#define HASH_INTER_H_
+
+#define GMTP_HASH_KEY_LEN  16
+
+#include <linux/netdevice.h>
+#include "../hash.h"
+#include "gmtp-inter.h"
+
+/**
+ * struct gmtp_inter_entry: entry in GMTP-inter Relay Table
+ *
+ * @flowname: Name of dataflow
+ * @server_addr: IP address of media server
+ * @relays: list of relays connected to this relay
+ * @nrelays: number of relays connected to this relay
+ * @media_port: port of media at server
+ * @channel_addr: IP address of media multicast channel
+ * @channel_port: Port of media multicast channel
+ * @state: state of media transmission
+ *
+ *  Control information for media transmission:
+ *
+ * @seq: sequence number of last received packet
+ * @total_bytes: amount of received bytes
+ * @last_rx_tstamp: time stamp of last received data packet (milliseconds)
+ * @last_data_tstamp: time stamp stored in last received data packet.
+ * @transm_r: default tx rate of server
+ *
+ * FIXME now, rcv_tx_rate is updated via acks (r -> s). his is wrong...
+ * @rcv_tx_rate: tx rate received from relays (or server) in path s->r
+ *
+ * @nfeedbacks: number of received feedbacks at last window
+ * @sum_feedbacks: sum of all feedbacks tx rates received at last window
+ * @recent_bytes: amount of received bytes in last window for calcs of RX
+ * @recent_rx_tstamp: time stamp of received data packet in calcs of RX
+ * @current_rx: current rx_rate calculated
+ * @required_tx: Max tx (via GMTP-MCC). 0 means unlimited.
+ * @data_pkt_out: number of data packets transmitted
+ * @RTT: RTT from server to client (available in data packets)
+ * @mcc_timer: Timer to control mcc tx reduction
+ *
+ * @clients: list of reporters connected to this relay
+ * @nclients: number of clients connected to this relay
+ * @cur_reporter: current reporter (to connect new clients)
+ *
+ * @buffer: buffer of GMTP-Data packets
+ * @buffer_size: size (in bytes) of GMTP-Data buffer.
+ * @buffer_len: number of packets in GMTP-Data buffer]
+ * @buffer_size: max number of packets in buffer
+ * @buffer_len: buffer length in bytes
+ *
+ * @next: pointer to next gmtp_inter_entry
+ */
+struct gmtp_inter_entry {
+    __u8 flowname[GMTP_FLOWNAME_LEN];
+    __be32 server_addr;
+    struct gmtp_relay *relays;
+    unsigned int nrelays;
+    __be16 media_port;
+    __be32 channel_addr;
+    __be16 channel_port;
+    __u8 state :3;
+
+    struct timer_list ack_timer;
+    struct timer_list register_timer;
+
+    unsigned char server_mac_addr[6];
+    unsigned char request_mac_addr[6];
+
+    /* Information of transmission state */
+    __be32 my_addr;
+    __be16 my_port;
+
+    unsigned int seq;
+    unsigned int total_bytes;
+    unsigned long last_rx_tstamp; /* milliseconds */
+    __be32 last_data_tstamp;
+    __be32 transm_r;
+    __be32 rcv_tx_rate;
+    __u8 ucc_type;
+    struct gmtp_inter_ucc_protocol ucc;
+
+    /* GMTP-MCC */
+    unsigned int nfeedbacks;
+    unsigned int sum_feedbacks;
+    unsigned int recent_bytes;
+    unsigned long recent_rx_tstamp;
+    unsigned int current_rx;
+    unsigned int required_tx;
+    unsigned int data_pkt_in;
+    unsigned int data_pkt_out;
+    unsigned int server_rtt;
+    unsigned int clients_rtt;
+    struct timer_list mcc_timer;
+
+    struct gmtp_client *clients;
+    unsigned int nclients;
+    struct gmtp_client *cur_reporter;
+
+    struct sk_buff_head *buffer;
+    unsigned int buffer_min;
+    unsigned int buffer_max; /* buffer_min * 3 */
+    unsigned int buffer_len; /* in bytes */
+
+    struct net_device *dev_in;
+    struct net_device *dev_out;
+    bool route_pending;
+
+    struct gmtp_inter_entry *next;
+};
+
+static inline void gmtp_set_buffer_limits(struct gmtp_inter_entry *info,
+        unsigned int buffer_min)
+{
+    info->buffer_min = buffer_min;
+    info->buffer_max = info->buffer_min * 3;
+}
+
+/**
+ * State of a flow
+ */
+enum {
+    GMTP_INTER_WAITING_REGISTER_REPLY=0,
+    GMTP_INTER_REGISTER_REPLY_RECEIVED,
+    GMTP_INTER_TRANSMITTING,
+    GMTP_INTER_CLOSE_RECEIVED,
+    GMTP_INTER_CLOSED
+};
+
+/*
+ * struct gmtp_inter_hashtable: GMTP-inter Relay Table
+ */
+struct gmtp_inter_hashtable {
+    int size;
+    struct gmtp_inter_entry **table;
+};
+
+/** hash.c */
+struct gmtp_inter_hashtable *gmtp_inter_create_hashtable(unsigned int size);
+struct gmtp_inter_entry *gmtp_inter_lookup_media(
+        struct gmtp_inter_hashtable *hashtable, const __u8 *media);
+int gmtp_inter_add_entry(struct gmtp_inter_hashtable *hashtable, __u8 *flowname,
+        __be32 server_addr, __be32 *relay, __be16 media_port,
+        __be32 channel_addr, __be16 channel_port);
+struct gmtp_inter_entry *gmtp_inter_del_entry(
+        struct gmtp_inter_hashtable *hashtable, __u8 *media);
+
+void kfree_gmtp_inter_hashtable(struct gmtp_inter_hashtable *hashtable);
+
+/**
+ * struct gmtp_relay - A list of GMTP Relays
+ *
+ * @state: state of relay
+ * @dev: struct net_device of incoming request from client
+ *
+ * @tx_rate: max tx rate to relay
+ * @tx_byte_budget: the amount of bytes that can be sent immediately.
+ */
+struct gmtp_relay {
+    struct list_head list;
+    __be32 addr;
+    __be16 port;
+    unsigned char mac_addr[6];
+
+    __u8  relay_id[GMTP_RELAY_ID_LEN];
+
+    enum gmtp_state state;
+    struct net_device *dev;
+
+    /** GMTP-UCC */
+    unsigned long tx_rate;
+    int tx_byte_budget;
+    struct timer_list xmit_timer;
+    int losses;
+};
+
+/** Relay.c **/
+
+struct gmtp_relay *gmtp_create_relay(__be32 addr, __be16 port);
+struct gmtp_relay *gmtp_list_add_relay(__be32 addr, __be16 port,
+        struct list_head *head);
+struct gmtp_relay *gmtp_inter_create_relay(struct sk_buff *skb,
+        struct gmtp_inter_entry *entry, __u8 *relay_id);
+struct gmtp_relay *gmtp_inter_create_relay_from_delegate(
+        struct gmtp_inter_entry *entry, __be32 addr, __be16 port,
+        __u8 *relay_id);
+struct gmtp_relay* gmtp_get_relay(struct list_head *head,
+        __be32 addr, __be16 port);
+int gmtp_delete_relays(struct list_head *list, __be32 addr, __be16 port);
+void print_gmtp_relay(struct gmtp_relay *r);
+
+
+#endif /* HASH_INTER_H_ */
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/input-inter.c linux-4.9-rc2/net/gmtp/gmtp-inter/input-inter.c
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/input-inter.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/input-inter.c	2016-12-01 16:50:35.550418692 -0300
@@ -0,0 +1,748 @@
+#include <net/ip.h>
+#include <asm-generic/unaligned.h>
+#include <linux/etherdevice.h>
+
+#include <uapi/linux/gmtp.h>
+#include <linux/gmtp.h>
+#include "../gmtp.h"
+
+#include "gmtp-inter.h"
+#include "mcc-inter.h"
+#include "ucc.h"
+
+int gmtp_inter_request_rcv(struct sk_buff *skb)
+{
+	int ret = NF_ACCEPT;
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_hdr *gh_reqnotify;
+	struct gmtp_inter_entry *entry;
+
+	__u8 code = GMTP_REQNOTIFY_CODE_ERROR;
+	__u8 max_nclients = 0;
+
+	gmtp_pr_func();
+
+	entry = gmtp_inter_lookup_media(gmtp_inter.hashtable, gh->flowname);
+	if(entry != NULL) {
+		struct gmtp_client *cl;
+		gmtp_pr_info("Media found. Sending RequestNotify.");
+		switch(entry->state) {
+
+		case GMTP_INTER_WAITING_REGISTER_REPLY:
+			gmtp_pr_info("Waiting Register-Reply from server...");
+			/* FIXME Make a timer to send register again... */
+			code = GMTP_REQNOTIFY_CODE_WAIT;
+			/*
+			gh->type = GMTP_PKT_REGISTER;  Request shall not pass
+			iph->ttl = 64;
+			ip_send_check(iph);*/
+			ret = NF_DROP;
+			break;
+		case GMTP_INTER_REGISTER_REPLY_RECEIVED:
+		case GMTP_INTER_TRANSMITTING:
+			code = GMTP_REQNOTIFY_CODE_OK;
+			ret = NF_DROP;
+			break;
+		default:
+			gmtp_pr_error("Inconsistent state: %d", entry->state);
+			ret = NF_DROP;
+			goto out;
+		}
+		cl = gmtp_get_client(&entry->clients->list, iph->saddr,
+				gh->sport);
+		if(cl != NULL) {
+			max_nclients = cl->max_nclients;
+			goto out;
+		}
+		max_nclients = new_reporter(entry);
+
+	} else {
+		__be32 mcst_addr = get_mcst_v4_addr();
+		int err = gmtp_inter_add_entry(gmtp_inter.hashtable,
+				gh->flowname,
+				iph->daddr,
+				NULL,
+				gh->dport, /* Server port */
+				mcst_addr,
+				gh->dport); /* Mcst port <- server port */
+
+		if(err) {
+			gmtp_pr_error("Failed to insert flow in table (%d)", err);
+			ret = NF_DROP;
+			goto out;
+		}
+
+		entry = gmtp_inter_lookup_media(gmtp_inter.hashtable,
+				gh->flowname);
+		max_nclients = new_reporter(entry);
+
+		entry->dev_out = skb->dev;
+		entry->my_addr = gmtp_dev_ip(skb->dev);
+		pr_info("My addr: %pI4\n", &entry->my_addr);
+		entry->my_port = gh->sport;
+		code = GMTP_REQNOTIFY_CODE_WAIT;
+
+		gmtp_inter_make_register(skb);
+	}
+
+	if(max_nclients > 0)
+		entry->cur_reporter = gmtp_list_add_client(
+				++entry->nclients, iph->saddr, gh->sport,
+				max_nclients, &entry->clients->list);
+	else
+		gmtp_list_add_client(++entry->nclients, iph->saddr, gh->sport,
+				max_nclients, &entry->clients->list);
+
+out:
+	gh_reqnotify = gmtp_inter_make_request_notify_hdr(skb, entry,
+			gh->dport, gh->sport, entry->cur_reporter,
+			max_nclients, code);
+
+	if(gh_reqnotify != NULL)
+		gmtp_inter_build_and_send_pkt(skb, iph->daddr,
+				iph->saddr, gh_reqnotify, GMTP_INTER_BACKWARD);
+
+	return ret;
+}
+
+int gmtp_inter_register_rcv(struct sk_buff *skb)
+{
+	int ret = NF_DROP;
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_hdr_register *gr = gmtp_hdr_register(skb);
+	struct ethhdr *eth = eth_hdr(skb);
+	struct gmtp_inter_entry *entry;
+	struct gmtp_relay *relay;
+
+	gmtp_pr_func();
+	print_packet(skb, true);
+	print_gmtp_packet(iph, gh);
+
+	entry = gmtp_inter_lookup_media(gmtp_inter.hashtable, gh->flowname);
+	if(entry != NULL) {
+		relay = gmtp_get_relay(&entry->relays->list, iph->saddr,
+				gh->sport);
+
+		if(relay == NULL && gh->server_rtt != 0)
+			return NF_ACCEPT;
+
+		switch(entry->state) {
+		case GMTP_INTER_WAITING_REGISTER_REPLY:
+			gmtp_pr_info("Waiting RegisterReply...");
+			ret = NF_ACCEPT;
+			goto out;
+		case GMTP_INTER_REGISTER_REPLY_RECEIVED:
+		case GMTP_INTER_TRANSMITTING:
+			if(relay == NULL)
+				relay = gmtp_inter_create_relay(skb, entry, gr->relay_id);
+			gmtp_pr_info("Media found. Sending RegisterReply.");
+			break;
+		case GMTP_INTER_CLOSE_RECEIVED:
+		case GMTP_INTER_CLOSED:
+			/* TODO Send a reset to requester */
+			gmtp_pr_warning("Server is already closed! "
+					"(TODO: send a reset to requester)\n");
+			break;
+		default:
+			gmtp_pr_error("Inconsistent state: %d", entry->state);
+		}
+		if(relay != NULL) {
+			struct gmtp_hdr *ghreply;
+			ghreply = gmtp_inter_make_register_reply_hdr(skb, entry,
+					gh->dport, gh->sport);
+			gmtp_inter_build_and_send_pkt(skb, iph->daddr,
+					iph->saddr, ghreply,
+					GMTP_INTER_BACKWARD);
+		}
+	} else { /* I am not the server */
+
+		__be32 mcst_addr = get_mcst_v4_addr();
+		int err = gmtp_inter_add_entry(gmtp_inter.hashtable,
+				gh->flowname, iph->daddr,
+				NULL, gh->dport, /* Media port */
+				mcst_addr, gh->dport); /* Mcst port <- server port */
+		if(err) {
+			gmtp_pr_error("Failed to insert flow in table (%d)", err);
+			return NF_DROP;
+		}
+		entry = gmtp_inter_lookup_media(gmtp_inter.hashtable,
+				gh->flowname);
+
+		entry->dev_out = skb->dev;
+		entry->my_addr = gmtp_dev_ip(skb->dev);
+		entry->my_port = gh->sport;
+		relay = gmtp_inter_create_relay(skb, entry, gr->relay_id);
+
+		if(relay != NULL)
+			ret = NF_ACCEPT;
+	}
+
+out:
+	return ret;
+}
+
+int gmtp_inter_register_local_in(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct ethhdr *eth = eth_hdr(skb);
+
+	gmtp_pr_func();
+
+	if(entry->state != GMTP_INTER_WAITING_REGISTER_REPLY)
+		return NF_DROP;
+
+	entry->my_addr = gmtp_dev_ip(skb->dev);
+	entry->my_port = gh->sport;
+	ether_addr_copy(entry->request_mac_addr, eth->h_source);
+
+	iph->ttl = 64;
+	ip_send_check(iph);
+
+	ether_addr_copy(eth->h_source, eth->h_dest);
+
+	return NF_ACCEPT;
+}
+
+
+/* A little trick...
+ * Just get any client IP to pass over GMTP-Intra.
+ */
+struct gmtp_client *jump_over_gmtp_intra(struct sk_buff *skb,
+		struct list_head *list_head)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_client *client = gmtp_get_first_client(list_head);
+
+	if(client != NULL) {
+		gh->dport = client->port;
+		iph->daddr = client->addr;
+		ip_send_check(iph);
+		GMTP_SKB_CB(skb)->jumped = 1;
+	} else
+		pr_info("There are no clients anymore!\n");
+	return client;
+}
+
+static int gmtp_inter_transmitting_register_reply_rcv(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+	struct ethhdr *eth = eth_hdr(skb);
+	struct gmtp_hdr *gh_route_n;
+
+	/* TODO write my ucc tx_rate here... */
+
+	gmtp_add_relayid(skb);
+
+	if(!gmtp_local_ip(iph->daddr))
+		return NF_ACCEPT;
+
+	gh_route_n = gmtp_inter_make_route_hdr(skb);
+
+	ether_addr_copy(entry->server_mac_addr, eth->h_source);
+
+	if(gh_route_n != NULL)
+		gmtp_inter_build_and_send_pkt(skb, iph->daddr, iph->saddr,
+				gh_route_n, GMTP_INTER_BACKWARD);
+
+	return NF_DROP;
+}
+
+static void gmtp_inter_send_reply_to_relay(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry, struct gmtp_relay *relay)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+
+	struct sk_buff *copy = skb_copy(skb, gfp_any());
+
+	if(copy != NULL) {
+		struct iphdr *iph_copy = ip_hdr(copy);
+		struct gmtp_hdr *gh_copy = gmtp_hdr(copy);
+		struct gmtp_hdr *gh_reply;
+
+		iph_copy->daddr = relay->addr;
+		ip_send_check(iph_copy);
+		gh_copy->dport = relay->port;
+
+		gh_reply = gmtp_inter_make_register_reply_hdr(copy, entry,
+				gh->sport, relay->port);
+		if(gh_reply != NULL)
+			gmtp_inter_build_and_send_pkt(skb, iph->saddr,
+					relay->addr, gh_reply,
+					GMTP_INTER_FORWARD);
+	}
+}
+static void gmtp_inter_send_reply_to_relays(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry)
+{
+	struct gmtp_relay *relay, *tempr;
+
+	list_for_each_entry_safe(relay, tempr, &entry->relays->list, list)
+	{
+		gmtp_inter_send_reply_to_relay(skb, entry, relay);
+	}
+
+}
+
+static void gmtp_inter_send_reqnotify_to_client(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry, struct gmtp_client *client,
+		struct gmtp_client *cur_reporter, __u8 code)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+
+	struct sk_buff *copy = skb_copy(skb, gfp_any());
+
+	if(copy != NULL) {
+		struct iphdr *iph_copy = ip_hdr(copy);
+		struct gmtp_hdr *gh_copy = gmtp_hdr(copy);
+		struct gmtp_hdr *gh_req_n;
+
+		iph_copy->daddr = client->addr;
+		ip_send_check(iph_copy);
+		gh_copy->dport = client->port;
+
+		gh_req_n = gmtp_inter_make_request_notify_hdr(copy, entry,
+				gh->sport, client->port, cur_reporter,
+				client->max_nclients, code);
+		if(gh_req_n != NULL)
+			gmtp_inter_build_and_send_pkt(skb, iph->saddr,
+					client->addr, gh_req_n,
+					GMTP_INTER_FORWARD);
+	}
+}
+
+static int gmtp_inter_send_reqnotify_to_clients(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry)
+{
+	int ret = NF_ACCEPT;
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_client *client, *tempc, *first_client, *cur_reporter = NULL;
+	__u8 code = GMTP_REQNOTIFY_CODE_OK;
+
+	/* Send it to first client */
+	first_client = gmtp_get_first_client(&entry->clients->list);
+	if(first_client == NULL) {
+		pr_info("No clients registered.\n");
+		return NF_ACCEPT;
+	}
+
+	if(first_client->max_nclients > 0)
+		cur_reporter = first_client;
+
+	ret = gmtp_inter_make_request_notify(skb, iph->saddr, gh->sport,
+			first_client->addr, first_client->port, cur_reporter,
+			first_client->max_nclients, code);
+
+	/* Clean list of clients and keep only reporters */
+	list_for_each_entry_safe(client, tempc, &entry->clients->list, list)
+	{
+		/* Send to other clients (not first) */
+		if(client == first_client)
+			continue;
+
+		if(client->max_nclients > 0)
+			cur_reporter = client;
+
+		gmtp_inter_send_reqnotify_to_client(skb, entry, client,
+				cur_reporter, code);
+
+		/** Deleting non-reporters */
+		if(client->max_nclients <= 0) {
+			list_del(&client->list);
+			kfree(client);
+		}
+	}
+
+	return ret;
+}
+
+int gmtp_inter_register_reply_rcv(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry,
+		enum gmtp_inter_direction direction)
+{
+	int ret = NF_ACCEPT;
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+	struct ethhdr *eth = eth_hdr(skb);
+	struct gmtp_hdr *gh_route_n;
+
+	__u8 code = GMTP_REQNOTIFY_CODE_OK;
+
+	gmtp_print_function();
+
+	print_packet(skb, true);
+	print_gmtp_packet(iph, gh);
+
+	if(entry->state == GMTP_INTER_REGISTER_REPLY_RECEIVED)
+		return NF_DROP;
+	else if(entry->state == GMTP_INTER_TRANSMITTING)
+		return gmtp_inter_transmitting_register_reply_rcv(skb, entry);
+
+	entry->transm_r =  gh->transm_r;
+	entry->rcv_tx_rate = gh->transm_r;
+	entry->server_rtt = (unsigned int)gh->server_rtt;
+	entry->ucc_type = gmtp_hdr_register_reply(skb)->ucc_type;
+	gmtp_inter_build_ucc(&entry->ucc, entry->ucc_type);
+	entry->route_pending = true;
+
+	if(direction != GMTP_INTER_LOCAL) {
+		pr_info("Direction: %u\n", direction);
+
+		entry->dev_in = skb->dev;
+
+		/* Add relay information in REGISTER-REPLY packet) */
+		gmtp_add_relayid(skb);
+
+		pr_info("UPDATING Tx Rate...\n");
+		gmtp_inter.worst_rtt = max(gmtp_inter.worst_rtt,
+				(unsigned int ) gh->server_rtt);
+
+		pr_info("Server RTT: %u ms\n", (unsigned int ) gh->server_rtt);
+		pr_info("Worst RTT: %u ms\n", gmtp_inter.worst_rtt);
+
+		if(gmtp_inter.ucc_rx < gh->transm_r)
+			gh->transm_r = (__be32) gmtp_inter.ucc_rx;
+
+		if(entry->state != GMTP_INTER_WAITING_REGISTER_REPLY)
+			return NF_ACCEPT;
+
+		ether_addr_copy(entry->server_mac_addr, eth->h_source);
+
+		gh_route_n = gmtp_inter_make_route_hdr(skb);
+		if(gh_route_n != NULL)
+			gmtp_inter_build_and_send_pkt(skb, iph->daddr,
+					iph->saddr, gh_route_n, direction);
+		mod_timer(&entry->ack_timer,
+				jiffies + msecs_to_jiffies(2*GMTP_DEFAULT_RTT));
+
+		/** FIXME This causes congestion... ! Why? */
+		mod_timer(&entry->register_timer, jiffies + HZ);
+	} else {
+		pr_info("Direction: LOCAL\n");
+		ether_addr_copy(entry->server_mac_addr, skb->dev->dev_addr);
+		ether_addr_copy(eth->h_dest, entry->request_mac_addr);
+	}
+
+	entry->state = GMTP_INTER_REGISTER_REPLY_RECEIVED;
+
+	if(entry->nrelays==0) {
+		pr_info("No relays registered.\n");
+		goto send_to_clients;
+	}
+
+	gmtp_inter_send_reply_to_relays(skb, entry);
+
+send_to_clients:
+	ret = gmtp_inter_send_reqnotify_to_clients(skb,	entry);
+
+	return ret;
+}
+
+/* TODO Separate functions to clients and relays */
+int gmtp_inter_ack_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_client *reporter;
+	struct gmtp_relay *relay;
+
+	reporter = gmtp_get_client(&entry->clients->list, iph->saddr,
+			gh->sport);
+	if(reporter != NULL)
+		reporter->ack_rx_tstamp = jiffies_to_msecs(jiffies);
+
+	relay = gmtp_get_relay(&entry->relays->list, iph->saddr, gh->sport);
+	if(relay != NULL) {
+		entry->rcv_tx_rate = gh->transm_r;
+		relay->tx_rate = gh->transm_r;
+
+		if(relay->state == GMTP_CLOSED) {
+			struct ethhdr *eth = eth_hdr(skb);
+			relay->dev = skb->dev;
+			ether_addr_copy(relay->mac_addr, eth->h_source);
+			return NF_ACCEPT;
+		}
+	}
+
+	if(!gmtp_local_ip(iph->daddr)) {
+		if(reporter == NULL && relay == NULL)
+			return NF_ACCEPT;
+	}
+
+	if(gmtp_local_ip(iph->daddr)) {
+		if(entry->route_pending) {
+			entry->route_pending = false;
+			return NF_ACCEPT;
+		} else if(relay != NULL) {
+			return NF_ACCEPT;
+		}
+	}
+
+	return NF_DROP;
+}
+
+/* Treat route_notify from relays */
+int gmtp_inter_route_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_hdr_route *route = gmtp_hdr_route(skb);
+	struct iphdr *iph = ip_hdr(skb);
+	struct ethhdr *eth = eth_hdr(skb);
+	struct gmtp_relay *relay;
+
+	print_gmtp_packet(iph, gh);
+	print_route_from_skb(skb);
+
+	relay = gmtp_get_relay(&entry->relays->list, iph->saddr, gh->sport);
+	pr_info("Relay: %p\n", relay);
+	if(relay == NULL)
+		return NF_ACCEPT;
+
+	relay->state = GMTP_OPEN;
+	ether_addr_copy(relay->mac_addr, eth->h_source);
+	relay->dev = skb->dev;
+
+	if(gmtp_local_ip(iph->daddr)) { /* I am the server itself */
+		if(route->nrelays > 0)
+			/*gmtp_add_server_entry(server_hashtable, gh->flowname,
+					route)*/;
+		pr_info("ROUTE_RCV: entry->route_pending = %d\n",
+				entry->route_pending);
+		if(entry->route_pending) {
+			entry->route_pending = false;
+			return NF_ACCEPT;
+		}
+	}
+
+	pr_info("Dropping Route...\n");
+	return NF_DROP;
+}
+
+int gmtp_inter_feedback_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_hdr_feedback *ghf = gmtp_hdr_feedback(skb);
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_client *reporter;
+	unsigned int now, rep_rtt;
+
+	reporter = gmtp_get_client(&entry->clients->list, iph->saddr, gh->sport);
+	if(reporter == NULL)
+		return NF_DROP;
+
+	if(likely(gh->transm_r > 0)) {
+		entry->nfeedbacks++;
+		entry->sum_feedbacks += (unsigned int) gh->transm_r;
+		reporter->ack_rx_tstamp = jiffies_to_msecs(jiffies);
+	}
+
+	now = jiffies_to_msecs(jiffies);
+	rep_rtt = now - ghf->orig_tstamp;
+	entry->clients_rtt = rtt_ewma(entry->clients_rtt, rep_rtt, 900);
+
+	return NF_DROP;
+}
+
+int gmtp_inter_delegate_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_hdr_delegate *ghd = gmtp_hdr_delegate(skb);
+	struct gmtp_relay *relay;
+
+	if(gh->type == GMTP_PKT_DELEGATE)
+		print_gmtp_packet(iph, gh);
+
+	pr_info("\t[relay_addr:port] = %pI4:%d\n", &ghd->relay.relay_ip,
+			ntohs(ghd->relay_port));
+
+	if(entry->state != GMTP_INTER_TRANSMITTING)
+		return NF_DROP;
+
+	relay = gmtp_get_relay(&entry->relays->list, iph->saddr, gh->sport);
+	if(relay == NULL)
+		relay = gmtp_inter_create_relay_from_delegate(entry,
+				ghd->relay.relay_ip, ghd->relay_port,
+				ghd->relay.relay_id);
+
+	return NF_DROP;
+}
+
+
+/**
+ * FIXME This works only with auto promoted reporters
+ */
+int gmtp_inter_elect_resp_rcv(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+	print_packet(skb, true);
+	print_gmtp_packet(iph, gh);
+
+	gmtp_list_add_client(++entry->nclients, iph->saddr,
+					gh->sport, gmtp_inter.kreporter,
+					&entry->clients->list);
+
+	return NF_DROP;
+}
+
+/**
+ * Update GMTP-inter statistics
+ */
+static inline void gmtp_update_stats(struct gmtp_inter_entry *info,
+		struct sk_buff *skb, struct gmtp_hdr *gh)
+{
+	info->total_bytes += skblen(skb);
+	info->recent_bytes += skblen(skb);
+	info->seq = (unsigned int)gh->seq;
+	info->server_rtt = (unsigned int)gh->server_rtt;
+	info->last_data_tstamp = gmtp_hdr_data(skb)->tstamp;
+	info->last_rx_tstamp = jiffies_to_msecs(jiffies);
+
+	info->transm_r = gh->transm_r;
+
+	/* FIXME Make a timer to update this */
+	/*info->rcv_tx_rate = gh->transm_r;
+	gh->transm_r = min(info->rcv_tx_rate, gmtp_inter.ucc_rx);*/
+
+	if(++info->data_pkt_in % gmtp_inter.rx_rate_wnd == 0) {
+		unsigned long current_time = ktime_to_ms(ktime_get_real());
+		unsigned long elapsed = current_time - info->recent_rx_tstamp;
+
+		if(elapsed != 0) {
+			info->current_rx = DIV_ROUND_CLOSEST(
+					info->recent_bytes * MSEC_PER_SEC, elapsed);
+		}
+		info->recent_rx_tstamp = ktime_to_ms(ktime_get_real());
+
+		info->recent_bytes = 0;
+		gmtp_inter.worst_rtt = GMTP_MIN_RTT_MS;
+	}
+	gmtp_inter.worst_rtt = max(gmtp_inter.worst_rtt,
+				(unsigned int ) gh->server_rtt);
+}
+
+
+static inline void print_drop(struct sk_buff *skb, __be32 daddr, __be32 seq, char *info)
+{
+	pr_info("Dropping pkt (%s - to %pI4, seq=%u, data=%s)\n",
+					info, &daddr, seq, gmtp_data(skb));
+}
+
+/**
+ * P = p.flowname
+ * If P != NULL:
+ *  in:
+ *     AddToBuffer(P)
+ *  out:
+ *     p.dest_address = get_multicast_channel(P)
+ *     p.port = get_multicast_port(P)
+ *     send(P)
+ */
+int gmtp_inter_data_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+	if(!gmtp_local_ip(iph->daddr)) /* Data is not to me */
+		return NF_ACCEPT;
+
+	if(unlikely(entry->state == GMTP_INTER_REGISTER_REPLY_RECEIVED)) {
+		entry->state = GMTP_INTER_TRANSMITTING;
+		mod_timer(&entry->mcc_timer, gmtp_mcc_interval(entry->server_rtt));
+
+		/** Accept the first one. Do not remove this!!! Never!
+		 *  This makes GMTP-Delegate work properly
+		 */
+		return NF_ACCEPT;
+	}
+
+	/*if(entry->buffer->qlen >= entry->buffer_max) {
+		print_drop(skb, iph->daddr, gh->seq, "buffer overflow");
+		goto out;
+
+		/*return NF_DROP;*/
+		/* Dont add it to buffer (equivalent to drop) */
+	/*}*/ /*else if(gh->seq < entry->seq) {
+		print_drop(skb, iph->daddr, gh->seq, "incorrect seq number");
+		return NF_DROP;
+		goto out;
+	}*/
+
+	/*if((gh->seq > entry->seq) && entry->state == GMTP_INTER_TRANSMITTING) {
+		gmtp_buffer_add(entry, skb);
+	}*/
+
+
+
+out:
+	/*pr_info("Receiving (to %pI4:%d, seq: %u)\n", &iph->daddr,
+			htons(gh->dport), gh->seq);*/
+
+	if(iph->daddr == entry->my_addr)
+		jump_over_gmtp_intra(skb, &entry->clients->list);
+	else
+		skb->dev = entry->dev_out;
+
+	gmtp_update_stats(entry, skb, gh);
+
+	return NF_ACCEPT;
+}
+
+int gmtp_inter_close_rcv(struct sk_buff *skb, struct gmtp_inter_entry *entry,
+		bool in)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+
+	gmtp_pr_func();
+
+	print_packet(skb, in);
+	print_gmtp_packet(iph, gh);
+	gmtp_pr_info("State: %u", entry->state);
+
+	if(!in) {
+		pr_info("Local out!\n");
+		entry->state = GMTP_INTER_CLOSE_RECEIVED;
+		return NF_ACCEPT;
+	}
+
+	if(iph->saddr != entry->server_addr
+			|| entry->state == GMTP_INTER_CLOSED)
+		return NF_ACCEPT;
+
+
+	if(entry->state == GMTP_INTER_TRANSMITTING) {
+		struct gmtp_hdr *gh_reset;
+		entry->state = GMTP_INTER_CLOSE_RECEIVED;
+
+		pr_info("Deleting timers...\n");
+		del_timer_sync(&entry->mcc_timer);
+		del_timer_sync(&entry->ack_timer);
+		del_timer_sync(&entry->register_timer);
+
+		gh_reset = gmtp_inter_make_reset_hdr(skb, GMTP_RESET_CODE_CLOSED);
+
+		if(gh_reset != NULL) {
+			gmtp_inter_build_and_send_pkt(skb, iph->daddr,
+					iph->saddr, gh_reset,
+					GMTP_INTER_BACKWARD);
+
+			jump_over_gmtp_intra(skb, &entry->clients->list);
+			gmtp_buffer_add(entry, skb);
+		}
+	}
+
+	return NF_ACCEPT;
+}
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/mcc-inter.c linux-4.9-rc2/net/gmtp/gmtp-inter/mcc-inter.c
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/mcc-inter.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/mcc-inter.c	2016-12-01 16:50:35.592418167 -0300
@@ -0,0 +1,106 @@
+/*
+ * mcc.h
+ *
+ *  Created on: 13/04/2015
+ *      Author: wendell
+ */
+
+#include "gmtp-inter.h"
+#include "mcc-inter.h"
+
+struct timer_list mcc_timer;
+
+void gmtp_inter_mcc_delay(struct gmtp_inter_entry *info, struct sk_buff *skb,
+		unsigned int server_tx)
+{
+	long server_delay, server_delay2, elapsed, req_delay, final_delay;
+	unsigned int len = skb->len + ETH_HLEN;
+	unsigned long now = jiffies_to_msecs(jiffies);
+
+	if(info->required_tx <= 0 || info->required_tx >= server_tx)
+		return;
+
+	server_delay = (long) DIV_ROUND_CLOSEST(HZ * len, server_tx);
+	elapsed = now - info->last_rx_tstamp;
+	server_delay2 = server_delay - elapsed;
+	req_delay = (long) DIV_ROUND_CLOSEST(HZ * len, info->required_tx);
+	final_delay = req_delay - server_delay2;
+
+	/* if delay2 <= 0, pass way... */
+	if(final_delay > 0)
+		gmtp_inter_wait_ms(final_delay);
+
+}
+
+/**
+ * FIXME Dont start timer if we are Waiting Register Reply...
+ *
+ * TODO update_stats RTT through feedbacks
+ *
+ * If the GMTP-MCC sender receives no reports from the Reporters for (4 RTTs),
+ * the sending rate is cut in half.
+ * TODO In addition, if the sender receives no reports from the Reporter for at
+ * least (12 RTTs), it assumes that the Reporter crashed or left the group.
+ * A new reporter is selected, sending an elect-request to control channel.
+ * The first client to respond will be the new Reporter.
+ * If no one respond... There no clients... Close-Connection
+ *
+ * TODO Undo temporally changes:
+ *   Change from 4 RTTs to GMTP_ACK_INTERVAL
+ *
+ */
+void mcc_timer_callback(unsigned long data)
+{
+	struct gmtp_inter_entry *info = (struct gmtp_inter_entry*) data;
+	struct gmtp_client *reporter, *temp;
+	unsigned int new_tx = info->required_tx;
+
+	if(info->nclients <= 0)
+		goto out;
+
+	if(likely(info->nfeedbacks > 0))
+		new_tx = DIV_ROUND_CLOSEST(info->sum_feedbacks,
+				info->nfeedbacks);
+	else
+		new_tx = info->required_tx / 2;
+
+	/* Avoid super TX reduction */
+	if(new_tx < DIV_ROUND_CLOSEST(info->transm_r, 8))
+		new_tx = DIV_ROUND_CLOSEST(info->transm_r, 8);
+
+	info->required_tx = new_tx;
+
+	/*pr_info("n=%u, req_tx=%u B/s\n", info->nfeedbacks, info->required_tx);*/
+
+	/* FIXME Colocar isso em outro timer? */
+	list_for_each_entry_safe(reporter, temp, &info->clients->list, list)
+	{
+		unsigned int now = jiffies_to_msecs(jiffies);
+		int interval = (int)(now - reporter->ack_rx_tstamp);
+
+		/** Deleting non-reporters */
+		if(unlikely(reporter->max_nclients <= 0)) {
+			list_del(&reporter->list);
+			kfree(reporter);
+			continue;
+		}
+
+		/*if(unlikely(interval > jiffies_to_msecs(GMTP_ACK_TIMEOUT))) {
+			pr_info("Timeout: Reporter %pI4@%-5d\n",
+					&reporter->addr, ntohs(reporter->port));
+			pr_info("TODO: select new reporter and delete this.\n");
+		}*/
+	}
+
+out:
+	info->nfeedbacks = 0;
+	info->sum_feedbacks = 0;
+
+	/* TODO Send here an ack to server? */
+	if(likely(info->state != GMTP_INTER_CLOSE_RECEIVED
+					&& info->state != GMTP_INTER_CLOSED))
+		mod_timer(&info->mcc_timer,
+				gmtp_mcc_interval(info->server_rtt
+							+ info->clients_rtt));
+}
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/mcc-inter.h linux-4.9-rc2/net/gmtp/gmtp-inter/mcc-inter.h
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/mcc-inter.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/mcc-inter.h	2016-12-01 16:50:35.592418167 -0300
@@ -0,0 +1,40 @@
+/*
+ * mcc.h
+ *
+ *  Created on: 13/04/2015
+ *      Author: wendell
+ */
+
+#ifndef MCC_INTER_H_
+#define MCC_INTER_H_
+
+#include <uapi/linux/gmtp.h>
+#include <linux/gmtp.h>
+#include "../gmtp.h"
+#include "gmtp-inter.h"
+
+
+static inline unsigned long gmtp_mcc_interval(unsigned int rtt)
+{
+	unsigned long interval;
+	if(unlikely(rtt <= 0))
+		return (jiffies + GMTP_ACK_INTERVAL);
+
+	interval = (unsigned long) (4 * rtt);
+	return (jiffies + msecs_to_jiffies(interval));
+	/*return (jiffies + GMTP_ACK_INTERVAL);*/
+}
+
+static inline int new_reporter(struct gmtp_inter_entry *entry)
+{
+	return (entry->nclients % GMTP_REPORTER_DEFAULT_PROPORTION) == 0 ?
+			gmtp_inter.kreporter : 0;
+}
+
+void gmtp_inter_mcc_delay(struct gmtp_inter_entry *info, struct sk_buff *skb,
+		unsigned int server_tx);
+
+void mcc_timer_callback(unsigned long data);
+
+
+#endif /* MCC_INTER_H_ */
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/output-inter.c linux-4.9-rc2/net/gmtp/gmtp-inter/output-inter.c
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/output-inter.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/output-inter.c	2016-12-01 16:50:35.550418692 -0300
@@ -0,0 +1,365 @@
+/*
+ * output.c
+ *
+ *  Created on: 27/02/2015
+ *      Author: wendell
+ */
+
+#include <net/ip.h>
+#include <linux/phy.h>
+#include <linux/etherdevice.h>
+#include <linux/list.h>
+
+#include <uapi/linux/gmtp.h>
+#include <linux/gmtp.h>
+#include "../gmtp.h"
+
+#include "gmtp-inter.h"
+#include "mcc-inter.h"
+
+int gmtp_inter_register_out(struct sk_buff *skb, struct gmtp_inter_entry *entry)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_client* cl;
+
+	cl = gmtp_get_client(&entry->clients->list, iph->saddr, gh->sport);
+	if(cl == NULL)
+		return NF_ACCEPT;
+
+	if(entry->state != GMTP_INTER_WAITING_REGISTER_REPLY)
+		return NF_DROP;
+
+	/* FIXME Get a valid and unused port */
+	entry->my_addr = gmtp_dev_ip(skb->dev);
+	ether_addr_copy(entry->request_mac_addr, skb->dev->dev_addr);
+
+	gh->sport = entry->my_port;
+	iph->saddr = entry->my_addr;
+	pr_info("My addr: %pI4\n", &entry->my_addr);
+	iph->ttl = 64;
+	ip_send_check(iph);
+
+	print_packet(skb, false);
+	print_gmtp_packet(iph, gh);
+
+	return NF_ACCEPT;
+}
+
+/** XXX HOOK LOCAL OUT Does not works for RegisterReply (skb->dev == NULL) */
+int gmtp_inter_register_reply_out(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+	gmtp_pr_func();
+
+	if(gmtp_local_ip(iph->saddr)) {
+		return gmtp_inter_register_reply_rcv(skb, entry,
+				GMTP_INTER_LOCAL);
+	}
+
+	print_packet(skb, false);
+	print_gmtp_packet(iph, gh);
+
+	return NF_ACCEPT;
+}
+
+/* In some cases, turn ACK into a DELEGATE_REPLY */
+int gmtp_inter_ack_out(struct sk_buff *skb, struct gmtp_inter_entry *entry)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_relay *relay;
+
+	pr_info("Out: Ack from %pI4\n", &iph->saddr);
+
+	relay = gmtp_get_relay(&entry->relays->list, iph->saddr, gh->sport);
+	if(relay != NULL) {
+		pr_info("relay: %pI4 (%s)\n", &relay->addr,
+				gmtp_state_name(relay->state));
+
+		if(relay->state == GMTP_CLOSED) {
+			gmtp_inter_make_delegate_reply(skb, relay, entry);
+			relay->state = GMTP_OPEN;
+		}
+	}
+
+	return NF_ACCEPT;
+}
+
+void gmtp_copy_data(struct sk_buff *skb, struct sk_buff *src_skb)
+{
+	__u8* data = gmtp_data(skb);
+	__u32 data_len = gmtp_data_len(skb);
+
+	__u8* data_src = gmtp_data(src_skb);
+	__u32 data_src_len = gmtp_data_len(src_skb);
+
+	int diff = (int)data_len - (int)data_src_len;
+
+	/* This way does not work... */
+	/*skb_trim(skb, data_len);
+	skb_put(skb, data_src_len);*/
+
+	if(diff > 0)
+		skb_trim(skb, diff);
+	else if(diff < 0)
+		skb_put(skb, -diff);
+
+	memcpy(data, data_src, data_src_len);
+}
+
+/**
+ * Read p in buffer
+ * P = p.flowname
+ * If P != NULL:
+ *     p.dest_address = get_multicast_channel(P)
+ *     p.port = get_multicast_port(P)
+ *     send(p)
+ */
+int gmtp_inter_data_out(struct sk_buff *skb, struct gmtp_inter_entry *entry)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_hdr_data *ghd = gmtp_hdr_data(skb);
+	struct iphdr *iph = ip_hdr(skb);
+
+	unsigned int server_tx;
+	struct gmtp_relay *relay, *temp;
+
+	if(unlikely(entry->state == GMTP_INTER_REGISTER_REPLY_RECEIVED))
+		entry->state = GMTP_INTER_TRANSMITTING;
+
+	/** TODO Verify close from server... */
+	if(entry->state != GMTP_INTER_TRANSMITTING) {
+		gmtp_ucc_buffer_dequeue(skb);
+		return NF_DROP;
+	}
+
+	if(gmtp_local_ip(iph->saddr))
+		goto send;
+
+	/*if(entry->buffer->qlen > entry->buffer_min) {
+		struct sk_buff *buffered = gmtp_buffer_dequeue(entry);
+		if(buffered != NULL) {
+			entry->data_pkt_out++;
+			skb = skb_copy(buffered, gfp_any());
+		}
+	} else {
+		return NF_DROP;
+	}*/
+
+send:
+	entry->data_pkt_out++;
+	GMTP_SKB_CB(skb)->jumped = 0;
+	list_for_each_entry_safe(relay, temp, &entry->relays->list, list)
+	{
+		if(relay->state == GMTP_OPEN) {
+		/*	struct ethhdr *eth = eth_hdr(skb);
+			gh->dport = relay->port;
+			ether_addr_copy(eth->h_dest, relay->mac_addr);
+			skb->dev = relay->dev;
+
+			pr_info("Sending to %pI4:%d (%u)\n", &relay->addr,
+					htons(relay->port), gh->seq);
+			entry->ucc.congestion_control(skb, entry, relay);*/
+
+			struct sk_buff *buffered = skb_copy(skb, gfp_any());
+			struct ethhdr *eth = eth_hdr(buffered);
+			struct gmtp_hdr *buffgh = gmtp_hdr(buffered);
+
+			gmtp_ucc_buffer_add(buffered);
+
+			buffgh->dport = relay->port;
+			ether_addr_copy(eth->h_dest, relay->mac_addr);
+			buffered->dev = relay->dev;
+
+			pr_info("Sending to %pI4:%d (%u)\n", &relay->addr,
+								htons(relay->port),
+								buffgh->seq);
+			entry->ucc.congestion_control(buffered, entry, relay);
+
+			/*gmtp_inter_build_and_send_pkt(skb, iph->saddr,
+					relay->addr, gh, GMTP_INTER_FORWARD);*/
+		}
+	}
+
+	iph->daddr = entry->channel_addr;
+	ip_send_check(iph);
+	gh->relay = 1;
+	gh->dport = entry->channel_port;
+	gh->server_rtt = entry->server_rtt + entry->clients_rtt;
+
+	if(entry->nclients > 0) {
+		server_tx = entry->current_rx <= 0 ?
+				(unsigned int)gh->transm_r : entry->current_rx;
+		gmtp_inter_mcc_delay(entry, skb, (u64)server_tx);
+	}
+	ghd->tstamp = jiffies_to_msecs(jiffies);
+
+	gmtp_ucc_buffer_dequeue(skb);
+
+	return NF_ACCEPT;
+}
+
+static int gmtp_inter_close_from_client(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_hdr *gh_reset;
+	unsigned int skb_len = skb->len;
+	__u8 *transport_header = NULL;
+	int del = 0;
+
+	gmtp_pr_func();
+
+	pr_info("entry->nclients: %u\n", entry->nclients);
+	del = gmtp_delete_clients(&entry->clients->list, iph->saddr, gh->sport);
+	if(del == 0)
+		return NF_ACCEPT;
+	pr_info("del: %d\n", del);
+	entry->nclients -= del;
+	pr_info("entry->nclients - del: %u\n", entry->nclients);
+
+	gh_reset = gmtp_inter_make_reset_hdr(skb, GMTP_RESET_CODE_CLOSED);
+	if(gh_reset == NULL) {
+		gmtp_ucc_buffer_dequeue(skb);
+		return NF_DROP;
+	}
+
+	/*
+	 * Here, we have no clients.
+	 * So, we can send 'close' to server
+	 * and send a 'reset' to client.
+	 */
+	if(entry->nclients <= 0) {
+
+		/* Build and send back 'reset' */
+		pr_info("FIXME: Sending RESET back to client");
+		/*gmtp_inter_build_and_send_pkt(skb, iph->daddr, iph->saddr,
+				gh_reset, GMTP_INTER_BACKWARD);*/
+
+		/* FIXME Transform 'reset' into 'close' before forwarding */
+		/*if(gh->type == GMTP_PKT_RESET) {
+			gh_close = gmtp_inter_make_close_hdr(skb);
+			skb_trim(skb, (skb_len - gh->hdrlen));
+			skb_reset_transport_header(skb);
+			pr_info("gh: %p\n", gh);
+			pr_info("gh->hdrlen: %u\n", gh->hdrlen);
+			skb_put(skb, gh_close->hdrlen);
+			gh = gmtp_hdr(skb);
+			memcpy(gh, gh_close, gh_close->hdrlen);
+			iph = ip_hdr(skb);
+			iph->tot_len = ntohs(skb->len);
+		}*/
+		gh->relay = 1;
+		gh->sport = entry->my_port;
+		iph->saddr = entry->my_addr;
+		ip_send_check(iph);
+
+		gmtp_inter_del_entry(gmtp_inter.hashtable, entry->flowname);
+
+	} else {
+		/* Some clients still alive.
+		 * Only send 'reset' to clients, discarding 'close'
+		 * */
+		pr_info("Some clients still alive.\n");
+		skb_trim(skb, (skb_len - sizeof(struct gmtp_hdr)));
+		transport_header = skb_put(skb, gh_reset->hdrlen);
+		skb_reset_transport_header(skb);
+		memcpy(transport_header, gh_reset, gh_reset->hdrlen);
+
+		gh = gmtp_hdr(skb);
+		gh->relay = 1;
+		iph = ip_hdr(skb);
+		swap((iph->saddr), (iph->daddr));
+		ip_send_check(iph);
+	}
+
+	print_gmtp_packet(iph, gh);
+
+	return NF_ACCEPT;
+}
+
+int gmtp_inter_close_out(struct sk_buff *skb, struct gmtp_inter_entry *entry)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_relay *relay, *temp;
+
+	gmtp_pr_func();
+	print_packet(skb, false);
+	print_gmtp_packet(iph, gh);
+	gmtp_pr_info("State: %u", entry->state);
+
+	switch(entry->state) {
+	case GMTP_INTER_TRANSMITTING:
+		return gmtp_inter_close_from_client(skb, entry);
+	case GMTP_INTER_CLOSED:
+		pr_info("GMTP_CLOSED\n");
+		list_for_each_entry_safe(relay, temp,
+				&entry->relays->list, list)
+		{
+			/* FIXME Wait send all data pending */
+			pr_info("FORWARDING close to %pI4:%d\n",
+					&relay->addr,
+					ntohs(relay->port));
+			if(relay->state == GMTP_OPEN) {
+				struct sk_buff *new_skb = skb_copy(skb, gfp_any());
+				struct ethhdr *eth = eth_hdr(new_skb);
+
+				gh->dport = relay->port;
+				ether_addr_copy(eth->h_dest, relay->mac_addr);
+				skb->dev = relay->dev;
+				gmtp_inter_build_and_send_pkt(new_skb, iph->saddr,
+						relay->addr, gh,
+						GMTP_INTER_FORWARD);
+				relay->state = GMTP_CLOSED;
+			}
+		}
+
+		gh->relay = 1;
+		gh->dport = entry->channel_port;
+		iph->daddr = entry->channel_addr;
+		ip_send_check(iph);
+
+		server_hashtable->hash_ops.del_entry(server_hashtable,
+				gh->flowname);
+		gmtp_inter_del_entry(gmtp_inter.hashtable, gh->flowname);
+
+		return NF_ACCEPT;
+
+	case GMTP_INTER_CLOSE_RECEIVED:
+		pr_info("GMTP_INTER_CLOSE_RECEIVED -> GMTP_INTER_CLOSED\n");
+		entry->state = GMTP_INTER_CLOSED;
+		pr_info("nclients = %d\n", entry->nclients);
+		if(entry->nclients == 0)
+			return NF_REPEAT;
+		break;
+	}
+
+	while(entry->buffer->qlen > 0) {
+		struct sk_buff *buffered = gmtp_buffer_dequeue(entry);
+		if(buffered == NULL) {
+			gmtp_pr_error("Buffered is NULL...");
+			return NF_ACCEPT;
+		}
+
+		gmtp_hdr(buffered)->relay = 1;
+
+		if(iph->saddr == entry->my_addr) {
+			skb->dev = entry->dev_out;
+			gmtp_inter_build_and_send_skb(buffered, GMTP_INTER_LOCAL);
+		} else {
+			buffered->dev = skb->dev;
+			gmtp_inter_build_and_send_skb(buffered, GMTP_INTER_FORWARD);
+			return NF_REPEAT;
+		}
+	}
+
+	entry->state = GMTP_INTER_CLOSED;
+
+	return NF_STOLEN;
+}
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/relay.c linux-4.9-rc2/net/gmtp/gmtp-inter/relay.c
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/relay.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/relay.c	2016-12-01 16:50:35.593418154 -0300
@@ -0,0 +1,120 @@
+#include <linux/list.h>
+#include <linux/etherdevice.h>
+
+#include "../gmtp.h"
+#include "../hash.h"
+#include "hash-inter.h"
+
+struct gmtp_relay *gmtp_create_relay(__be32 addr, __be16 port)
+{
+	struct gmtp_relay *new = kmalloc(sizeof(struct gmtp_relay),
+			GFP_ATOMIC);
+
+	if(new != NULL) {
+		new->addr = addr;
+		new->port = port;
+		new->state = GMTP_CLOSED;
+		new->tx_rate = UINT_MAX;
+	}
+	return new;
+}
+
+/**
+ * Create and add a relay in the list of relays
+ */
+struct gmtp_relay *gmtp_list_add_relay(__be32 addr, __be16 port,
+		struct list_head *head)
+{
+	struct gmtp_relay *newr = gmtp_create_relay(addr, port);
+
+	if(newr == NULL) {
+		gmtp_pr_error("Error while creating new relay...");
+		return NULL;
+	}
+
+	INIT_LIST_HEAD(&newr->list);
+	list_add_tail(&newr->list, head);
+	return newr;
+}
+
+struct gmtp_relay *gmtp_inter_create_relay(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry, __u8 *relay_id)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct ethhdr *eth = eth_hdr(skb);
+	struct gmtp_relay *relay;
+
+	relay = gmtp_list_add_relay(iph->saddr, gh->sport, &entry->relays->list);
+	if(relay != NULL) {
+		++entry->nrelays;
+		ether_addr_copy(relay->mac_addr, eth->h_source);
+		relay->state = GMTP_CLOSED;
+		relay->losses = 0;
+		memcpy(relay->relay_id, relay_id, GMTP_RELAY_ID_LEN);
+	}
+	return relay;
+}
+
+struct gmtp_relay *gmtp_inter_create_relay_from_delegate(
+		struct gmtp_inter_entry *entry, __be32 addr, __be16 port,
+		__u8 *relay_id)
+{
+	struct gmtp_relay *relay;
+
+	relay = gmtp_list_add_relay(addr, port, &entry->relays->list);
+	if(relay != NULL) {
+		++entry->nrelays;
+		/*ether_addr_copy(relay->mac_addr, eth->h_source);*/
+		relay->state = GMTP_CLOSED;
+		relay->losses = 0;
+		memcpy(relay->relay_id, relay_id, GMTP_RELAY_ID_LEN);
+	}
+	return relay;
+}
+
+struct gmtp_relay* gmtp_get_relay(struct list_head *head,
+		__be32 addr, __be16 port)
+{
+	struct gmtp_relay *relay;
+	list_for_each_entry(relay, head, list)
+	{
+		if(relay->addr == addr && relay->port == port)
+			return relay;
+	}
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(gmtp_get_relay);
+
+int gmtp_delete_relays(struct list_head *list, __be32 addr, __be16 port)
+{
+	struct gmtp_relay *relay, *temp;
+	int ret = 0;
+
+	pr_info("Searching for %pI4@%-5d\n", &addr, ntohs(port));
+	pr_info("List of relays:\n");
+	list_for_each_entry_safe(relay, temp, list, list)
+	{
+		pr_info("Relay: %pI4@%-5d\n", &relay->addr,
+						ntohs(relay->port));
+		if(addr == relay->addr && port == relay->port) {
+			pr_info("Deleting relay: %pI4@%-5d\n", &relay->addr,
+					ntohs(relay->port));
+			list_del(&relay->list);
+			kfree(relay);
+			++ret;
+		}
+	}
+	if(ret == 0)
+		gmtp_pr_warning("Relay %pI4@%-5d was not found!", &addr,
+				ntohs(port));
+
+	return ret;
+}
+
+void print_gmtp_relay(struct gmtp_relay *r)
+{
+	pr_info("R: %pI4@%-5d\n", &r->addr, ntohs(r->port));
+}
+EXPORT_SYMBOL_GPL(print_gmtp_relay);
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/ucc.c linux-4.9-rc2/net/gmtp/gmtp-inter/ucc.c
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/ucc.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/ucc.c	2016-12-14 00:09:20.980296564 -0300
@@ -0,0 +1,338 @@
+/*
+ * gmtp-ucc.c
+ *
+ *  Created on: 08/03/2015
+ *      Author: wendell
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/ktime.h>
+#include <linux/kthread.h>
+#include <linux/sched.h>
+
+#include "../gmtp.h"
+#include "gmtp-inter.h"
+#include "ucc.h"
+
+extern struct gmtp_inter gmtp_inter;
+
+void gmtp_ucc_equation_callback(unsigned long data)
+{
+	/*unsigned int next = min(gmtp_inter.worst_rtt, gmtp_inter.h_user);
+	if(next <= 0)
+		next = GMTP_DEFAULT_RTT;*/
+
+	unsigned int next = GMTP_DEFAULT_RTT;
+	gmtp_pr_func();
+	gmtp_ucc_equation(GMTP_UCC_NONE);
+	mod_timer(&gmtp_inter.gmtp_ucc_timer, jiffies + msecs_to_jiffies(next));
+}
+
+unsigned int gmtp_relay_queue_size()
+{
+	return gmtp_inter.total_bytes_rx;
+}
+
+static inline unsigned long gmtp_ucc_interval(unsigned int rtt)
+{
+	unsigned long interval;
+	if(unlikely(rtt <= 0))
+		return (jiffies + GMTP_ACK_INTERVAL);
+
+	interval = (unsigned long)(rtt);
+	return (jiffies + msecs_to_jiffies(interval));
+}
+
+void gmtp_inter_ack_timer_callback(unsigned long data)
+{
+	struct gmtp_inter_entry *entry = (struct gmtp_inter_entry*) data;
+	struct sk_buff *skb;
+
+//	gmtp_ucc_equation(GMTP_UCC_NONE);
+	gmtp_ucc_equation(GMTP_UCC_ALL);
+	skb = gmtp_inter_build_ack(entry);
+	if(skb != NULL)
+		gmtp_inter_send_pkt(skb);
+
+	mod_timer(&entry->ack_timer, gmtp_ucc_interval(gmtp_inter.worst_rtt));
+}
+
+void gmtp_inter_register_timer_callback(unsigned long data)
+{
+	struct gmtp_inter_entry *entry = (struct gmtp_inter_entry*) data;
+	struct sk_buff *skb = gmtp_inter_build_register(entry);
+
+	if(skb != NULL)
+		gmtp_inter_send_pkt(skb);
+	mod_timer(&entry->register_timer, jiffies + HZ);
+}
+
+/**
+ * Get TX rate, via RCP
+ *
+ * FIXME Work with MSEC in RTT and TX.
+ * After convert to SEC...
+ */
+void gmtp_ucc_equation(enum gmtp_ucc_log_level log_level)
+{
+	int r = 0, H, h;
+	s64 up, mult, delta;
+
+	int r_prev = gmtp_inter.ucc_rx;
+	int C = gmtp_inter.capacity;
+	s64 q = gmtp_inter.buffer_len * 1000;
+   	int y = gmtp_inter.total_rx;
+   	int rcv_bytes = gmtp_inter.ucc_bytes;
+
+   	s64 alpha_cy, beta_qh;
+
+	unsigned long current_time = ktime_to_ms(ktime_get_real());
+	unsigned long elapsed = current_time - gmtp_inter.ucc_rx_tstamp;
+
+	if(elapsed != 0)
+		y = DIV_ROUND_CLOSEST(gmtp_inter.ucc_bytes * MSEC_PER_SEC, elapsed);
+		/*y = DIV_ROUND_CLOSEST(gmtp_inter.ucc_bytes, elapsed);*/ /* B/ms */
+
+	/* FIXME Sane RTT before using it (in server and relays) */
+	h = gmtp_inter.worst_rtt;
+	if(h <= 0) {
+		gmtp_pr_error("Error: h = %u. Assuming h = 64 ms", h);
+		h = GMTP_DEFAULT_RTT;
+	}
+	H = min(h, gmtp_inter.h_user);
+
+	alpha_cy = (s64) GMTP_ALPHA(GMTP_GHAMA(C)-y);
+	beta_qh = (s64) GMTP_BETA(q / h);
+	up = DIV_ROUND_CLOSEST(H, h) * (alpha_cy - beta_qh);
+	/*up = DIV_ROUND_CLOSEST(H, h) * (GMTP_ALPHA(GMTP_GHAMA(C)-y) - GMTP_BETA(q / h));*/
+	/*delta = DIV_ROUND_CLOSEST(r_prev * up, GMTP_GHAMA(C));*/
+
+	mult = up * (s64)r_prev; /* s64 */
+	delta = 0; // DIV_ROUND_CLOSEST(mult, (s64) GMTP_GHAMA(C));
+
+	/*delta = (r_prev * up) / GMTP_GHAMA(C);*/
+
+	/**
+	 * r = r_prev * (1 + up/GHAMA(C)) =>
+	 * r = r_prev + [(r_prev * up) / GMTP_GHAMA(C)] =>
+	 * r = r_prev + delta
+	 */
+	r = r_prev + (int) delta;
+	r = max(r, 1000);
+	r = min(r, GMTP_GHAMA(C));
+	gmtp_inter.ucc_rx = r;
+
+	/* Reset GMTP-UCC variables */
+	gmtp_inter.ucc_bytes = 0;
+	gmtp_inter.ucc_rx_tstamp = ktime_to_ms(ktime_get_real());
+	gmtp_inter.total_rx = y;
+
+	if(log_level > GMTP_UCC_NONE) {
+
+		if(log_level > GMTP_UCC_OUTPUT) {
+			pr_info("------------------------------------------\n");
+			gmtp_pr_debug("r_prev: %d B/s", r_prev);
+			gmtp_pr_debug("Received: %d B\n", rcv_bytes);
+			gmtp_pr_debug("h_user: %d ms", gmtp_inter.h_user);
+			gmtp_pr_debug("h0: %d ms", h);
+			gmtp_pr_debug("H: %d ms", H);
+			gmtp_pr_debug("C: %d B/s", C);
+			gmtp_pr_debug("y(t): %d B/s", y);
+			gmtp_pr_debug("buffer(t): %u B", gmtp_inter.buffer_len);
+			gmtp_pr_debug("q(t): %lld B", q);
+			gmtp_pr_debug("H/h0: %d\n", DIV_ROUND_CLOSEST(H, h));
+
+			if(log_level > GMTP_UCC_DEBUG) {
+				gmtp_pr_debug("GHAMA(C): %d", GMTP_GHAMA(C));
+				gmtp_pr_debug("GHAMA(C)-y: %d", GMTP_GHAMA(C)-y);
+				gmtp_pr_debug("ALPHA(GHAMA(C)-y): %lld", alpha_cy);
+				gmtp_pr_debug("up = ((H / h) * [ALPHA(GHAMA(C)-y) " "- BETA(q / h)])");
+				gmtp_pr_debug("up = %d * [%lld - %lld]", H / h,
+						alpha_cy, beta_qh);
+				gmtp_pr_debug("up = %lld\n", up);
+				gmtp_pr_debug("delta = (r_prev * up)/GHAMA(C)");
+				gmtp_pr_debug("delta = (%d * %lld)/%d", r_prev,
+						up, GMTP_GHAMA(C));
+				gmtp_pr_debug("delta = %lld/%d", mult,
+						GMTP_GHAMA(C));
+
+			}
+
+			gmtp_pr_debug("delta = %lld", delta);
+			gmtp_pr_debug("new_r = (int)(r_prev) + delta");
+			gmtp_pr_debug("new_r = %d + %lld\n", r_prev, delta);
+		}
+		gmtp_pr_debug("new_r = %d B/s", r);
+
+		if(log_level > GMTP_UCC_OUTPUT)
+			pr_info("------------------------------------------\n");
+	}
+
+}
+EXPORT_SYMBOL_GPL(gmtp_ucc_equation);
+
+int gmtp_inter_build_ucc(struct gmtp_inter_ucc_protocol *ucc,
+		enum gmtp_ucc_type ucc_type)
+{
+	switch(ucc_type) {
+	case GMTP_DELAY_UCC:
+		ucc->congestion_control = gmtp_inter_delay_cc;
+		break;
+	case GMTP_MEDIA_ADAPT_UCC:
+		ucc->congestion_control = gmtp_inter_media_adapt_cc;
+		break;
+	default:
+		return 1;
+		break;
+	}
+
+	return 0;
+}
+
+struct gmtp_delay_cc_data {
+	struct sk_buff *skb;
+	struct gmtp_inter_entry *entry;
+	struct gmtp_relay *relay;
+	struct timer_list *delay_cc_timer;
+};
+
+void gmtp_inter_xmit_timer(unsigned long data)
+{
+	struct gmtp_delay_cc_data *cc_data = (struct gmtp_delay_cc_data *) data;
+	gmtp_inter_delay_cc(cc_data->skb, cc_data->entry, cc_data->relay);
+	del_timer(cc_data->delay_cc_timer);
+	kfree(cc_data->delay_cc_timer);
+}
+
+void gmtp_inter_delay_cc(struct sk_buff *skb, struct gmtp_inter_entry *entry,
+		struct gmtp_relay *relay)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+	unsigned long elapsed = 0;
+	long delay = 0, delay2 = 0, delay_budget = 0;
+	unsigned long tx_rate = relay->tx_rate;
+	int len;
+
+	/** TODO Continue tests with different scales... */
+	static const int scale = 1;
+	/*static const int scale = HZ/100;*/
+
+	if(tx_rate == UINT_MAX)
+		goto send;
+
+	elapsed = jiffies - entry->last_data_tstamp;
+	len = skb->len;
+	if(relay->tx_byte_budget >= mult_frac(len, 3, 4)) {
+		goto send;
+	} else if(relay->tx_byte_budget != INT_MIN) {
+		delay_budget = scale;
+		goto wait;
+	}
+
+	delay = DIV_ROUND_CLOSEST((HZ * len), tx_rate);
+	delay2 = delay - elapsed;
+
+	/*if(delay2 > 0)
+		delay2 += mult_frac(delay2, get_rate_gap(gp, 1), 100);*/
+
+wait:
+	delay2 += delay_budget;
+
+	if(delay <= 0)
+		relay->tx_byte_budget =	mult_frac(scale, tx_rate, HZ) /*-
+			mult_frac(relay->tx_byte_budget,
+					(int) get_rate_gap(gp, 0), 100)*/;
+	else
+		relay->tx_byte_budget = INT_MIN;
+
+	/* Subcaminhos GMTP-UCC... */
+	 if(delay2 > 0) {
+		struct gmtp_delay_cc_data *cc_data;
+		cc_data = kmalloc(sizeof(struct gmtp_delay_cc_data), GFP_KERNEL);
+		cc_data->skb = skb;
+		cc_data->entry = entry;
+		cc_data->relay = relay;
+		cc_data->delay_cc_timer = kmalloc(sizeof(struct timer_list),
+				GFP_KERNEL);
+
+		setup_timer(cc_data->delay_cc_timer, gmtp_inter_xmit_timer,
+				(unsigned long) cc_data);
+		mod_timer(cc_data->delay_cc_timer, jiffies + delay2);
+
+		schedule_timeout(delay2);
+		return;
+	}
+
+send:
+	gmtp_inter_build_and_send_pkt(skb, iph->saddr, relay->addr, gh,
+			GMTP_INTER_FORWARD);
+	gmtp_ucc_buffer_dequeue(skb);
+
+}
+
+void gmtp_inter_media_adapt_cc(struct sk_buff *skb, struct gmtp_inter_entry *entry,
+		struct gmtp_relay *relay)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+	unsigned int len, hdrlen, datalen, datalen20, datalen40, datalen80;
+	unsigned int rate, new_datalen;
+	unsigned int rx_rate = entry->current_rx <= 0 ?
+			(unsigned int) entry->transm_r : entry->current_rx;
+
+	hdrlen = gmtp_data_hdr_len() + ip_hdrlen(skb);
+	new_datalen = datalen = skb->len - hdrlen;
+
+	if(relay->tx_rate >= rx_rate)
+		goto send;
+
+	rate = DIV_ROUND_CLOSEST(1000 * rx_rate,
+			(unsigned int) relay->tx_rate);
+
+	if(rate == 0)
+		goto send;
+
+	datalen20 = DIV_ROUND_CLOSEST(200 * skb->len, 1000) - hdrlen;
+	datalen40 = DIV_ROUND_CLOSEST(400 * skb->len, 1000) - hdrlen;
+	datalen80 = DIV_ROUND_CLOSEST(800 * skb->len, 1000) - hdrlen;
+
+	new_datalen = DIV_ROUND_CLOSEST(skb->len * 1000, rate) - hdrlen;
+
+	char label[90];
+
+	if(new_datalen >= datalen80)
+		new_datalen = datalen80;
+	else if(new_datalen >= datalen40)
+		new_datalen = datalen40;
+	else if(new_datalen >= datalen20)
+		new_datalen = datalen20;
+	else {
+		goto drop;
+	}
+
+	if(new_datalen < 0) {
+		goto drop;
+
+	}
+
+	sprintf(label, "Cur_RX: %u B/s, TX: %lu B/s. Data to %pI4, reducing to %u B (-%u B): ",
+			rx_rate, relay->tx_rate, &relay->addr, new_datalen,
+			(datalen - new_datalen));
+	print_gmtp_data(skb, label);
+
+send:
+	gmtp_inter_build_and_send_pkt_len(skb, iph->saddr, relay->addr,
+			gh, new_datalen, GMTP_INTER_FORWARD);
+	return;
+drop:
+	sprintf(label, "Cur_RX: %u B/s, TX: %lu B/s. Dropping packet to %pI4: ",
+			rx_rate, relay->tx_rate, &relay->addr);
+	print_gmtp_data(skb, label);
+}
+
+
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp-inter/ucc.h linux-4.9-rc2/net/gmtp/gmtp-inter/ucc.h
--- linux-4.9-rc2-original/net/gmtp/gmtp-inter/ucc.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp-inter/ucc.h	2016-12-13 23:57:38.540078275 -0300
@@ -0,0 +1,59 @@
+/*
+ * ucc.h
+ *
+ *  Created on: 14/05/2015
+ *      Author: wendell
+ */
+
+#ifndef UCC_H_
+#define UCC_H_
+
+#define GMTP_ALPHA(X) DIV_ROUND_CLOSEST((X) * 30, 100) /* X*0.3 */
+#define GMTP_BETA(X)  DIV_ROUND_CLOSEST((X) * 60, 100) /* X*0.6 */
+#define GMTP_GHAMA(X) (X) /* DIV_ROUND_CLOSEST(X * 100, 100) /* X*1.0 */
+#define GMTP_THETA(X) DIV_ROUND_CLOSEST((X) * 2000, 100000) /* X*0.02 */
+#define GMTP_ONE_MINUS_THETA(X) DIV_ROUND_CLOSEST((X) * 98000, 100000) /* X*(1-0.02) */
+
+#include "gmtp-inter.h"
+
+enum gmtp_ucc_log_level {
+	GMTP_UCC_NONE,
+	GMTP_UCC_OUTPUT,
+	GMTP_UCC_DEBUG,
+	GMTP_UCC_ALL
+};
+
+/** gmtp-ucc. */
+void gmtp_ucc_equation_callback(unsigned long);
+unsigned int gmtp_relay_queue_size(void);
+void gmtp_inter_ack_timer_callback(unsigned long data);
+void gmtp_inter_register_timer_callback(unsigned long data);
+
+void gmtp_ucc_equation(enum gmtp_ucc_log_level log_level);
+
+
+struct gmtp_relay;
+struct gmtp_inter_entry;
+
+struct gmtp_inter_ucc_protocol {
+	void (*congestion_control)(struct sk_buff *skb,
+			struct gmtp_inter_entry *entry,
+			struct gmtp_relay *relay);
+};
+
+int gmtp_inter_build_ucc(struct gmtp_inter_ucc_protocol *ucc,
+		enum gmtp_ucc_type ucc_type);
+
+void gmtp_inter_delay_cc(struct sk_buff *skb, struct gmtp_inter_entry *entry,
+		struct gmtp_relay *relay);
+void gmtp_inter_media_adapt_cc(struct sk_buff *skb,
+		struct gmtp_inter_entry *entry, struct gmtp_relay *relay);
+
+struct gmtp_inter_ucc_info {
+	struct sk_buff *skb;
+	struct gmtp_inter_entry *entry;
+	struct gmtp_relay *relay;
+	struct timer_list *timer;
+};
+
+#endif /* UCC_H_ */
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/gmtp.h linux-4.9-rc2/net/gmtp/gmtp.h
--- linux-4.9-rc2-original/net/gmtp/gmtp.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/gmtp.h	2016-12-04 03:22:15.287628093 -0300
@@ -0,0 +1,324 @@
+/*
+ * gmtp.h
+ *
+ *  Created on: 18/06/2014
+ *      Author: Wendell Silva Soares <wendell@compelab.org>
+ */
+
+#ifndef GMTP_H_
+#define GMTP_H_
+
+#include <net/inet_timewait_sock.h>
+#include <net/inet_hashtables.h>
+#include <uapi/asm-generic/errno.h>
+#include <uapi/linux/ip.h>
+#include <linux/types.h>
+#include <linux/skbuff.h>
+
+#include <net/tcp.h>
+#include <net/netns/gmtp.h>
+#include <linux/gmtp.h>
+#include <uapi/linux/gmtp.h>
+
+#include "hash.h"
+
+/** GMTP Debugs */
+#define GMTP_INFO "[GMTP] %s:%d - "
+#define GMTP_DEBUG GMTP_INFO
+#define GMTP_WARNING "[GMTP_WARNING]  %s:%d - "
+#define GMTP_ERROR "[GMTP_ERROR] %s:%d - "
+
+/* TODO Improve debug func names */
+#define gmtp_print_debug(fmt, args...) pr_info(GMTP_DEBUG fmt \
+        "\n", __FUNCTION__, __LINE__, ##args)
+#define gmtp_print_warning(fmt, args...) pr_warning(GMTP_WARNING fmt \
+        "\n", __FUNCTION__, __LINE__, ##args)
+#define gmtp_print_error(fmt, args...) pr_err(GMTP_ERROR fmt \
+        "\n", __FUNCTION__, __LINE__, ##args)
+#define gmtp_print_function() pr_info("-------- %s --------\n" , __FUNCTION__)
+
+/* Better print names */
+#define gmtp_pr_func() pr_info("-------- %s --------\n" , __FUNCTION__)
+#define gmtp_pr_info(fmt, args...) pr_info(GMTP_DEBUG fmt \
+        "\n", __FUNCTION__, __LINE__, ##args)
+#define gmtp_pr_debug(fmt, args...) gmtp_pr_info(fmt, ##args);
+#define gmtp_pr_warning(fmt, args...) pr_warning(GMTP_WARNING fmt \
+        "\n", __FUNCTION__, __LINE__, ##args)
+#define gmtp_pr_error(fmt, args...) pr_err(GMTP_ERROR fmt \
+        "\n", __FUNCTION__, __LINE__, ##args)
+
+/** ---- */
+#define GMTP_MAX_HDR_LEN 2047  /* 2^11 - 1 */
+#define GMTP_FIXED_HDR_LEN 36  /* theoretically: 32 bytes, In fact: 36 bytes */
+#define GMTP_MAX_VARIABLE_HDR_LEN (GMTP_MAX_HDR_LEN - GMTP_FIXED_HDR_LEN)
+
+#define GMTP_MIN_SAMPLE_LEN 100 /* Minimal sample to measure 'instant' Tx rate*/
+#define GMTP_DEFAULT_SAMPLE_LEN 1000 /* Sample to measure 'instant' Tx rate */
+#define GMTP_MAX_SAMPLE_LEN 10000 /* Max sample to measure 'instant' Tx rate */
+
+/**
+ * Based on TCP Default Maximum Segment Size calculation
+ * The solution to these two competing issues was to establish a default MSS
+ * for TCP that was as large as possible while avoiding fragmentation for most
+ * transmitted segments.
+ * This was computed by starting with the minimum MTU for IP networks of 576.
+ * All networks are required to be able to handle an IP datagram of this size
+ * without fragmenting.
+ * From this number, we subtract 36 bytes for the GMTP header and 20 for the
+ * IP header, leaving 536 bytes. This is the standard MSS for GMTP.
+ */
+#define GMTP_DEFAULT_MSS (576 - GMTP_FIXED_HDR_LEN - 20)
+
+#define GMTP_DEFAULT_RTT    64  /* milisseconds */
+#define GMTP_MIN_RTT_MS     1  /* milisseconds */
+/*
+ * RTT sampling: sanity bounds and fallback RTT value from RFC 4340, section 3.4
+ * Units in usec (microseconds)
+ */
+#define GMTP_SANE_RTT_MIN   100         /* 0.1 ms */
+#define GMTP_FALLBACK_RTT   ((GMTP_DEFAULT_RTT * USEC_PER_MSEC) / 5)
+#define GMTP_SANE_RTT_MAX   (3 * USEC_PER_SEC)  /* 3 s    */
+#define GMTP_RTT_WEIGHT     20  /* 0.02 */
+
+/**
+ * rtt_ewma  -  Exponentially weighted moving average
+ * @weight: Weight to be used as damping factor, in units of 1/1000
+ *      factor 1/1000 allows better weight granularity
+ */
+static inline u32 rtt_ewma(const u32 avg, const u32 newval, const u32 weight)
+{
+    return avg ? (weight * avg + (1000 - weight) * newval) / 1000 : newval;
+}
+
+/* initial RTO value
+ * The back-off value for retransmissions. This is needed for
+ *  - retransmitting Client-Requests
+ *  - retransmitting Close/CloseReq when closing
+ */
+#define GMTP_TIMEOUT_INIT ((unsigned int)(3 * HZ))
+#define GMTP_RTO_MAX ((unsigned int)(64 * HZ))
+#define GMTP_TIMEWAIT_LEN (60 * HZ)
+#define GMTP_REQ_INTERVAL (TCP_SYNQ_INTERVAL)
+#define GMTP_SYN_RETRIES (2 * TCP_SYN_RETRIES)
+
+/* For reporters and servers keep_alive */
+#define GMTP_ACK_INTERVAL ((unsigned int)(HZ))
+#define GMTP_ACK_TIMEOUT  (4 * GMTP_ACK_INTERVAL)
+
+#define MD5_LEN GMTP_RELAY_ID_LEN
+
+/* Int to __U12 operations */
+#define TO_U12(x)   min((U16_MAX >> 4), (x))
+#define SUB_U12(a, b)   min((U16_MAX >> 4), (a-b))
+#define ADD_U12(a, b)   min((U16_MAX >> 4), (a+b))
+
+extern struct gmtp_info *gmtp_info;
+extern struct inet_hashinfo gmtp_inet_hashinfo;
+extern struct percpu_counter gmtp_orphan_count;
+extern struct gmtp_hashtable *client_hashtable;
+extern struct gmtp_hashtable *server_hashtable;
+
+void gmtp_init_xmit_timers(struct sock *sk);
+static inline void gmtp_clear_xmit_timers(struct sock *sk)
+{
+    inet_csk_clear_xmit_timers(sk);
+    if(gmtp_sk(sk)->type == GMTP_SOCK_TYPE_REGULAR
+            && gmtp_sk(sk)->role == GMTP_ROLE_CLIENT) {
+        if(gmtp_sk(sk)->myself->rsock != NULL)
+            inet_csk_clear_xmit_timers(gmtp_sk(sk)->myself->rsock);
+    }
+}
+
+static inline u32 gmtp_get_elect_timeout(struct gmtp_sock *gp)
+{
+    return (gp->rx_rtt > 0 ? gp->rx_rtt : GMTP_DEFAULT_RTT);
+}
+
+/** proto.c */
+unsigned char *gmtp_build_md5(unsigned char *buf);
+unsigned char *gmtp_inter_build_relay_id(void);
+__be32 gmtp_dev_ip(struct net_device *dev);
+bool gmtp_local_ip(__be32 ip);
+void gmtp_add_relayid(struct sk_buff *skb);
+int gmtp_init_sock(struct sock *sk);
+void gmtp_done(struct sock *sk);
+void gmtp_close(struct sock *sk, long timeout);
+int gmtp_connect(struct sock *sk);
+int gmtp_disconnect(struct sock *sk, int flags);
+int gmtp_ioctl(struct sock *sk, int cmd, unsigned long arg);
+int gmtp_sendmsg(struct sock *sk, struct msghdr *msg, size_t size);
+int gmtp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int nonblock,
+        int flags, int *addr_len);
+void gmtp_shutdown(struct sock *sk, int how);
+void gmtp_destroy_sock(struct sock *sk);
+void gmtp_set_state(struct sock*, const int);
+int inet_gmtp_listen(struct socket *sock, int backlog);
+const char *gmtp_packet_name(const __u8);
+const char *gmtp_state_name(const int);
+void flowname_str(__u8* str, const __u8 *flowname);
+void print_gmtp_packet(const struct iphdr *iph, const struct gmtp_hdr *gh);
+void print_gmtp_data(struct sk_buff *skb, char* label);
+void print_gmtp_hdr_relay(const struct gmtp_hdr_relay *relay);
+void print_route_from_skb(struct sk_buff *skb);
+void print_route_from_list(struct gmtp_relay_entry *relay_list);
+void print_gmtp_sock(struct sock *sk);
+
+/** sockopt.c */
+int gmtp_getsockopt(struct sock *sk, int level, int optname,
+        char __user *optval, int __user *optlen);
+int gmtp_setsockopt(struct sock *sk, int level, int optname,
+        char __user *optval, unsigned int optlen);
+
+/** ipv4.c */
+int gmtp_v4_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len);
+
+/** input.c */
+struct sock* gmtp_multicast_connect(struct sock *sk, enum gmtp_sock_type type,
+        __be32 addr, __be16 port);
+struct sock* gmtp_sock_connect(struct sock *sk, enum gmtp_sock_type type,
+        __be32 addr, __be16 port);
+int gmtp_rcv_established(struct sock *sk, struct sk_buff *skb,
+        const struct gmtp_hdr *dh, const unsigned int len);
+int gmtp_rcv_state_process(struct sock *sk, struct sk_buff *skb,
+        struct gmtp_hdr *gh, unsigned int len);
+
+/** output.c */
+void gmtp_send_ack(struct sock *sk);
+void gmtp_send_route_notify(struct sock *sk, struct sk_buff *rcv_skb);
+void gmtp_send_elect_request(struct sock *sk, unsigned long interval);
+void gmtp_send_elect_response(struct sock *sk, __u8 code);
+void gmtp_send_feedback(struct sock *sk);
+void gmtp_send_close(struct sock *sk, const int active);
+int gmtp_send_reset(struct sock *sk, enum gmtp_reset_codes code);
+void gmtp_write_xmit(struct sock *sk, struct sk_buff *skb);
+unsigned int gmtp_sync_mss(struct sock *sk, u32 pmtu);
+int gmtp_transmit_built_skb(struct sock *sk, struct sk_buff *skb);
+struct sk_buff *gmtp_make_register_reply(struct sock *sk, struct dst_entry *dst,
+        struct request_sock *req);
+struct sk_buff *gmtp_make_register_reply_open(struct sock *sk,
+        struct sk_buff *rcv_skb);
+struct sk_buff *gmtp_make_delegate(struct sock *sk, struct sk_buff *rcv_skb,
+        __u8 *rid);
+struct sk_buff *gmtp_ctl_make_reset(struct sock *sk,
+        struct sk_buff *rcv_skb);
+/** output.c - Packet Output and Timers  */
+void gmtp_write_xmit_timer(unsigned long data);
+void gmtp_write_space(struct sock *sk);
+int gmtp_retransmit_skb(struct sock *sk);
+struct sk_buff *gmtp_ctl_make_elect_response(struct sock *sk,
+        struct sk_buff *rcv_skb);
+struct sk_buff *gmtp_ctl_make_ack(struct sock *sk, struct sk_buff *rcv_skb);
+
+/** minisocks.c */
+void gmtp_time_wait(struct sock *sk, int state, int timeo);
+int gmtp_reqsk_init(struct request_sock *rq, struct gmtp_sock const *gp,
+        struct sk_buff const *skb);
+struct sock *gmtp_create_openreq_child(struct sock *sk,
+                       const struct request_sock *req,
+                       const struct sk_buff *skb);
+int gmtp_child_process(struct sock *parent, struct sock *child,
+               struct sk_buff *skb);
+struct sock *gmtp_check_req(struct sock *sk, struct sk_buff *skb,
+                struct request_sock *req);
+void gmtp_reqsk_send_ack(const struct sock *sk, struct sk_buff *skb,
+             struct request_sock *rsk);
+unsigned int gmtp_poll(struct file *file, struct socket *sock, poll_table *wait);
+
+
+/** GMTP structs and etc **/
+struct gmtp_info {
+    unsigned char       relay_id[GMTP_RELAY_ID_LEN];
+    unsigned char       relay_enabled:1;
+    int pkt_sent;
+
+    struct sock     *control_sk;
+    struct sockaddr_in  *ctrl_addr;
+};
+
+static inline void kfree_gmtp_info(struct gmtp_info *gmtp_info)
+{
+    if(gmtp_info->control_sk != NULL)
+        kfree(gmtp_info->control_sk);
+    if(gmtp_info->ctrl_addr != NULL)
+        kfree(gmtp_info->ctrl_addr);
+    kfree(gmtp_info);
+}
+
+/**
+ * This is the control buffer. It is free to use by any layer.
+ * This is an opaque area used to store private information.
+ *
+ * struct sk_buff {
+ * (...)
+ *      char cb[48]
+ * }
+ *
+ * gmtp_skb_cb  -  GMTP per-packet control information
+ *
+ * @type: one of %gmtp_pkt_type (or unknown)
+ * @ackcode: ack code. One of sock, one of %gmtp_ack_codes
+ * @reset_code: one of %gmtp_reset_codes
+ * @reset_data: Data1..3 fields (depend on @gmtpd_reset_code)
+ * @seq: sequence number
+ * @orig_tstamp: time stamp of last data packet (stamped at origin)
+ * @jumped: used in gmtp-inter. It is 1 if "jump_over_gmtp_intra" was called.
+ *
+ * This is used for transmission as well as for reception.
+ */
+struct gmtp_skb_cb {
+    __u8 type :5;
+    __be16  hdrlen:11;
+    __u8 reset_code,
+        reset_data[3];
+    __u8 elect_code:2;
+    __u8 retransmits;
+    __be32 seq;
+    __be32 orig_tstamp;
+    __u8 jumped;
+};
+
+#define GMTP_SKB_CB(__skb) ((struct gmtp_skb_cb *)&((__skb)->cb[0]))
+
+/**
+ * Returns subtraction of two ktimes, in __be32 format (milliseconds)
+ */
+static inline __be32 ktime_sub_ms_be32(ktime_t last, ktime_t first)
+{
+    return (__be32) ktime_to_ms(ktime_sub(last, first));
+}
+
+/**
+ * gmtp_loss_count - Approximate the number of lost data packets in a burst loss
+ * @s1:  last known sequence number before the loss ('hole')
+ * @s2:  first sequence number seen after the 'hole'
+ */
+static inline __be32 gmtp_loss_count(const __be32 s1, const __be32 s2,
+        const __be32 ndp)
+{
+    __be32 delta = s2 - s1;
+
+    WARN_ON(delta < 0);
+    delta -= ndp + 1;
+
+    return delta > 0 ? delta : 0;
+}
+
+/**
+ * gmtp_loss_free - Evaluate condition for data loss from RFC 4340, 7.7.1
+ */
+static inline bool gmtp_loss_free(const __be32 s1, const __be32 s2,
+        const __be32 ndp)
+{
+    return gmtp_loss_count(s1, s2, ndp) == 0;
+}
+
+static inline int gmtp_data_packet(const struct sk_buff *skb)
+{
+    const __u8 type = GMTP_SKB_CB(skb)->type;
+
+    return type == GMTP_PKT_DATA     ||
+           type == GMTP_PKT_DATAACK;
+}
+
+#endif /* GMTP_H_ */
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/hash/client.c linux-4.9-rc2/net/gmtp/hash/client.c
--- linux-4.9-rc2-original/net/gmtp/hash/client.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/hash/client.c	2016-12-01 16:50:35.706416742 -0300
@@ -0,0 +1,121 @@
+/*
+ * client.c
+ *
+ *  Created on: 20/08/2015
+ *      Author: wendell
+ */
+
+#include <linux/list.h>
+
+#include "../gmtp.h"
+#include "hash.h"
+
+struct gmtp_client *gmtp_create_client(__be32 addr, __be16 port,
+		__u8 max_nclients)
+{
+	struct gmtp_client *new = kmalloc(sizeof(struct gmtp_client),
+	GFP_ATOMIC);
+
+	if(new != NULL) {
+		new->addr = addr;
+		new->port = port;
+		new->max_nclients = max_nclients;
+		new->nclients = 0;
+		new->ack_rx_tstamp = 0;
+
+		new->clients = 0;
+		new->reporter = 0;
+		new->rsock = 0;
+		new->mysock = 0;
+	}
+	return new;
+}
+
+/**
+ * Create and add a client in the list of clients
+ */
+struct gmtp_client *gmtp_list_add_client(u32 id, __be32 addr, __be16 port,
+		__u8 max_nclients, struct list_head *head)
+{
+	struct gmtp_client *newc = gmtp_create_client(addr, port, max_nclients);
+
+	if(newc == NULL) {
+		gmtp_pr_error("Error while creating new gmtp_client...");
+		return NULL;
+	}
+
+	newc->id = id;
+	gmtp_pr_info("New client (%u): ADDR=%pI4@%-5d",
+			newc->id, &addr, ntohs(port));
+
+	INIT_LIST_HEAD(&newc->list);
+	list_add_tail(&newc->list, head);
+	return newc;
+}
+
+struct gmtp_client* gmtp_get_first_client(struct list_head *head)
+{
+	struct gmtp_client *client;
+	list_for_each_entry(client, head, list)
+	{
+		return client;
+	}
+	return NULL;
+}
+
+struct gmtp_client* gmtp_get_client(struct list_head *head,
+		__be32 addr, __be16 port)
+{
+	struct gmtp_client *client;
+	list_for_each_entry(client, head, list)
+	{
+		if(client->addr == addr && client->port == port)
+			return client;
+	}
+	return NULL;
+}
+
+struct gmtp_client* gmtp_get_client_by_id(struct list_head *head,
+		unsigned int id)
+{
+	struct gmtp_client *client;
+	list_for_each_entry(client, head, list)
+	{
+		if(client->id == id)
+			return client;
+	}
+	return NULL;
+}
+
+int gmtp_delete_clients(struct list_head *list, __be32 addr, __be16 port)
+{
+	struct gmtp_client *client, *temp;
+	int ret = 0;
+
+	pr_info("Searching for %pI4@%-5d\n", &addr, ntohs(port));
+	pr_info("List of clients:\n");
+	list_for_each_entry_safe(client, temp, list, list)
+	{
+		pr_info("Client: %pI4@%-5d\n", &client->addr,
+							ntohs(client->port));
+		if(addr == client->addr && port == client->port) {
+			pr_info("Deleting client: %pI4@%-5d\n", &client->addr,
+					ntohs(client->port));
+			list_del(&client->list);
+			kfree(client);
+			++ret;
+		}
+	}
+	if(ret == 0)
+		gmtp_pr_warning("Client %pI4@%-5d was not found!", &addr,
+				ntohs(port));
+
+	return ret;
+}
+
+void print_gmtp_client(struct gmtp_client *c)
+{
+	pr_info("C: %pI4@%-5d\n", &c->addr, ntohs(c->port));
+}
+EXPORT_SYMBOL_GPL(print_gmtp_client);
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/hash/hash.c linux-4.9-rc2/net/gmtp/hash/hash.c
--- linux-4.9-rc2-original/net/gmtp/hash/hash.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/hash/hash.c	2016-12-01 16:50:35.706416742 -0300
@@ -0,0 +1,138 @@
+/*
+ * hash.c
+ *
+ *  Created on: 27/02/2015
+ *      Author: mario
+ */
+
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+
+#include "../gmtp.h"
+#include "hash.h"
+
+struct gmtp_hashtable *gmtp_build_hashtable(unsigned int size,
+		struct gmtp_hash_ops hash_ops)
+{
+	int i;
+	struct gmtp_hashtable *new_table;
+
+	gmtp_print_function();
+	gmtp_print_debug("Size of gmtp_hashtable: %d", size);
+
+	if(size < 1)
+		return NULL;
+
+	new_table = kmalloc(sizeof(struct gmtp_hashtable), GFP_KERNEL);
+	if(new_table == NULL)
+		return NULL;
+
+	new_table->entry = kmalloc(sizeof(void*) * size, GFP_KERNEL);
+
+	if(new_table->entry == NULL)
+		return NULL;
+
+	for(i = 0; i < size; ++i)
+		new_table->entry[i] = NULL;
+
+	new_table->size = size;
+	new_table->len = 0;
+	new_table->hash_ops = hash_ops;
+	new_table->hashval = hash_ops.hashval;
+	new_table->add_entry = hash_ops.add_entry;
+	new_table->del_entry = hash_ops.del_entry;
+	new_table->destroy = hash_ops.destroy;
+
+	return new_table;
+}
+EXPORT_SYMBOL_GPL(gmtp_build_hashtable);
+
+void kfree_gmtp_hashtable(struct gmtp_hashtable *table)
+{
+	table->destroy(table);
+}
+EXPORT_SYMBOL_GPL(kfree_gmtp_hashtable);
+
+unsigned int gmtp_hashval(struct gmtp_hashtable *table, const __u8 *key)
+{
+	unsigned int hashval;
+	int i;
+
+	if(unlikely(table == NULL))
+		return -EINVAL;
+
+	if(unlikely(key == NULL))
+		return -ENOKEY;
+
+	hashval = 0;
+	for(i = 0; i < GMTP_HASH_KEY_LEN; ++i)
+		hashval = key[i] + (hashval << 5) - hashval;
+
+	return hashval % table->size;
+}
+
+struct gmtp_hash_entry *gmtp_lookup_entry(struct gmtp_hashtable *table,
+		const __u8 *key)
+{
+	struct gmtp_hash_entry *entry;
+	unsigned int hashval = table->hashval(table, key);
+
+	/* Error */
+	if(hashval < 0)
+		return NULL;
+
+	entry = table->entry[hashval];
+	for(; entry != NULL; entry = entry->next)
+		if(memcmp(key, entry->key, GMTP_HASH_KEY_LEN) == 0)
+			return entry;
+	return NULL;
+}
+
+int gmtp_add_entry(struct gmtp_hashtable *table, struct gmtp_hash_entry *entry)
+{
+	struct gmtp_hash_entry *cur_entry;
+	unsigned int hashval;
+
+	gmtp_print_function();
+
+	hashval = table->hashval(table, entry->key);
+	if(hashval < 0)
+		return hashval;
+
+	/** Primary key at client hashtable is flowname */
+	cur_entry = gmtp_lookup_entry(table, entry->key);
+	if(cur_entry != NULL)
+		return 1; /* Entry already exists */
+
+	entry->next = table->entry[hashval];
+	table->entry[hashval] = entry;
+	table->len++;
+
+	return 0;
+}
+
+void destroy_gmtp_hashtable(struct gmtp_hashtable *table)
+{
+	int i;
+	struct gmtp_hash_entry *entry, *tmp;
+
+	gmtp_print_function();
+
+	if(table == NULL)
+		return;
+
+	for(i = 0; i < table->size; ++i) {
+		entry = table->entry[i];
+		while(entry != NULL) {
+			tmp = entry;
+			entry = entry->next;
+			table->del_entry(table, tmp->key);
+		}
+	}
+
+	kfree(table->entry);
+	kfree(table);
+}
+
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/hash/hash.h linux-4.9-rc2/net/gmtp/hash/hash.h
--- linux-4.9-rc2-original/net/gmtp/hash/hash.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/hash/hash.h	2016-12-01 16:50:35.707416729 -0300
@@ -0,0 +1,198 @@
+/*
+ * hash.h
+ *
+ *  Created on: 07/05/2015
+ *      Author: wendell
+ */
+
+#ifndef HASH_INTRA_H_
+#define HASH_INTRA_H_
+
+#define GMTP_HASH_KEY_LEN  16
+
+struct gmtp_hashtable;
+struct gmtp_hash_entry;
+
+/**
+ * struct gmtp_hash_ops - The GMTP hash table operations
+ */
+struct gmtp_hash_ops {
+	unsigned int (*hashval)(struct gmtp_hashtable *table,
+			const __u8 *key);
+	int (*add_entry)(struct gmtp_hashtable *table,
+			struct gmtp_hash_entry *entry);
+	void (*del_entry)(struct gmtp_hashtable *table, const __u8 *key);
+	void (*destroy)(struct gmtp_hashtable *table);
+};
+
+extern const struct gmtp_hash_ops gmtp_client_hash_ops;
+extern const struct gmtp_hash_ops gmtp_server_hash_ops;
+
+/**
+ * struct gmtp_hash_entry - The GMTP hash table entry
+ *
+ * @flowname:	the key of hash table entry
+ * @next: 	the next entry with the same key (hash)
+ */
+struct gmtp_hash_entry {
+	__u8 				key[GMTP_HASH_KEY_LEN];
+	struct gmtp_hash_entry		*next;
+};
+
+/**
+ * struct gmtp_hashtable - The GMTP hash table
+ *
+ * @size: 		the max number of entries in hash table (fixed)
+ * @len: 		the current number of entries in hash table
+ * @gmtp_hash_ops: 	the operations of hashtable
+ * @table:		the array of table entries
+ * 			(it can be a client or a server entry)
+ */
+struct gmtp_hashtable {
+	unsigned int 			size;
+	unsigned int			len;
+
+	struct gmtp_hash_entry		**entry;
+	struct gmtp_hash_ops		hash_ops;
+
+	unsigned int (*hashval)(struct gmtp_hashtable *table,
+			const __u8 *key);
+	int (*add_entry)(struct gmtp_hashtable *table,
+			struct gmtp_hash_entry *entry);
+	void (*del_entry)(struct gmtp_hashtable *table, const __u8 *key);
+	void (*destroy)(struct gmtp_hashtable *table);
+};
+
+/** hash.c */
+struct gmtp_hashtable *gmtp_build_hashtable(unsigned int size,
+		struct gmtp_hash_ops hash_ops);
+unsigned int gmtp_hashval(struct gmtp_hashtable *table, const __u8 *key);
+struct gmtp_hash_entry *gmtp_lookup_entry(struct gmtp_hashtable *table,
+		const __u8 *key);
+int gmtp_add_entry(struct gmtp_hashtable *table, struct gmtp_hash_entry *entry);
+void destroy_gmtp_hashtable(struct gmtp_hashtable *table);
+void kfree_gmtp_hashtable(struct gmtp_hashtable *table);
+
+/**
+ * struct gmtp_client_entry - An entry in client hash table
+ * @entry: hash entry
+ *
+ * @clients: list of clients connected to media P
+ * @channel_addr: multicast channel to receive media
+ * @channel_port: multicast port to receive media
+ */
+struct gmtp_client_entry {
+	/* gmtp_hash_entry has to be the first member of gmtp_client_entry */
+	struct gmtp_hash_entry		entry;
+
+	struct gmtp_client 		*clients;
+	__be32 				channel_addr;
+	__be16 				channel_port;
+};
+
+
+int gmtp_add_client_entry(struct gmtp_hashtable *table,
+		const __u8 *flowname, __be32 local_addr, __be16 local_port,
+		__be32 channel_addr, __be16 channel_port);
+struct gmtp_client_entry *gmtp_lookup_client(struct gmtp_hashtable *table,
+		const __u8 *key);
+void gmtp_del_client_entry(struct gmtp_hashtable *table, const __u8 *key);
+
+
+
+/** Servers **/
+
+/**
+ * struct gmtp_relay_table_entry - An entry in relays hash table (in server)
+ *
+ * @entry: hash entry
+ *
+ * @relay_list:  the list head of
+ *
+ * @relay: ID and IP of relay
+ * @nrelays: number of relays of route (if this is the last relay of route)
+ * @sk: socket to last relay of route
+ */
+struct gmtp_relay_entry {
+	struct gmtp_hash_entry		entry;
+
+	struct list_head 		relay_list;
+	struct list_head 		path_list;
+
+	struct gmtp_hdr_relay 		relay;
+	__u8 				nrelays;
+	struct sock 			*sk;
+};
+
+/**
+ * struct gmtp_server_entry - An entry in server hash table
+ *
+ * @entry: hash entry
+ * @relay_hashtable: a hash table of all relays in network
+ * @relay_list: a list of all relays in network (relay tree)
+ * @nroutes: the number of routes stored in server for media P
+ */
+struct gmtp_server_entry {
+	struct gmtp_hash_entry		entry;
+	struct gmtp_hashtable 		*relay_hashtable;
+	struct gmtp_relay_entry		relays; /* list of routes */
+	unsigned int 			nrelays;
+	struct sock 			*first_sk;
+};
+
+int gmtp_add_server_entry(struct gmtp_hashtable *table, struct sock *sk,
+		struct sk_buff *skb);
+
+
+
+/** GMTP Clients **/
+
+/**
+ * struct gmtp_clients - A list of GMTP Clients
+ *
+ * @list: The list_head
+ * @id: a number to identify and count clients
+ * @addr: IP address of client
+ * @port: reception port of client
+ * @max_clients: for reporters, the max amount of clients.
+ * 			0 means that clients is not a reporter
+ * @nclients: number of occupied slots at a reporter.
+ * 			It must be less or equal %max_clients
+ *
+ * @ack_rx_tstamp: time stamp of last received ack (or feedback)
+ *
+ * @clients: clients of a reporter.
+ * @reporter: reporter of a client
+ * @rsock: socket to reporter
+ * @mysock: socket of the client
+ * @mac_addr: MAC addr of client
+ */
+struct gmtp_client {
+	struct list_head 	list;
+	u32			id;
+	__be32 			addr;
+	__be16 			port;
+	__u8			max_nclients;
+	__u8			nclients;
+	__u32			ack_rx_tstamp;
+
+	struct gmtp_client	*clients;
+	struct gmtp_client	*reporter;
+	struct sock 		*rsock;
+	struct sock 		*mysock;
+	unsigned char 		mac_addr[6];
+};
+
+struct gmtp_client *gmtp_create_client(__be32 addr, __be16 port, __u8 max_nclients);
+struct gmtp_client *gmtp_list_add_client(u32 id, __be32 addr, __be16 port,
+		__u8 max_nclients, struct list_head *head);
+
+struct gmtp_client* gmtp_get_first_client(struct list_head *head);
+struct gmtp_client* gmtp_get_client(struct list_head *head, __be32 addr, __be16 port);
+struct gmtp_client* gmtp_get_client_by_id(struct list_head *head, u32 id);
+
+int gmtp_delete_clients(struct list_head *list, __be32 addr, __be16 port);
+void print_gmtp_client(struct gmtp_client *c);
+
+
+#endif /* HASH_H_ */
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/hash/hash_client.c linux-4.9-rc2/net/gmtp/hash/hash_client.c
--- linux-4.9-rc2-original/net/gmtp/hash/hash_client.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/hash/hash_client.c	2016-12-01 16:50:35.707416729 -0300
@@ -0,0 +1,91 @@
+/*
+ * hash.c
+ *
+ *  Created on: 27/02/2015
+ *      Author: mario
+ */
+
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+
+#include "../gmtp.h"
+#include "hash.h"
+
+struct gmtp_hashtable* client_hashtable;
+EXPORT_SYMBOL_GPL(client_hashtable);
+
+int gmtp_add_client_entry(struct gmtp_hashtable *table,
+		const __u8 *flowname, __be32 local_addr, __be16 local_port,
+		__be32 channel_addr, __be16 channel_port)
+{
+	struct gmtp_client_entry *new_entry;
+
+	new_entry = kmalloc(sizeof(struct gmtp_client_entry), GFP_ATOMIC);
+	if(new_entry == NULL)
+		return 1;
+
+	memcpy(new_entry->entry.key, flowname, GMTP_HASH_KEY_LEN);
+	new_entry->clients = kmalloc(sizeof(struct gmtp_client), GFP_ATOMIC);
+	if(new_entry->clients == NULL)
+		return 2;
+	INIT_LIST_HEAD(&new_entry->clients->list);
+
+	new_entry->channel_addr = channel_addr;
+	new_entry->channel_port = channel_port;
+
+	return table->add_entry(table, (struct gmtp_hash_entry*) new_entry);
+}
+EXPORT_SYMBOL_GPL(gmtp_add_client_entry);
+
+struct gmtp_client_entry *gmtp_lookup_client(struct gmtp_hashtable *table,
+		const __u8 *key)
+{
+	return (struct gmtp_client_entry *) gmtp_lookup_entry(table, key);
+}
+EXPORT_SYMBOL_GPL(gmtp_lookup_client);
+
+void gmtp_del_client_entry(struct gmtp_hashtable *table, const __u8 *key)
+{
+	gmtp_pr_func();
+	table->del_entry(table, key);
+}
+EXPORT_SYMBOL_GPL(gmtp_del_client_entry);
+
+void gmtp_del_client_list(struct gmtp_client_entry *entry)
+{
+	struct gmtp_client *client, *temp;
+	gmtp_pr_func();
+	list_for_each_entry_safe(client, temp, &entry->clients->list, list)
+	{
+		gmtp_pr_error("FIXME: list_del(&client->list) crashes GMTP");
+		/** FIXME Call list_dell here crashes GMTP... */
+		/*list_del(&client->list);
+		kfree(client);*/
+	}
+
+}
+
+void gmtp_del_client_hash_entry(struct gmtp_hashtable *table, const __u8 *key)
+{
+	struct gmtp_client_entry *entry;
+	int hashval;
+
+	gmtp_print_function();
+
+	entry = (struct gmtp_client_entry *) gmtp_lookup_entry(table, key);
+	if(entry != NULL) {
+		gmtp_del_client_list(entry);
+		table->len--;
+		/*kfree(entry);*/
+	}
+}
+
+const struct gmtp_hash_ops gmtp_client_hash_ops = {
+		.hashval = gmtp_hashval,
+		.add_entry = gmtp_add_entry,
+		.del_entry = gmtp_del_client_hash_entry,
+		.destroy = destroy_gmtp_hashtable,
+};
+
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/hash/hash_server.c linux-4.9-rc2/net/gmtp/hash/hash_server.c
--- linux-4.9-rc2-original/net/gmtp/hash/hash_server.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/hash/hash_server.c	2016-12-01 16:50:35.708416717 -0300
@@ -0,0 +1,282 @@
+/*
+ * hash.c
+ *
+ *  Created on: 27/02/2015
+ *      Author: mario
+ */
+
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+
+#include <uapi/linux/gmtp.h>
+#include "../gmtp.h"
+#include "hash.h"
+
+struct gmtp_hashtable* server_hashtable;
+EXPORT_SYMBOL_GPL(server_hashtable);
+
+void gmtp_del_relay_hash_entry(struct gmtp_hashtable *table, const __u8 *key);
+
+const struct gmtp_hash_ops gmtp_relay_hash_ops = {
+		.hashval = gmtp_hashval,
+		.add_entry = gmtp_add_entry,
+		.del_entry = gmtp_del_relay_hash_entry,
+		.destroy = destroy_gmtp_hashtable,
+};
+
+static void gmtp_print_server_entry(struct gmtp_server_entry *entry)
+{
+	struct gmtp_relay_entry *relay;
+	int i;
+
+	pr_info("Server entry: \n");
+	pr_info("\t%u relays on hash table\n", entry->relay_hashtable->len);
+	pr_info("\t%u routes in the server\n", entry->nrelays);
+	list_for_each_entry(relay, &entry->relays.relay_list, relay_list)
+	{
+		print_route_from_list(relay);
+	}
+}
+
+static struct gmtp_relay_entry *gmtp_build_relay_entry(
+		const struct gmtp_hdr_relay *relay)
+{
+	struct gmtp_relay_entry *relay_entry;
+
+	relay_entry = kmalloc(sizeof(struct gmtp_relay_entry), GFP_KERNEL);
+	if(relay_entry == NULL)
+		return NULL;
+
+	memcpy(relay_entry->entry.key, relay->relay_id, GMTP_HASH_KEY_LEN);
+	memcpy(&relay_entry->relay, relay, sizeof(struct gmtp_hdr_relay));
+
+	return relay_entry;
+}
+
+static struct gmtp_relay_entry *gmtp_get_relay_entry(
+		struct gmtp_hashtable *relay_table, const __u8 *key)
+{
+	return ((struct gmtp_relay_entry*) gmtp_lookup_entry(relay_table, key));
+}
+
+static int gmtp_add_new_route(struct gmtp_server_entry* server_entry,
+		struct sock *sk, struct sk_buff *skb)
+{
+	struct gmtp_hashtable *relay_table = server_entry->relay_hashtable;
+	struct gmtp_hdr_relay *relay_list = gmtp_hdr_relay(skb);
+	struct list_head *path_list_head = NULL;
+	int i, err = 0;
+	__u8 nrelays = gmtp_hdr_route(skb)->nrelays;
+
+	gmtp_pr_func();
+
+	for(i = nrelays-1; i >= 0; --i) {
+		struct gmtp_relay_entry *relay_entry;
+		relay_entry = gmtp_build_relay_entry(&relay_list[i]);
+
+		if(relay_entry == NULL)
+			return 2;
+
+		if(i == (nrelays-1)) {
+			struct gmtp_sock *gp = gmtp_sk(sk);
+			struct gmtp_sock *sgp = gmtp_sk(server_entry->first_sk);
+			gp->isr = sgp->isr;
+			gp->gsr = sgp->gsr;
+			gp->iss = sgp->iss;
+			gp->gss = sgp->gss;
+
+			relay_entry->sk = sk;
+			relay_entry->nrelays++;
+
+			/* add it on the list of relays at server */
+			pr_info("Adding relay %pI4 on server list...\n",
+					&relay_entry->relay.relay_ip);
+
+			INIT_LIST_HEAD(&relay_entry->path_list);
+			path_list_head = &relay_entry->path_list;
+			list_add(&relay_entry->relay_list,
+					&server_entry->relays.relay_list);
+			server_entry->nrelays++; /* Number of routes */
+		}
+		err = relay_table->add_entry(relay_table, &relay_entry->entry);
+		if(!err && path_list_head != NULL)
+			list_add(&relay_entry->path_list, path_list_head);
+	}
+
+	return err;
+}
+
+static int gmtp_update_route_add_tail(struct gmtp_hashtable *relay_table,
+		struct gmtp_hdr_relay *relay_list, __u8 nrelays,
+		struct list_head *list)
+{
+	int i, err = 0;
+	for(i = nrelays - 2; i >= 0; --i) {
+		struct gmtp_relay_entry *new_relay_entry;
+		new_relay_entry = gmtp_build_relay_entry(&relay_list[i]);
+		err = relay_table->add_entry(relay_table, &new_relay_entry->entry);
+		list_add_tail(&new_relay_entry->path_list, list);
+	}
+	return err;
+}
+
+int gmtp_update_route(struct gmtp_server_entry *server_entry,
+	struct gmtp_relay_entry *relay_entry, struct sock *sk,
+	struct sk_buff *skb)
+{
+	struct gmtp_hashtable *relay_table = server_entry->relay_hashtable;
+	struct gmtp_hdr_relay *relay_list = gmtp_hdr_relay(skb);
+	__u8  nrelays = gmtp_hdr_route(skb)->nrelays;
+
+	pr_info("Relays in path: from %u to %u\n", relay_entry->nrelays, nrelays);
+	if(nrelays > relay_entry->nrelays && nrelays >= 2) {
+
+		struct gmtp_relay_entry *new_relay;
+		struct sk_buff *delegate_skb;
+
+		gmtp_update_route_add_tail(relay_table, relay_list, nrelays,
+				&relay_entry->path_list);
+		relay_entry->nrelays = nrelays;
+
+		/*{
+			unsigned char *deny = "\x0a\x02\x00\x01";  10.2.0.1
+			__be32 deny_addr = *(unsigned int *)deny;
+			if(relay_entry->relay.relay_ip == deny_addr) {
+				pr_info("We dont delegate %pI4\n", &deny_addr);
+				return 1;
+			}
+		}*/
+
+		pr_info("Sending a GMTP-Delegate to new relay...\n");
+		new_relay = gmtp_get_relay_entry(relay_table, relay_list[nrelays-2].relay_id);
+		if(new_relay != NULL) {
+			int err = 0;
+			delegate_skb = gmtp_make_delegate(new_relay->sk, skb,
+					relay_entry->relay.relay_id);
+			print_gmtp_packet(ip_hdr(delegate_skb), gmtp_hdr(delegate_skb));
+			err = gmtp_transmit_built_skb(new_relay->sk, delegate_skb);
+			pr_info("gmtp_transmit_built_skb returned: %d\n", err);
+		}
+
+	} else if(memcmp(&relay_entry->relay, relay_list,
+			sizeof(relay_entry->relay))) {
+		pr_info("Content changed!");
+	} else {
+		pr_info("Equal!\n");
+	}
+
+	return 1;
+}
+
+int gmtp_add_route(struct gmtp_server_entry* entry, struct sock *sk,
+		struct sk_buff *skb)
+{
+	struct gmtp_hashtable *relay_table = entry->relay_hashtable;
+	struct gmtp_hdr_relay *relay_list = gmtp_hdr_relay(skb);
+	__u8  nrelays = gmtp_hdr_route(skb)->nrelays;
+
+	if(nrelays > 0) {
+		struct gmtp_relay_entry *relay;
+		relay = gmtp_get_relay_entry(relay_table, relay_list[(nrelays-1)].relay_id);
+		if(relay == NULL)
+			return gmtp_add_new_route(entry, sk, skb);
+		else {
+			pr_info("Relay %pI4 already exists\n", &relay->relay.relay_ip);
+			return gmtp_update_route(entry, relay, sk, skb);
+		}
+	}
+
+	return 2;
+}
+
+int gmtp_add_server_entry(struct gmtp_hashtable *table, struct sock *sk,
+		struct sk_buff *skb)
+{
+	struct gmtp_hdr_route *route = gmtp_hdr_route(skb);
+	struct gmtp_sock *gp = gmtp_sk(sk);
+	struct gmtp_server_entry *entry;
+
+	gmtp_pr_func();
+
+	entry = (struct gmtp_server_entry*) gmtp_lookup_entry(table, gp->flowname);
+
+	if(entry == NULL) {
+		pr_info("New server entry\n");
+		entry = kmalloc(sizeof(struct gmtp_server_entry), GFP_KERNEL);
+		if(entry == NULL)
+			return 1;
+
+		entry->nrelays = 0;
+		entry->first_sk = sk;
+		INIT_LIST_HEAD(&entry->relays.relay_list);
+		memcpy(entry->entry.key, gp->flowname, GMTP_HASH_KEY_LEN);
+		entry->relay_hashtable = gmtp_build_hashtable(U8_MAX,
+				gmtp_relay_hash_ops);
+	}
+
+	gmtp_print_server_entry(entry);
+
+	if(gmtp_add_route(entry, sk, skb))
+		return 1;
+
+	return table->add_entry(table, (struct gmtp_hash_entry*)entry);
+}
+EXPORT_SYMBOL_GPL(gmtp_add_server_entry);
+
+/* FIXME This function crashes all... */
+void gmtp_del_relay_list(struct list_head *list_head)
+{
+	struct gmtp_relay_entry *relay, *temp;
+	gmtp_pr_func();
+	list_for_each_entry_safe(relay, temp, list_head, path_list)
+	{
+		list_del(&relay->path_list);
+		kfree(relay);
+	}
+}
+
+void gmtp_del_relay_hash_entry(struct gmtp_hashtable *table, const __u8 *key)
+{
+	struct gmtp_relay_entry *entry;
+	int hashval;
+
+	gmtp_print_function();
+
+	hashval = table->hashval(table, key);
+	if(hashval < 0)
+		return;
+
+	entry = (struct gmtp_relay_entry*) table->entry[hashval];
+	if(entry != NULL) {
+		gmtp_del_relay_list(&entry->path_list);
+		table->len--;
+		kfree(entry);
+	}
+}
+
+void gmtp_del_server_hash_entry(struct gmtp_hashtable *table, const __u8 *key)
+{
+	struct gmtp_server_entry *entry;
+	int hashval;
+
+	gmtp_print_function();
+
+	hashval = table->hashval(table, key);
+	if(hashval < 0)
+		return;
+
+	entry = (struct gmtp_server_entry*) table->entry[hashval];
+	if(entry != NULL) {
+		/*entry->relay_hashtable->destroy(entry->relay_hashtable);*/
+		table->len--;
+		kfree(entry);
+	}
+}
+
+const struct gmtp_hash_ops gmtp_server_hash_ops = {
+		.hashval = gmtp_hashval,
+		.add_entry = gmtp_add_entry,
+		.del_entry = gmtp_del_server_hash_entry,
+		.destroy = destroy_gmtp_hashtable,
+};
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/hash.h linux-4.9-rc2/net/gmtp/hash.h
--- linux-4.9-rc2-original/net/gmtp/hash.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/hash.h	2016-12-01 16:50:35.698416842 -0300
@@ -0,0 +1,14 @@
+/*
+ * hash.h
+ *
+ *  Created on: 23/06/2015
+ *      Author: wendell
+ */
+
+#ifndef HASH_H_
+#define HASH_H_
+
+#include "hash/hash.h"
+
+
+#endif /* HASH_H_ */
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/input.c linux-4.9-rc2/net/gmtp/input.c
--- linux-4.9-rc2-original/net/gmtp/input.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/input.c	2016-12-01 19:03:11.519492676 -0300
@@ -0,0 +1,710 @@
+#include <linux/kernel.h>
+#include <linux/skbuff.h>
+#include <linux/slab.h>
+#include <linux/types.h>
+#include <linux/gmtp.h>
+#include <linux/net.h>
+#include <linux/security.h>
+#include <linux/igmp.h>
+
+#include <net/inet_common.h>
+#include <net/inet_sock.h>
+#include <net/sock.h>
+
+#include <uapi/linux/gmtp.h>
+#include "gmtp.h"
+#include "hash.h"
+#include "mcc.h"
+
+static void gmtp_enqueue_skb(struct sock *sk, struct sk_buff *skb)
+{
+	__skb_pull(skb, gmtp_hdr(skb)->hdrlen);
+	__skb_queue_tail(&sk->sk_receive_queue, skb);
+	skb_set_owner_r(skb, sk);
+	sk->sk_data_ready(sk);
+}
+
+static void gmtp_fin(struct sock *sk, struct sk_buff *skb)
+{
+	gmtp_print_function();
+	sk->sk_shutdown = SHUTDOWN_MASK;
+	sock_set_flag(sk, SOCK_DONE);
+	gmtp_enqueue_skb(sk, skb);
+}
+
+static int gmtp_rcv_close(struct sock *sk, struct sk_buff *skb)
+{
+	int queued = 0;
+
+	gmtp_print_function();
+
+	switch(sk->sk_state) {
+	/*
+	 * We ignore Close when received in one of the following states:
+	 *  - CLOSED		(may be a late or duplicate packet)
+	 *  - PASSIVE_CLOSEREQ	(the peer has sent a CloseReq earlier)
+	 */
+	case GMTP_CLOSING:
+		/*
+		 * Simultaneous-close: receiving a Close after sending one. This
+		 * can happen if both client and server perform active-close and
+		 * will result in an endless ping-pong of crossing and retrans-
+		 * mitted Close packets, which only terminates when one of the
+		 * nodes times out (min. 64 seconds). Quicker convergence can be
+		 * achieved when one of the nodes acts as tie-breaker.
+		 * This is ok as both ends are done with data transfer and each
+		 * end is just waiting for the other to acknowledge termination.
+		 */
+		if(gmtp_role_client(sk))
+			break;
+		/* fall through */
+	case GMTP_REQUESTING:
+	case GMTP_ACTIVE_CLOSEREQ:
+		gmtp_send_reset(sk, GMTP_RESET_CODE_CLOSED);
+		gmtp_done(sk);
+		break;
+	case GMTP_OPEN:
+		/* FIXME Close only if gh->flowname == gp->flowname */
+		/* Clear hash table */
+		if(gmtp_role_client(sk))
+			gmtp_del_client_entry(client_hashtable,
+					gmtp_sk(sk)->flowname);
+		/* FIXME: Implement gmtp_del_server_entry() */
+		/*
+		else if(gp->role == GMTP_ROLE_SERVER)
+			gmtp_print_error("FIXME: Implement gmtp_del_server_entry()");*/
+
+		/* Give waiting application a chance to read pending data */
+		queued = 1;
+		gmtp_fin(sk, skb);
+		gmtp_set_state(sk, GMTP_PASSIVE_CLOSE);
+		/* fall through */
+	case GMTP_PASSIVE_CLOSE:
+		/*
+		 * Retransmitted Close: we have already enqueued the first one.
+		 */
+		sk_wake_async(sk, SOCK_WAKE_WAITD, POLL_HUP);
+	}
+	return queued;
+}
+
+struct sock* gmtp_sock_connect(struct sock *sk, enum gmtp_sock_type type,
+		__be32 addr, __be16 port)
+{
+	struct sock *newsk;
+
+	gmtp_pr_func();
+
+	newsk = sk_clone_lock(sk, GFP_KERNEL);
+	if(newsk == NULL)
+		return NULL;
+
+	newsk->sk_protocol = sk->sk_protocol;
+	newsk->sk_daddr = addr;
+	newsk->sk_dport = port;
+
+	gmtp_sk(newsk)->type = type;
+	gmtp_sk(newsk)->req_stamp = 0;
+	gmtp_sk(newsk)->ack_rx_tstamp = jiffies_to_msecs(jiffies);
+	gmtp_sk(newsk)->ack_tx_tstamp = 0;
+
+	pr_info("myself: %p == %p\n", gmtp_sk(newsk), gmtp_sk(sk));
+
+	bh_unlock_sock(newsk);
+	gmtp_init_xmit_timers(newsk);
+
+	return newsk;
+
+}
+EXPORT_SYMBOL_GPL(gmtp_sock_connect);
+
+struct sock* gmtp_multicast_connect(struct sock *sk, enum gmtp_sock_type type,
+		__be32 addr, __be16 port)
+{
+	struct sock *newsk;
+	struct ip_mreqn mreq;
+	int ret;
+
+	gmtp_pr_func();
+
+	newsk = sk_clone_lock(sk, GFP_KERNEL);
+	if(newsk == NULL)
+		return NULL;
+
+	/* FIXME Validate received multicast channel */
+	newsk->sk_protocol = sk->sk_protocol;
+	newsk->sk_reuse = true; /* SO_REUSEADDR */
+	newsk->sk_reuseport = true;
+	newsk->sk_rcv_saddr = htonl(INADDR_ANY);
+
+	mreq.imr_multiaddr.s_addr = addr;
+	mreq.imr_address.s_addr = htonl(INADDR_ANY);
+	/* NS-3 sim0 interface is 7 */
+	mreq.imr_ifindex = 7;
+
+	gmtp_pr_debug("Joining the multicast group in %pI4@%-5d",
+			&addr, ntohs(port));
+	rtnl_lock();
+	ret = ip_mc_join_group(newsk, &mreq);
+	rtnl_unlock();
+	pr_info("ip_mc_join_group returned %d\n", ret);
+
+	inet_ehash_nolisten(newsk, NULL);
+
+	gmtp_sk(newsk)->type = type;
+
+	bh_unlock_sock(newsk);
+	gmtp_set_state(newsk, GMTP_OPEN);
+
+	return newsk;
+}
+EXPORT_SYMBOL_GPL(gmtp_multicast_connect);
+
+/*
+ *    Step 10: Process REQUEST state (second part)
+ *       If S.state == REQUESTING,
+ *	  If we get here, P is a valid Response from the
+ *	      relay, and we should move to
+ *	      OPEN state.
+ *
+ *	 Connect to mcst channel (if we received GMTP_PKT_REQUESTNOTIFY)
+ *	 Connect to reporter (if i'm not a reporter)
+ *
+ *	  S.state := OPEN
+ *	  / * Step 12 will send the Ack completing the
+ *	      three-way handshake * /
+ */
+static int gmtp_rcv_request_sent_state_process(struct sock *sk,
+					       struct sk_buff *skb,
+					       const struct gmtp_hdr *gh,
+					       const unsigned int len)
+{
+	struct gmtp_sock *gp = gmtp_sk(sk);
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+	struct gmtp_client_entry *client_entry;
+
+	gmtp_pr_func();
+
+	if (gh->type != GMTP_PKT_REQUESTNOTIFY &&
+				gh->type != GMTP_PKT_REGISTER_REPLY) {
+		goto out_invalid_packet;
+	}
+	gmtp_pr_debug("Packet received: %s", gmtp_packet_name(gh->type));
+
+	client_entry = gmtp_lookup_client(client_hashtable, gh->flowname);
+	if(client_entry == NULL)
+		goto out_invalid_packet;
+
+	/*** FIXME Check sequence numbers  ***/
+
+	gp->rx_rtt = (u32) gh->server_rtt;
+	gmtp_pr_debug("RTT: %u ms", gp->rx_rtt);
+
+	if(gh->type == GMTP_PKT_REQUESTNOTIFY) {
+		struct gmtp_hdr_reqnotify *gh_rnotify;
+
+		gh_rnotify = gmtp_hdr_reqnotify(skb);
+		pr_info("ReqNotify => Channel: %pI4@%-5d | Code: %d | Cl: %u\n",
+				&gh_rnotify->mcst_addr,
+				ntohs(gh_rnotify->mcst_port),
+				gh_rnotify->rn_code,
+				gh_rnotify->max_nclients);
+
+		switch(gh_rnotify->rn_code) {
+		case GMTP_REQNOTIFY_CODE_OK: /* Process packet */
+			pr_info("Reporter: %pI4@%-5d\n",
+					&gh_rnotify->reporter_addr,
+					ntohs(gh_rnotify->reporter_port));
+			memcpy(gp->relay_id, gh_rnotify->relay_id,
+					GMTP_RELAY_ID_LEN);
+
+			gp->myself->max_nclients = gh_rnotify->max_nclients;
+			if(gp->myself->max_nclients > 0) {
+				gp->role = GMTP_ROLE_REPORTER;
+				gp->myself->clients = kmalloc(
+						sizeof(struct gmtp_client),
+						GFP_ATOMIC);
+				INIT_LIST_HEAD(&gp->myself->clients->list);
+			}
+			break;
+		case GMTP_REQNOTIFY_CODE_WAIT: /* Do nothing... */
+			return 0;
+			/* FIXME Del entry in table when receiving error... */
+		case GMTP_REQNOTIFY_CODE_ERROR:
+			goto err;
+		default:
+			goto out_invalid_packet;
+		}
+
+		if(gp->role != GMTP_ROLE_REPORTER) {
+			gp->myself->reporter = gmtp_create_client(
+					gh_rnotify->reporter_addr,
+					gh_rnotify->reporter_port, 1);
+
+			gp->myself->rsock = gmtp_sock_connect(sk,
+					GMTP_SOCK_TYPE_REPORTER,
+					gh_rnotify->reporter_addr,
+					gh_rnotify->reporter_port);
+
+			if(gp->myself->rsock == NULL
+					|| gp->myself->reporter == NULL)
+				goto err;
+
+			gmtp_set_state(gp->myself->rsock, GMTP_REQUESTING);
+			gmtp_send_elect_request(gp->myself->rsock,
+					GMTP_REQ_INTERVAL);
+		}
+
+		/* Inserting information in client table */
+		client_entry->channel_addr = gh_rnotify->mcst_addr;
+		client_entry->channel_port = gh_rnotify->mcst_port;
+
+		gp->channel_sk = gmtp_multicast_connect(sk,
+				GMTP_SOCK_TYPE_DATA_CHANNEL,
+				gh_rnotify->mcst_addr, gh_rnotify->mcst_port);
+		if(gp->channel_sk == NULL)
+			goto err;
+
+	}
+
+	/* Stop the REQUEST timer */
+	inet_csk_clear_xmit_timer(sk, ICSK_TIME_RETRANS);
+	WARN_ON(sk->sk_send_head == NULL);
+	kfree_skb(sk->sk_send_head);
+	sk->sk_send_head = NULL;
+
+	gp->gsr = gp->isr = GMTP_SKB_CB(skb)->seq;
+	gmtp_sync_mss(sk, icsk->icsk_pmtu_cookie);
+
+	gmtp_set_state(sk, GMTP_OPEN);
+
+	/* Make sure socket is routed, for correct metrics. */
+	icsk->icsk_af_ops->rebuild_header(sk);
+
+	if(!sock_flag(sk, SOCK_DEAD)) {
+		sk->sk_state_change(sk);
+		sk_wake_async(sk, SOCK_WAKE_IO, POLL_OUT);
+	}
+
+	if(sk->sk_write_pending || icsk->icsk_ack.pingpong
+			|| icsk->icsk_accept_queue.rskq_defer_accept) {
+		/* Save one ACK. Data will be ready after
+		 * several ticks, if write_pending is set.
+		 */
+		__kfree_skb(skb);
+		return 0;
+	}
+
+	if(gh->type == GMTP_PKT_REGISTER_REPLY) {
+		gmtp_add_relayid(skb);
+		gmtp_send_route_notify(sk, skb);
+		gp->role = GMTP_ROLE_REPORTER;
+	} else
+		gmtp_send_ack(sk);
+
+	if(gp->role == GMTP_ROLE_REPORTER) {
+		if(mcc_rx_init(sk))
+			goto err;
+		inet_csk_reset_keepalive_timer(sk, GMTP_ACK_TIMEOUT);
+	}
+
+
+	return -1;
+
+	/* FIXME Treat invalid responses */
+out_invalid_packet:
+ 	/* gmtp_v4_do_rcv will send a reset */
+ 	GMTP_SKB_CB(skb)->reset_code = GMTP_RESET_CODE_PACKET_ERROR;
+ 	return 1;
+
+err:
+ 	/*
+ 	 * We mark this socket as no longer usable, so that the loop in
+ 	 * gmtp_sendmsg() terminates and the application gets notified.
+ 	 */
+	gmtp_del_client_entry(client_hashtable, gp->flowname);
+ 	gmtp_set_state(sk, GMTP_CLOSED);
+ 	sk->sk_err = ECOMM;
+ 	return 1;
+}
+
+/**** FIXME Make GMTP reset codes */
+static u16 gmtp_reset_code_convert(const u8 code)
+{
+	const u16 error_code[] = {
+	[GMTP_RESET_CODE_CLOSED]	     = 0,	/* normal termination */
+	[GMTP_RESET_CODE_UNSPECIFIED]	     = 0,	/* nothing known */
+	[GMTP_RESET_CODE_ABORTED]	     = ECONNRESET,
+
+	[GMTP_RESET_CODE_NO_CONNECTION]	     = ECONNREFUSED,
+	[GMTP_RESET_CODE_CONNECTION_REFUSED] = ECONNREFUSED,
+	[GMTP_RESET_CODE_TOO_BUSY]	     = EUSERS,
+	[GMTP_RESET_CODE_AGGRESSION_PENALTY] = EDQUOT,
+
+	[GMTP_RESET_CODE_PACKET_ERROR]	     = ENOMSG,
+	[GMTP_RESET_CODE_MANDATORY_ERROR]    = EOPNOTSUPP,
+
+	[GMTP_RESET_CODE_BAD_FLOWNAME]       = EBADR, /* Invalid request
+								descriptor */
+	};
+
+	return code >= GMTP_MAX_RESET_CODES ? 0 : error_code[code];
+}
+
+static void gmtp_rcv_reset(struct sock *sk, struct sk_buff *skb)
+{
+	u16 err = gmtp_reset_code_convert(gmtp_hdr_reset(skb)->reset_code);
+
+	gmtp_print_function();
+
+	sk->sk_err = err;
+
+	/*Queue the equivalent of TCP fin so that gmtp_recvmsg exits the loop */
+	gmtp_fin(sk, skb);
+
+	if (err && !sock_flag(sk, SOCK_DEAD))
+		sk_wake_async(sk, SOCK_WAKE_IO, POLL_ERR);
+	gmtp_time_wait(sk, GMTP_TIME_WAIT, 0);
+}
+
+static void gmtp_deliver_input_to_mcc(struct sock *sk, struct sk_buff *skb)
+{
+	/*const struct gmtp_sock *gp = gmtp_sk(sk);*/
+
+	/* Don't deliver to RX MCC when node has shut down read end. */
+	if (!(sk->sk_shutdown & RCV_SHUTDOWN))
+		mcc_rx_packet_recv(sk, skb);
+	/*
+	 * FIXME Until the TX queue has been drained, we can not honour SHUT_WR,
+	 * since we need received feedback as input to adjust congestion control.
+	 */
+/*	if (sk->sk_write_queue.qlen > 0 || !(sk->sk_shutdown & SEND_SHUTDOWN))
+		mcc_tx_packet_recv(sk, skb);*/
+}
+
+static int gmtp_rcv_route_notify(struct sock *sk, struct sk_buff *skb,
+			 const struct gmtp_hdr *gh)
+{
+	struct gmtp_hdr_route *route = gmtp_hdr_route(skb);
+
+	print_route_from_skb(skb);
+
+	if(route->nrelays <= 0)
+		return 0;
+
+	gmtp_add_server_entry(server_hashtable, sk, skb);
+
+	return 0;
+}
+
+static int gmtp_rcv_delegate_reply(struct sock *sk, struct sk_buff *skb,
+		 const struct gmtp_hdr *gh)
+{
+	struct gmtp_hdr_delegate *dh = gmtp_hdr_delegate(skb);
+	struct gmtp_server_entry *s;
+	struct gmtp_relay_entry *r;
+
+	print_gmtp_hdr_relay(&dh->relay);
+
+	s = (struct gmtp_server_entry*) gmtp_lookup_entry(server_hashtable,
+				gh->flowname);
+	if(s != NULL) {
+		r = (struct gmtp_relay_entry*) gmtp_lookup_entry(s->relay_hashtable,
+						dh->relay.relay_id);
+		pr_info("Found: %pI4\n", &r->relay.relay_ip);
+		gmtp_set_state(r->sk, GMTP_DELEGATED);
+	}
+
+	return 0;
+}
+
+/* TODO Implement check sequence number */
+static int gmtp_check_seqno(struct sock *sk, struct sk_buff *skb)
+{
+	struct gmtp_hdr *gh = gmtp_hdr(skb);
+	struct gmtp_sock *gp = gmtp_sk(sk);
+
+	if(gh->type == GMTP_PKT_DATA && gp->role == GMTP_ROLE_REPORTER) {
+		if(unlikely(gp->rx_state == MCC_RSTATE_NO_DATA)) {
+			pr_info("Setting first seqno to %u \n", gh->seq);
+			gp->gsr = gh->seq;
+			gp->isr = gh->seq;
+			gp->iss = gh->seq;
+			gp->gss = gh->seq;
+			return 0;
+		} /*else if(gh->seq < gp->gsr) {
+			pr_info("Seqno error => Received: %u. GSR: %u.\n",
+					gh->seq, gp->gsr);
+			return 1;
+		}*/
+	}
+
+	return 0;
+}
+
+static int __gmtp_rcv_established(struct sock *sk, struct sk_buff *skb,
+		const struct gmtp_hdr *gh, const unsigned int len)
+{
+	struct gmtp_sock *gp = gmtp_sk(sk);
+
+	switch (gh->type) {
+	case GMTP_PKT_DATAACK:
+	case GMTP_PKT_DATA:
+		gmtp_enqueue_skb(sk, skb);
+		return 0;
+	case GMTP_PKT_ACK:
+	case GMTP_PKT_FEEDBACK:
+		if(gp->role == GMTP_ROLE_SERVER) {
+			__be32 otstamp;
+			__be32 new_tx = gh->transm_r;
+
+			if(gh->type == GMTP_PKT_ACK)
+				otstamp = gmtp_hdr_ack(skb)->orig_tstamp;
+			else
+				otstamp = gmtp_hdr_feedback(skb)->orig_tstamp;
+
+			gp->tx_rtt = jiffies_to_msecs(jiffies) - otstamp;
+			gp->tx_avg_rtt = rtt_ewma(gp->tx_avg_rtt, gp->tx_rtt,
+					GMTP_RTT_WEIGHT);
+
+			/* Avoid super TX reduction */
+			if(new_tx < DIV_ROUND_CLOSEST(gp->tx_media_rate, 4)) {
+				pr_info("Avoiding super TX reduction...\n");
+				pr_info("gh->tx = %u\n", gh->transm_r);
+				pr_info("max_tx: %lu\n", gp->tx_media_rate);
+				new_tx = DIV_ROUND_CLOSEST(gp->tx_media_rate, 4);
+			}
+
+			gp->tx_ucc_rate = min((__be32 )gp->tx_max_rate, new_tx);
+
+			pr_info("cong. control tx: %lu B/s, from: %pI4\n", gp->tx_ucc_rate,
+					&ip_hdr(skb)->saddr);
+		}
+		goto discard;
+	case GMTP_PKT_ROUTE_NOTIFY:
+		gp->tx_rtt = jiffies_to_msecs(jiffies) - gmtp_sk(sk)->reply_stamp;
+		gp->tx_rtt = gp->tx_rtt > 0? gp->tx_rtt : 1;
+		gp->tx_avg_rtt = rtt_ewma(gp->tx_avg_rtt, gp->tx_rtt,
+		GMTP_RTT_WEIGHT);
+
+		gmtp_pr_debug("RTT: %u ms | RTT_AVG: %u ms", gp->tx_rtt,
+				gp->tx_avg_rtt);
+
+		/** TODO Update routes */
+		gmtp_rcv_route_notify(sk, skb, gh);
+
+		goto discard;
+	case GMTP_PKT_DELEGATE_REPLY:
+		gmtp_rcv_delegate_reply(sk, skb, gh);
+		goto discard;
+	case GMTP_PKT_REGISTER: {
+		struct sk_buff *new_skb = gmtp_make_register_reply_open(sk, skb);
+		if(new_skb != NULL) {
+			gmtp_sk(sk)->reply_stamp = jiffies_to_msecs(jiffies);
+			return gmtp_transmit_built_skb(sk, new_skb);
+		}
+	}
+		break;
+	case GMTP_PKT_RESET:
+		/*
+		 *  Step 9: Process Reset
+		 *	If P.type == Reset,
+		 *		Tear down connection
+		 *		S.state := TIMEWAIT
+		 *		Set TIMEWAIT timer
+		 *		Drop packet and return
+		 */
+		gmtp_rcv_reset(sk, skb);
+		return 0;
+	case GMTP_PKT_CLOSE:
+		if (gmtp_rcv_close(sk, skb))
+			return 0;
+		goto discard;
+	}
+discard:
+	__kfree_skb(skb);
+	return 0;
+}
+
+int gmtp_rcv_established(struct sock *sk, struct sk_buff *skb,
+			 const struct gmtp_hdr *gh, const unsigned int len)
+{
+	struct gmtp_sock *gp = gmtp_sk(sk);
+
+	/* Check sequence numbers... */
+	if(gmtp_check_seqno(sk, skb)) {
+		goto discard;
+	}
+
+	gp->gsr = gh->seq;
+	gp->rx_rtt = (u32) gh->server_rtt;
+	if(likely(gh->type == GMTP_PKT_DATA))
+		gp->rx_last_orig_tstamp = gmtp_hdr_data(skb)->tstamp;
+	else
+		gp->ndp_count++;
+
+	if(gp->role == GMTP_ROLE_REPORTER) {
+		gmtp_deliver_input_to_mcc(sk, skb);
+	}
+
+	return __gmtp_rcv_established(sk, skb, gh, len);
+discard:
+	__kfree_skb(skb);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(gmtp_rcv_established);
+
+static int gmtp_rcv_request_rcv_state_process(struct sock *sk,
+						   struct sk_buff *skb,
+						   const struct gmtp_hdr *gh,
+						   const unsigned int len)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	struct gmtp_sock *gp = gmtp_sk(sk);
+	int queued = 0;
+
+	gmtp_print_function();
+
+	switch (gh->type) {
+	case GMTP_PKT_RESET:
+		inet_csk_clear_xmit_timer(sk, ICSK_TIME_DACK);
+		break;
+	case GMTP_PKT_DATA:
+		if (sk->sk_state == GMTP_REQUEST_RECV)
+			break;
+	/* ROUTE_NOTIFY is a special ack */
+	case GMTP_PKT_ROUTE_NOTIFY:
+	case GMTP_PKT_DATAACK:
+	case GMTP_PKT_ACK:
+		gp->tx_rtt = jiffies_to_msecs(jiffies) - gmtp_sk(sk)->reply_stamp;
+		gp->tx_avg_rtt = rtt_ewma(gp->tx_avg_rtt, gp->tx_rtt,
+							GMTP_RTT_WEIGHT);
+		gmtp_pr_debug("RTT: %u ms | RTT_AVG: %u ms", gp->tx_rtt,
+				gp->tx_avg_rtt);
+
+		inet_csk_clear_xmit_timer(sk, ICSK_TIME_DACK);
+
+		icsk->icsk_af_ops->rebuild_header(sk);
+		smp_mb();
+		gmtp_set_state(sk, GMTP_OPEN);
+		sk->sk_state_change(sk);
+		sk_wake_async(sk, SOCK_WAKE_IO, POLL_OUT);
+
+		if(gh->type == GMTP_PKT_ROUTE_NOTIFY)
+			gmtp_rcv_route_notify(sk, skb, gh);
+
+		if (gh->type == GMTP_PKT_DATAACK)
+		{
+			__gmtp_rcv_established(sk, skb, gh, len);
+			queued = 1;
+		}
+
+		break;
+	}
+	return queued;
+}
+EXPORT_SYMBOL_GPL(gmtp_rcv_request_rcv_state_process);
+
+int gmtp_rcv_state_process(struct sock *sk, struct sk_buff *skb,
+			   struct gmtp_hdr *gh, unsigned int len)
+{
+	struct gmtp_skb_cb *gcb = GMTP_SKB_CB(skb);
+	int queued = 0;
+
+	gmtp_print_function();
+	gmtp_print_debug("State: %s | Packet: %s", gmtp_state_name(sk->sk_state),
+			gmtp_packet_name(gh->type));
+
+	print_gmtp_packet(ip_hdr(skb), gh);
+
+	/*
+	 *  Step 3: Process LISTEN state
+	 *
+	 *  If S.state == LISTEN,
+	 *
+	 *  If P.type == Request
+	 *  (* Generate a new socket and switch to that socket *)
+	 *	      Set S := new socket for this port pair
+	 *	      S.state = GMTP_REQUEST_RECV
+	 *	      Continue with S.state == REQ_RECV
+	 *	      (* A REQUEST_REPLY packet will be generated in Step 11 (GMTP) *)
+	 *	 Otherwise,
+	 *	      Generate Reset(No Connection) unless P.type == Reset
+	 *	      Drop packet and return
+	 */
+
+	if (sk->sk_state == GMTP_LISTEN)  {
+
+		if(gh->type == GMTP_PKT_REQUEST
+				|| gh->type == GMTP_PKT_REGISTER) {
+			if(inet_csk(sk)->icsk_af_ops->conn_request(sk, skb) < 0)
+				return 1;
+			goto discard;
+		}
+		if(gh->type == GMTP_PKT_RESET)
+			goto discard;
+
+		/* Avoid GMTP-Inter problems */
+		if(gmtp_info->relay_enabled)
+			goto discard;
+
+		/* Caller (gmtp_v4_do_rcv) will send Reset */
+		gcb->reset_code = GMTP_RESET_CODE_NO_CONNECTION;
+		return 1;
+	} else if (sk->sk_state == GMTP_CLOSED || sk->sk_state == GMTP_ACTIVE_CLOSEREQ) {
+		gcb->reset_code = GMTP_RESET_CODE_NO_CONNECTION;
+		return 1;
+	}
+
+	/* Step 6: Check sequence numbers (omitted in LISTEN/REQUEST state) */
+	if (sk->sk_state != GMTP_REQUESTING && gmtp_check_seqno(sk, skb))
+		goto discard;
+
+	/*
+	 *   Step 7: Check for unexpected packet types
+	 */
+	if ((!gmtp_role_client(sk) && gh->type == GMTP_PKT_REQUESTNOTIFY) ||
+		(gmtp_role_client(sk) && gh->type == GMTP_PKT_REQUEST) ||
+		(sk->sk_state == GMTP_REQUEST_RECV && gh->type == GMTP_PKT_DATA))
+	{
+		gmtp_print_error("Unexpected packet type");
+		goto discard;
+	}
+
+	/*
+	 *  Step 9: Process Reset
+	 *	If P.type == Reset,
+	 *		Tear down connection
+	 *		S.state := TIMEWAIT
+	 *		Set TIMEWAIT timer
+	 *		Drop packet and return
+	 */
+	if (gh->type == GMTP_PKT_RESET) {
+		gmtp_rcv_reset(sk, skb);
+		return 0;
+	} else if (gh->type == GMTP_PKT_CLOSE) {		/* Step 14 */
+		if (gmtp_rcv_close(sk, skb))
+			return 0;
+		goto discard;
+	}
+
+	switch (sk->sk_state) {
+	case GMTP_REQUESTING: /* client */
+		queued = gmtp_rcv_request_sent_state_process(sk, skb, gh, len);
+		if (queued >= 0)
+			return queued;
+
+		__kfree_skb(skb);
+		return 0;
+
+	case GMTP_REQUEST_RECV: /* Request or Register was received. */
+		queued = gmtp_rcv_request_rcv_state_process(sk, skb, gh, len);
+		break;
+	}
+
+discard:
+	__kfree_skb(skb);
+	return 0;
+
+}
+EXPORT_SYMBOL_GPL(gmtp_rcv_state_process);
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/ipv4.c linux-4.9-rc2/net/gmtp/ipv4.c
--- linux-4.9-rc2-original/net/gmtp/ipv4.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/ipv4.c	2016-12-05 01:18:10.597816925 -0300
@@ -0,0 +1,1361 @@
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/netfilter.h>
+#include <linux/err.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <net/inet_hashtables.h>
+#include <net/inet_common.h>
+#include <net/inet_connection_sock.h>
+#include <net/icmp.h>
+#include <net/ip.h>
+#include <net/protocol.h>
+#include <net/request_sock.h>
+#include <net/sock.h>
+#include <net/xfrm.h>
+#include <net/secure_seq.h>
+#include <linux/netfilter_ipv4.h>
+
+#include <uapi/linux/gmtp.h>
+#include <linux/gmtp.h>
+#include "gmtp-inter/gmtp-inter.h"
+#include "gmtp.h"
+
+static struct nf_hook_ops nfho_gmtp_out;
+
+extern int sysctl_ip_nonlocal_bind __read_mostly;
+extern struct inet_timewait_death_row gmtp_death_row;
+
+static inline __u32 gmtp_v4_init_sequence(const struct sk_buff *skb)
+{
+    return secure_gmtp_sequence_number(ip_hdr(skb)->daddr,
+            ip_hdr(skb)->saddr, gmtp_hdr(skb)->sport,
+            gmtp_hdr(skb)->dport);
+}
+
+struct sock* gmtp_v4_build_control_sk(struct sock *sk)
+{
+    struct sockaddr_in *local;
+    unsigned char *channel = "\xee\xff\xff\xfa"; /* 238.255.255.250 */
+
+    gmtp_pr_func();
+
+    local = kmalloc(sizeof(struct sockaddr_in), GFP_KERNEL);
+    local->sin_family = AF_INET;
+    local->sin_port = htons(1900);
+    local->sin_addr.s_addr = *(unsigned int *)channel;
+    memset(&local->sin_zero, 0, sizeof(local->sin_zero));
+    gmtp_info->ctrl_addr = local;
+
+    return gmtp_multicast_connect(sk, GMTP_SOCK_TYPE_CONTROL_CHANNEL,
+            local->sin_addr.s_addr, local->sin_port);
+}
+
+int gmtp_v4_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)
+{
+    const struct sockaddr_in *usin = (struct sockaddr_in *)uaddr;
+    struct inet_sock *inet = inet_sk(sk);
+    struct gmtp_sock *gp = gmtp_sk(sk);
+    __be16 orig_sport, orig_dport;
+    __be32 daddr, nexthop;
+    struct flowi4 *fl4;
+    struct rtable *rt;
+    int err;
+    struct ip_options_rcu *inet_opt;
+
+    gmtp_print_function();
+
+    gp->role = GMTP_ROLE_CLIENT;
+
+    if(addr_len < sizeof(struct sockaddr_in))
+        return -EINVAL;
+
+    if(usin->sin_family != AF_INET)
+        return -EAFNOSUPPORT;
+
+    nexthop = daddr = usin->sin_addr.s_addr;
+
+    inet_opt = rcu_dereference_protected(inet->inet_opt,
+            sock_owned_by_user(sk));
+    if(inet_opt != NULL && inet_opt->opt.srr) {
+        if(daddr == 0)
+            return -EINVAL;
+        nexthop = inet_opt->opt.faddr;
+    }
+
+    orig_sport = inet->inet_sport;
+    orig_dport = usin->sin_port;
+    fl4 = &inet->cork.fl.u.ip4;
+
+    rt = ip_route_connect(fl4, nexthop, inet->inet_saddr, RT_CONN_FLAGS(sk),
+            sk->sk_bound_dev_if,
+            IPPROTO_GMTP, orig_sport, orig_dport, sk);
+    if(IS_ERR(rt))
+        return PTR_ERR(rt);
+
+    if(rt->rt_flags & (RTCF_MULTICAST | RTCF_BROADCAST)) {
+        ip_rt_put(rt);
+        return -ENETUNREACH;
+    }
+
+    if(inet_opt == NULL || !inet_opt->opt.srr)
+        daddr = fl4->daddr;
+
+    if(inet->inet_saddr == 0)
+        inet->inet_saddr = fl4->saddr;
+    inet->inet_rcv_saddr = inet->inet_saddr;
+    inet->inet_dport = usin->sin_port;
+    inet->inet_daddr = daddr;
+
+    inet_csk(sk)->icsk_ext_hdr_len = 0;
+    if(inet_opt)
+        inet_csk(sk)->icsk_ext_hdr_len = inet_opt->opt.optlen;
+    /*
+     * Socket identity is still unknown (sport may be zero).
+     * However we set state to GMTP_REQUESTING and not releasing socket
+     * lock select source port, enter ourselves into the hash tables and
+     * complete initialization after this.
+     */
+    gmtp_set_state(sk, GMTP_REQUESTING);
+    err = inet_hash_connect(&gmtp_death_row, sk);
+    if(err != 0)
+        goto failure;
+
+    rt = ip_route_newports(fl4, rt, orig_sport, orig_dport,
+            inet->inet_sport, inet->inet_dport, sk);
+
+    if(IS_ERR(rt)) {
+        err = PTR_ERR(rt);
+        rt = NULL;
+        goto failure;
+    }
+    /* OK, now commit destination to socket.  */
+    sk_setup_caps(sk, &rt->dst);
+
+    gp->iss = secure_gmtp_sequence_number(inet->inet_saddr,
+            inet->inet_daddr, inet->inet_sport, inet->inet_dport);
+    inet->inet_id = gp->iss ^ jiffies;
+
+    err = gmtp_connect(sk);
+    rt = NULL;
+    if(err != 0)
+        goto failure;
+
+    gmtp_info->control_sk = gmtp_v4_build_control_sk(sk);
+
+out:
+    return err;
+
+failure:
+    /*
+     * This unhashes the socket and releases the local port, if necessary.
+     */
+    gmtp_set_state(sk, GMTP_CLOSED);
+    ip_rt_put(rt);
+    sk->sk_route_caps = 0;
+    inet->inet_dport = 0;
+    goto out;
+}
+EXPORT_SYMBOL_GPL(gmtp_v4_connect);
+
+static void gmtp_do_redirect(struct sk_buff *skb, struct sock *sk)
+{
+    struct dst_entry *dst = __sk_dst_check(sk, 0);
+
+    if(dst)
+        dst->ops->redirect(dst, sk, skb);
+}
+
+/**
+ * This routine is called by the ICMP module when it gets some sort of error
+ * condition.
+ */
+void gmtp_v4_err(struct sk_buff *skb, u32 info)
+{
+    const struct iphdr *iph = (struct iphdr *)skb->data;
+    const u8 offset = iph->ihl << 2;
+    const struct gmtp_hdr *gh = (struct gmtp_hdr *)(skb->data + offset);
+    struct gmtp_sock *gp;
+    struct inet_sock *inet;
+    struct inet_connection_sock *icsk;
+    const int type = icmp_hdr(skb)->type;
+    const int code = icmp_hdr(skb)->code;
+    struct sock *sk;
+    __be32 seq;
+    int err;
+    struct net *net = dev_net(skb->dev);
+
+    struct request_sock *req, **prev;
+
+    pr_info("ICMP: Type: %d, Code: %d | ", type, code);
+    print_packet(skb, true);
+
+    if(skb->len < offset + sizeof(*gh)) {
+        __ICMP_INC_STATS(net, ICMP_MIB_INERRORS);
+        return;
+    }
+
+    sk = inet_lookup(net, &gmtp_inet_hashinfo,
+            skb, 0,
+            iph->daddr, gh->dport,
+            iph->saddr, gh->sport, inet_iif(skb));
+    if(sk == NULL) {
+        __ICMP_INC_STATS(net, ICMP_MIB_INERRORS);
+        return;
+    }
+
+    if(sk->sk_state == GMTP_TIME_WAIT) {
+        inet_twsk_put(inet_twsk(sk));
+        return;
+    }
+
+    bh_lock_sock(sk);
+    /* If too many ICMPs get dropped on busy
+     * servers this needs to be solved differently.
+     */
+    if(sock_owned_by_user(sk))
+        __NET_INC_STATS(net, LINUX_MIB_LOCKDROPPEDICMPS);
+
+    if(sk->sk_state == GMTP_CLOSED)
+        goto out;
+
+    gp = gmtp_sk(sk);
+    seq = gh->seq;
+
+    if((1 << sk->sk_state) & ~(GMTPF_REQUESTING | GMTPF_LISTEN)) {
+        __NET_INC_STATS(net, LINUX_MIB_OUTOFWINDOWICMPS);
+        goto out;
+    }
+
+    switch(type) {
+    case ICMP_REDIRECT:
+        gmtp_do_redirect(skb, sk);
+        goto out;
+    case ICMP_SOURCE_QUENCH:
+        /* Just silently ignore these. */
+        goto out;
+    case ICMP_PARAMETERPROB:
+        err = EPROTO;
+        break;
+    case ICMP_DEST_UNREACH:
+        if(code > NR_ICMP_UNREACH)
+            goto out;
+
+        if(code == ICMP_FRAG_NEEDED) { /* PMTU discovery (RFC1191) */
+            if(!sock_owned_by_user(sk))
+                /*FIXME gmtp_do_pmtu_discovery(sk, iph, info);*/;
+            goto out;
+        }
+        err = icmp_err_convert[code].errno;
+        break;
+    case ICMP_TIME_EXCEEDED:
+        err = EHOSTUNREACH;
+        break;
+    default:
+        goto out;
+    }
+
+    icsk = inet_csk(sk);
+    switch(sk->sk_state) {
+    case GMTP_REQUESTING:
+        if(err == EHOSTUNREACH && icsk->icsk_retransmits <= 3)
+            goto out;
+    case GMTP_REQUEST_RECV:
+        if(!sock_owned_by_user(sk)) {
+            sk->sk_err = err;
+            sk->sk_error_report(sk);
+            gmtp_done(sk);
+        } else
+            sk->sk_err_soft = err;
+        goto out;
+    }
+
+    /* If we've already connected we will keep trying
+     * until we time out, or the user gives up.
+     */
+    inet = inet_sk(sk);
+    if(!sock_owned_by_user(sk) && inet->recverr) {
+        sk->sk_err = err;
+        sk->sk_error_report(sk);
+    } else
+        /* Only an error on timeout */
+        sk->sk_err_soft = err;
+out:
+    bh_unlock_sock(sk);
+    sock_put(sk);
+}
+EXPORT_SYMBOL_GPL(gmtp_v4_err);
+
+static struct dst_entry* gmtp_v4_route_skb(struct net *net, struct sock *sk,
+        struct sk_buff *skb)
+{
+    struct rtable *rt;
+    const struct iphdr *iph = ip_hdr(skb);
+    struct flowi4 fl4 = {
+            .flowi4_oif = inet_iif(skb),
+            .daddr = iph->saddr,
+            .saddr = iph->daddr,
+            .flowi4_tos = RT_CONN_FLAGS(sk),
+            .flowi4_proto = sk->sk_protocol,
+            .fl4_sport = gmtp_hdr(skb)->dport,
+            .fl4_dport = gmtp_hdr(skb)->sport, };
+
+    security_skb_classify_flow(skb, flowi4_to_flowi(&fl4));
+    rt = ip_route_output_flow(net, &fl4, sk);
+    if(IS_ERR(rt)) {
+        __IP_INC_STATS(net, IPSTATS_MIB_OUTNOROUTES);
+        return NULL;
+    }
+
+    return &rt->dst;
+}
+
+static int gmtp_v4_send_register_reply(const struct sock *sk,
+        struct request_sock *req)
+{
+    int err = -1;
+    struct sk_buff *skb;
+    struct dst_entry *dst;
+    struct flowi4 fl4;
+
+    gmtp_print_function();
+
+    dst = inet_csk_route_req(sk, &fl4, req);
+    pr_info("dst: %p\n", dst);
+    if(dst == NULL)
+        goto out;
+
+    skb = gmtp_make_register_reply(sk, dst, req);
+    if(skb != NULL) {
+        const struct inet_request_sock *ireq = inet_rsk(req);
+        gmtp_sk(sk)->reply_stamp = jiffies_to_msecs(jiffies);
+
+        err = ip_build_and_send_pkt(skb, sk, ireq->ir_loc_addr,
+                ireq->ir_rmt_addr, ireq->opt);
+        err = net_xmit_eval(err);
+    }
+
+out:
+    dst_release(dst);
+    return err;
+}
+
+static void gmtp_v4_ctl_send_packet(struct sock *sk, struct sk_buff *rxskb, __u8 type)
+{
+    int err;
+    const struct iphdr *rxiph;
+    struct sk_buff *skb = NULL;
+    struct dst_entry *dst;
+    struct net *net = dev_net(skb_dst(rxskb)->dev);
+    struct sock *ctl_sk = net->gmtp.v4_ctl_sk;
+
+    gmtp_pr_debug("%s (%u)", gmtp_packet_name(type), type);
+
+    if(skb_rtable(rxskb)->rt_type != RTN_LOCAL)
+        return;
+
+    dst = gmtp_v4_route_skb(net, ctl_sk, rxskb);
+    if(dst == NULL)
+        return;
+
+    switch(type) {
+    case GMTP_PKT_RESET:
+        /* Never send a reset in response to a reset. */
+        if(gmtp_hdr(rxskb)->type == GMTP_PKT_RESET)
+            return;
+        skb = gmtp_ctl_make_reset(ctl_sk, rxskb);
+        break;
+    case GMTP_PKT_ELECT_RESPONSE:
+        skb = gmtp_ctl_make_elect_response(ctl_sk, rxskb);
+        break;
+    case GMTP_PKT_ACK:
+        skb = gmtp_ctl_make_ack(ctl_sk, rxskb);
+        break;
+    }
+
+    if(skb == NULL)
+        goto out;
+
+    rxiph = ip_hdr(rxskb);
+    skb_dst_set(skb, dst_clone(dst));
+
+    bh_lock_sock(ctl_sk);
+    err = ip_build_and_send_pkt(skb, ctl_sk, rxiph->daddr, rxiph->saddr,
+            NULL);
+    bh_unlock_sock(ctl_sk);
+
+    if(net_xmit_eval(err) == 0) {
+        /*      DCCP_INC_STATS_BH(DCCP_MIB_OUTSEGS);
+         DCCP_INC_STATS_BH(DCCP_MIB_OUTRSTS);*/
+    }
+
+out:
+    dst_release(dst);
+}
+
+static void gmtp_v4_ctl_send_reset(const struct sock *sk, struct sk_buff *rxskb)
+{
+    gmtp_v4_ctl_send_packet(sk, rxskb, GMTP_PKT_RESET);
+}
+
+static struct sock *gmtp_v4_hnd_req(struct sock *sk, struct sk_buff *skb)
+{
+    const struct gmtp_hdr *gh = gmtp_hdr(skb);
+    const struct iphdr *iph = ip_hdr(skb);
+    struct sock *nsk;
+
+    /* Find possible connection requests. */
+    /****
+    struct request_sock *req = inet_csk_search_req(sk, gh->sport,
+            iph->saddr, iph->daddr);
+    ****/
+
+    struct request_sock *req = inet_reqsk(sk);
+
+    sk = req->rsk_listener;
+    if (unlikely(sk->sk_state != GMTP_LISTEN)) {
+        inet_csk_reqsk_queue_drop_and_put(sk, req);
+        goto lookup;
+    }
+    sock_hold(sk);
+    // refcounted = true;
+    // nsk = dccp_check_req(sk, skb, req);
+
+    gmtp_pr_func();
+
+    if(req != NULL)
+        return gmtp_check_req(sk, skb, req);
+
+lookup:
+    nsk = inet_lookup_established(sock_net(sk), &gmtp_inet_hashinfo,
+            iph->saddr, gh->sport, iph->daddr, gh->dport,
+            inet_iif(skb));
+
+    if(nsk != NULL) {
+        if(nsk->sk_state != GMTP_TIME_WAIT) {
+            bh_lock_sock(nsk);
+            return nsk;
+        }
+        inet_twsk_put(inet_twsk(nsk));
+        return NULL;
+    }
+
+    return sk;
+}
+
+int gmtp_v4_do_rcv(struct sock *sk, struct sk_buff *skb)
+{
+    struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+    if(sk->sk_state == GMTP_OPEN) { /* Fast path */
+        if(gmtp_rcv_established(sk, skb, gh, skb->len))
+            goto reset;
+        return 0;
+    }
+
+    /*
+     * Step 3: Process LISTEN state
+     *
+     * If P.type == Request
+     *     Generate a new socket and switch to that socket.
+     *     Set S := new socket for this port pair
+     *        S.state = RESPOND //TODO change to Request-Reply
+     *    A Response packet will be generated in Step 11 *)
+     *  Otherwise,
+     *        Generate Reset(No Connection) unless P.type == Reset
+     *        Drop packet and return
+     */
+    if(sk->sk_state == GMTP_LISTEN) {
+
+        struct sock *nsk;
+
+        nsk = gmtp_v4_hnd_req(sk, skb);
+        if(nsk == NULL)
+            goto discard;
+
+        /* TODO Treat it */
+        if(nsk != sk) {
+            if(gmtp_child_process(sk, nsk, skb))
+                goto reset;
+            return 0;
+        }
+    }
+
+    if(gmtp_rcv_state_process(sk, skb, gh, skb->len))
+        goto reset;
+
+    return 0;
+
+reset:
+    gmtp_v4_ctl_send_reset(sk, skb);
+discard:
+    kfree_skb(skb);
+    return 0;
+
+}
+EXPORT_SYMBOL_GPL(gmtp_v4_do_rcv);
+
+/**
+ *  gmtp_check_packet  -  check for malformed packets
+ *  Packets that fail these checks are ignored and do not receive Resets.
+ */
+static int gmtp_check_packet(struct sk_buff *skb)
+{
+    const struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+    /** Accept multicast only for Data, Close and Reset packets */
+    if(skb->pkt_type != PACKET_HOST && gh->type != GMTP_PKT_DATA
+            && gh->type != GMTP_PKT_CLOSE
+            && gh->type != GMTP_PKT_RESET) {
+        gmtp_pr_warning("invalid packet destiny\n");
+        return 1;
+    }
+
+    /* If the packet is shorter than sizeof(struct gmtp_hdr),
+     * drop packet and return */
+    if(!pskb_may_pull(skb, sizeof(struct gmtp_hdr))) {
+        gmtp_pr_warning("pskb_may_pull failed\n");
+        return 1;
+    }
+
+    /* If P.type is not understood, drop packet and return */
+    if(gh->type >= GMTP_PKT_INVALID) {
+        gmtp_pr_warning("invalid packet type\n");
+        return 1;
+    }
+
+    /*
+     * If P.hdrlen is too small for packet type, drop packet and return
+     */
+    if(gh->hdrlen < gmtp_hdr_len(skb) / sizeof(u32)) {
+        gmtp_pr_warning("P.hdrlen(%u) too small\n", gh->hdrlen);
+        return 1;
+    }
+
+    /* If header checksum is incorrect, drop packet and return.
+     * (This step is completed in the AF-dependent functions.) */
+    skb->csum = skb_checksum(skb, 0, skb->len, 0);
+
+    return 0;
+}
+
+/**
+ * FIXME verify if client already is added.
+ */
+static int gmtp_v4_reporter_rcv_elect_request(struct sk_buff *skb)
+{
+    const struct iphdr *iph = ip_hdr(skb);
+    const struct gmtp_hdr *gh = gmtp_hdr(skb);
+    struct gmtp_client_entry *media_entry;
+    struct gmtp_client *r;
+    struct gmtp_client *c;
+
+    gmtp_pr_func();
+
+    media_entry = gmtp_lookup_client(client_hashtable, gh->flowname);
+    if(media_entry == NULL) {
+        pr_info("Media entry == NULL\n");
+        return 1;
+    }
+
+    r = gmtp_get_client(&media_entry->clients->list, iph->daddr, gh->dport);
+    if(r == NULL) {
+        pr_info("Reporter == NULL\n");
+        return 1;
+    }
+
+    pr_info("Reporter: ADDR=%pI4@%-5d, max_nclients: %u, nclients: %u\n",
+            &r->addr, ntohs(r->port), r->max_nclients, r->nclients);
+
+    if((r->max_nclients <= 0) || (r->nclients >= r->max_nclients)) {
+        pr_info("r->max_nclients <= 0 || r->nclients >= r->max_nclients\n");
+        GMTP_SKB_CB(skb)->elect_code = GMTP_ELECT_REJECT;
+    } else {
+        r->nclients++;
+        c = gmtp_list_add_client(0, iph->saddr, gh->sport, 0,
+                &r->clients->list);
+        GMTP_SKB_CB(skb)->elect_code = GMTP_ELECT_ACCEPT;
+    }
+
+    gmtp_v4_ctl_send_packet(0, skb, GMTP_PKT_ELECT_RESPONSE);
+    return 0;
+}
+EXPORT_SYMBOL_GPL(gmtp_v4_reporter_rcv_elect_request);
+
+static int gmtp_v4_client_rcv_elect_response(struct sk_buff *skb)
+{
+    const struct iphdr *iph = ip_hdr(skb);
+    const struct gmtp_hdr *gh = gmtp_hdr(skb);
+    struct gmtp_client_entry *media_entry;
+    struct gmtp_client *client;
+
+    gmtp_pr_func();
+
+    media_entry = gmtp_lookup_client(client_hashtable, gh->flowname);
+    if(media_entry == NULL) {
+        pr_info("Media entry == NULL\n");
+        return 1;
+    }
+
+    client = gmtp_get_client(&media_entry->clients->list, iph->daddr,
+            gh->dport);
+    if(client == NULL) {
+        pr_info("Client == NULL\n");
+        return 1;
+    }
+
+    pr_info("Client: ADDR=%pI4@%-5d\n", &client->addr, ntohs(client->port));
+    if(client->rsock == NULL) {
+        pr_info("client->rsock == NULL\n");
+        return 1;
+    }
+
+    gmtp_set_state(client->rsock, GMTP_OPEN);
+    gmtp_send_ack(client->rsock);
+
+    return 0;
+}
+EXPORT_SYMBOL_GPL(gmtp_v4_client_rcv_elect_response);
+
+static int gmtp_v4_client_rcv_reporter_ack(struct sk_buff *skb,
+        struct gmtp_client *c)
+{
+    const struct iphdr *iph = ip_hdr(skb);
+    const struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+    gmtp_pr_func();
+
+    if(c == NULL) {
+        gmtp_pr_error("Client is NULL!");
+        return 1;
+    }
+
+    if(c->reporter == NULL || c->rsock == NULL) {
+        gmtp_pr_warning("Reporter %pI4@%-5d null!", &iph->saddr,
+                ntohs(gh->sport));
+        return 1;
+    }
+
+    if((iph->saddr != c->reporter->addr) || (gh->sport != c->reporter->port)) {
+        gmtp_pr_warning("Reporter %pI4@%-5d invalid!", &iph->saddr,
+                ntohs(gh->sport));
+        return 1;
+    }
+
+    c->ack_rx_tstamp = jiffies_to_msecs(jiffies);
+    gmtp_sk(c->rsock)->ack_rx_tstamp = c->ack_rx_tstamp;
+
+    pr_info("ACK received from reporter %pI4@%-5d\n", &iph->saddr,
+            ntohs(gh->sport));
+
+    return 0;
+}
+
+static int gmtp_v4_reporter_rcv_ack(struct sk_buff *skb)
+{
+    const struct iphdr *iph = ip_hdr(skb);
+    const struct gmtp_hdr *gh = gmtp_hdr(skb);
+    struct gmtp_client_entry *media_entry;
+    struct gmtp_client *r;
+    struct gmtp_client *c;
+
+    gmtp_pr_func();
+
+    media_entry = gmtp_lookup_client(client_hashtable, gh->flowname);
+    if(media_entry == NULL) {
+        pr_info("Media entry == NULL\n");
+        return 1;
+    }
+
+    r = gmtp_get_client(&media_entry->clients->list, iph->daddr, gh->dport);
+    if(r == NULL) {
+        gmtp_pr_warning("Reporter %pI4@%-5d not found!", &iph->daddr,
+                ntohs(gh->dport));
+        return 1;
+    }
+
+    /* If i'm a client, check ack from reporter */
+    if(r->max_nclients <= 0) {
+        return gmtp_v4_client_rcv_reporter_ack(skb, r);
+    }
+
+    c = gmtp_get_client(&r->clients->list, iph->saddr, gh->sport);
+    if(c == NULL) {
+        gmtp_pr_warning("Client %pI4@%-5d not found!", &iph->saddr,
+                ntohs(gh->sport));
+        return 1;
+    }
+    c->ack_rx_tstamp = jiffies_to_msecs(jiffies);
+
+    pr_info("ACK received from client %pI4@%-5d\n", &iph->saddr,
+            ntohs(gh->sport));
+
+    gmtp_v4_ctl_send_packet(0, skb, GMTP_PKT_ACK);
+
+    return 0;
+}
+
+/*
+
+ static int gmtp_v4_reporter_rcv_close(struct sk_buff *skb)
+ {
+ const struct iphdr *iph = ip_hdr(skb);
+ const struct gmtp_hdr *gh = gmtp_hdr(skb);
+ struct gmtp_client_entry *media_entry;
+ struct gmtp_client *r;
+ struct gmtp_client *c;
+
+ gmtp_pr_func();
+
+ media_entry = gmtp_lookup_client(gmtp_hashtable, gh->flowname);
+ if(media_entry == NULL) {
+ pr_info("Media entry == NULL\n");
+ return 1;
+ }
+
+ r = gmtp_get_client(&media_entry->clients->list, iph->daddr, gh->dport);
+ if(r == NULL) {
+ pr_info("Reporter == NULL\n");
+ return 1;
+ }
+
+ if(r->max_nclients <= 0) {
+ pr_info("r->max_nclients <= 0\n");
+ return 1;
+ }
+
+ c = gmtp_get_client(&r->clients->list, iph->saddr, gh->sport);
+ if(c == NULL) {
+ pr_info("client == NULL\n");
+ return 1;
+ }
+
+ pr_info("CLOSE received from client %pI4@%-5d\n", &c->addr, ntohs(c->port));
+
+ return 0;
+ }
+ */
+
+static int gmtp_v4_sk_receive_skb(struct sk_buff *skb, struct sock *sk)
+{
+    const struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+    if(sk == NULL) {
+
+        const struct iphdr *iph = ip_hdr(skb);
+
+        if(gmtp_info->relay_enabled) {
+            /*gmtp_pr_error("Relay enabled (%s)",
+                    gmtp_packet_name(gh->type));*/
+            if(gh->type == GMTP_PKT_DATA) {
+                gmtp_pr_info("Data pkt received...");
+                /*print_gmtp_packet(iph, gh);*/
+                goto ignore_it;
+            }
+        }
+
+        /* TODO Make a reset code for each error here! */
+        switch(gh->type) {
+        case GMTP_PKT_ELECT_REQUEST:
+            if(gmtp_v4_reporter_rcv_elect_request(skb))
+                goto no_gmtp_socket;
+            break;
+        case GMTP_PKT_ELECT_RESPONSE:
+            if(gmtp_v4_client_rcv_elect_response(skb))
+                goto no_gmtp_socket;
+            break;
+        case GMTP_PKT_ACK:
+            if(gmtp_v4_reporter_rcv_ack(skb)) {
+                print_gmtp_packet(iph, gh);
+                goto no_gmtp_socket;
+            }
+            break;
+            /* FIXME Manage close from server... */
+            /*case GMTP_PKT_CLOSE:
+             pr_info("CLOSE received!\n");
+             if(gmtp_v4_reporter_rcv_close(skb))
+             goto no_gmtp_socket;
+             break;*/
+        default:
+            gmtp_pr_error("Failed to look up flow ID in table and "
+                "get corresponding socket for this packet: ");
+            print_gmtp_packet(iph, gh);
+            goto no_gmtp_socket;
+        }
+
+        goto discard_it;
+    }
+
+    /*
+     * Step 2:
+     *  ... or S.state == TIMEWAIT,
+     *      Generate Reset(No Connection) unless P.type == Reset
+     *      Drop packet and return
+     */
+    if(sk->sk_state == GMTP_TIME_WAIT) {
+        inet_twsk_put(inet_twsk(sk));
+        goto no_gmtp_socket;
+    }
+
+    if(!xfrm4_policy_check(sk, XFRM_POLICY_IN, skb)) {
+        sock_put(sk);
+        goto discard_it;
+    }
+
+    nf_reset(skb);
+
+    return sk_receive_skb(sk, skb, 1);
+
+no_gmtp_socket:
+
+    if(!xfrm4_policy_check(NULL, XFRM_POLICY_IN, skb))
+        goto discard_it;
+    /*
+     * Step 2:
+     *  If no socket ...
+     *      Generate Reset(No Connection) unless P.type == Reset
+     *      Drop packet and return
+     */
+    if(gh->type != GMTP_PKT_RESET) {
+        GMTP_SKB_CB(skb)->reset_code =
+                GMTP_RESET_CODE_NO_CONNECTION;
+        gmtp_v4_ctl_send_reset(sk, skb);
+    }
+
+discard_it:
+    kfree_skb(skb);
+    return 0;
+
+ignore_it:
+    return 0;
+}
+
+/* this is called when real data arrives */
+static int gmtp_v4_rcv(struct sk_buff *skb)
+{
+    const struct gmtp_hdr *gh;
+    const struct iphdr *iph;
+    struct sock *sk;
+
+    /* Step 1: Check header basics */
+    if(gmtp_check_packet(skb)) {
+        gmtp_pr_error("gmtp_check_packet returned with an error!");
+        goto discard_it;
+    }
+
+    gh = gmtp_hdr(skb);
+    iph = ip_hdr(skb);
+
+    GMTP_SKB_CB(skb)->seq = gh->seq;
+    GMTP_SKB_CB(skb)->type = gh->type;
+
+    /*if(unlikely(gh->type != GMTP_PKT_DATA && gh->type != GMTP_PKT_ACK)) {*/
+        print_gmtp_packet(iph, gh);
+    /*}*/
+
+
+    /**
+     * FIXME Change Election algorithm to fully distributed using multicast
+     */
+    if(skb->pkt_type == PACKET_MULTICAST) {
+
+        struct gmtp_client *tmp;
+        struct gmtp_client_entry *media_entry = gmtp_lookup_client(
+                client_hashtable, gh->flowname);
+
+        if(media_entry == NULL)
+            goto discard_it;
+
+        list_for_each_entry(tmp, &(media_entry->clients->list), list)
+        {
+            if(!tmp)
+                goto discard_it;
+
+            sk = __inet_lookup(dev_net(skb_dst(skb)->dev),
+                    &gmtp_inet_hashinfo,
+                    skb,0,
+                    iph->saddr, gh->sport,
+                    tmp->addr, tmp->port,
+                    inet_iif(skb), NULL);
+
+            /** FIXME Check warnings at receive skb... */
+            gmtp_v4_sk_receive_skb(skb_copy(skb, GFP_ATOMIC), sk);
+        }
+        /*
+         * We made a copy of skb for each client.
+         * So, we can discard the original skb.
+         */
+        goto discard_it;
+
+    } else {
+        /* Unicast packet...
+         * Look up flow ID in table and get corresponding socket
+         */
+        sk = __inet_lookup_skb(&gmtp_inet_hashinfo, skb, 0,
+                gh->sport, gh->dport, NULL);
+
+        return gmtp_v4_sk_receive_skb(skb, sk);
+    }
+
+discard_it:
+    kfree_skb(skb);
+    return 0;
+}
+EXPORT_SYMBOL_GPL(gmtp_v4_rcv);
+
+static void gmtp_v4_reqsk_destructor(struct request_sock *req)
+{
+    gmtp_print_function();
+    kfree(inet_rsk(req)->opt);
+}
+
+void gmtp_syn_ack_timeout(const struct request_sock *req)
+{
+}
+EXPORT_SYMBOL(gmtp_syn_ack_timeout);
+
+static struct request_sock_ops gmtp_request_sock_ops __read_mostly = {
+        .family = PF_INET,
+        .obj_size = sizeof(struct gmtp_request_sock),
+        .rtx_syn_ack = gmtp_v4_send_register_reply,
+        .send_ack = gmtp_reqsk_send_ack,
+        .destructor = gmtp_v4_reqsk_destructor,
+        .send_reset = gmtp_v4_ctl_send_reset,
+        .syn_ack_timeout = gmtp_syn_ack_timeout,
+};
+
+/*
+ * Called by SERVER when it received a request/register from client/relay
+ */
+int gmtp_v4_conn_request(struct sock *sk, struct sk_buff *skb)
+{
+    struct inet_request_sock *ireq;
+
+    struct gmtp_sock *gp = gmtp_sk(sk);
+    struct gmtp_hdr *gh = gmtp_hdr(skb);
+    struct gmtp_hdr_register *gr = gmtp_hdr_register(skb);
+
+    struct request_sock *req;
+    struct gmtp_request_sock *greq;
+    struct gmtp_skb_cb *gcb = GMTP_SKB_CB(skb);
+
+    gmtp_print_function();
+
+    /* Never answer to GMTP_PKT_REQUESTs send to broadcast or multicast */
+    if(skb_rtable(skb)->rt_flags & (RTCF_BROADCAST | RTCF_MULTICAST))
+        return 0; /* discard, don't send a reset here */
+
+    /*
+     * TW buckets are converted to open requests without
+     * limitations, they conserve resources and peer is
+     * evidently real one.
+     */
+    gcb->reset_code = GMTP_RESET_CODE_TOO_BUSY;
+    if(inet_csk_reqsk_queue_is_full(sk)) {
+        pr_info("inet_csk_reqsk_queue_is_full(sk)\n");
+        goto drop;
+    }
+
+    /**
+     * FIXME Update sk->sk_ack_backlog correctly
+     */
+    sk->sk_ack_backlog = 0;
+
+    /*
+     * Accept backlog is full. If we have already queued enough
+     * of warm entries in syn queue, drop request. It is better than
+     * clogging syn queue with openreqs with exponentially increasing
+     * timeout.
+     */
+    if(sk_acceptq_is_full(sk) && inet_csk_reqsk_queue_young(sk) > 1) {
+        pr_info("Accept backlog is full!\n");
+        pr_info("%u > %u? %u\n", sk->sk_ack_backlog,
+                sk->sk_max_ack_backlog, sk_acceptq_is_full(sk));
+        pr_info("inet_csk_reqsk_queue_young(sk) > 1: %u\n", inet_csk_reqsk_queue_young(sk) > 1);
+        goto drop;
+    }
+
+    req = inet_reqsk_alloc(&gmtp_request_sock_ops, sk, true);
+    if(req == NULL)
+        goto drop;
+
+    if(gmtp_reqsk_init(req, gmtp_sk(sk), skb))
+        goto drop_and_free;
+
+    if(security_inet_conn_request(sk, skb, req))
+        goto drop_and_free;
+
+    ireq = inet_rsk(req);
+    sk_rcv_saddr_set(req_to_sk(req), ip_hdr(skb)->daddr);
+    sk_daddr_set(req_to_sk(req), ip_hdr(skb)->saddr);
+    ireq->ireq_family = AF_INET;
+    ireq->ir_iif = sk->sk_bound_dev_if;
+
+    /*
+     * Step 3: Process LISTEN state
+     */
+    greq = gmtp_rsk(req);
+    greq->isr = gcb->seq;
+    greq->gsr = greq->isr;
+    greq->iss = greq->isr;
+    greq->gss = greq->iss;
+    greq->tx_ucc_type = gp->tx_ucc_type;
+    if(memcmp(gh->flowname, gp->flowname, GMTP_FLOWNAME_LEN))
+        goto reset;
+
+    memcpy(greq->flowname, gp->flowname, GMTP_FLOWNAME_LEN);
+    memcpy(gp->relay_id, gr->relay_id, GMTP_RELAY_ID_LEN);
+
+    if(gmtp_v4_send_register_reply(sk, req))
+        goto drop_and_free;
+
+    inet_csk_reqsk_queue_hash_add(sk, req, GMTP_TIMEOUT_INIT);
+
+    return 0;
+
+reset:
+    pr_info("Sending RESET...\n");
+    gcb->reset_code = GMTP_RESET_CODE_BAD_FLOWNAME;
+    gmtp_v4_ctl_send_reset(sk, skb);
+
+drop_and_free:
+    pr_info("reqsk_free(req)...\n");
+    reqsk_free(req);
+drop:
+    pr_info("drop...\n");
+    return 0;
+}
+EXPORT_SYMBOL_GPL(gmtp_v4_conn_request);
+
+/*
+ * The three way handshake has completed - we got a valid ACK or DATAACK -
+ * now create the new socket.
+ *
+ * This is the equivalent of TCP's tcp_v4_syn_recv_sock
+ */
+struct sock *gmtp_v4_request_recv_sock(const struct sock *sk, struct sk_buff *skb,
+        struct request_sock *req, struct dst_entry *dst,
+                      struct request_sock *req_unhash,
+                      bool *own_req)
+
+{
+    struct inet_request_sock *ireq;
+    struct inet_sock *newinet;
+    struct sock *newsk;
+
+    gmtp_print_function();
+
+    // sk->sk_ack_backlog = 0; comenetado por ser read only
+
+    if(sk_acceptq_is_full(sk)) {
+        pr_info("sk_acceptq_is_full(sk)\n");
+        goto exit_overflow;
+    }
+
+    newsk = gmtp_create_openreq_child(sk, req, skb);
+    if(newsk == NULL)
+        goto exit_nonewsk;
+
+    newinet = inet_sk(newsk);
+    ireq = inet_rsk(req);
+    newinet->inet_daddr = ireq->ir_rmt_addr;
+    newinet->inet_rcv_saddr = ireq->ir_loc_addr;
+    newinet->inet_saddr = ireq->ir_loc_addr;
+    newinet->inet_opt = ireq->opt;
+    ireq->opt = NULL;
+    newinet->mc_index = inet_iif(skb);
+    newinet->mc_ttl = ip_hdr(skb)->ttl;
+    newinet->inet_id = jiffies;
+
+    if(dst == NULL  &&
+            (dst = inet_csk_route_child_sock(sk, newsk, req)) == NULL)
+        goto put_and_exit;
+
+    sk_setup_caps(newsk, dst);
+
+    gmtp_sync_mss(newsk, dst_mtu(dst));
+
+    if(__inet_inherit_port(sk, newsk) < 0)
+        goto put_and_exit;
+    inet_ehash_nolisten(newsk, NULL);
+
+    return newsk;
+
+exit_overflow:
+    __NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS);
+exit_nonewsk:
+    dst_release(dst);
+exit:
+    __NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENDROPS);
+    return NULL;
+put_and_exit:
+    inet_csk_prepare_forced_close(newsk);
+    gmtp_done(newsk);
+    goto exit;
+}
+EXPORT_SYMBOL_GPL(gmtp_v4_request_recv_sock);
+
+void gmtp_v4_send_check(struct sock *sk, struct sk_buff *skb)
+{
+    gmtp_print_warning("GMTP has no ckecksum!");
+}
+EXPORT_SYMBOL_GPL(gmtp_v4_send_check);
+
+static const struct inet_connection_sock_af_ops gmtp_ipv4_af_ops = {
+        .queue_xmit = ip_queue_xmit,
+        .send_check = gmtp_v4_send_check, /* GMTP has no checksum... */
+        .rebuild_header = inet_sk_rebuild_header,
+        .conn_request = gmtp_v4_conn_request,
+        .syn_recv_sock = gmtp_v4_request_recv_sock,
+        .net_header_len = sizeof(struct iphdr),
+        .setsockopt = ip_setsockopt,
+        .getsockopt = ip_getsockopt,
+        .addr2sockaddr = inet_csk_addr2sockaddr,
+        .sockaddr_len = sizeof(struct sockaddr_in),
+        .bind_conflict = inet_csk_bind_conflict,
+#ifdef CONFIG_COMPAT
+        .compat_setsockopt = compat_ip_setsockopt,
+        .compat_getsockopt = compat_ip_getsockopt,
+#endif
+    };
+
+static int gmtp_v4_init_sock(struct sock *sk)
+{
+
+    int err = 0;
+
+    gmtp_print_function();
+
+    err = gmtp_init_sock(sk);
+    if(err == 0) {
+        /* Setting AF options */
+        inet_csk(sk)->icsk_af_ops = &gmtp_ipv4_af_ops;
+    }
+
+    return err;
+}
+
+/* Networking protocol blocks we attach to sockets.
+ *
+ * socket layer -> transport layer interface (struct proto)
+ * transport -> network interface is defined by (struct inet_proto)
+ */
+static struct proto gmtp_v4_prot = {
+        .name = "GMTP",
+        .owner = THIS_MODULE,
+        .close = gmtp_close,
+        .connect = gmtp_v4_connect,
+        .disconnect = gmtp_disconnect,
+        .ioctl = gmtp_ioctl,
+        .init = gmtp_v4_init_sock,
+        .setsockopt = gmtp_setsockopt,
+        .getsockopt = gmtp_getsockopt,
+        .sendmsg = gmtp_sendmsg,
+        .recvmsg = gmtp_recvmsg,
+        .backlog_rcv = gmtp_v4_do_rcv,
+        .hash = inet_hash,
+        .unhash = inet_unhash,
+        .accept = inet_csk_accept,
+        .get_port = inet_csk_get_port,
+        .shutdown = gmtp_shutdown,
+        .destroy = gmtp_destroy_sock,
+        .orphan_count = &gmtp_orphan_count,
+        .max_header = GMTP_MAX_HDR_LEN,
+        .obj_size = sizeof(struct gmtp_sock),
+        .slab_flags = SLAB_DESTROY_BY_RCU,
+        .rsk_prot = &gmtp_request_sock_ops,
+        .h.hashinfo = &gmtp_inet_hashinfo,
+};
+
+/**
+ * We define the gmtp_protocol object (net_protocol object) and add it with the
+ * inet_add_protocol() method.
+ * This sets the gmtp_protocol object to be an element in the global
+ * protocols array (inet_protos).
+ *
+ * @handler is called when real data arrives
+ *
+ */
+static const struct net_protocol gmtp_protocol = {
+        .handler = gmtp_v4_rcv,
+        .err_handler = gmtp_v4_err,
+        .no_policy = 1,
+        .netns_ok = 1, /* mandatory */
+        .icmp_strict_tag_validation = 1,
+};
+
+/**
+ * In the socket creation routine, protocol implementer specifies a
+ * 'struct proto_ops' (/include/linux/net.h) instance.
+ * The socket layer calls function members of this proto_ops instance before the
+ * protocol specific functions are called.
+ *
+ * socket layer -> transport layer interface (struct proto)
+ * transport -> network interface is defined by (struct inet_proto)
+ */
+static const struct proto_ops inet_gmtp_ops = {
+        .family = PF_INET,
+        .owner = THIS_MODULE,
+        .release = inet_release,
+        .bind = inet_bind,
+        .connect = inet_stream_connect,
+        .socketpair = sock_no_socketpair,
+        .accept = inet_accept,
+        .getname = inet_getname,
+        .poll = gmtp_poll,
+        .ioctl = inet_ioctl,
+        .listen = inet_gmtp_listen,
+        .shutdown = inet_shutdown,
+        .setsockopt = sock_common_setsockopt,
+        .getsockopt = sock_common_getsockopt,
+        .sendmsg = inet_sendmsg,
+        .recvmsg = sock_common_recvmsg,
+        .mmap = sock_no_mmap,
+        .sendpage = sock_no_sendpage,
+};
+
+/**
+ * Describes the PF_INET protocols
+ * Defines the different SOCK types for PF_INET
+ * Ex: SOCK_STREAM (TCP), SOCK_DGRAM (UDP), SOCK_RAW
+ *
+ * inet_register_protosw() is the function called to register inet sockets.
+ * There is a static array of type inet_protosw inetsw_array[] which contains
+ * information about all the inet socket types.
+ *
+ * @list: This is a pointer to the next node in the list.
+ * @type: This is the socket type and is a key to search entry for a given
+ * socket and type in inetsw[] array.
+ * @protocol: This is again a key to find an entry for the socket type in the
+ * inetsw[] array. This is an L4 protocol number (L4 Transport layer protocol).
+ * @prot: This is a pointer to struct proto.
+ * ops: This is a pointer to the structure of type 'proto_ops'.
+ */
+static struct inet_protosw gmtp_protosw = {
+        .type = SOCK_GMTP,
+        .protocol = IPPROTO_GMTP,
+        .prot = &gmtp_v4_prot,
+        .ops = &inet_gmtp_ops,
+        .flags = INET_PROTOSW_ICSK,
+};
+
+static int __net_init gmtp_v4_init_net(struct net *net)
+{
+    gmtp_print_function();
+
+    if(gmtp_inet_hashinfo.bhash == NULL)
+        return -ESOCKTNOSUPPORT;
+
+    return inet_ctl_sock_create(&net->gmtp.v4_ctl_sk, PF_INET, SOCK_GMTP,
+    IPPROTO_GMTP, net);
+}
+
+static void __net_exit gmtp_v4_exit_net(struct net *net)
+{
+    gmtp_print_function();
+    inet_ctl_sock_destroy(net->gmtp.v4_ctl_sk);
+}
+
+static struct pernet_operations gmtp_v4_ops = {
+        .init = gmtp_v4_init_net,
+        .exit = gmtp_v4_exit_net,
+};
+
+// static unsigned int hook_func_gmtp_out(unsigned int hooknum, struct sk_buff *skb,
+//         const struct net_device *in, const struct net_device *out,
+//         int (*okfn)(struct sk_buff *))
+static unsigned int hook_func_gmtp_out(unsigned int hooknum, struct sk_buff *skb,
+        const struct nf_hook_state *state)
+{
+    struct iphdr *iph = ip_hdr(skb);
+
+    if(iph->protocol == IPPROTO_GMTP) {
+
+        struct gmtp_hdr *gh = gmtp_hdr(skb);
+        int new_ttl = 1;
+
+        switch(gh->type) {
+        case GMTP_PKT_REQUEST:
+            if(GMTP_SKB_CB(skb)->retransmits <= 3) {
+                gmtp_pr_info("Changing TTL to %d\n", new_ttl);
+                iph->ttl = new_ttl;
+                ip_send_check(iph);
+            } else {
+                pr_info("Auto promoting to relay\n");
+                gh->type = GMTP_PKT_REGISTER;
+            }
+        }
+    }
+
+    return NF_ACCEPT;
+}
+
+/*************************************************************/
+static int __init gmtp_v4_init(void)
+{
+    int err = 0;
+
+    gmtp_print_function();
+
+    inet_hashinfo_init(&gmtp_inet_hashinfo);
+
+    err = proto_register(&gmtp_v4_prot, 1);
+    if(err != 0)
+        goto out;
+
+    err = inet_add_protocol(&gmtp_protocol, IPPROTO_GMTP);
+    if(err != 0)
+        goto out_proto_unregister;
+
+    inet_register_protosw(&gmtp_protosw);
+
+    err = register_pernet_subsys(&gmtp_v4_ops);
+    if(err)
+        goto out_destroy_ctl_sock;
+
+    /****
+    nfho_gmtp_out.hook = hook_func_gmtp_out;
+    nfho_gmtp_out.hooknum = NF_INET_LOCAL_OUT;
+    nfho_gmtp_out.pf = PF_INET;
+    nfho_gmtp_out.priority = NF_IP_PRI_FIRST;
+    nf_register_hook(&nfho_gmtp_out);
+    ****/
+
+    return err;
+
+out_destroy_ctl_sock:
+    inet_unregister_protosw(&gmtp_protosw);
+    inet_del_protocol(&gmtp_protocol, IPPROTO_GMTP);
+    return err;
+
+out_proto_unregister:
+    proto_unregister(&gmtp_v4_prot);
+
+out:
+    return err;
+}
+
+static void __exit gmtp_v4_exit(void)
+{
+
+    gmtp_print_function();
+
+    /* nf_unregister_hook(&nfho_gmtp_out); */
+    unregister_pernet_subsys(&gmtp_v4_ops);
+    inet_unregister_protosw(&gmtp_protosw);
+    inet_del_protocol(&gmtp_protocol, IPPROTO_GMTP);
+    proto_unregister(&gmtp_v4_prot);
+}
+
+module_init(gmtp_v4_init);
+module_exit(gmtp_v4_exit);
+
+MODULE_ALIAS_NET_PF_PROTO_TYPE(PF_INET, IPPROTO_GMTP, SOCK_GMTP);
+MODULE_ALIAS_NET_PF_PROTO_TYPE(PF_INET, 0, SOCK_GMTP);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Joilnen Leite <joilnen@gmail.com>");
+MODULE_AUTHOR("Mrio Andr Menezes <mariomenezescosta@gmail.com>");
+MODULE_AUTHOR("Wendell Silva Soares <wss@ic.ufal.br>");
+MODULE_DESCRIPTION("GMTP - Global Media Transmission Protocol");
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/mcc/loss_interval.c linux-4.9-rc2/net/gmtp/mcc/loss_interval.c
--- linux-4.9-rc2-original/net/gmtp/mcc/loss_interval.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/mcc/loss_interval.c	2016-12-01 16:50:35.741416304 -0300
@@ -0,0 +1,194 @@
+/*
+ *  Copyright (c) 2007   The University of Aberdeen, Scotland, UK
+ *  Copyright (c) 2005-7 The University of Waikato, Hamilton, New Zealand.
+ *  Copyright (c) 2005-7 Ian McDonald <ian.mcdonald@jandi.co.nz>
+ *  Copyright (c) 2005 Arnaldo Carvalho de Melo <acme@conectiva.com.br>
+ *
+ *  Adapted to GMTP by
+ *  Copyright (c) 2015   Federal University of Alagoas, Macei, Brazil
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; either version 2 of the License, or
+ *  (at your option) any later version.
+ */
+#include <net/sock.h>
+#include <linux/gmtp.h>
+
+#include "mcc_proto.h"
+
+static struct kmem_cache  *tfrc_lh_slab  __read_mostly;
+/* Loss Interval weights from [RFC 3448, 5.4], scaled by 10 */
+static const int tfrc_lh_weights[NINTERVAL] = { 10, 10, 10, 10, 8, 6, 4, 2 };
+
+/* implements LIFO semantics on the array */
+static inline u8 LIH_INDEX(const u8 ctr)
+{
+	return LIH_SIZE - 1 - (ctr % LIH_SIZE);
+}
+
+/* the `counter' index always points at the next entry to be populated */
+static inline struct mcc_loss_interval *mcc_lh_peek(struct mcc_loss_hist *lh)
+{
+	return lh->counter ? lh->ring[LIH_INDEX(lh->counter - 1)] : NULL;
+}
+
+/* given i with 0 <= i <= k, return I_i as per the rfc3448bis notation */
+static inline u32 mcc_lh_get_interval(struct mcc_loss_hist *lh, const u8 i)
+{
+	BUG_ON(i >= lh->counter);
+	return lh->ring[LIH_INDEX(lh->counter - i - 1)]->li_length;
+}
+
+/*
+ *	On-demand allocation and de-allocation of entries
+ */
+static struct mcc_loss_interval *mcc_lh_demand_next(struct mcc_loss_hist *lh)
+{
+	if (lh->ring[LIH_INDEX(lh->counter)] == NULL)
+		lh->ring[LIH_INDEX(lh->counter)] = kmem_cache_alloc(tfrc_lh_slab,
+								    GFP_ATOMIC);
+	return lh->ring[LIH_INDEX(lh->counter)];
+}
+
+void mcc_lh_cleanup(struct mcc_loss_hist *lh)
+{
+	if (!mcc_lh_is_initialised(lh))
+		return;
+
+	for (lh->counter = 0; lh->counter < LIH_SIZE; lh->counter++)
+		if (lh->ring[LIH_INDEX(lh->counter)] != NULL) {
+			kmem_cache_free(tfrc_lh_slab,
+					lh->ring[LIH_INDEX(lh->counter)]);
+			lh->ring[LIH_INDEX(lh->counter)] = NULL;
+		}
+}
+
+static void mcc_lh_calc_i_mean(struct mcc_loss_hist *lh)
+{
+	u32 i_i, i_tot0 = 0, i_tot1 = 0, w_tot = 0;
+	int i, k = mcc_lh_length(lh) - 1; /* k is as in rfc3448bis, 5.4 */
+
+	if (k <= 0)
+		return;
+
+	for (i = 0; i <= k; i++) {
+		i_i = mcc_lh_get_interval(lh, i);
+
+		if (i < k) {
+			i_tot0 += i_i * tfrc_lh_weights[i];
+			w_tot  += tfrc_lh_weights[i];
+		}
+		if (i > 0)
+			i_tot1 += i_i * tfrc_lh_weights[i-1];
+	}
+
+	lh->i_mean = max(i_tot0, i_tot1) / w_tot;
+}
+
+/**
+ * mcc_lh_update_i_mean  -  Update the `open' loss interval I_0
+ * For recomputing p: returns `true' if p > p_prev  <=>  1/p < 1/p_prev
+ */
+u8 mcc_lh_update_i_mean(struct mcc_loss_hist *lh, struct sk_buff *skb)
+{
+	struct mcc_loss_interval *cur = mcc_lh_peek(lh);
+	u32 old_i_mean = lh->i_mean;
+	s64 len;
+
+	if (cur == NULL)			/* not initialised */
+		return 0;
+
+	len = GMTP_SKB_CB(skb)->seq - cur->li_seqno + 1;
+
+	if (len - (s64)cur->li_length <= 0)	/* duplicate or reordered */
+		return 0;
+
+	if(gmtp_hdr(skb)->type == GMTP_PKT_DATA) {
+		if((gmtp_hdr_data(skb)->tstamp - cur->li_tstamp) > cur->li_rtt)
+			/*
+			 * Implements TFRC:
+			 * If a packet S (skb) exists whose seqno comes `after'
+			 * the one starting the current loss interval (cur) and
+			 * if the distance from C(cur) to C(S) is greater than RTT,
+			 * consider all subsequent packets as belonging to a
+			 * new loss interval.
+			 */
+			cur->li_is_closed = 1;
+	}
+
+	if (mcc_lh_length(lh) == 1)		/* due to RFC 3448, 6.3.1 */
+		return 0;
+
+	cur->li_length = len;
+	mcc_lh_calc_i_mean(lh);
+
+	return lh->i_mean < old_i_mean;
+}
+
+/* Determine if `new_loss' does begin a new loss interval [RFC 4342, 10.2] */
+static inline u8 mcc_lh_is_new_loss(struct mcc_loss_interval *cur,
+				     struct mcc_rx_hist_entry *new_loss)
+{
+	return	(new_loss->seqno - cur->li_seqno) > 0 &&
+		(cur->li_is_closed ||
+		(new_loss->tx_tstamp - cur->li_tstamp) > (__u64) cur->li_rtt);
+}
+
+/**
+ * mcc_lh_interval_add  -  Insert new record into the Loss Interval database
+ * @lh:		   Loss Interval database
+ * @rh:		   Receive history containing a fresh loss event
+ * @calc_first_li: Caller-dependent routine to compute length of first interval
+ * @sk:		   Used by @calc_first_li in caller-specific way (subtyping)
+ *
+ * Updates I_mean and returns 1 if a new interval has in fact been added to @lh.
+ */
+int mcc_lh_interval_add(struct mcc_loss_hist *lh, struct mcc_rx_hist *rh,
+			 u32 (*calc_first_li)(struct sock *), struct sock *sk)
+{
+	struct mcc_loss_interval *cur = mcc_lh_peek(lh), *new;
+
+	if (cur != NULL && !mcc_lh_is_new_loss(cur, mcc_rx_hist_loss_prev(rh)))
+		return 0;
+
+	new = mcc_lh_demand_next(lh);
+	if (unlikely(new == NULL)) {
+		gmtp_print_error("Cannot allocate/add loss record.");
+		return 0;
+	}
+
+	new->li_seqno	  = mcc_rx_hist_loss_prev(rh)->seqno;
+	new->li_tstamp 	  = mcc_rx_hist_loss_prev(rh)->tx_tstamp;
+	new->li_rtt 	  = gmtp_sk(sk)->rx_rtt;
+	new->li_is_closed = 0;
+
+	if (++lh->counter == 1)
+		lh->i_mean = new->li_length = (*calc_first_li)(sk);
+	else {
+		cur->li_length = new->li_seqno - cur->li_seqno;
+		new->li_length = mcc_rx_hist_last_rcv(rh)->seqno -
+				new->li_seqno + 1;
+		if (lh->counter > (2*LIH_SIZE))
+			lh->counter -= LIH_SIZE;
+
+		mcc_lh_calc_i_mean(lh);
+	}
+	return 1;
+}
+
+int __init mcc_li_init(void)
+{
+	tfrc_lh_slab = kmem_cache_create("mcc_li_hist",
+					 sizeof(struct mcc_loss_interval), 0,
+					 SLAB_HWCACHE_ALIGN, NULL);
+	return tfrc_lh_slab == NULL ? -ENOBUFS : 0;
+}
+
+void mcc_li_exit(void)
+{
+	if (tfrc_lh_slab != NULL) {
+		kmem_cache_destroy(tfrc_lh_slab);
+		tfrc_lh_slab = NULL;
+	}
+}
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/mcc/loss_interval.h linux-4.9-rc2/net/gmtp/mcc/loss_interval.h
--- linux-4.9-rc2-original/net/gmtp/mcc/loss_interval.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/mcc/loss_interval.h	2016-12-01 16:50:35.741416304 -0300
@@ -0,0 +1,60 @@
+#ifndef _MCC_LI_HIST
+#define _MCC_LI_HIST_
+/*
+ *  Copyright (c) 2007   The University of Aberdeen, Scotland, UK
+ *  Copyright (c) 2005-7 The University of Waikato, Hamilton, New Zealand.
+ *  Copyright (c) 2005-7 Ian McDonald <ian.mcdonald@jandi.co.nz>
+ *  Copyright (c) 2005 Arnaldo Carvalho de Melo <acme@conectiva.com.br>
+ *
+ *  Adapted to GMTP by
+ *  Copyright (c) 2015   Federal University of Alagoas, Macei, Brazil
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the Free
+ *  Software Foundation; either version 2 of the License, or (at your option)
+ *  any later version.
+ */
+#include <linux/ktime.h>
+#include <linux/list.h>
+#include <linux/slab.h>
+
+#include <linux/gmtp.h>
+
+/**
+ *  mcc_loss_interval  -  Loss history record for TFRC-based protocols
+ *  @li_seqno:		Highest received seqno before the start of loss
+ *  @li_is_closed:	Whether @li_seqno is older than 1 RTT
+ *  @li_length:		Loss interval sequence length
+ *  @li_tstamp:		Time stamp of packet with seqno.
+ */
+struct mcc_loss_interval {
+	__be32		 li_seqno;
+	__be32		 li_is_closed:1;
+	__u32		 li_length;
+	__u32		 li_tstamp;
+	__u32		 li_rtt;
+};
+
+static inline void mcc_lh_init(struct mcc_loss_hist *lh)
+{
+	memset(lh, 0, sizeof(struct mcc_loss_hist));
+}
+
+static inline u8 mcc_lh_is_initialised(struct mcc_loss_hist *lh)
+{
+	return lh->counter > 0;
+}
+
+static inline u8 mcc_lh_length(struct mcc_loss_hist *lh)
+{
+	return min(lh->counter, (u8)LIH_SIZE);
+}
+
+struct mcc_rx_hist;
+
+int mcc_lh_interval_add(struct mcc_loss_hist *, struct mcc_rx_hist *,
+			 u32 (*first_li)(struct sock *), struct sock *);
+u8 mcc_lh_update_i_mean(struct mcc_loss_hist *lh, struct sk_buff *);
+void mcc_lh_cleanup(struct mcc_loss_hist *lh);
+
+#endif /* _MCC_LI_HIST */
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/mcc/mcc_equation.c linux-4.9-rc2/net/gmtp/mcc/mcc_equation.c
--- linux-4.9-rc2-original/net/gmtp/mcc/mcc_equation.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/mcc/mcc_equation.c	2016-12-01 16:50:35.756416117 -0300
@@ -0,0 +1,713 @@
+/*
+ *  Copyright (c) 2005 The University of Waikato, Hamilton, New Zealand.
+ *  Copyright (c) 2005 Ian McDonald <ian.mcdonald@jandi.co.nz>
+ *  Copyright (c) 2005 Arnaldo Carvalho de Melo <acme@conectiva.com.br>
+ *  Copyright (c) 2003 Nils-Erik Mattsson, Joacim Haggmark, Magnus Erixzon
+ *
+ *  Adapted to GMTP by
+ *  Copyright (c) 2015   Federal University of Alagoas, Macei, Brazil
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; either version 2 of the License, or
+ *  (at your option) any later version.
+ */
+
+#include <linux/module.h>
+#include "mcc_proto.h"
+#include "../gmtp.h"
+
+#define MCC_CALC_X_ARRSIZE 500
+#define MCC_CALC_X_SPLIT   50000	/* 0.05 * 1000000, details below */
+#define MCC_SMALLEST_P	    (MCC_CALC_X_SPLIT/MCC_CALC_X_ARRSIZE)
+
+/*
+  TFRC TCP Reno Throughput Equation Lookup Table for f(p)
+
+  The following two-column lookup table implements a part of the TCP throughput
+  equation from [RFC 3448, sec. 3.1]:
+
+				     s
+  X_calc  =  --------------------------------------------------------------
+	     R * sqrt(2*b*p/3) + (3 * t_RTO * sqrt(3*b*p/8) * (p + 32*p^3))
+
+  Where:
+	X      is the transmit rate in bytes/second
+	s      is the packet size in bytes
+	R      is the round trip time in seconds
+	p      is the loss event rate, between 0 and 1.0, of the number of loss
+		      events as a fraction of the number of packets transmitted
+	t_RTO  is the TCP retransmission timeout value in seconds
+	b      is the number of packets acknowledged by a single TCP ACK
+
+  We can assume that b = 1 and t_RTO is 4 * R. The equation now becomes:
+
+				     s
+  X_calc  =  -------------------------------------------------------
+	     R * sqrt(p*2/3) + (12 * R * sqrt(p*3/8) * (p + 32*p^3))
+
+  which we can break down into:
+
+		      s
+	X_calc  =  ---------
+		    R * f(p)
+
+  where f(p) is given for 0 < p <= 1 by:
+
+	f(p)  =  sqrt(2*p/3) + 12 * sqrt(3*p/8) *  (p + 32*p^3)
+
+  Since this is kernel code, floating-point arithmetic is avoided in favour of
+  integer arithmetic. This means that nearly all fractional parameters are
+  scaled by 1000000:
+    * the parameters p and R
+    * the return result f(p)
+  The lookup table therefore actually tabulates the following function g(q):
+
+	g(q)  =  1000000 * f(q/1000000)
+
+  Hence, when p <= 1, q must be less than or equal to 1000000. To achieve finer
+  granularity for the practically more relevant case of small values of p (up to
+  5%), the second column is used; the first one ranges up to 100%.  This split
+  corresponds to the value of q = TFRC_CALC_X_SPLIT. At the same time this also
+  determines the smallest resolution possible with this lookup table:
+
+    TFRC_SMALLEST_P   =  TFRC_CALC_X_SPLIT / TFRC_CALC_X_ARRSIZE
+
+  The entire table is generated by:
+    for(i=0; i < TFRC_CALC_X_ARRSIZE; i++) {
+	lookup[i][0]  =  g((i+1) * 1000000/TFRC_CALC_X_ARRSIZE);
+	lookup[i][1]  =  g((i+1) * TFRC_CALC_X_SPLIT/TFRC_CALC_X_ARRSIZE);
+    }
+
+  With the given configuration, we have, with M = TFRC_CALC_X_ARRSIZE-1,
+    lookup[0][0]  =  g(1000000/(M+1))		= 1000000 * f(0.2%)
+    lookup[M][0]  =  g(1000000)			= 1000000 * f(100%)
+    lookup[0][1]  =  g(TFRC_SMALLEST_P)		= 1000000 * f(0.01%)
+    lookup[M][1]  =  g(TFRC_CALC_X_SPLIT)	= 1000000 * f(5%)
+
+  In summary, the two columns represent f(p) for the following ranges:
+    * The first column is for   0.002  <= p <= 1.0
+    * The second column is for  0.0001 <= p <= 0.05
+  Where the columns overlap, the second (finer-grained) is given preference,
+  i.e. the first column is used only for p >= 0.05.
+ */
+static const u32 mcc_calc_x_lookup[MCC_CALC_X_ARRSIZE][2] = {
+	{     37172,   8172 },
+	{     53499,  11567 },
+	{     66664,  14180 },
+	{     78298,  16388 },
+	{     89021,  18339 },
+	{     99147,  20108 },
+	{    108858,  21738 },
+	{    118273,  23260 },
+	{    127474,  24693 },
+	{    136520,  26052 },
+	{    145456,  27348 },
+	{    154316,  28589 },
+	{    163130,  29783 },
+	{    171919,  30935 },
+	{    180704,  32049 },
+	{    189502,  33130 },
+	{    198328,  34180 },
+	{    207194,  35202 },
+	{    216114,  36198 },
+	{    225097,  37172 },
+	{    234153,  38123 },
+	{    243294,  39055 },
+	{    252527,  39968 },
+	{    261861,  40864 },
+	{    271305,  41743 },
+	{    280866,  42607 },
+	{    290553,  43457 },
+	{    300372,  44293 },
+	{    310333,  45117 },
+	{    320441,  45929 },
+	{    330705,  46729 },
+	{    341131,  47518 },
+	{    351728,  48297 },
+	{    362501,  49066 },
+	{    373460,  49826 },
+	{    384609,  50577 },
+	{    395958,  51320 },
+	{    407513,  52054 },
+	{    419281,  52780 },
+	{    431270,  53499 },
+	{    443487,  54211 },
+	{    455940,  54916 },
+	{    468635,  55614 },
+	{    481581,  56306 },
+	{    494785,  56991 },
+	{    508254,  57671 },
+	{    521996,  58345 },
+	{    536019,  59014 },
+	{    550331,  59677 },
+	{    564939,  60335 },
+	{    579851,  60988 },
+	{    595075,  61636 },
+	{    610619,  62279 },
+	{    626491,  62918 },
+	{    642700,  63553 },
+	{    659253,  64183 },
+	{    676158,  64809 },
+	{    693424,  65431 },
+	{    711060,  66050 },
+	{    729073,  66664 },
+	{    747472,  67275 },
+	{    766266,  67882 },
+	{    785464,  68486 },
+	{    805073,  69087 },
+	{    825103,  69684 },
+	{    845562,  70278 },
+	{    866460,  70868 },
+	{    887805,  71456 },
+	{    909606,  72041 },
+	{    931873,  72623 },
+	{    954614,  73202 },
+	{    977839,  73778 },
+	{   1001557,  74352 },
+	{   1025777,  74923 },
+	{   1050508,  75492 },
+	{   1075761,  76058 },
+	{   1101544,  76621 },
+	{   1127867,  77183 },
+	{   1154739,  77741 },
+	{   1182172,  78298 },
+	{   1210173,  78852 },
+	{   1238753,  79405 },
+	{   1267922,  79955 },
+	{   1297689,  80503 },
+	{   1328066,  81049 },
+	{   1359060,  81593 },
+	{   1390684,  82135 },
+	{   1422947,  82675 },
+	{   1455859,  83213 },
+	{   1489430,  83750 },
+	{   1523671,  84284 },
+	{   1558593,  84817 },
+	{   1594205,  85348 },
+	{   1630518,  85878 },
+	{   1667543,  86406 },
+	{   1705290,  86932 },
+	{   1743770,  87457 },
+	{   1782994,  87980 },
+	{   1822973,  88501 },
+	{   1863717,  89021 },
+	{   1905237,  89540 },
+	{   1947545,  90057 },
+	{   1990650,  90573 },
+	{   2034566,  91087 },
+	{   2079301,  91600 },
+	{   2124869,  92111 },
+	{   2171279,  92622 },
+	{   2218543,  93131 },
+	{   2266673,  93639 },
+	{   2315680,  94145 },
+	{   2365575,  94650 },
+	{   2416371,  95154 },
+	{   2468077,  95657 },
+	{   2520707,  96159 },
+	{   2574271,  96660 },
+	{   2628782,  97159 },
+	{   2684250,  97658 },
+	{   2740689,  98155 },
+	{   2798110,  98651 },
+	{   2856524,  99147 },
+	{   2915944,  99641 },
+	{   2976382, 100134 },
+	{   3037850, 100626 },
+	{   3100360, 101117 },
+	{   3163924, 101608 },
+	{   3228554, 102097 },
+	{   3294263, 102586 },
+	{   3361063, 103073 },
+	{   3428966, 103560 },
+	{   3497984, 104045 },
+	{   3568131, 104530 },
+	{   3639419, 105014 },
+	{   3711860, 105498 },
+	{   3785467, 105980 },
+	{   3860253, 106462 },
+	{   3936229, 106942 },
+	{   4013410, 107422 },
+	{   4091808, 107902 },
+	{   4171435, 108380 },
+	{   4252306, 108858 },
+	{   4334431, 109335 },
+	{   4417825, 109811 },
+	{   4502501, 110287 },
+	{   4588472, 110762 },
+	{   4675750, 111236 },
+	{   4764349, 111709 },
+	{   4854283, 112182 },
+	{   4945564, 112654 },
+	{   5038206, 113126 },
+	{   5132223, 113597 },
+	{   5227627, 114067 },
+	{   5324432, 114537 },
+	{   5422652, 115006 },
+	{   5522299, 115474 },
+	{   5623389, 115942 },
+	{   5725934, 116409 },
+	{   5829948, 116876 },
+	{   5935446, 117342 },
+	{   6042439, 117808 },
+	{   6150943, 118273 },
+	{   6260972, 118738 },
+	{   6372538, 119202 },
+	{   6485657, 119665 },
+	{   6600342, 120128 },
+	{   6716607, 120591 },
+	{   6834467, 121053 },
+	{   6953935, 121514 },
+	{   7075025, 121976 },
+	{   7197752, 122436 },
+	{   7322131, 122896 },
+	{   7448175, 123356 },
+	{   7575898, 123815 },
+	{   7705316, 124274 },
+	{   7836442, 124733 },
+	{   7969291, 125191 },
+	{   8103877, 125648 },
+	{   8240216, 126105 },
+	{   8378321, 126562 },
+	{   8518208, 127018 },
+	{   8659890, 127474 },
+	{   8803384, 127930 },
+	{   8948702, 128385 },
+	{   9095861, 128840 },
+	{   9244875, 129294 },
+	{   9395760, 129748 },
+	{   9548529, 130202 },
+	{   9703198, 130655 },
+	{   9859782, 131108 },
+	{  10018296, 131561 },
+	{  10178755, 132014 },
+	{  10341174, 132466 },
+	{  10505569, 132917 },
+	{  10671954, 133369 },
+	{  10840345, 133820 },
+	{  11010757, 134271 },
+	{  11183206, 134721 },
+	{  11357706, 135171 },
+	{  11534274, 135621 },
+	{  11712924, 136071 },
+	{  11893673, 136520 },
+	{  12076536, 136969 },
+	{  12261527, 137418 },
+	{  12448664, 137867 },
+	{  12637961, 138315 },
+	{  12829435, 138763 },
+	{  13023101, 139211 },
+	{  13218974, 139658 },
+	{  13417071, 140106 },
+	{  13617407, 140553 },
+	{  13819999, 140999 },
+	{  14024862, 141446 },
+	{  14232012, 141892 },
+	{  14441465, 142339 },
+	{  14653238, 142785 },
+	{  14867346, 143230 },
+	{  15083805, 143676 },
+	{  15302632, 144121 },
+	{  15523842, 144566 },
+	{  15747453, 145011 },
+	{  15973479, 145456 },
+	{  16201939, 145900 },
+	{  16432847, 146345 },
+	{  16666221, 146789 },
+	{  16902076, 147233 },
+	{  17140429, 147677 },
+	{  17381297, 148121 },
+	{  17624696, 148564 },
+	{  17870643, 149007 },
+	{  18119154, 149451 },
+	{  18370247, 149894 },
+	{  18623936, 150336 },
+	{  18880241, 150779 },
+	{  19139176, 151222 },
+	{  19400759, 151664 },
+	{  19665007, 152107 },
+	{  19931936, 152549 },
+	{  20201564, 152991 },
+	{  20473907, 153433 },
+	{  20748982, 153875 },
+	{  21026807, 154316 },
+	{  21307399, 154758 },
+	{  21590773, 155199 },
+	{  21876949, 155641 },
+	{  22165941, 156082 },
+	{  22457769, 156523 },
+	{  22752449, 156964 },
+	{  23049999, 157405 },
+	{  23350435, 157846 },
+	{  23653774, 158287 },
+	{  23960036, 158727 },
+	{  24269236, 159168 },
+	{  24581392, 159608 },
+	{  24896521, 160049 },
+	{  25214642, 160489 },
+	{  25535772, 160929 },
+	{  25859927, 161370 },
+	{  26187127, 161810 },
+	{  26517388, 162250 },
+	{  26850728, 162690 },
+	{  27187165, 163130 },
+	{  27526716, 163569 },
+	{  27869400, 164009 },
+	{  28215234, 164449 },
+	{  28564236, 164889 },
+	{  28916423, 165328 },
+	{  29271815, 165768 },
+	{  29630428, 166208 },
+	{  29992281, 166647 },
+	{  30357392, 167087 },
+	{  30725779, 167526 },
+	{  31097459, 167965 },
+	{  31472452, 168405 },
+	{  31850774, 168844 },
+	{  32232445, 169283 },
+	{  32617482, 169723 },
+	{  33005904, 170162 },
+	{  33397730, 170601 },
+	{  33792976, 171041 },
+	{  34191663, 171480 },
+	{  34593807, 171919 },
+	{  34999428, 172358 },
+	{  35408544, 172797 },
+	{  35821174, 173237 },
+	{  36237335, 173676 },
+	{  36657047, 174115 },
+	{  37080329, 174554 },
+	{  37507197, 174993 },
+	{  37937673, 175433 },
+	{  38371773, 175872 },
+	{  38809517, 176311 },
+	{  39250924, 176750 },
+	{  39696012, 177190 },
+	{  40144800, 177629 },
+	{  40597308, 178068 },
+	{  41053553, 178507 },
+	{  41513554, 178947 },
+	{  41977332, 179386 },
+	{  42444904, 179825 },
+	{  42916290, 180265 },
+	{  43391509, 180704 },
+	{  43870579, 181144 },
+	{  44353520, 181583 },
+	{  44840352, 182023 },
+	{  45331092, 182462 },
+	{  45825761, 182902 },
+	{  46324378, 183342 },
+	{  46826961, 183781 },
+	{  47333531, 184221 },
+	{  47844106, 184661 },
+	{  48358706, 185101 },
+	{  48877350, 185541 },
+	{  49400058, 185981 },
+	{  49926849, 186421 },
+	{  50457743, 186861 },
+	{  50992759, 187301 },
+	{  51531916, 187741 },
+	{  52075235, 188181 },
+	{  52622735, 188622 },
+	{  53174435, 189062 },
+	{  53730355, 189502 },
+	{  54290515, 189943 },
+	{  54854935, 190383 },
+	{  55423634, 190824 },
+	{  55996633, 191265 },
+	{  56573950, 191706 },
+	{  57155606, 192146 },
+	{  57741621, 192587 },
+	{  58332014, 193028 },
+	{  58926806, 193470 },
+	{  59526017, 193911 },
+	{  60129666, 194352 },
+	{  60737774, 194793 },
+	{  61350361, 195235 },
+	{  61967446, 195677 },
+	{  62589050, 196118 },
+	{  63215194, 196560 },
+	{  63845897, 197002 },
+	{  64481179, 197444 },
+	{  65121061, 197886 },
+	{  65765563, 198328 },
+	{  66414705, 198770 },
+	{  67068508, 199213 },
+	{  67726992, 199655 },
+	{  68390177, 200098 },
+	{  69058085, 200540 },
+	{  69730735, 200983 },
+	{  70408147, 201426 },
+	{  71090343, 201869 },
+	{  71777343, 202312 },
+	{  72469168, 202755 },
+	{  73165837, 203199 },
+	{  73867373, 203642 },
+	{  74573795, 204086 },
+	{  75285124, 204529 },
+	{  76001380, 204973 },
+	{  76722586, 205417 },
+	{  77448761, 205861 },
+	{  78179926, 206306 },
+	{  78916102, 206750 },
+	{  79657310, 207194 },
+	{  80403571, 207639 },
+	{  81154906, 208084 },
+	{  81911335, 208529 },
+	{  82672880, 208974 },
+	{  83439562, 209419 },
+	{  84211402, 209864 },
+	{  84988421, 210309 },
+	{  85770640, 210755 },
+	{  86558080, 211201 },
+	{  87350762, 211647 },
+	{  88148708, 212093 },
+	{  88951938, 212539 },
+	{  89760475, 212985 },
+	{  90574339, 213432 },
+	{  91393551, 213878 },
+	{  92218133, 214325 },
+	{  93048107, 214772 },
+	{  93883493, 215219 },
+	{  94724314, 215666 },
+	{  95570590, 216114 },
+	{  96422343, 216561 },
+	{  97279594, 217009 },
+	{  98142366, 217457 },
+	{  99010679, 217905 },
+	{  99884556, 218353 },
+	{ 100764018, 218801 },
+	{ 101649086, 219250 },
+	{ 102539782, 219698 },
+	{ 103436128, 220147 },
+	{ 104338146, 220596 },
+	{ 105245857, 221046 },
+	{ 106159284, 221495 },
+	{ 107078448, 221945 },
+	{ 108003370, 222394 },
+	{ 108934074, 222844 },
+	{ 109870580, 223294 },
+	{ 110812910, 223745 },
+	{ 111761087, 224195 },
+	{ 112715133, 224646 },
+	{ 113675069, 225097 },
+	{ 114640918, 225548 },
+	{ 115612702, 225999 },
+	{ 116590442, 226450 },
+	{ 117574162, 226902 },
+	{ 118563882, 227353 },
+	{ 119559626, 227805 },
+	{ 120561415, 228258 },
+	{ 121569272, 228710 },
+	{ 122583219, 229162 },
+	{ 123603278, 229615 },
+	{ 124629471, 230068 },
+	{ 125661822, 230521 },
+	{ 126700352, 230974 },
+	{ 127745083, 231428 },
+	{ 128796039, 231882 },
+	{ 129853241, 232336 },
+	{ 130916713, 232790 },
+	{ 131986475, 233244 },
+	{ 133062553, 233699 },
+	{ 134144966, 234153 },
+	{ 135233739, 234608 },
+	{ 136328894, 235064 },
+	{ 137430453, 235519 },
+	{ 138538440, 235975 },
+	{ 139652876, 236430 },
+	{ 140773786, 236886 },
+	{ 141901190, 237343 },
+	{ 143035113, 237799 },
+	{ 144175576, 238256 },
+	{ 145322604, 238713 },
+	{ 146476218, 239170 },
+	{ 147636442, 239627 },
+	{ 148803298, 240085 },
+	{ 149976809, 240542 },
+	{ 151156999, 241000 },
+	{ 152343890, 241459 },
+	{ 153537506, 241917 },
+	{ 154737869, 242376 },
+	{ 155945002, 242835 },
+	{ 157158929, 243294 },
+	{ 158379673, 243753 },
+	{ 159607257, 244213 },
+	{ 160841704, 244673 },
+	{ 162083037, 245133 },
+	{ 163331279, 245593 },
+	{ 164586455, 246054 },
+	{ 165848586, 246514 },
+	{ 167117696, 246975 },
+	{ 168393810, 247437 },
+	{ 169676949, 247898 },
+	{ 170967138, 248360 },
+	{ 172264399, 248822 },
+	{ 173568757, 249284 },
+	{ 174880235, 249747 },
+	{ 176198856, 250209 },
+	{ 177524643, 250672 },
+	{ 178857621, 251136 },
+	{ 180197813, 251599 },
+	{ 181545242, 252063 },
+	{ 182899933, 252527 },
+	{ 184261908, 252991 },
+	{ 185631191, 253456 },
+	{ 187007807, 253920 },
+	{ 188391778, 254385 },
+	{ 189783129, 254851 },
+	{ 191181884, 255316 },
+	{ 192588065, 255782 },
+	{ 194001698, 256248 },
+	{ 195422805, 256714 },
+	{ 196851411, 257181 },
+	{ 198287540, 257648 },
+	{ 199731215, 258115 },
+	{ 201182461, 258582 },
+	{ 202641302, 259050 },
+	{ 204107760, 259518 },
+	{ 205581862, 259986 },
+	{ 207063630, 260454 },
+	{ 208553088, 260923 },
+	{ 210050262, 261392 },
+	{ 211555174, 261861 },
+	{ 213067849, 262331 },
+	{ 214588312, 262800 },
+	{ 216116586, 263270 },
+	{ 217652696, 263741 },
+	{ 219196666, 264211 },
+	{ 220748520, 264682 },
+	{ 222308282, 265153 },
+	{ 223875978, 265625 },
+	{ 225451630, 266097 },
+	{ 227035265, 266569 },
+	{ 228626905, 267041 },
+	{ 230226576, 267514 },
+	{ 231834302, 267986 },
+	{ 233450107, 268460 },
+	{ 235074016, 268933 },
+	{ 236706054, 269407 },
+	{ 238346244, 269881 },
+	{ 239994613, 270355 },
+	{ 241651183, 270830 },
+	{ 243315981, 271305 }
+};
+
+/* return largest index i such that fval <= lookup[i][small] */
+static inline u32 mcc_binsearch(u32 fval, u8 small)
+{
+	u32 try, low = 0, high = MCC_CALC_X_ARRSIZE - 1;
+
+	while (low < high) {
+		try = (low + high) / 2;
+		if (fval <= mcc_calc_x_lookup[try][small])
+			high = try;
+		else
+			low  = try + 1;
+	}
+	return high;
+}
+
+/**
+ * mcc_calc_x - Calculate the send rate as per section 3.1 of RFC3448
+ * @s: packet size          in bytes
+ * @R: RTT                  scaled by 1000000   (i.e., microseconds)
+ * @p: loss ratio estimate  scaled by 1000000
+ *
+ * Returns X_calc           in bytes per second (not scaled).
+ */
+u32 mcc_calc_x(u16 s, u32 R, u32 p)
+{
+	u16 index;
+	u32 f;
+	u64 result;
+
+	/* check against invalid parameters and divide-by-zero   */
+	BUG_ON(p >  1000000);		/* p must not exceed 100%   */
+	BUG_ON(p == 0);			/* f(0) = 0, divide by zero */
+
+	/*
+	if(p == 0 || p > 1000000) {
+		gmtp_pr_error("Invalid value of p: %u", p);
+		return 0;
+	}
+	*/
+
+	if (R == 0) {			/* possible  divide by zero */
+		gmtp_pr_error("WARNING: RTT is 0, returning maximum X_calc.");
+		return ~0U;
+	}
+
+	if (p <= MCC_CALC_X_SPLIT)		{     /* 0.0000 < p <= 0.05   */
+		if (p < MCC_SMALLEST_P)	      /* 0.0000 < p <  0.0001 */
+			index = 0;
+		else			      /* 0.0001 <= p <= 0.05  */
+			index =  p/MCC_SMALLEST_P - 1;
+
+		f = mcc_calc_x_lookup[index][1];
+
+	} else {				      /* 0.05   <  p <= 1.00  */
+		index = p/(1000000/MCC_CALC_X_ARRSIZE) - 1;
+		f = mcc_calc_x_lookup[index][0];
+	}
+
+	/*
+	 * Compute X = s/(R*f(p)) in bytes per second.
+	 * Since f(p) and R are both scaled by 1000000, we need to multiply by
+	 * 1000000^2. To avoid overflow, the result is computed in two stages.
+	 * This works under almost all reasonable operational conditions, for a
+	 * wide range of parameters. Yet, should some strange combination of
+	 * parameters result in overflow, the use of scaled_div32 will catch
+	 * this and return UINT_MAX - which is a logically adequate consequence.
+	 */
+	result = scaled_div(s, R);
+	return scaled_div32(result, f);
+}
+
+/**
+ *  mcc_calc_x_reverse_lookup  -  try to find p given f(p)
+ *  @fvalue: function value to match, scaled by 1000000
+ *
+ *  Returns closest match for p, also scaled by 1000000
+ */
+u32 mcc_calc_x_reverse_lookup(u32 fvalue)
+{
+	int index;
+
+	if (fvalue == 0)	/* f(p) = 0  whenever  p = 0 */
+		return 0;
+
+	/* Error cases. */
+	if (fvalue < mcc_calc_x_lookup[0][1]) {
+		gmtp_pr_warning("fvalue %u smaller than resolution\n", fvalue);
+		return MCC_SMALLEST_P;
+	}
+	if (fvalue > mcc_calc_x_lookup[MCC_CALC_X_ARRSIZE - 1][0]) {
+		gmtp_pr_warning("fvalue %u exceeds bounds!\n", fvalue);
+		return 1000000;
+	}
+
+	if (fvalue <= mcc_calc_x_lookup[MCC_CALC_X_ARRSIZE - 1][1]) {
+		index = mcc_binsearch(fvalue, 1);
+		return (index + 1) * MCC_CALC_X_SPLIT / MCC_CALC_X_ARRSIZE;
+	}
+
+	/* else ... it must be in the coarse-grained column */
+	index = mcc_binsearch(fvalue, 0);
+	return (index + 1) * 1000000 / MCC_CALC_X_ARRSIZE;
+}
+
+/**
+ * mcc_invert_loss_event_rate  -  Compute p so that 10^6 corresponds to 100%
+ * When @loss_event_rate is large, there is a chance that p is truncated to 0.
+ * To avoid re-entering slow-start in that case, we set p = TFRC_SMALLEST_P > 0.
+ */
+u32 mcc_invert_loss_event_rate(u32 loss_event_rate)
+{
+	if (loss_event_rate == UINT_MAX)		/* see RFC 4342, 8.5 */
+		return 0;
+	if (unlikely(loss_event_rate == 0))		/* map 1/0 into 100% */
+		return 1000000;
+	return max_t(u32, scaled_div(1, loss_event_rate), MCC_SMALLEST_P);
+}
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/mcc/mcc_input.c linux-4.9-rc2/net/gmtp/mcc/mcc_input.c
--- linux-4.9-rc2-original/net/gmtp/mcc/mcc_input.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/mcc/mcc_input.c	2016-12-01 16:50:35.757416104 -0300
@@ -0,0 +1,295 @@
+/*
+ * mcc_input.c
+ *
+ *  Created on: 13/04/2015
+ *      Author: wendell
+ *
+ *  GMTP-MCC receiver routines
+ */
+
+#include <linux/gmtp.h>
+
+#include "mcc_proto.h"
+
+/* GMTP-MCC feedback types */
+enum mcc_fback_type {
+	MCC_FBACK_NONE = 0,
+	MCC_FBACK_INITIAL,
+	MCC_FBACK_PERIODIC,
+	MCC_FBACK_PARAM_CHANGE
+};
+
+static const char *mcc_rx_state_name(enum mcc_rx_states state)
+{
+	static const char *const mcc_rx_state_names[] = {
+	[MCC_RSTATE_NO_DATA] = "NO_DATA",
+	[MCC_RSTATE_DATA]    = "DATA",
+	};
+
+	return mcc_rx_state_names[state];
+}
+
+static void mcc_rx_set_state(struct sock *sk, enum mcc_rx_states state)
+{
+	struct gmtp_sock *hc = gmtp_sk(sk);
+	enum mcc_rx_states oldstate = hc->rx_state;
+
+	gmtp_pr_func();
+	mcc_pr_debug("%s(%p) %-8.8s -> %s\n",
+			gmtp_role_name(sk), sk, mcc_rx_state_name(oldstate),
+		       mcc_rx_state_name(state));
+	WARN_ON(state == oldstate);
+	hc->rx_state = state;
+}
+
+
+static void mcc_rx_send_feedback(struct sock *sk,
+				      const struct sk_buff *skb,
+				      enum mcc_fback_type fbtype)
+{
+	struct gmtp_sock *gp = gmtp_sk(sk);
+	ktime_t now = ktime_get_real();
+	u32 sample;
+	s64 delta = 0;
+	u32 p;
+
+	switch (fbtype) {
+	case MCC_FBACK_INITIAL:
+		gp->rx_x_recv = 0;
+		gp->rx_pinv   = ~0U;   /* see RFC 4342, 8.5 */
+		break;
+	case MCC_FBACK_PARAM_CHANGE:
+		/*
+		 * When parameters change (new loss or p > p_prev), we do not
+		 * have a reliable estimate for R_m of [RFC 3448, 6.2] and so
+		 * need to  reuse the previous value of X_recv. However, when
+		 * X_recv was 0 (due to early loss), this would kill X down to
+		 * s/t_mbi (i.e. one packet in 64 seconds).
+		 * To avoid such drastic reduction, we approximate X_recv as
+		 * the number of bytes since last feedback.
+		 * This is a safe fallback, since X is bounded above by X_calc.
+		 */
+		if (gp->rx_x_recv > 0)
+			break;
+		/* fall through */
+	case MCC_FBACK_PERIODIC:
+		delta = ktime_us_delta(now, gp->rx_tstamp_last_feedback);
+		if (delta <= 0)
+			gmtp_pr_error("delta (%ld) <= 0", (long)delta);
+		else
+			gp->rx_x_recv = scaled_div32(gp->rx_bytes_recv, delta);
+		break;
+	default:
+		return;
+	}
+
+	now = ktime_get_real();
+	gp->rx_tstamp_last_feedback = now;
+	gp->rx_bytes_recv	    = 0;
+	sample = gp->rx_rtt * USEC_PER_MSEC;
+
+	if(sample != 0)
+		gp->rx_avg_rtt = rtt_ewma(gp->rx_avg_rtt, sample, 900);
+
+	if(gp->rx_avg_rtt <= 0)
+		gp->rx_avg_rtt = GMTP_SANE_RTT_MIN;
+
+	p = mcc_invert_loss_event_rate(gp->rx_pinv);
+	if(p > 0) {
+		u32 new_rate = mcc_calc_x(gp->rx_s, gp->rx_avg_rtt, p);
+		/*
+		 * Change only if the value is valid!
+		 */
+		if(new_rate > 0)
+			gp->rx_max_rate = new_rate;
+	} else {
+		/*
+		 * No loss events. Returning max X_calc.
+		 * Sender will ignore feedback and keep last TX
+		 */
+		gp->rx_max_rate = ~0U;
+	}
+
+	if(likely(gp->role == GMTP_ROLE_REPORTER)) {
+
+		if(p > 0)
+			mcc_pr_debug("Loss: %u", p);
+
+		mcc_pr_debug("REPORT: RTT=%u us (sample=%u us), s=%u, "
+			       "p=%u, X_calc=%u B/s, X_recv=%u B/s",
+			       gp->rx_avg_rtt, sample,
+			       gp->rx_s, p,
+			       gp->rx_max_rate,
+			       gp->rx_x_recv);
+
+		gmtp_send_feedback(sk);
+	}
+}
+
+
+
+/**
+ * mcc_first_li  -  Implements [RFC 5348, 6.3.1]
+ *
+ * Determine the length of the first loss interval via inverse lookup.
+ * Assume that X_recv can be computed by the throughput equation
+ *		    s
+ *	X_recv = --------
+ *		 R * fval
+ * Find some p such that f(p) = fval; return 1/p (scaled).
+ */
+static u32 mcc_first_li(struct sock *sk)
+{
+	struct gmtp_sock *hc = gmtp_sk(sk);
+	u32 x_recv, p, delta;
+	u64 fval;
+
+	if (hc->rx_rtt == 0) {
+		gmtp_pr_warning("No RTT estimate available, using fallback RTT");
+		/* FIXME Use server RTT */
+		hc->rx_rtt = GMTP_FALLBACK_RTT;
+	}
+
+	delta  = ktime_to_us(net_timedelta(hc->rx_tstamp_last_feedback));
+	x_recv = scaled_div32(hc->rx_bytes_recv, delta);
+	if (x_recv == 0) {		/* would also trigger divide-by-zero */
+		gmtp_pr_warning("X_recv==0\n");
+		if (hc->rx_x_recv == 0) {
+			gmtp_pr_error("stored value of X_recv is zero");
+			return ~0U;
+		}
+		x_recv = hc->rx_x_recv;
+	}
+
+	fval = scaled_div(hc->rx_s, hc->rx_rtt);
+	fval = scaled_div32(fval, x_recv);
+	p = mcc_calc_x_reverse_lookup(fval);
+
+	mcc_pr_debug("%s receive rate=%u bytes/s, implied "
+		       "loss rate=%u\n", gmtp_role_name(sk), x_recv, p);
+
+	return p == 0 ? ~0U : scaled_div(1, p);
+}
+
+
+void mcc_rx_packet_recv(struct sock *sk, struct sk_buff *skb)
+{
+	struct gmtp_sock *gp = gmtp_sk(sk);
+	enum mcc_fback_type do_feedback = MCC_FBACK_NONE;
+	const __be32 ndp = gmtp_sk(sk)->ndp_count;
+	const bool is_data_packet = gmtp_data_packet(skb);
+	ktime_t now = ktime_get_real();
+	s64 delta = 0;
+
+	if(unlikely(gp->rx_state == MCC_RSTATE_NO_DATA)) {
+		if(is_data_packet) {
+			const u32 payload = skb->len
+					- gmtp_hdr(skb)->hdrlen * 4;
+			do_feedback = MCC_FBACK_INITIAL;
+			mcc_rx_set_state(sk, MCC_RSTATE_DATA);
+			gp->rx_s = payload;
+			/*
+			 * Not necessary to update rx_bytes_recv here,
+			 * since X_recv = 0 for the first feedback packet (cf.
+			 * RFC 3448, 6.3) -- gerrit
+			 */
+		}
+		goto update_records;
+	}
+
+	if(mcc_rx_hist_duplicate(&gp->rx_hist, skb))
+		return;  /* done receiving */
+
+	if(is_data_packet) {
+		const u32 payload = skb->len - gmtp_hdr(skb)->hdrlen;
+		struct gmtp_hdr_data *dh = gmtp_hdr_data(skb);
+
+		/*
+		 * Update moving-average of s and the sum of received payload bytes
+		 */
+		gp->rx_s = rtt_ewma(gp->rx_s, payload, 900);
+		gp->rx_bytes_recv += payload;
+	}
+
+	/*
+	 * Perform loss detection and handle pending losses
+	 */
+	if(mcc_rx_handle_loss(&gp->rx_hist, &gp->rx_li_hist,
+			skb, ndp, mcc_first_li, sk)) {
+		do_feedback = MCC_FBACK_PARAM_CHANGE;
+		goto done_receiving;
+	}
+
+	if(mcc_rx_hist_loss_pending(&gp->rx_hist))
+		return;  /* done receiving */
+
+	/*
+	 * Handle data packets: RTT sampling and monitoring p
+	 */
+	if(unlikely(!is_data_packet))
+		goto update_records;
+
+	if(!mcc_lh_is_initialised(&gp->rx_li_hist)) {
+		/* ms to us */
+		const u32 sample = gp->rx_rtt * USEC_PER_MSEC;
+		/*
+		 * Empty loss history: no loss so far, hence p stays 0.
+		 * Sample RTT values, since an RTT estimate is required for the
+		 * computation of p when the first loss occurs; RFC 3448, 6.3.1.
+		 */
+		if(sample != 0)
+			gp->rx_avg_rtt = rtt_ewma(gp->rx_avg_rtt, sample, 900);
+
+	} else if(mcc_lh_update_i_mean(&gp->rx_li_hist, skb)) {
+		/*
+		 * Step (3) of [RFC 3448, 6.1]: Recompute I_mean and, if I_mean
+		 * has decreased (resp. p has increased), send feedback now.
+		 */
+		do_feedback = MCC_FBACK_PARAM_CHANGE;
+	}
+
+	/*
+	 * Check if the periodic once-per-RTT feedback is due; RFC 4342, 10.3
+	 */
+	delta = ktime_us_delta(now, gp->rx_tstamp_last_feedback);
+	if(delta <= 0)
+		gmtp_pr_error("delta (%ld) <= 0", (long )delta);
+	else if(delta >= gp->rx_avg_rtt)
+		do_feedback = MCC_FBACK_PERIODIC;
+
+update_records:
+	mcc_rx_hist_add_packet(&gp->rx_hist, skb, ndp);
+
+done_receiving:
+	if(do_feedback)
+		mcc_rx_send_feedback(sk, skb, do_feedback);
+}
+EXPORT_SYMBOL_GPL(mcc_rx_packet_recv);
+
+int mcc_rx_init(struct sock *sk)
+{
+	struct gmtp_sock *hc = gmtp_sk(sk);
+
+	gmtp_pr_func();
+
+	hc->rx_state = MCC_RSTATE_NO_DATA;
+	hc->ndp_count = 0;
+	mcc_lh_init(&hc->rx_li_hist);
+	return mcc_rx_hist_alloc(&hc->rx_hist);
+}
+
+void mcc_rx_exit(struct sock *sk)
+{
+	/*struct gmtp_sock *hc = gmtp_sk(sk);*/
+
+	gmtp_pr_func();
+
+	/* FIXME this breaks the modules  */
+	/*
+	mcc_rx_hist_purge(&hc->rx_hist);
+	mcc_lh_cleanup(&hc->rx_li_hist);
+	*/
+}
+
+
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/mcc/mcc_proto.c linux-4.9-rc2/net/gmtp/mcc/mcc_proto.c
--- linux-4.9-rc2-original/net/gmtp/mcc/mcc_proto.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/mcc/mcc_proto.c	2016-12-01 16:50:35.757416104 -0300
@@ -0,0 +1,38 @@
+/*
+ * GMTP-MCC library initialisation
+
+ *
+ * Copyright (c) 2007 The University of Aberdeen, Scotland, UK
+ * Copyright (c) 2007 Arnaldo Carvalho de Melo <acme@redhat.com>
+ *
+ * Adapted to GMTP by
+ * Copyright (c) 2015 Federal University of Alagoas, Macei, Brazil
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include "mcc_proto.h"
+
+int __init mcc_lib_init(void)
+{
+	int rc = mcc_li_init();
+
+	mcc_pr_debug("Starting GMTP-MCC");
+
+	rc = mcc_rx_packet_history_init();
+	if (rc)
+		goto out;
+
+	return 0;
+
+out:
+	mcc_li_exit();
+	return rc;
+}
+
+void mcc_lib_exit(void)
+{
+	mcc_pr_debug("Finishing GMTP-MCC");
+	mcc_rx_packet_history_exit();
+	mcc_li_exit();
+}
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/mcc/mcc_proto.h linux-4.9-rc2/net/gmtp/mcc/mcc_proto.h
--- linux-4.9-rc2-original/net/gmtp/mcc/mcc_proto.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/mcc/mcc_proto.h	2016-12-01 16:50:35.782415792 -0300
@@ -0,0 +1,59 @@
+#ifndef _MCC_H_
+#define _MCC_H_
+/*
+ *  Copyright (c) 2007   The University of Aberdeen, Scotland, UK
+ *  Copyright (c) 2005-6 The University of Waikato, Hamilton, New Zealand.
+ *  Copyright (c) 2005-6 Ian McDonald <ian.mcdonald@jandi.co.nz>
+ *  Copyright (c) 2005   Arnaldo Carvalho de Melo <acme@conectiva.com.br>
+ *  Copyright (c) 2003   Nils-Erik Mattsson, Joacim Haggmark, Magnus Erixzon
+ *
+ *  Adapted to GMTP by
+ *  Copyright (c) 2015   Federal University of Alagoas, Macei, Brazil
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; either version 2 of the License, or
+ *  (at your option) any later version.
+ */
+#include <linux/types.h>
+#include <linux/math64.h>
+
+#include "../gmtp.h"
+
+#include "loss_interval.h"
+#include "packet_history.h"
+
+#define MCC_DEBUG "[GMTP-MCC] %s:%d - "
+#define mcc_pr_debug(format, args...) pr_info(MCC_DEBUG format \
+		"\n", __FUNCTION__, __LINE__, ##args)
+
+/* integer-arithmetic divisions of type (a * 1000000)/b */
+static inline u64 scaled_div(u64 a, u64 b)
+{
+	BUG_ON(b == 0);
+	return div64_u64(a * 1000000, b);
+}
+
+static inline u32 scaled_div32(u64 a, u64 b)
+{
+	u64 result = scaled_div(a, b);
+
+	if (result > UINT_MAX) {
+		gmtp_print_error("Overflow: %llu/%llu > UINT_MAX",
+			  (unsigned long long)a, (unsigned long long)b);
+		return UINT_MAX;
+	}
+	return result;
+}
+
+u32 mcc_calc_x(u16 s, u32 R, u32 p);
+u32 mcc_calc_x_reverse_lookup(u32 fvalue);
+u32 mcc_invert_loss_event_rate(u32 loss_event_rate);
+
+int mcc_rx_packet_history_init(void);
+void mcc_rx_packet_history_exit(void);
+
+int mcc_li_init(void);
+void mcc_li_exit(void);
+
+#endif /* _MCC_H_ */
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/mcc/packet_history.c linux-4.9-rc2/net/gmtp/mcc/packet_history.c
--- linux-4.9-rc2-original/net/gmtp/mcc/packet_history.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/mcc/packet_history.c	2016-12-01 16:50:35.782415792 -0300
@@ -0,0 +1,362 @@
+/*
+ *  Copyright (c) 2007   The University of Aberdeen, Scotland, UK
+ *  Copyright (c) 2005-7 The University of Waikato, Hamilton, New Zealand.
+ *
+ *  This code has been developed by the University of Waikato WAND
+ *  research group. For further information please see http://www.wand.net.nz/
+ *  or e-mail Ian McDonald - ian.mcdonald@jandi.co.nz
+ *
+ *  This code also uses code from Lulea University, rereleased as GPL by its
+ *  authors:
+ *  Copyright (c) 2003 Nils-Erik Mattsson, Joacim Haggmark, Magnus Erixzon
+ *
+ *  Changes to meet Linux coding standards, to make it meet latest ccid3 draft
+ *  and to make it work as a loadable module in the DCCP stack written by
+ *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>.
+ *
+ *  Copyright (c) 2005 Arnaldo Carvalho de Melo <acme@conectiva.com.br>
+ *
+ *  Adapted to GMTP by
+ *  Copyright (c) 2015   Federal University of Alagoas, Macei, Brazil
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; either version 2 of the License, or
+ *  (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/string.h>
+#include <linux/slab.h>
+#include "packet_history.h"
+
+#include "../gmtp.h"
+
+/*
+ *	Receiver History Routines
+ */
+static struct kmem_cache *tfrc_rx_hist_slab;
+
+int __init mcc_rx_packet_history_init(void)
+{
+	tfrc_rx_hist_slab = kmem_cache_create("mcc_rxh_cache",
+					      sizeof(struct mcc_rx_hist_entry),
+					      0, SLAB_HWCACHE_ALIGN, NULL);
+	return tfrc_rx_hist_slab == NULL ? -ENOBUFS : 0;
+}
+
+void mcc_rx_packet_history_exit(void)
+{
+	if (tfrc_rx_hist_slab != NULL) {
+		kmem_cache_destroy(tfrc_rx_hist_slab);
+		tfrc_rx_hist_slab = NULL;
+	}
+}
+
+/**
+ * FIXME insert timestamp from gmtp_hdr...
+ */
+static inline void mcc_rx_hist_entry_from_skb(struct mcc_rx_hist_entry *entry,
+					       const struct sk_buff *skb,
+					       const __be32 ndp)
+{
+	const struct gmtp_hdr *gh = gmtp_hdr(skb);
+
+	entry->seqno = GMTP_SKB_CB(skb)->seq;
+	entry->type  = gh->type;
+	entry->ndp   = ndp;
+	entry->tstamp = ktime_get_real();
+
+	if(gh->type == GMTP_PKT_DATA) {
+		const struct gmtp_hdr_data *gh_data = gmtp_hdr_data(skb);
+		entry->tx_tstamp = gh_data->tstamp;
+	}
+}
+
+void mcc_rx_hist_add_packet(struct mcc_rx_hist *h,
+			     const struct sk_buff *skb,
+			     const __be32 ndp)
+{
+	struct mcc_rx_hist_entry *entry = mcc_rx_hist_last_rcv(h);
+	mcc_rx_hist_entry_from_skb(entry, skb, ndp);
+}
+
+/* has the packet contained in skb been seen before? */
+int mcc_rx_hist_duplicate(struct mcc_rx_hist *h, struct sk_buff *skb)
+{
+	const __be32 seq = GMTP_SKB_CB(skb)->seq;
+	struct mcc_rx_hist_entry *loss_prev = mcc_rx_hist_loss_prev(h);
+	int i;
+
+	if(loss_prev == NULL) {
+		gmtp_pr_warning("loss_prev is NULL");
+		return 1;
+	}
+
+	if ((seq - loss_prev->seqno) <= 0)
+		return 1;
+
+	for (i = 1; i <= h->loss_count; i++)
+		if (mcc_rx_hist_entry(h, i)->seqno == seq)
+			return 1;
+
+	return 0;
+}
+
+static void mcc_rx_hist_swap(struct mcc_rx_hist *h, const u8 a, const u8 b)
+{
+	const u8 idx_a = mcc_rx_hist_index(h, a),
+		 idx_b = mcc_rx_hist_index(h, b);
+	struct mcc_rx_hist_entry *tmp = h->ring[idx_a];
+
+	h->ring[idx_a] = h->ring[idx_b];
+	h->ring[idx_b] = tmp;
+}
+
+/*
+ * Private helper functions for loss detection.
+ *
+ * In the descriptions, `Si' refers to the sequence number of entry number i,
+ * whose NDP count is `Ni' (lower case is used for variables).
+ * Note: All __xxx_loss functions expect that a test against duplicates has been
+ *       performed already: the seqno of the skb must not be less than the seqno
+ *       of loss_prev; and it must not equal that of any valid history entry.
+ */
+static void __do_track_loss(struct mcc_rx_hist *h, struct sk_buff *skb,
+		__be32 n1)
+{
+	__be32 s0 = mcc_rx_hist_loss_prev(h)->seqno,
+	    s1 = GMTP_SKB_CB(skb)->seq;
+
+	if (!gmtp_loss_free(s0, s1, n1)) {	/* gap between S0 and S1 */
+		h->loss_count = 1;
+		mcc_rx_hist_entry_from_skb(mcc_rx_hist_entry(h, 1), skb, n1);
+	}
+}
+
+static void __one_after_loss(struct mcc_rx_hist *h, struct sk_buff *skb, u32 n2)
+{
+	__be32 s0 = mcc_rx_hist_loss_prev(h)->seqno,
+	    s1 = mcc_rx_hist_entry(h, 1)->seqno,
+	    s2 = GMTP_SKB_CB(skb)->seq;
+
+	if (likely((s2 - s1) > 0)) {	/* S1  <  S2 */
+		h->loss_count = 2;
+		mcc_rx_hist_entry_from_skb(mcc_rx_hist_entry(h, 2), skb, n2);
+		return;
+	}
+
+	/* S0  <  S2  <  S1 */
+
+	if (gmtp_loss_free(s0, s2, n2)) {
+		__be32 n1 = mcc_rx_hist_entry(h, 1)->ndp;
+
+		if (gmtp_loss_free(s2, s1, n1)) {
+			/* hole is filled: S0, S2, and S1 are consecutive */
+			h->loss_count = 0;
+			h->loss_start = mcc_rx_hist_index(h, 1);
+		} else
+			/* gap between S2 and S1: just update loss_prev */
+			mcc_rx_hist_entry_from_skb(mcc_rx_hist_loss_prev(h), skb, n2);
+
+	} else {	/* gap between S0 and S2 */
+		/*
+		 * Reorder history to insert S2 between S0 and S1
+		 */
+		mcc_rx_hist_swap(h, 0, 3);
+		h->loss_start = mcc_rx_hist_index(h, 3);
+		mcc_rx_hist_entry_from_skb(mcc_rx_hist_entry(h, 1), skb, n2);
+		h->loss_count = 2;
+	}
+}
+
+/* return 1 if a new loss event has been identified */
+static int __two_after_loss(struct mcc_rx_hist *h, struct sk_buff *skb, u32 n3)
+{
+	__be32 s0 = mcc_rx_hist_loss_prev(h)->seqno,
+	    s1 = mcc_rx_hist_entry(h, 1)->seqno,
+	    s2 = mcc_rx_hist_entry(h, 2)->seqno,
+	    s3 = GMTP_SKB_CB(skb)->seq;
+
+	if (likely((s3 - s2) > 0)) {	/* S2  <  S3 */
+		h->loss_count = 3;
+		mcc_rx_hist_entry_from_skb(mcc_rx_hist_entry(h, 3), skb, n3);
+		return 1;
+	}
+
+	/* S3  <  S2 */
+	if ((s3 - s1) > 0) {		/* S1  <  S3  <  S2 */
+		/*
+		 * Reorder history to insert S3 between S1 and S2
+		 */
+		mcc_rx_hist_swap(h, 2, 3);
+		mcc_rx_hist_entry_from_skb(mcc_rx_hist_entry(h, 2), skb, n3);
+		h->loss_count = 3;
+		return 1;
+	}
+
+	/* S0  <  S3  <  S1 */
+	if (gmtp_loss_free(s0, s3, n3)) {
+		__be32 n1 = mcc_rx_hist_entry(h, 1)->ndp;
+
+		if (gmtp_loss_free(s3, s1, n1)) {
+			/* hole between S0 and S1 filled by S3 */
+			__be32 n2 = mcc_rx_hist_entry(h, 2)->ndp;
+
+			if (gmtp_loss_free(s1, s2, n2)) {
+				/* entire hole filled by S0, S3, S1, S2 */
+				h->loss_start = mcc_rx_hist_index(h, 2);
+				h->loss_count = 0;
+			} else {
+				/* gap remains between S1 and S2 */
+				h->loss_start = mcc_rx_hist_index(h, 1);
+				h->loss_count = 1;
+			}
+
+		} else /* gap exists between S3 and S1, loss_count stays at 2 */
+			mcc_rx_hist_entry_from_skb(mcc_rx_hist_loss_prev(h), skb, n3);
+
+		return 0;
+	}
+
+	/*
+	 * The remaining case:  S0  <  S3  <  S1  <  S2;  gap between S0 and S3
+	 * Reorder history to insert S3 between S0 and S1.
+	 */
+	mcc_rx_hist_swap(h, 0, 3);
+	h->loss_start = mcc_rx_hist_index(h, 3);
+	mcc_rx_hist_entry_from_skb(mcc_rx_hist_entry(h, 1), skb, n3);
+	h->loss_count = 3;
+
+	return 1;
+}
+
+/* recycle RX history records to continue loss detection if necessary */
+static void __three_after_loss(struct mcc_rx_hist *h)
+{
+	/*
+	 * At this stage we know already that there is a gap between S0 and S1
+	 * (since S0 was the highest sequence number received before detecting
+	 * the loss). To recycle the loss record, it is	thus only necessary to
+	 * check for other possible gaps between S1/S2 and between S2/S3.
+	 */
+	__be32 s1 = mcc_rx_hist_entry(h, 1)->seqno,
+	    s2 = mcc_rx_hist_entry(h, 2)->seqno,
+	    s3 = mcc_rx_hist_entry(h, 3)->seqno;
+	__be32 n2 = mcc_rx_hist_entry(h, 2)->ndp,
+	    n3 = mcc_rx_hist_entry(h, 3)->ndp;
+
+	if (gmtp_loss_free(s1, s2, n2)) {
+
+		if (gmtp_loss_free(s2, s3, n3)) {
+			/* no gap between S2 and S3: entire hole is filled */
+			h->loss_start = mcc_rx_hist_index(h, 3);
+			h->loss_count = 0;
+		} else {
+			/* gap between S2 and S3 */
+			h->loss_start = mcc_rx_hist_index(h, 2);
+			h->loss_count = 1;
+		}
+
+	} else {	/* gap between S1 and S2 */
+		h->loss_start = mcc_rx_hist_index(h, 1);
+		h->loss_count = 2;
+	}
+}
+
+/**
+ *  mcc_rx_handle_loss  -  Loss detection and further processing
+ *  @h:		    The non-empty RX history object
+ *  @lh:	    Loss Intervals database to update
+ *  @skb:	    Currently received packet
+ *  @ndp:	    The NDP count belonging to @skb
+ *  @calc_first_li: Caller-dependent computation of first loss interval in @lh
+ *  @sk:	    Used by @calc_first_li (see mcc_lh_interval_add)
+ *
+ *  Chooses action according to pending loss, updates LI database when a new
+ *  loss was detected, and does required post-processing. Returns 1 when caller
+ *  should send feedback, 0 otherwise.
+ *  Since it also takes care of reordering during loss detection and updates the
+ *  records accordingly, the caller should not perform any more RX history
+ *  operations when loss_count is greater than 0 after calling this function.
+ */
+int mcc_rx_handle_loss(struct mcc_rx_hist *h,
+			struct mcc_loss_hist *lh,
+			struct sk_buff *skb, const __be32 ndp,
+			u32 (*calc_first_li)(struct sock *), struct sock *sk)
+{
+	int is_new_loss = 0;
+
+	if (h->loss_count == 0) {
+		__do_track_loss(h, skb, ndp);
+	} else if (h->loss_count == 1) {
+		__one_after_loss(h, skb, ndp);
+	} else if (h->loss_count != 2) {
+		gmtp_print_error("invalid loss_count %d", h->loss_count);
+	} else if (__two_after_loss(h, skb, ndp)) {
+		/*
+		 * Update Loss Interval database and recycle RX records
+		 */
+		is_new_loss = mcc_lh_interval_add(lh, h, calc_first_li, sk);
+		__three_after_loss(h);
+	}
+	return is_new_loss;
+}
+
+int mcc_rx_hist_alloc(struct mcc_rx_hist *h)
+{
+	int i;
+
+	for (i = 0; i <= MCC_NDUPACK; i++) {
+		h->ring[i] = kmem_cache_alloc(tfrc_rx_hist_slab, GFP_ATOMIC);
+		if (h->ring[i] == NULL)
+			goto out_free;
+	}
+
+	h->loss_count = h->loss_start = 0;
+	return 0;
+
+out_free:
+	while (i-- != 0) {
+		kmem_cache_free(tfrc_rx_hist_slab, h->ring[i]);
+		h->ring[i] = NULL;
+	}
+	return -ENOBUFS;
+}
+
+void mcc_rx_hist_purge(struct mcc_rx_hist *h)
+{
+	int i;
+
+	for (i = 0; i <= MCC_NDUPACK; ++i)
+		if (h->ring[i] != NULL) {
+			kmem_cache_free(tfrc_rx_hist_slab, h->ring[i]);
+			h->ring[i] = NULL;
+		}
+}
+
+/**
+ * tfrc_rx_hist_rtt_last_s - reference entry to compute RTT samples against
+ */
+static inline struct mcc_rx_hist_entry *
+			mcc_rx_hist_rtt_last_s(const struct mcc_rx_hist *h)
+{
+	return h->ring[0];
+}
+
+/**
+ * tfrc_rx_hist_rtt_prev_s - previously suitable (wrt rtt_last_s) RTT-sampling entry
+ */
+static inline struct mcc_rx_hist_entry *
+			mcc_rx_hist_rtt_prev_s(const struct mcc_rx_hist *h)
+{
+	return h->ring[h->rtt_sample_prev];
+}
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/mcc/packet_history.h linux-4.9-rc2/net/gmtp/mcc/packet_history.h
--- linux-4.9-rc2-original/net/gmtp/mcc/packet_history.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/mcc/packet_history.h	2016-12-01 16:50:35.801415554 -0300
@@ -0,0 +1,115 @@
+/*
+ *  Packet RX/TX history data structures and routines for TFRC-based protocols.
+ *
+ *  Copyright (c) 2007   The University of Aberdeen, Scotland, UK
+ *  Copyright (c) 2005-6 The University of Waikato, Hamilton, New Zealand.
+ *
+ *  Adapted to GMTP by
+ *  Copyright (c) 2015   Federal University of Alagoas, Macei, Brazil
+ *
+ *  This code has been developed by the University of Waikato WAND
+ *  research group. For further information please see http://www.wand.net.nz/
+ *  or e-mail Ian McDonald - ian.mcdonald@jandi.co.nz
+ *
+ *  This code also uses code from Lulea University, rereleased as GPL by its
+ *  authors:
+ *  Copyright (c) 2003 Nils-Erik Mattsson, Joacim Haggmark, Magnus Erixzon
+ *
+ *  Changes to meet Linux coding standards, to make it meet latest ccid3 draft
+ *  and to make it work as a loadable module in the DCCP stack written by
+ *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>.
+ *
+ *  Copyright (c) 2005 Arnaldo Carvalho de Melo <acme@conectiva.com.br>
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; either version 2 of the License, or
+ *  (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#ifndef _GMTP_PKT_HIST_
+#define _GMTP_PKT_HIST_
+
+#include <linux/list.h>
+#include <linux/slab.h>
+#include "mcc_proto.h"
+
+/**
+ * mcc_rx_hist_entry - Store information about a single received packet
+ * @seqno:	GMTP packet sequence number
+ * @ndp:	the NDP count (if any) of the packet
+ * @tstamp:	actual receive time of packet
+ * @tx_tstamp:	send time of packet with sequence number @seqno
+ */
+struct mcc_rx_hist_entry {
+	__be32		 seqno;
+	__be32		 type:5;
+	__be32		 ndp;
+	ktime_t		 tstamp;
+	__u32 		 tx_tstamp;
+};
+
+/**
+ * mcc_rx_hist_index - index to reach n-th entry after loss_start
+ */
+static inline u8 mcc_rx_hist_index(const struct mcc_rx_hist *h, const u8 n)
+{
+	return (h->loss_start + n) & MCC_NDUPACK;
+}
+
+/**
+ * mcc_rx_hist_last_rcv - entry with highest-received-seqno so far
+ */
+static inline struct mcc_rx_hist_entry *
+			mcc_rx_hist_last_rcv(const struct mcc_rx_hist *h)
+{
+	return h->ring[mcc_rx_hist_index(h, h->loss_count)];
+}
+
+/**
+ * mcc_rx_hist_entry - return the n-th history entry after loss_start
+ */
+static inline struct mcc_rx_hist_entry *
+			mcc_rx_hist_entry(const struct mcc_rx_hist *h, const u8 n)
+{
+	return h->ring[mcc_rx_hist_index(h, n)];
+}
+
+/**
+ * mcc_rx_hist_loss_prev - entry with highest-received-seqno before loss was detected
+ */
+static inline struct mcc_rx_hist_entry *
+			mcc_rx_hist_loss_prev(const struct mcc_rx_hist *h)
+{
+	return h->ring[h->loss_start];
+}
+
+/* indicate whether previously a packet was detected missing */
+static inline bool mcc_rx_hist_loss_pending(const struct mcc_rx_hist *h)
+{
+	return h->loss_count > 0;
+}
+
+void mcc_rx_hist_add_packet(struct mcc_rx_hist *h, const struct sk_buff *skb,
+			     const __be32 ndp);
+
+int mcc_rx_hist_duplicate(struct mcc_rx_hist *h, struct sk_buff *skb);
+
+struct mcc_loss_hist;
+int mcc_rx_handle_loss(struct mcc_rx_hist *h, struct mcc_loss_hist *lh,
+			struct sk_buff *skb, const __be32 ndp,
+			u32 (*first_li)(struct sock *sk), struct sock *sk);
+u32 mcc_rx_hist_sample_rtt(struct mcc_rx_hist *h, const struct sk_buff *skb);
+int mcc_rx_hist_alloc(struct mcc_rx_hist *h);
+void mcc_rx_hist_purge(struct mcc_rx_hist *h);
+
+#endif /* _GMTP_PKT_HIST_ */
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/mcc.h linux-4.9-rc2/net/gmtp/mcc.h
--- linux-4.9-rc2-original/net/gmtp/mcc.h	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/mcc.h	2016-12-01 16:50:35.740416317 -0300
@@ -0,0 +1,22 @@
+/*
+ * mcc.h
+ *
+ *  Created on: 13/04/2015
+ *      Author: wendell
+ */
+
+#ifndef MCC_H_
+#define MCC_H_
+
+#include <linux/gmtp.h>
+
+#include "mcc/mcc_proto.h"
+
+int mcc_lib_init(void);
+void mcc_lib_exit(void);
+
+void mcc_rx_packet_recv(struct sock *sk, struct sk_buff *skb);
+int mcc_rx_init(struct sock *sk);
+void mcc_rx_exit(struct sock *sk);
+
+#endif /* MCC_H_ */
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/minisocks.c linux-4.9-rc2/net/gmtp/minisocks.c
--- linux-4.9-rc2-original/net/gmtp/minisocks.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/minisocks.c	2016-12-04 03:23:04.047018517 -0300
@@ -0,0 +1,231 @@
+/*
+ * minisocks.c
+ *
+ *  Created on: 21/01/2015
+ *      Author: wendell
+ */
+
+#include <linux/gfp.h>
+#include <linux/kernel.h>
+#include <linux/skbuff.h>
+#include <linux/timer.h>
+
+#include <net/sock.h>
+#include <net/xfrm.h>
+#include <net/inet_timewait_sock.h>
+
+#include <linux/gmtp.h>
+#include "gmtp.h"
+
+struct inet_timewait_death_row gmtp_death_row = {
+    .sysctl_max_tw_buckets = NR_FILE * 2,
+    .hashinfo   = &gmtp_inet_hashinfo,
+};
+EXPORT_SYMBOL_GPL(gmtp_death_row);
+
+void gmtp_time_wait(struct sock *sk, int state, int timeo)
+{
+    struct inet_timewait_sock *tw = NULL;
+
+    gmtp_print_function();
+
+    /*print_gmtp_sock(sk);
+
+    tw = inet_twsk_alloc(sk, &gmtp_death_row, state);
+
+    if(tw != NULL) {
+        const struct inet_connection_sock *icsk = inet_csk(sk);
+        const int rto = (icsk->icsk_rto << 2) - (icsk->icsk_rto >> 1);
+         Linkage updates.
+        __inet_twsk_hashdance(tw, sk, &gmtp_inet_hashinfo);
+
+         Get the TIME_WAIT timeout firing.
+        if(timeo < rto)
+            timeo = rto;
+
+        tw->tw_timeout = GMTP_TIMEWAIT_LEN;
+        if(state == GMTP_TIME_WAIT)
+            timeo = GMTP_TIMEWAIT_LEN;
+
+        inet_twsk_schedule(tw, timeo);
+        inet_twsk_put(tw);
+    } else {
+         If we're out of memory, just CLOSE this
+         * socket up.
+
+
+        gmtp_print_warning("time wait bucket table overflow!");
+    }*/
+
+    gmtp_done(sk);
+}
+
+struct sock *gmtp_create_openreq_child(struct sock *sk,
+                       const struct request_sock *req,
+                       const struct sk_buff *skb)
+{
+    /*
+     * Step 3: Process LISTEN state
+     *
+     *   (* Generate a new socket and switch to that socket *)
+     *   Set S := new socket for this port pair
+     */
+    struct sock *newsk = inet_csk_clone_lock(sk, req, GFP_ATOMIC);
+
+    gmtp_print_function();
+
+    if (newsk != NULL) {
+        struct gmtp_request_sock *dreq = gmtp_rsk(req);
+        struct inet_connection_sock *newicsk = inet_csk(newsk);
+        struct gmtp_sock *newdp = gmtp_sk(newsk);
+
+        newdp->role     = GMTP_ROLE_SERVER;
+        memcpy(newdp->flowname, dreq->flowname, GMTP_FLOWNAME_LEN);
+        newicsk->icsk_rto   = GMTP_TIMEOUT_INIT;
+
+        /* Step 3: Process LISTEN state
+         *
+         *    Choose S.ISS (initial seqno)
+         *    Set S.ISR, S.GSR from packet
+         */
+        newdp->iss = dreq->iss;
+        newdp->gss = dreq->gss;
+        newdp->isr = dreq->isr;
+        newdp->gsr = dreq->gsr;
+
+
+        gmtp_init_xmit_timers(newsk);
+    }
+    return newsk;
+}
+EXPORT_SYMBOL_GPL(gmtp_create_openreq_child);
+
+/*
+ * Process an incoming packet for RESPOND sockets represented
+ * as an request_sock.
+ */
+struct sock *gmtp_check_req(struct sock *sk, struct sk_buff *skb,
+                struct request_sock *req)
+{
+    struct sock *child = NULL;
+    struct gmtp_request_sock *greq = gmtp_rsk(req);
+    __be32 seq;
+
+    gmtp_print_function();
+
+    if (gmtp_hdr(skb)->type == GMTP_PKT_REQUEST) {
+
+        if(GMTP_SKB_CB(skb)->seq > greq->gsr) {
+            gmtp_print_debug("Retransmitted REQUEST\n");
+            greq->gsr = GMTP_SKB_CB(skb)->seq;
+            /*
+             * Send another RESPONSE packet
+             * To protect against Request floods, increment retrans
+             * counter (backoff, monitored by gmtp_response_timer).
+             */
+            inet_rtx_syn_ack(sk, req);
+         }
+        /* Network Duplicate, discard packet */
+        return NULL;
+    }
+
+    GMTP_SKB_CB(skb)->reset_code = GMTP_RESET_CODE_PACKET_ERROR;
+
+    if (gmtp_hdr(skb)->type != GMTP_PKT_ROUTE_NOTIFY &&
+        gmtp_hdr(skb)->type != GMTP_PKT_ACK &&
+        gmtp_hdr(skb)->type != GMTP_PKT_DATAACK)
+        goto drop;
+
+    /* FIXME Check for invalid Sequence nuber */
+    seq = GMTP_SKB_CB(skb)->seq;
+    if(!(seq >= greq->iss && seq <= greq->gss)) {
+        gmtp_print_debug("Invalid Seq number: "
+                "seq=%llu, iss=%llu, gss=%llu",
+                (unsigned long long ) seq,
+                (unsigned long long ) greq->iss,
+                (unsigned long long ) greq->gss);
+        print_gmtp_packet(ip_hdr(skb), gmtp_hdr(skb));
+        goto drop;
+    }
+
+    child = inet_csk(sk)->icsk_af_ops->syn_recv_sock(sk, skb, req, NULL, NULL, NULL);
+    /****
+    struct sock *(*syn_recv_sock)(const struct sock *sk, struct sk_buff *skb,
+                      struct request_sock *req,
+                      struct dst_entry *dst,
+                      struct request_sock *req_unhash,
+                      bool *own_req);
+    ****/
+
+    if (child == NULL)
+        goto listen_overflow;
+
+    inet_csk_reqsk_queue_drop(sk, req);
+    inet_csk_reqsk_queue_add(sk, req, child);
+out:
+    return child;
+listen_overflow:
+    gmtp_print_error("listen_overflow!\n");
+    GMTP_SKB_CB(skb)->reset_code = GMTP_RESET_CODE_TOO_BUSY;
+drop:
+    if (gmtp_hdr(skb)->type != GMTP_PKT_RESET)
+        req->rsk_ops->send_reset(sk, skb);
+
+    inet_csk_reqsk_queue_drop(sk, req);
+    goto out;
+}
+EXPORT_SYMBOL_GPL(gmtp_check_req);
+
+/*
+ *  Queue segment on the new socket if the new socket is active,
+ *  otherwise we just shortcircuit this and continue with
+ *  the new socket.
+ */
+int gmtp_child_process(struct sock *parent, struct sock *child,
+               struct sk_buff *skb)
+{
+    int ret = 0;
+    const int state = child->sk_state;
+
+    if (!sock_owned_by_user(child)) {
+        ret = gmtp_rcv_state_process(child, skb, gmtp_hdr(skb),
+                         skb->len);
+
+        /* Wakeup parent, send SIGIO */
+        if (state == GMTP_REQUEST_RECV && child->sk_state != state)
+            parent->sk_data_ready(parent);
+    } else {
+        /* Alas, it is possible again, because we do lookup
+         * in main socket hash table and lock on listening
+         * socket does not protect us more.
+         */
+        __sk_add_backlog(child, skb);
+    }
+
+    bh_unlock_sock(child);
+    sock_put(child);
+    return ret;
+}
+
+EXPORT_SYMBOL_GPL(gmtp_child_process);
+
+void gmtp_reqsk_send_ack(const struct sock *sk, struct sk_buff *skb,
+             struct request_sock *rsk)
+{
+    gmtp_print_error("GMTP-ACK packets are never sent in LISTEN state");
+}
+EXPORT_SYMBOL_GPL(gmtp_reqsk_send_ack);
+
+int gmtp_reqsk_init(struct request_sock *req,
+            struct gmtp_sock const *gp, struct sk_buff const *skb)
+{
+    gmtp_print_function();
+
+    inet_rsk(req)->ir_rmt_port = gmtp_hdr(skb)->sport;
+    inet_rsk(req)->ir_num      = ntohs(gmtp_hdr(skb)->dport);
+    inet_rsk(req)->acked       = 0;
+
+    return 0;
+}
+EXPORT_SYMBOL_GPL(gmtp_reqsk_init);
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/output.c linux-4.9-rc2/net/gmtp/output.c
--- linux-4.9-rc2-original/net/gmtp/output.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/output.c	2016-12-01 22:22:55.727267273 -0300
@@ -0,0 +1,920 @@
+#include <linux/kernel.h>
+#include <linux/skbuff.h>
+#include <linux/slab.h>
+#include <linux/types.h>
+#include <linux/if_ether.h>
+#include <asm/param.h>
+
+#include <net/inet_sock.h>
+#include <net/tcp.h>
+#include <net/sock.h>
+
+#include <uapi/linux/gmtp.h>
+#include <linux/gmtp.h>
+#include "gmtp.h"
+#include "mcc.h"
+
+static inline void gmtp_event_ack_sent(struct sock *sk)
+{
+    gmtp_sk(sk)->ack_tx_tstamp = jiffies_to_msecs(jiffies);
+    inet_csk_clear_xmit_timer(sk, ICSK_TIME_DACK);
+}
+
+/* enqueue @skb on sk_send_head for retransmission, return clone to send now */
+static struct sk_buff *gmtp_skb_entail(struct sock *sk, struct sk_buff *skb) {
+    skb_set_owner_w(skb, sk);
+    WARN_ON(sk->sk_send_head);
+    sk->sk_send_head = skb;
+    return skb_clone(sk->sk_send_head, gfp_any());
+}
+
+/*
+ * All SKB's seen here are completely headerless. It is our
+ * job to build the GMTP header, and pass the packet down to
+ * IP so it can do the same plus pass the packet off to the
+ * device.
+ */
+static int gmtp_transmit_skb(struct sock *sk, struct sk_buff *skb) {
+
+    if (likely(skb != NULL)) {
+
+        struct inet_sock *inet = inet_sk(sk);
+        const struct inet_connection_sock *icsk = inet_csk(sk);
+        struct gmtp_sock *gp = gmtp_sk(sk);
+        struct gmtp_skb_cb *gcb = GMTP_SKB_CB(skb);
+        struct gmtp_hdr *gh;
+        const u32 gmtp_header_size = sizeof(struct gmtp_hdr) +
+                gmtp_packet_hdr_variable_len(gcb->type);
+        int err, set_ack = 1;
+
+        gp->ndp_sent++;
+
+        switch (gcb->type) {
+        case GMTP_PKT_DATA:
+            set_ack = 0;
+            gp->ndp_sent--;
+            /* fall through */
+        case GMTP_PKT_DATAACK:
+        case GMTP_PKT_RESET:
+            break;
+        case GMTP_PKT_REQUEST:
+            set_ack = 0;
+            GMTP_SKB_CB(skb)->retransmits = icsk->icsk_retransmits;
+            /* Use ISS on the first (non-retransmitted) Request. */
+            if (icsk->icsk_retransmits == 0)
+                gcb->seq = gp->iss;
+            /* fall through */
+        default:
+            /*
+             * Set owner/destructor: some skbs are allocated via
+             * alloc_skb (e.g. when retransmission may happen).
+             * Only Data, DataAck, and Reset packets should come
+             * through here with skb->sk set.
+             */
+            WARN_ON(skb->sk);
+            skb_set_owner_w(skb, sk);
+            break;
+        }
+
+        gh = gmtp_zeroed_hdr(skb, gmtp_header_size);
+
+        gh->version = GMTP_VERSION;
+        gh->type = gcb->type;
+        gh->sport = inet->inet_sport;
+        gh->dport = inet->inet_dport;
+        gh->hdrlen = gmtp_header_size;
+        gh->server_rtt = gp->role == GMTP_ROLE_SERVER ?
+                TO_U12(gp->tx_avg_rtt) : TO_U12(gp->rx_rtt);
+
+        memcpy(gh->flowname, gp->flowname, GMTP_FLOWNAME_LEN);
+
+        gh->transm_r = (__be32) gp->tx_media_rate;
+        if (gcb->type == GMTP_PKT_RESET)
+            gmtp_hdr_reset(skb)->reset_code = gcb->reset_code;
+
+        gcb->seq = ++gp->gss;
+        if (set_ack) {
+            gcb->seq = --gp->gss;
+            gmtp_event_ack_sent(sk);
+        }
+        gh->seq = gcb->seq;
+
+        /* Specific headers */
+        switch(gcb->type) {
+        case GMTP_PKT_DATA: {
+            struct gmtp_hdr_data *gh_data = gmtp_hdr_data(skb);
+            gh_data->tstamp = jiffies_to_msecs(jiffies);
+            /*pr_info("Server RTT: %u ms\n", gh->server_rtt);*/
+            break;
+        }
+        case GMTP_PKT_FEEDBACK: {
+            struct gmtp_hdr_feedback *fh = gmtp_hdr_feedback(skb);
+            gh->seq = gcb->seq = gp->gsr;
+            gh->transm_r = gp->rx_max_rate;
+            fh->orig_tstamp = gcb->orig_tstamp;
+            fh->nclients = gp->myself->nclients;
+            break;
+        }
+        case GMTP_PKT_ELECT_REQUEST: {
+            struct gmtp_hdr_elect_request *gh_ereq;
+            gh_ereq = gmtp_hdr_elect_request(skb);
+            memcpy(gh_ereq->relay_id, gp->relay_id,
+            GMTP_RELAY_ID_LEN);
+            gh_ereq->max_nclients = 0;
+            break;
+        }
+        case GMTP_PKT_ELECT_RESPONSE: {
+            struct gmtp_hdr_elect_response *gh_eresp;
+            gh_eresp = gmtp_hdr_elect_response(skb);
+            gh_eresp->elect_code = GMTP_SKB_CB(skb)->elect_code;
+            break;
+        }
+        }
+
+        err = icsk->icsk_af_ops->queue_xmit(sk, skb, &inet->cork.fl);
+        return net_xmit_eval(err);
+    }
+    return -ENOBUFS;
+}
+
+/*
+ * All SKB's seen here are completely header full.
+ * Here, we don't build the GMTP header. We only pass the packet down to
+ * IP so it can do the same plus pass the packet off to the device.
+ */
+int gmtp_transmit_built_skb(struct sock *sk, struct sk_buff *skb) {
+
+    if (likely(skb != NULL)) {
+
+        const struct inet_connection_sock *icsk = inet_csk(sk);
+        struct inet_sock *inet = inet_sk(sk);
+        int err;
+
+        if(likely(gmtp_hdr(skb)->type != GMTP_PKT_DATA))
+            gmtp_sk(sk)->ndp_sent++;
+
+        err = icsk->icsk_af_ops->queue_xmit(sk, skb, &inet->cork.fl);
+        return net_xmit_eval(err);
+    }
+    return -ENOBUFS;
+}
+EXPORT_SYMBOL_GPL(gmtp_transmit_built_skb);
+
+unsigned int gmtp_sync_mss(struct sock *sk, u32 pmtu)
+{
+    struct inet_connection_sock *icsk = inet_csk(sk);
+    struct gmtp_sock *gp = gmtp_sk(sk);
+    u32 cur_mps = pmtu;
+
+    /* Account for header lengths and IPv4/v6 option overhead */
+    /* FIXME Account variable part of GMTP Header */
+    cur_mps -= (icsk->icsk_af_ops->net_header_len + icsk->icsk_ext_hdr_len +
+            sizeof(struct gmtp_hdr));
+
+    /* And store cached results */
+    icsk->icsk_pmtu_cookie = pmtu;
+    gp->mss = cur_mps;
+
+    pr_info("MSS: %u\n", gp->mss);
+
+    return cur_mps;
+}
+EXPORT_SYMBOL_GPL(gmtp_sync_mss);
+
+void gmtp_write_space(struct sock *sk)
+{
+    struct socket_wq *wq;
+
+    rcu_read_lock();
+    wq = rcu_dereference(sk->sk_wq);
+    if (wq_has_sleeper(&wq->wait))
+        wake_up_interruptible(&wq->wait);
+    /* Should agree with poll, otherwise some programs break */
+    if (sock_writeable(sk))
+        sk_wake_async(sk, SOCK_WAKE_SPACE, POLL_OUT);
+
+    rcu_read_unlock();
+}
+
+/**
+ * gmtp_retransmit_skb  -  Retransmit Request, Close, or CloseReq packets
+ * This function expects sk->sk_send_head to contain the original skb.
+ */
+int gmtp_retransmit_skb(struct sock *sk)
+{
+    WARN_ON(sk->sk_send_head == NULL);
+
+    if (inet_csk(sk)->icsk_af_ops->rebuild_header(sk) != 0)
+        return -EHOSTUNREACH; /* Routing failure or similar. */
+
+    /* this count is used to distinguish original and retransmitted skb */
+    inet_csk(sk)->icsk_retransmits++;
+
+    return gmtp_transmit_skb(sk, skb_clone(sk->sk_send_head, GFP_ATOMIC));
+}
+
+struct sk_buff *gmtp_make_register_reply(struct sock *sk, struct dst_entry *dst,
+                   struct request_sock *req)
+{
+    struct gmtp_hdr *gh;
+    struct gmtp_request_sock *greq;
+
+    const u32 gmtp_header_size = sizeof(struct gmtp_hdr) +
+            gmtp_packet_hdr_variable_len(GMTP_PKT_REGISTER_REPLY);
+
+    struct sk_buff *skb = sock_wmalloc(sk, sk->sk_prot->max_header, 1,
+            GFP_ATOMIC);
+
+    gmtp_print_function();
+
+    if (skb == NULL)
+        return NULL;
+
+    /* Reserve space for headers. */
+    skb_reserve(skb, sk->sk_prot->max_header);
+
+    skb_dst_set(skb, dst_clone(dst));
+
+    greq = gmtp_rsk(req);
+    if (inet_rsk(req)->acked)   /* increase GSS upon retransmission */
+        greq->gss++;
+    GMTP_SKB_CB(skb)->type = GMTP_PKT_REGISTER_REPLY;
+    GMTP_SKB_CB(skb)->seq  = greq->gss;
+
+    /* Build header */
+    gh = gmtp_zeroed_hdr(skb, gmtp_header_size);
+
+    /* At this point, Register-Reply specific header is zeroed. */
+    gh->sport   = htons(inet_rsk(req)->ir_num);
+    gh->dport   = inet_rsk(req)->ir_rmt_port;
+    gh->type    = GMTP_PKT_REGISTER_REPLY;
+    gh->seq     = greq->gss;
+    gh->server_rtt  = GMTP_DEFAULT_RTT;
+    gh->transm_r    = (__be32) gmtp_sk(sk)->tx_media_rate;
+    gh->hdrlen  = gmtp_header_size;
+    memcpy(gh->flowname, greq->flowname, GMTP_FLOWNAME_LEN);
+
+    gmtp_hdr_register_reply(skb)->ucc_type = greq->tx_ucc_type;
+
+    /* We use `acked' to remember that a Register-Reply was already sent. */
+    inet_rsk(req)->acked = 1;
+
+    return skb;
+}
+EXPORT_SYMBOL_GPL(gmtp_make_register_reply);
+
+struct sk_buff *gmtp_make_register_reply_open(struct sock *sk,
+        struct sk_buff *rcv_skb)
+{
+    struct sk_buff *skb;
+    struct gmtp_hdr *rxgh = gmtp_hdr(rcv_skb), *gh;
+    const u32 gmtp_hdr_len = sizeof(struct gmtp_hdr) +
+            gmtp_packet_hdr_variable_len(GMTP_PKT_REGISTER_REPLY);
+
+    gmtp_print_function();
+
+    skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);
+    if(skb == NULL)
+        return NULL;
+
+    skb_reserve(skb, sk->sk_prot->max_header);
+
+    gh = gmtp_zeroed_hdr(skb, gmtp_hdr_len);
+
+    gh->type = GMTP_PKT_REGISTER_REPLY;
+    gh->seq = rxgh->seq;
+    gh->sport = rxgh->dport;
+    gh->dport = rxgh->sport;
+    gh->hdrlen = gmtp_hdr_len;
+    gh->server_rtt = rxgh->server_rtt;
+    gh->transm_r = rxgh->transm_r;
+    memcpy(gh->flowname, rxgh->flowname, GMTP_FLOWNAME_LEN);
+
+    gmtp_hdr_register_reply(skb)->ucc_type = gmtp_sk(sk)->tx_ucc_type;
+
+    return skb;
+}
+EXPORT_SYMBOL_GPL(gmtp_make_register_reply_open);
+
+
+struct sk_buff *gmtp_make_route_notify(struct sock *sk,
+        struct sk_buff *rcv_skb)
+{
+    struct sk_buff *skb;
+    struct gmtp_hdr *rxgh = gmtp_hdr(rcv_skb), *gh;
+
+    gmtp_print_function();
+
+    skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);
+    if(skb == NULL)
+        return NULL;
+
+    skb_reserve(skb, sk->sk_prot->max_header);
+
+    gh = gmtp_zeroed_hdr(skb, rxgh->hdrlen);
+
+    memcpy(gh, rxgh, rxgh->hdrlen);
+    gh->type = GMTP_PKT_ROUTE_NOTIFY;
+    swap(gh->sport, gh->dport);
+    gh->relay = 0;
+
+    return skb;
+}
+
+void gmtp_send_route_notify(struct sock *sk,
+        struct sk_buff *rcv_skb)
+{
+    struct sk_buff *skb = gmtp_make_route_notify(sk, rcv_skb);
+    if(skb != NULL)
+        return gmtp_transmit_built_skb(sk, skb);
+}
+EXPORT_SYMBOL_GPL(gmtp_send_route_notify);
+
+struct sk_buff *gmtp_make_delegate(struct sock *sk, struct sk_buff *rcv_skb,
+        __u8 *rid)
+{
+    struct sk_buff *skb;
+    struct gmtp_hdr *rxgh = gmtp_hdr(rcv_skb), *gh;
+    const u32 gmtp_hdr_len = sizeof(struct gmtp_hdr)
+            + gmtp_packet_hdr_variable_len(GMTP_PKT_DELEGATE);
+
+    gmtp_print_function();
+
+    skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);
+    if(skb == NULL)
+        return NULL;
+
+    skb_reserve(skb, sk->sk_prot->max_header);
+
+    gh = gmtp_zeroed_hdr(skb, gmtp_hdr_len);
+
+    gh->type = GMTP_PKT_DELEGATE;
+    gh->seq = rxgh->seq;
+    gh->sport = rxgh->dport;
+    gh->dport = sk->sk_dport;
+    gh->hdrlen = gmtp_hdr_len;
+    gh->server_rtt = gmtp_sk(sk)->tx_avg_rtt;
+    gh->transm_r = rxgh->transm_r;
+    memcpy(gh->flowname, rxgh->flowname, GMTP_FLOWNAME_LEN);
+
+    memcpy(gmtp_hdr_delegate(skb)->relay.relay_id, rid, GMTP_RELAY_ID_LEN);
+    gmtp_hdr_delegate(skb)->relay.relay_ip = ip_hdr(rcv_skb)->saddr;
+    gmtp_hdr_delegate(skb)->relay_port = rxgh->sport;
+
+    return skb;
+}
+EXPORT_SYMBOL_GPL(gmtp_make_delegate);
+
+/* answer offending packet in @rcv_skb with Reset from control socket @ctl */
+struct sk_buff *gmtp_ctl_make_reset(struct sock *sk, struct sk_buff *rcv_skb)
+{
+    struct gmtp_hdr *rxgh = gmtp_hdr(rcv_skb), *gh;
+    struct gmtp_skb_cb *gcb = GMTP_SKB_CB(rcv_skb);
+    const u32 gmtp_hdr_len = sizeof(struct gmtp_hdr) +
+            sizeof(struct gmtp_hdr_reset);
+
+    struct gmtp_hdr_reset *ghr;
+    struct sk_buff *skb;
+
+    gmtp_pr_func();
+
+    skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);
+    if (skb == NULL)
+        return NULL;
+
+    skb_reserve(skb, sk->sk_prot->max_header);
+
+    /* Swap the send and the receive. */
+    gh = gmtp_zeroed_hdr(skb, gmtp_hdr_len);
+    gh->type    = GMTP_PKT_RESET;
+    gh->sport   = rxgh->dport;
+    gh->dport   = rxgh->sport;
+    gh->hdrlen  = gmtp_hdr_len;
+    gh->seq     = rxgh->seq;
+    gh->server_rtt  = rxgh->server_rtt;
+    gh->transm_r    = rxgh->transm_r;
+    memcpy(gh->flowname, rxgh->flowname, GMTP_FLOWNAME_LEN);
+
+    ghr = gmtp_hdr_reset(skb);
+    ghr->reset_code = gcb->reset_code;
+
+    switch (gcb->reset_code) {
+    case GMTP_RESET_CODE_PACKET_ERROR:
+        ghr->reset_data[0] = rxgh->type;
+        break;
+    case GMTP_RESET_CODE_MANDATORY_ERROR:
+        memcpy(ghr->reset_data, gcb->reset_data, 3);
+        break;
+    default:
+        break;
+    }
+
+    return skb;
+}
+EXPORT_SYMBOL_GPL(gmtp_ctl_make_reset);
+
+int gmtp_send_reset(struct sock *sk, enum gmtp_reset_codes code)
+{
+    struct sk_buff *skb;
+    int err = inet_csk(sk)->icsk_af_ops->rebuild_header(sk);
+
+    gmtp_print_function();
+
+    if (err != 0)
+        return err;
+
+    skb = sock_wmalloc(sk, sk->sk_prot->max_header, 1, GFP_ATOMIC);
+    if (skb == NULL)
+        return -ENOBUFS;
+
+    /* Reserve space for headers and prepare control bits. */
+    skb_reserve(skb, sk->sk_prot->max_header);
+    GMTP_SKB_CB(skb)->type = GMTP_PKT_RESET;
+    GMTP_SKB_CB(skb)->reset_code = code;
+
+    return gmtp_transmit_skb(sk, skb);
+}
+
+/*
+ * Do all connect socket setups that can be done AF independent.
+ */
+int gmtp_connect(struct sock *sk)
+{
+    struct sk_buff *skb;
+    struct gmtp_sock *gp = gmtp_sk(sk);
+    struct dst_entry *dst = __sk_dst_get(sk);
+    struct inet_sock *inet = inet_sk(sk);
+    struct inet_connection_sock *icsk = inet_csk(sk);
+    struct gmtp_client_entry *client_entry;
+    int err = 0;
+
+    gmtp_print_function();
+
+    sk->sk_err = 0;
+    sock_reset_flag(sk, SOCK_DONE);
+
+    gmtp_sync_mss(sk, dst_mtu(dst));
+
+    skb = alloc_skb(sk->sk_prot->max_header, sk->sk_allocation);
+    if (unlikely(skb == NULL))
+        return -ENOBUFS;
+
+    /* Reserve space for headers. */
+    skb_reserve(skb, sk->sk_prot->max_header);
+    GMTP_SKB_CB(skb)->type = GMTP_PKT_REQUEST;
+
+    client_entry = gmtp_lookup_client(client_hashtable, gp->flowname);
+    if(client_entry == NULL)
+        err = gmtp_add_client_entry(client_hashtable, gp->flowname,
+                inet->inet_saddr, inet->inet_sport, 0, 0);
+
+    client_entry = gmtp_lookup_client(client_hashtable, gp->flowname);
+    if(err != 0 || client_entry == NULL) {
+        return -ENOBUFS;
+    }
+
+    gp->myself = gmtp_list_add_client(0, inet->inet_saddr, inet->inet_sport,
+            0, &client_entry->clients->list);
+
+    if(gp->myself == NULL)
+        return -ENOBUFS;
+
+    /** First transmission: gss <- iss */
+    gp->gss = gp->iss;
+    gp->req_stamp = jiffies_to_msecs(jiffies);
+    gp->ack_rx_tstamp = jiffies_to_msecs(jiffies);
+    gp->myself->ack_rx_tstamp = gp->ack_rx_tstamp;
+    gp->myself->mysock = sk;
+
+    gmtp_transmit_skb(sk, gmtp_skb_entail(sk, skb));
+
+    icsk->icsk_retransmits = 0;
+    inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
+                      icsk->icsk_rto, GMTP_RTO_MAX);
+    return 0;
+}
+EXPORT_SYMBOL_GPL(gmtp_connect);
+
+void gmtp_send_ack(struct sock *sk)
+{
+    gmtp_print_function();
+
+    /* If we have been reset, we may not send again. */
+    if(sk->sk_state != GMTP_CLOSED) {
+
+        struct sk_buff *skb = alloc_skb(sk->sk_prot->max_header,
+        GFP_ATOMIC);
+
+        /* FIXME How to define the ackcode in this case? */
+        if(skb == NULL) {
+            inet_csk_schedule_ack(sk);
+            inet_csk(sk)->icsk_ack.ato = TCP_ATO_MIN;
+            inet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,
+                    TCP_DELACK_MAX, GMTP_RTO_MAX);
+            return;
+        }
+
+        /* Reserve space for headers */
+        skb_reserve(skb, sk->sk_prot->max_header);
+        GMTP_SKB_CB(skb)->type = GMTP_PKT_ACK;
+        gmtp_transmit_skb(sk, skb);
+    }
+}
+EXPORT_SYMBOL_GPL(gmtp_send_ack);
+
+void gmtp_send_elect_request(struct sock *sk, unsigned long interval)
+{
+    struct sk_buff *skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);
+    struct gmtp_sock *gp = gmtp_sk(sk);
+
+    gmtp_pr_func();
+
+    if(skb == NULL)
+        return;
+
+    if(gp->req_stamp == 0)
+        gp->req_stamp = jiffies_to_msecs(jiffies);
+
+    /* Reserve space for headers */
+    skb_reserve(skb, sk->sk_prot->max_header);
+    GMTP_SKB_CB(skb)->type = GMTP_PKT_ELECT_REQUEST;
+
+    gmtp_transmit_skb(sk, skb);
+
+    if(interval > 0)
+        inet_csk_reset_keepalive_timer(sk, interval);
+}
+EXPORT_SYMBOL_GPL(gmtp_send_elect_request);
+
+void gmtp_send_elect_response(struct sock *sk, __u8 code)
+{
+    struct sk_buff *skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);
+    struct gmtp_sock *gp = gmtp_sk(sk);
+
+    gmtp_pr_func();
+
+    if(skb == NULL)
+        return;
+
+    /* Reserve space for headers */
+    skb_reserve(skb, sk->sk_prot->max_header);
+    GMTP_SKB_CB(skb)->type = GMTP_PKT_ELECT_RESPONSE;
+    GMTP_SKB_CB(skb)->elect_code = code;
+
+    if(code == GMTP_ELECT_AUTO) {
+
+        pr_info("Turning a client into a Reporter\n");
+
+        /* We dont need init mcc, because mcc is already started */
+        gp->role = GMTP_ROLE_REPORTER;
+        gp->myself->max_nclients =
+                GMTP_REPORTER_DEFAULT_PROPORTION - 1;
+        gp->myself->clients = kmalloc(sizeof(struct gmtp_client),
+        GFP_ATOMIC);
+        INIT_LIST_HEAD(&gp->myself->clients->list);
+        mcc_rx_init(sk);
+        inet_csk_reset_keepalive_timer(sk, GMTP_ACK_TIMEOUT);
+    }
+
+    gmtp_transmit_skb(sk, skb);
+}
+EXPORT_SYMBOL_GPL(gmtp_send_elect_response);
+
+struct sk_buff *gmtp_ctl_make_elect_response(struct sock *sk,
+        struct sk_buff *rcv_skb)
+{
+    struct gmtp_hdr *rxgh = gmtp_hdr(rcv_skb), *gh;
+    struct gmtp_skb_cb *gcb = GMTP_SKB_CB(rcv_skb);
+    const u32 gmtp_hdr_len = sizeof(struct gmtp_hdr) +
+            sizeof(struct gmtp_hdr_elect_response);
+
+    struct gmtp_hdr_elect_response *ghr;
+    struct sk_buff *skb;
+
+    gmtp_print_function();
+
+    skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);
+    if (skb == NULL)
+        return NULL;
+
+    skb_reserve(skb, sk->sk_prot->max_header);
+
+    /* Swap the send and the receive. */
+    gh = gmtp_zeroed_hdr(skb, gmtp_hdr_len);
+    gh->type    = GMTP_PKT_ELECT_RESPONSE;
+    gh->sport   = rxgh->dport;
+    gh->dport   = rxgh->sport;
+    gh->hdrlen  = gmtp_hdr_len;
+    gh->seq     = rxgh->seq;
+    gh->server_rtt  = rxgh->server_rtt;
+    gh->transm_r    = rxgh->transm_r;
+    memcpy(gh->flowname, rxgh->flowname, GMTP_FLOWNAME_LEN);
+
+    ghr = gmtp_hdr_elect_response(skb);
+    ghr->elect_code = gcb->elect_code;
+
+    return skb;
+}
+EXPORT_SYMBOL_GPL(gmtp_ctl_make_elect_response);
+
+struct sk_buff *gmtp_ctl_make_ack(struct sock *sk, struct sk_buff *rcv_skb)
+{
+    struct gmtp_hdr *rxgh = gmtp_hdr(rcv_skb), *gh;
+    struct gmtp_hdr_ack *gack;
+    const u32 gmtp_hdr_len = sizeof(struct gmtp_hdr)
+            + sizeof(struct gmtp_hdr_ack);
+    struct sk_buff *skb;
+
+    gmtp_print_function();
+
+    skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);
+    if(skb == NULL)
+        return NULL;
+
+    skb_reserve(skb, sk->sk_prot->max_header);
+
+    /* Swap the send and the receive. */
+    gh = gmtp_zeroed_hdr(skb, gmtp_hdr_len);
+    gh->type = GMTP_PKT_ACK;
+    gh->sport = rxgh->dport;
+    gh->dport = rxgh->sport;
+    gh->hdrlen = gmtp_hdr_len;
+    gh->seq = rxgh->seq;
+    gh->server_rtt = rxgh->server_rtt;
+    gh->transm_r = rxgh->transm_r;
+    memcpy(gh->flowname, rxgh->flowname, GMTP_FLOWNAME_LEN);
+
+
+    if(rxgh->type == GMTP_PKT_DATA) {
+        struct gmtp_hdr_data *ghd = gmtp_hdr_data(rcv_skb);
+        pr_info("Responding a DATA with a ACK");
+        gack = gmtp_hdr_ack(skb);
+        gack->orig_tstamp = ghd->tstamp;
+    } else {
+        pr_info("Responding a NON-DATA with a ACK\n");
+    }
+
+    return skb;
+}
+EXPORT_SYMBOL_GPL(gmtp_ctl_make_ack);
+
+void gmtp_send_feedback(struct sock *sk)
+{
+    if(sk->sk_state != GMTP_CLOSED) {
+
+        struct sk_buff *skb = alloc_skb(sk->sk_prot->max_header,
+        GFP_ATOMIC);
+
+        /* Reserve space for headers */
+        skb_reserve(skb, sk->sk_prot->max_header);
+        GMTP_SKB_CB(skb)->type = GMTP_PKT_FEEDBACK;
+        GMTP_SKB_CB(skb)->orig_tstamp = gmtp_sk(sk)->rx_last_orig_tstamp;
+
+        gmtp_transmit_skb(sk, skb);
+    }
+}
+EXPORT_SYMBOL_GPL(gmtp_send_feedback);
+
+/*
+ * Send a GMTP_PKT_CLOSE/CLOSEREQ. The caller locks the socket for us.
+ * This cannot be allowed to fail queueing a GMTP_PKT_CLOSE/CLOSEREQ frame
+ * under any circumstances.
+ */
+void gmtp_send_close(struct sock *sk, const int active)
+{
+    struct sk_buff *skb;
+    const gfp_t prio = active ? GFP_KERNEL : GFP_ATOMIC;
+
+    gmtp_print_function();
+
+    skb = alloc_skb(sk->sk_prot->max_header, prio);
+    if(skb == NULL)
+        return;
+
+    /* Reserve space for headers and prepare control bits. */
+    skb_reserve(skb, sk->sk_prot->max_header);
+    GMTP_SKB_CB(skb)->type = GMTP_PKT_CLOSE;
+
+    if(active) {
+        skb = gmtp_skb_entail(sk, skb);
+        /*
+         * TODO Verify if we need Retransmission timer
+         * for active-close...
+         */
+        /*inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
+                GMTP_TIMEOUT_INIT, GMTP_RTO_MAX);*/
+    }
+    gmtp_transmit_skb(sk, skb);
+}
+
+/**
+ * gmtp_wait_for_delay  -  Await GMTP send permission
+ * @sk:    socket to wait for
+ * @delay: timeout in jiffies
+ *
+ * To delay the send time in process context.
+ */
+static long gmtp_wait_for_delay(struct sock *sk, unsigned long delay)
+{
+    DEFINE_WAIT(wait);
+    long remaining;
+    gmtp_pr_func();
+    prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);
+
+    sk->sk_write_pending++;
+    release_sock(sk);
+    remaining = schedule_timeout(delay);
+
+    lock_sock(sk);
+    sk->sk_write_pending--;
+    finish_wait(sk_sleep(sk), &wait);
+
+    if (signal_pending(current) || sk->sk_err)
+        return -1;
+
+    return remaining;
+}
+
+static inline unsigned int packet_len(struct sk_buff *skb)
+{
+    /* Total = Data + (GMTP + IP + MAC) */
+    return skb->len + (gmtp_data_hdr_len() + 20 + ETH_HLEN);
+}
+
+static inline unsigned int payload_len(struct sk_buff *skb)
+{
+    /* Data = Total - (GMTP + IP + MAC) */
+    return skb->len - (gmtp_data_hdr_len() + 20 + ETH_HLEN);
+}
+
+static inline void packet_sent(struct sock *sk, struct sk_buff *skb)
+{
+    struct gmtp_sock *gp = gmtp_sk(sk);
+    unsigned long elapsed = 0;
+    int data_len = payload_len(skb);
+
+    if(unlikely(gp->tx_dpkts_sent == 0))
+        gmtp_pr_info("Start sending data packets...\n\n");
+
+    ++gp->tx_dpkts_sent;
+    gp->tx_data_sent += data_len;
+    gp->tx_bytes_sent += skb->len;
+
+    gp->tx_last_stamp = jiffies;
+    if(unlikely(gp->tx_first_stamp == 0)) { /* This is the first sent */
+        gp->tx_first_stamp = gp->tx_last_stamp;
+        gp->tx_time_sample = jiffies;
+        gp->tx_byte_sample = gp->tx_bytes_sent;
+    }
+
+    if(gp->tx_byte_budget != INT_MIN)
+        gp->tx_byte_budget -= (int) skb->len;
+
+    elapsed = jiffies - gp->tx_first_stamp;
+    if(gp->tx_first_stamp != 0 && elapsed != 0)
+        gp->tx_total_rate = mult_frac(HZ, gp->tx_bytes_sent, elapsed);
+
+    if(gp->tx_dpkts_sent >= gp->tx_sample_len) {
+
+        gp->tx_time_sample = jiffies - gp->tx_time_sample;
+        gp->tx_byte_sample = gp->tx_bytes_sent - gp->tx_byte_sample;
+
+        if(gp->tx_time_sample != 0 && gp->tx_byte_sample != 0)
+            gp->tx_sample_rate = mult_frac(HZ,
+                            gp->tx_byte_sample,
+                            gp->tx_time_sample);
+    }
+}
+
+static void gmtp_xmit_packet(struct sock *sk, struct sk_buff *skb) {
+
+    int err;
+
+    GMTP_SKB_CB(skb)->type = GMTP_PKT_DATA;
+    err = gmtp_transmit_skb(sk, skb);
+
+    /*
+    char label[30];
+    sprintf(label, "To %pI4 (%d pkts sent, err=%d)", &sk->sk_daddr,
+            gmtp_sk(sk)->tx_dpkts_sent, err);
+    print_gmtp_data(skb, label);
+    */
+
+    /*
+     * Register this one as sent (even if an error occurred).
+     * To the remote end a local packet drop is indistinguishable from
+     * network loss.
+     */
+    packet_sent(sk, skb);
+
+    if (unlikely(err)) {
+        gmtp_pr_error("transmit_skb() returned err=%d\n", err);
+
+        print_gmtp_packet(ip_hdr(skb), gmtp_hdr(skb));
+
+        pr_info("ISS: %u, GSS: %u, N: %u\n", gmtp_sk(sk)->iss,
+                gmtp_sk(sk)->gss,
+                (gmtp_sk(sk)->gss - gmtp_sk(sk)->iss));
+    }
+}
+
+/**
+ * Return difference between actual tx_rate and max tx_rate
+ * If return > 0, actual tx_rate is greater than max tx_rate
+ */
+static long get_rate_gap(struct gmtp_sock *gp, int acum)
+{
+    long rate = (long) gp->tx_sample_rate;
+    long tx = (long) min(gp->tx_max_rate, gp->tx_ucc_rate);
+
+    long coef_adj = 0;
+
+    if(gp->tx_dpkts_sent < GMTP_MIN_SAMPLE_LEN)
+        return 0;
+
+    if(rate <= gp->tx_total_rate/2) /* Eliminate discrepancies */
+        rate = (long)gp->tx_total_rate;
+
+    coef_adj = mult_frac((rate - tx), 100, tx);
+
+    if(acum) {
+        coef_adj += gp->tx_adj_budget;
+        if(coef_adj > 110 || coef_adj < -90)
+            gp->tx_adj_budget = 0;
+        else
+            gp->tx_adj_budget += coef_adj;
+    }
+
+    return coef_adj;
+}
+
+void gmtp_write_xmit(struct sock *sk, struct sk_buff *skb)
+{
+    struct gmtp_sock *gp = gmtp_sk(sk);
+    unsigned long elapsed = 0;
+    long delay = 0, delay2 = 0, delay_budget = 0;
+    unsigned long tx_rate = min(gp->tx_max_rate, gp->tx_ucc_rate);
+    int len;
+
+    /** TODO Continue tests with different scales... */
+    static const int scale = 1;
+    /*static const int scale = HZ/100;*/
+
+    if(unlikely(skb == NULL))
+        return;
+
+    if(tx_rate == UINT_MAX || gp->tx_ucc_type != GMTP_DELAY_UCC)
+        goto send;
+
+    /*pr_info("[%d] Tx rate: %lu bytes/s\n", gp->tx_dpkts_sent, gp->tx_total_rate);
+    pr_info("[-] Tx rate (sample): %lu bytes/s\n", gp->tx_sample_rate);*/
+
+    elapsed = jiffies - gp->tx_last_stamp; /* time elapsed since last sent */
+
+    len = packet_len(skb);
+    if(gp->tx_byte_budget >= mult_frac(len, 3, 4)) {
+        goto send;
+    } else if(gp->tx_byte_budget != INT_MIN) {
+        delay_budget = scale;
+        goto wait;
+    }
+
+    delay = DIV_ROUND_CLOSEST((HZ * len), tx_rate);
+    delay2 = delay - elapsed;
+
+    if(delay2 > 0)
+        delay2 += mult_frac(delay2, get_rate_gap(gp, 1), 100);
+
+wait:
+    delay2 += delay_budget;
+
+    /*
+     * TODO More tests with byte_budgets...
+     */
+    if(delay <= 0)
+        gp->tx_byte_budget = mult_frac(scale, tx_rate, HZ) -
+            mult_frac(gp->tx_byte_budget, (int) get_rate_gap(gp, 0), 100);
+    else
+        gp->tx_byte_budget = INT_MIN;
+
+    if(delay2 > 0) {
+        struct gmtp_packet_info *pkt_info;
+        pkt_info = kmalloc(sizeof(struct gmtp_packet_info), GFP_KERNEL);
+        pkt_info->sk = sk;
+        pkt_info->skb = skb;
+
+        setup_timer(&gp->xmit_timer, gmtp_write_xmit_timer,
+                (unsigned long ) pkt_info);
+        mod_timer(&gp->xmit_timer, jiffies + delay2);
+
+        /* Never use gmtp_wait_for_delay(sk, delay2); in NS-3/dce*/
+        schedule_timeout(delay2);
+        return;
+    }
+
+send:
+    gmtp_xmit_packet(sk, skb);
+
+}
+EXPORT_SYMBOL_GPL(gmtp_write_xmit);
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/proto.c linux-4.9-rc2/net/gmtp/proto.c
--- linux-4.9-rc2-original/net/gmtp/proto.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/proto.c	2016-12-02 03:34:41.854878795 -0300
@@ -0,0 +1,1324 @@
+#include <asm/ioctls.h>
+#include <asm-generic/unaligned.h>
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/dirent.h>
+#include <linux/inetdevice.h>
+#include <linux/crypto.h>
+#include <linux/err.h>
+#include <linux/scatterlist.h>
+
+#include <net/inet_hashtables.h>
+#include <net/sock.h>
+#include <net/tcp.h>
+
+#include <uapi/linux/gmtp.h>
+#include <linux/gmtp.h>
+#include <linux/poll.h>
+#include "gmtp.h"
+#include "mcc.h"
+
+struct percpu_counter gmtp_orphan_count;
+EXPORT_SYMBOL_GPL(gmtp_orphan_count);
+
+struct inet_hashinfo gmtp_inet_hashinfo;
+EXPORT_SYMBOL_GPL(gmtp_inet_hashinfo);
+
+struct gmtp_info* gmtp_info;
+EXPORT_SYMBOL_GPL(gmtp_info);
+
+const char *gmtp_packet_name(const __u8 type)
+{
+    static const char *const gmtp_packet_names[] = {
+        [GMTP_PKT_REQUEST]  = "REQUEST",
+        [GMTP_PKT_REQUESTNOTIFY]  = "REQUESTNOTIFY",
+        [GMTP_PKT_RESPONSE] = "RESPONSE",
+        [GMTP_PKT_REGISTER] = "REGISTER",
+        [GMTP_PKT_REGISTER_REPLY] = "REGISTER_REPLY",
+        [GMTP_PKT_ROUTE_NOTIFY] = "ROUTE_NOTIFY",
+        [GMTP_PKT_RELAYQUERY] = "RELAYQUERY",
+        [GMTP_PKT_RELAYQUERY_REPLY] = "RELAYQUERY_REPLY",
+        [GMTP_PKT_DATA]     = "DATA",
+        [GMTP_PKT_ACK]      = "ACK",
+        [GMTP_PKT_DATAACK]  = "DATAACK",
+        [GMTP_PKT_MEDIADESC]  = "MEDIADESC",
+        [GMTP_PKT_DATAPULL_REQUEST]  = "DATAPULL_REQUEST",
+        [GMTP_PKT_DATAPULL_RESPONSE]  = "DATAPULL_RESPONSE",
+        [GMTP_PKT_ELECT_REQUEST]  = "ELECT_REQUEST",
+        [GMTP_PKT_ELECT_RESPONSE]  = "ELECT_RESPONSE",
+        [GMTP_PKT_CLOSE]    = "CLOSE",
+        [GMTP_PKT_RESET]    = "RESET",
+        [GMTP_PKT_FEEDBACK]    = "REPORTER_FEEDBACK",
+        [GMTP_PKT_DELEGATE]    = "DELEGATE",
+        [GMTP_PKT_DELEGATE_REPLY]    = "DELEGATE_REPLY",
+    };
+
+    if (type >= GMTP_NR_PKT_TYPES)
+        return "INVALID";
+    else
+        return gmtp_packet_names[type];
+}
+EXPORT_SYMBOL_GPL(gmtp_packet_name);
+
+void gmtp_done(struct sock *sk)
+{
+    gmtp_print_function();
+
+    gmtp_set_state(sk, GMTP_CLOSED);
+    gmtp_clear_xmit_timers(sk);
+
+    sk->sk_shutdown = SHUTDOWN_MASK;
+
+    if(!sock_flag(sk, SOCK_DEAD))
+        sk->sk_state_change(sk);
+    else
+        inet_csk_destroy_sock(sk);
+}
+EXPORT_SYMBOL_GPL(gmtp_done);
+
+const char *gmtp_state_name(const int state)
+{
+    static const char *const gmtp_state_names[] = {
+    [GMTP_OPEN]     = "OPEN",
+    [GMTP_REQUESTING]   = "REQUESTING",
+    [GMTP_LISTEN]       = "LISTEN",
+    [GMTP_REQUEST_RECV]     = "REQUEST/REGISTER_RECEIVED",
+    [GMTP_ACTIVE_CLOSEREQ]  = "ACTIVE_CLOSEREQ",
+    [GMTP_PASSIVE_CLOSE]    = "PASSIVE_CLOSE",
+    [GMTP_CLOSING]      = "CLOSING",
+    [GMTP_TIME_WAIT]    = "TIME_WAIT",
+    [GMTP_CLOSED]       = "CLOSED",
+    [GMTP_DELEGATED]    = "DELEGATED",
+    };
+
+    if (state >= GMTP_PKT_INVALID)
+        return "INVALID STATE!";
+    else
+        return gmtp_state_names[state];
+}
+EXPORT_SYMBOL_GPL(gmtp_state_name);
+
+/**
+ * @str size MUST HAVE len >= GMTP_FLOWNAME_STR_LEN
+ */
+void flowname_str(__u8* str, const __u8 *flowname)
+{
+    int i;
+    for(i = 0; i < GMTP_FLOWNAME_LEN; ++i)
+        sprintf(&str[i*2], "%02x", flowname[i]);
+}
+EXPORT_SYMBOL_GPL(flowname_str);
+
+void flowname_strn(__u8* str, const __u8 *buffer, int length)
+{
+    int i;
+    for(i = 0; i < length; ++i)
+        sprintf(&str[i*2], "%02x", buffer[i]);
+}
+EXPORT_SYMBOL_GPL(flowname_strn);
+
+/*
+ * Print IP packet basic information
+ */
+void print_packet(struct sk_buff *skb, bool in)
+{
+    struct iphdr *iph = ip_hdr(skb);
+    const char *type = in ? "IN" : "OUT";
+    pr_info("%s: Src=%pI4 | Dst=%pI4 | TTL=%u | Proto: %d | Len: %d B\n",
+            type,
+            &iph->saddr, &iph->daddr,
+            iph->ttl,
+            iph->protocol,
+            ntohs(iph->tot_len));
+}
+
+/*
+ * Print GMTP packet basic information
+ */
+void print_gmtp_packet(const struct iphdr *iph, const struct gmtp_hdr *gh)
+{
+    __u8 flowname[GMTP_FLOWNAME_STR_LEN];
+    flowname_str(flowname, gh->flowname);
+
+    pr_info("%s (%u) src=%pI4@%-5d, dst=%pI4@%-5d, ttl=%u, len=%u B, seq=%u, "
+            "rtt=%u ms, tx=%u B/s, P=%s\n",
+                gmtp_packet_name(gh->type), gh->type,
+                &iph->saddr, ntohs(gh->sport),
+                &iph->daddr, ntohs(gh->dport),
+                iph->ttl, ntohs(iph->tot_len),
+                gh->seq, gh->server_rtt, gh->transm_r,
+                flowname);
+}
+EXPORT_SYMBOL_GPL(print_gmtp_packet);
+
+/*
+ * Print Data of GMTP-Data packets
+ */
+void print_gmtp_data(struct sk_buff *skb, char* label)
+{
+    __u8* data = gmtp_data(skb);
+    __u32 data_len = gmtp_data_len(skb);
+    char *lb = (label != NULL) ? label : "Data";
+    if(data_len > 0) {
+        unsigned char *data_str = kmalloc(data_len+1, GFP_KERNEL);
+        memcpy(data_str, data, data_len);
+        data_str[data_len] = '\0';
+        pr_info("%s: %s\n", lb, data_str);
+        kfree(data_str);
+    } else {
+        pr_info("%s: <empty>\n", lb);
+    }
+}
+EXPORT_SYMBOL_GPL(print_gmtp_data);
+
+void print_gmtp_hdr_relay(const struct gmtp_hdr_relay *relay)
+{
+    unsigned char relayid[GMTP_FLOWNAME_STR_LEN];
+    flowname_str(relayid, relay->relay_id);
+    pr_info("\t%s :: %pI4\n", relayid, &relay->relay_ip);
+}
+EXPORT_SYMBOL_GPL(print_gmtp_hdr_relay);
+
+void print_route_from_skb(struct sk_buff *skb)
+{
+    int i;
+    struct gmtp_hdr_route *route = gmtp_hdr_route(skb);
+    struct gmtp_hdr_relay *relay_list = gmtp_hdr_relay(skb);
+
+    pr_info("On packet -> Path to %pI4: \n", &(ip_hdr(skb)->saddr));
+    if(route->nrelays <= 0) {
+        pr_info("\tEmpty route.\n");
+        return;
+    }
+
+    for(i = route->nrelays - 1; i >= 0; --i)
+        print_gmtp_hdr_relay(&relay_list[i]);
+}
+EXPORT_SYMBOL_GPL(print_route_from_skb);
+
+void print_route_from_list(struct gmtp_relay_entry *relay_list)
+{
+    struct gmtp_relay_entry *relay;
+
+    pr_info("On list -> Path to %pI4: \n", &relay_list->relay.relay_ip);
+    if(relay_list->nrelays <= 0) {
+        pr_info("\tEmpty route.\n");
+        return;
+    }
+
+    print_gmtp_hdr_relay(&relay_list->relay);
+    list_for_each_entry(relay, &relay_list->path_list, path_list) {
+        print_gmtp_hdr_relay(&relay->relay);
+    }
+}
+EXPORT_SYMBOL_GPL(print_route_from_list);
+
+const char *gmtp_sock_type_name(const int type)
+{
+    static const char *const gmtp_sock_type_names[] = {
+    [GMTP_SOCK_TYPE_REGULAR]     = "REGULAR",
+    [GMTP_SOCK_TYPE_REPORTER]    = "TO_REPORTER",
+    [GMTP_SOCK_TYPE_CONTROL_CHANNEL] = "CONTROL_CHANNEL",
+    [GMTP_SOCK_TYPE_DATA_CHANNEL]    = "DATA_CHANNEL"
+    };
+
+    if(type > GMTP_SOCK_TYPE_DATA_CHANNEL)
+        return "INVALID TYPE!";
+    else
+        return gmtp_sock_type_names[type];
+}
+EXPORT_SYMBOL_GPL(gmtp_sock_type_name);
+
+/*
+ * Print GMTP sock basic information
+ */
+void print_gmtp_sock(struct sock *sk)
+{
+    pr_info("Socket (%s) - dst=%pI4@%-5d [%s]\n",
+            gmtp_sock_type_name(gmtp_sk(sk)->type), &sk->sk_daddr,
+            ntohs(sk->sk_dport), gmtp_state_name(sk->sk_state));
+}
+EXPORT_SYMBOL_GPL(print_gmtp_sock);
+
+/* FIXME This fails at NS-3-DCE */
+unsigned char *gmtp_build_md5(unsigned char *buf)
+{
+    /****
+    struct scatterlist sg;
+    struct crypto_hash *tfm;
+    struct hash_desc desc;
+    unsigned char *output;
+    size_t buf_size = sizeof(buf) - 1;
+     __u8 md5[21];
+
+    gmtp_print_function();
+
+    output = kmalloc(MD5_LEN * sizeof(unsigned char), GFP_KERNEL);
+    tfm = crypto_alloc_hash("md5", 0, CRYPTO_ALG_ASYNC);
+
+    if(output == NULL || IS_ERR(tfm)) {
+        gmtp_pr_warning("Allocation failed...");
+        return NULL;
+    }
+    desc.tfm = tfm;
+    desc.flags = 0;
+
+    crypto_hash_init(&desc);
+
+    sg_init_one(&sg, buf, buf_size);
+    crypto_hash_update(&desc, &sg, buf_size);
+    crypto_hash_final(&desc, output);
+
+    flowname_strn(md5, output, MD5_LEN);
+    printk("Output md5 = %s\n", md5);
+
+    crypto_free_hash(tfm);
+
+    return output;
+    ****/
+    return NULL;
+}
+EXPORT_SYMBOL_GPL(gmtp_build_md5);
+
+static inline int bytes_added(int sprintf_return)
+{
+    return (sprintf_return > 0) ? sprintf_return : 0;
+}
+
+unsigned char *gmtp_build_relay_id(void)
+{
+    struct socket *sock = NULL;
+    struct net_device *dev = NULL;
+    struct net *net;
+
+    int i, retval, length = 0;
+    char mac_address[6];
+
+    char buffer[50];
+    u8 *str[30];
+
+    gmtp_print_function();
+
+    retval = sock_create(AF_INET, SOCK_STREAM, 0, &sock);
+    net = sock_net(sock->sk);
+
+    for(i = 2; (dev = dev_get_by_index_rcu(net, i)) != NULL; ++i) {
+        memcpy(&mac_address, dev->dev_addr, 6);
+        length += bytes_added(sprintf((char*)(buffer + length), str[0]));
+    }
+
+    sock_release(sock);
+    return gmtp_build_md5(buffer);
+}
+EXPORT_SYMBOL_GPL(gmtp_build_relay_id);
+
+__be32 gmtp_dev_ip(struct net_device *dev)
+{
+    struct in_device *in_dev;
+    struct in_ifaddr *if_info;
+
+    if(dev == NULL)
+        return 0;
+
+    in_dev = (struct in_device *)dev->ip_ptr;
+    if_info = in_dev->ifa_list;
+    for(; if_info; if_info = if_info->ifa_next) {
+        /* just return the first entry for now */
+        return if_info->ifa_address;
+    }
+
+    return 0;
+}
+EXPORT_SYMBOL_GPL(gmtp_dev_ip);
+
+bool gmtp_local_ip(__be32 ip)
+{
+    struct socket *sock = NULL;
+    struct net_device *dev = NULL;
+    struct net *net;
+
+    int i, length = 0;
+    char mac_address[6];
+
+    char buffer[50];
+    u8 *str[30];
+
+    bool ret = false;
+
+    sock_create(AF_INET, SOCK_STREAM, 0, &sock);
+    net = sock_net(sock->sk);
+
+    for(i = 2; (dev = dev_get_by_index_rcu(net, i)) != NULL; ++i) {
+        __be32 dev_ip = gmtp_dev_ip(dev);
+        if(ip == dev_ip) {
+            ret = true;
+            break;
+        }
+    }
+
+    sock_release(sock);
+    return ret;
+}
+EXPORT_SYMBOL_GPL(gmtp_local_ip);
+
+void gmtp_add_relayid(struct sk_buff *skb)
+{
+    struct iphdr *iph = ip_hdr(skb);
+    struct gmtp_hdr *gh = gmtp_hdr(skb);
+    struct gmtp_hdr_register_reply *gh_rply = gmtp_hdr_register_reply(skb);
+    struct gmtp_hdr_relay *relay;
+    int relay_len = sizeof(struct gmtp_hdr_relay);
+
+    gmtp_print_function();
+
+    relay = (struct gmtp_hdr_relay*) skb_put(skb, relay_len);
+    memcpy(relay->relay_id, gmtp_info->relay_id, GMTP_RELAY_ID_LEN);
+    relay->relay_ip =  gmtp_dev_ip(skb->dev);
+    ++gh_rply->nrelays;
+
+    gh->hdrlen += relay_len;
+    put_unaligned(htons(skb->len), &(iph->tot_len));
+    ip_send_check(iph);
+
+    print_route_from_skb(skb);
+}
+EXPORT_SYMBOL_GPL(gmtp_add_relayid);
+
+void gmtp_set_state(struct sock *sk, const int state)
+{
+    const int oldstate = sk->sk_state;
+
+    print_gmtp_sock(sk);
+    gmtp_pr_info("(%s --> %s)", gmtp_state_name(oldstate),
+                gmtp_state_name(state));
+
+    if(state == oldstate)
+        gmtp_print_warning("new state == old state!");
+
+    switch(state) {
+    case GMTP_CLOSED:
+        /* TODO Implement protocol stats
+        if(oldstate == GMTP_OPEN || oldstate == GMTP_CLOSING)
+            DCCP_INC_STATS(DCCP_MIB_ESTABRESETS); */
+
+        sk->sk_prot->unhash(sk);
+        if(inet_csk(sk)->icsk_bind_hash != NULL
+                && !(sk->sk_userlocks & SOCK_BINDPORT_LOCK))
+            inet_put_port(sk);
+        /* fall through */
+    }
+
+    /* Change state AFTER socket is unhashed to avoid closed
+     * socket sitting in hash tables.
+     */
+    sk->sk_state = state;
+}
+EXPORT_SYMBOL_GPL(gmtp_set_state);
+
+static void gmtp_finish_passive_close(struct sock *sk)
+{
+    gmtp_print_function();
+    if(sk->sk_state == GMTP_PASSIVE_CLOSE) {
+        /* Node (client or server) has received Close packet. */
+        gmtp_send_reset(sk, GMTP_RESET_CODE_CLOSED);
+        gmtp_set_state(sk, GMTP_CLOSED);
+    }
+}
+
+int gmtp_init_sock(struct sock *sk)
+{
+    struct gmtp_sock *gp = gmtp_sk(sk);
+    struct inet_connection_sock *icsk = inet_csk(sk);
+    int ret = 0;
+
+    gmtp_pr_func();
+
+    gmtp_init_xmit_timers(sk);
+
+    icsk->icsk_rto      = GMTP_TIMEOUT_INIT;
+    icsk->icsk_syn_retries  = GMTP_SYN_RETRIES;
+    sk->sk_state        = GMTP_CLOSED;
+    sk->sk_write_space  = gmtp_write_space;
+    icsk->icsk_sync_mss = gmtp_sync_mss;
+
+    memset(gp->flowname, 0, GMTP_FLOWNAME_LEN);
+
+    gp->mss         = GMTP_DEFAULT_MSS;
+    gp->type        = GMTP_SOCK_TYPE_REGULAR;
+    gp->role        = GMTP_ROLE_UNDEFINED;
+
+    gp->req_stamp       = 0;
+    gp->ack_rx_tstamp   = 0;
+    gp->ack_tx_tstamp   = 0;
+    gp->tx_rtt      = 0;
+    gp->tx_avg_rtt      = 0;
+
+    gp->rx_max_rate     = 0;
+
+    gp->tx_dpkts_sent   = 0;
+    gp->tx_data_sent    = 0;
+    gp->tx_bytes_sent   = 0;
+
+    gp->tx_sample_len   = GMTP_DEFAULT_SAMPLE_LEN;
+    gp->tx_time_sample  = 0;
+    gp->tx_byte_sample  = 0;
+
+    gp->tx_sample_rate  = 0;
+    gp->tx_total_rate   = 0;
+
+    gp->tx_first_stamp  = 0UL;
+    gp->tx_last_stamp   = 0UL;
+    gp->tx_media_rate   = UINT_MAX;
+    gp->tx_max_rate     = UINT_MAX; /* Unlimited */
+    gp->tx_ucc_rate     = UINT_MAX; /* Unlimited */
+    gp->tx_byte_budget  = INT_MIN;
+    gp->tx_adj_budget   = 0;
+
+    return ret;
+}
+EXPORT_SYMBOL_GPL(gmtp_init_sock);
+
+void gmtp_destroy_sock(struct sock *sk)
+{
+    gmtp_pr_func();
+
+    if(gmtp_sk(sk)->role == GMTP_ROLE_CLIENT && gmtp_sk(sk)->myself != NULL) {
+        if(gmtp_sk(sk)->myself->rsock != NULL)
+            inet_csk_clear_xmit_timers(gmtp_sk(sk)->myself->rsock);
+    }
+
+    if(gmtp_sk(sk)->role == GMTP_ROLE_REPORTER)
+        mcc_rx_exit(sk);
+
+    if (sk->sk_send_head != NULL) {
+        kfree_skb(sk->sk_send_head);
+        sk->sk_send_head = NULL;
+    }
+
+    /* Clean up a referenced GMTP bind bucket. */
+    if (inet_csk(sk)->icsk_bind_hash != NULL)
+        inet_put_port(sk);
+
+}
+EXPORT_SYMBOL_GPL(gmtp_destroy_sock);
+
+static void gmtp_terminate_connection(struct sock *sk)
+{
+    u8 next_state = GMTP_CLOSED;
+
+    gmtp_print_function();
+
+    switch (sk->sk_state) {
+    case GMTP_PASSIVE_CLOSE:
+        gmtp_finish_passive_close(sk);
+        break;
+    case GMTP_OPEN:
+        gmtp_send_close(sk, 1);
+
+        if (gmtp_sk(sk)->role == GMTP_ROLE_SERVER &&
+            !gmtp_sk(sk)->server_timewait)
+            next_state = GMTP_ACTIVE_CLOSEREQ;
+        else
+            next_state = GMTP_CLOSING;
+        /* fall through */
+    default:
+        gmtp_set_state(sk, next_state);
+    }
+}
+
+void gmtp_close(struct sock *sk, long timeout)
+{
+    /*struct gmtp_sock *gp = gmtp_sk(sk);*/
+    struct sk_buff *skb;
+    u32 data_was_unread = 0;
+    int state;
+
+    gmtp_pr_func();
+
+    pr_info("state: %s, timeout: %ld\n", gmtp_state_name(sk->sk_state), timeout);
+
+    lock_sock(sk);
+
+    sk->sk_shutdown = SHUTDOWN_MASK;
+    if(sk->sk_state == GMTP_LISTEN) {
+        gmtp_set_state(sk, GMTP_CLOSED);
+
+        /* Special case. */
+        inet_csk_listen_stop(sk);
+
+        goto adjudge_to_death;
+    }
+
+    /*
+     * We need to flush the recv. buffs.  We do this only on the
+     * descriptor close, not protocol-sourced closes, because the
+     * reader process may not have drained the data yet!
+     */
+    while((skb = __skb_dequeue(&sk->sk_receive_queue)) != NULL) {
+        data_was_unread += skb->len;
+        __kfree_skb(skb);
+    }
+
+    if(data_was_unread) {
+        /* Unread data was tossed, send an appropriate Reset Code */
+        gmtp_pr_warning("ABORT with %u bytes unread", data_was_unread);
+        gmtp_send_reset(sk, GMTP_RESET_CODE_ABORTED);
+        gmtp_set_state(sk, GMTP_CLOSED);
+    } else if(sock_flag(sk, SOCK_LINGER) && !sk->sk_lingertime) {
+        /* Check zero linger _after_ checking for unread data. */
+        sk->sk_prot->disconnect(sk, 0);
+    } else if(sk->sk_state != GMTP_CLOSED) {
+        /*
+         * May need to wait if there are still packets in the
+         * TX queue that are delayed by the CCID.
+         */
+        gmtp_terminate_connection(sk);
+    }
+
+    /*
+     * Flush write queue. This may be necessary in several cases:
+     * - we have been closed by the peer but still have application data;
+     * - abortive termination (unread data or zero linger time),
+     * - normal termination but queue could not be flushed within time limit
+     */
+    __skb_queue_purge(&sk->sk_write_queue);
+    sk_stream_wait_close(sk, timeout);
+
+adjudge_to_death:
+    state = sk->sk_state;
+    sock_hold(sk);
+    sock_orphan(sk);
+
+    /*
+     * It is the last release_sock in its life. It will remove backlog.
+     */
+    release_sock(sk);
+    /*
+     * Now socket is owned by kernel and we acquire BH lock
+     * to finish close. No need to check for user refs.
+     */
+    local_bh_disable();
+    bh_lock_sock(sk);
+    WARN_ON(sock_owned_by_user(sk));
+
+    percpu_counter_inc(sk->sk_prot->orphan_count);
+
+    /* Have we already been destroyed by a softirq or backlog? */
+    if(state != GMTP_CLOSED && sk->sk_state == GMTP_CLOSED) {
+        gmtp_print_debug("we already been destroyed by a "
+                "softirq or backlog");
+        goto out;
+    }
+
+    if(sk->sk_state == GMTP_CLOSED)
+        inet_csk_destroy_sock(sk);
+
+    /* Otherwise, socket is reprieved until protocol close. */
+out:
+    bh_unlock_sock(sk);
+    local_bh_enable();
+    sock_put(sk);
+}
+EXPORT_SYMBOL_GPL(gmtp_close);
+
+static inline int gmtp_need_reset(int state)
+{
+    return state != GMTP_CLOSED && state != GMTP_LISTEN &&
+           state != GMTP_REQUESTING;
+}
+
+int gmtp_disconnect(struct sock *sk, int flags)
+{
+    struct inet_connection_sock *icsk = inet_csk(sk);
+    struct inet_sock *inet = inet_sk(sk);
+    int err = 0;
+    const int old_state = sk->sk_state;
+
+    gmtp_print_function();
+
+    if(old_state != GMTP_CLOSED)
+        gmtp_set_state(sk, GMTP_CLOSED);
+
+
+    /* This corresponds to the ABORT function of RFC793, sec. 3.8
+     * TCP uses a RST segment, DCCP a Reset packet with Code 2, "Aborted".
+     */
+    if(old_state == GMTP_LISTEN) {
+        inet_csk_listen_stop(sk);
+    } else if(gmtp_need_reset(old_state)) {
+        gmtp_send_reset(sk, GMTP_RESET_CODE_ABORTED);
+        sk->sk_err = ECONNRESET;
+    } else if(old_state == GMTP_REQUESTING)
+        sk->sk_err = ECONNRESET;
+
+    gmtp_clear_xmit_timers(sk);
+
+    __skb_queue_purge(&sk->sk_receive_queue);
+    __skb_queue_purge(&sk->sk_write_queue);
+    if(sk->sk_send_head != NULL) {
+        __kfree_skb(sk->sk_send_head);
+        sk->sk_send_head = NULL;
+    }
+
+    inet->inet_dport = 0;
+
+    if(!(sk->sk_userlocks & SOCK_BINDADDR_LOCK))
+        inet_reset_saddr(sk);
+
+    sk->sk_shutdown = 0;
+    sock_reset_flag(sk, SOCK_DONE);
+
+    icsk->icsk_backoff = 0;
+    inet_csk_delack_init(sk);
+    __sk_dst_reset(sk);
+
+    WARN_ON(inet->inet_num && !icsk->icsk_bind_hash);
+
+    sk->sk_error_report(sk);
+    return err;
+}
+EXPORT_SYMBOL_GPL(gmtp_disconnect);
+
+unsigned int gmtp_poll(struct file *file, struct socket *sock, poll_table *wait)
+{
+    unsigned int mask;
+    struct sock *sk = sock->sk;
+
+    sock_poll_wait(file, sk_sleep(sk), wait);
+    if(sk->sk_state == GMTP_LISTEN)
+        return inet_csk_listen_poll(sk);
+
+    /* Socket is not locked. We are protected from async events
+     by poll logic and correct handling of state changes
+     made by another threads is impossible in any case.
+     */
+
+    mask = 0;
+    if(sk->sk_err)
+        mask = POLLERR;
+
+    if(sk->sk_shutdown == SHUTDOWN_MASK || sk->sk_state == GMTP_CLOSED)
+        mask |= POLLHUP;
+    if(sk->sk_shutdown & RCV_SHUTDOWN)
+        mask |= POLLIN | POLLRDNORM | POLLRDHUP;
+
+    /* Connected? */
+    if((1 << sk->sk_state) & ~(GMTPF_REQUESTING | GMTPF_REQUEST_RECV)) {
+        if(atomic_read(&sk->sk_rmem_alloc) > 0)
+            mask |= POLLIN | POLLRDNORM;
+
+        if(!(sk->sk_shutdown & SEND_SHUTDOWN)) {
+            if(sk_stream_is_writeable(sk)) {
+                mask |= POLLOUT | POLLWRNORM;
+            } else { /* send SIGIO later */
+                set_bit(SOCKWQ_ASYNC_NOSPACE,
+                        &sk->sk_socket->flags);
+                set_bit(SOCK_NOSPACE, &sk->sk_socket->flags);
+
+                /* Race breaker. If space is freed after
+                 * wspace test but before the flags are set,
+                 * IO signal will be lost.
+                 */
+                if(sk_stream_is_writeable(sk))
+                    mask |= POLLOUT | POLLWRNORM;
+            }
+        }
+    }
+    return mask;
+}
+EXPORT_SYMBOL_GPL(gmtp_poll);
+
+int gmtp_ioctl(struct sock *sk, int cmd, unsigned long arg)
+{
+    int rc = -ENOTCONN;
+
+    lock_sock(sk);
+
+    if (sk->sk_state == GMTP_LISTEN)
+        goto out;
+
+    switch (cmd) {
+    case SIOCINQ: {
+        struct sk_buff *skb;
+        unsigned long amount = 0;
+
+        skb = skb_peek(&sk->sk_receive_queue);
+
+        if (skb != NULL) {
+            /*
+             * We will only return the amount of this packet since
+             * that is all that will be read.
+             */
+            amount = skb->len;
+        }
+        rc = put_user(amount, (int __user *)arg);
+    }
+    break;
+    default:
+        rc = -ENOIOCTLCMD;
+        break;
+    }
+out:
+    release_sock(sk);
+    return rc;
+}
+EXPORT_SYMBOL_GPL(gmtp_ioctl);
+
+int gmtp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int nonblock,
+        int flags, int *addr_len)
+{
+    const struct gmtp_hdr *gh;
+    long timeo;
+
+    lock_sock(sk);
+
+    if(sk->sk_state == GMTP_LISTEN) {
+        len = -ENOTCONN;
+        goto out;
+    }
+
+    timeo = sock_rcvtimeo(sk, nonblock);
+
+    do {
+        struct sk_buff *skb = skb_peek(&sk->sk_receive_queue);
+        if(skb == NULL)
+            goto verify_sock_status;
+
+        gh = gmtp_hdr(skb);
+
+        switch(gh->type) {
+        case GMTP_PKT_DATA:
+        case GMTP_PKT_DATAACK:
+            goto found_ok_skb;
+        case GMTP_PKT_CLOSE:
+            pr_info("CLOSE received!\n");
+            if(!(flags & MSG_PEEK))
+                gmtp_finish_passive_close(sk);
+            /* fall through */
+        case GMTP_PKT_RESET:
+            gmtp_print_debug("found fin (%s) ok!\n",
+                    gmtp_packet_name(gh->type));
+            len = 0;
+            goto found_fin_ok;
+        default:
+            gmtp_print_debug("packet_type=%s\n",
+                    gmtp_packet_name(gh->type));
+            sk_eat_skb(sk, skb);
+        }
+verify_sock_status:
+        if(sock_flag(sk, SOCK_DONE)) {
+            len = 0;
+            break;
+        }
+
+        if(sk->sk_err) {
+            len = sock_error(sk);
+            break;
+        }
+
+        if(sk->sk_shutdown & RCV_SHUTDOWN) {
+            len = 0;
+            break;
+        }
+
+        if(sk->sk_state == GMTP_CLOSED) {
+            if(!sock_flag(sk, SOCK_DONE)) {
+                /* This occurs when user tries to read
+                 * from never connected socket.
+                 */
+                len = -ENOTCONN;
+                break;
+            }
+            len = 0;
+            break;
+        }
+
+        if(!timeo) {
+            len = -EAGAIN;
+            break;
+        }
+
+        if(signal_pending(current)) {
+            len = sock_intr_errno(timeo);
+            break;
+        }
+
+        sk_wait_data(sk, &timeo, skb);
+        continue;
+found_ok_skb:
+        if(len > skb->len)
+            len = skb->len;
+        else if(len < skb->len)
+            msg->msg_flags |= MSG_TRUNC;
+
+        if(skb_copy_datagram_msg(skb, 0, msg, len)) {
+            /* Exception. Bailout! */
+            len = -EFAULT;
+            break;
+        }
+        if(flags & MSG_TRUNC)
+            len = skb->len;
+found_fin_ok:
+        if(!(flags & MSG_PEEK))
+            sk_eat_skb(sk, skb);
+        break;
+    } while(1);
+out:
+    release_sock(sk);
+    return len;
+}
+
+EXPORT_SYMBOL_GPL(gmtp_recvmsg);
+
+struct gmtp_sendmsg_data {
+    struct sock *sk;
+    struct sk_buff *skb;
+    struct timer_list *sendmsg_timer;
+};
+
+static void gmtp_sendmsg_callback(unsigned long data)
+{
+    struct gmtp_sendmsg_data *sd = (struct gmtp_sendmsg_data*) data;
+    if(!timer_pending(&gmtp_sk(sd->sk)->xmit_timer)) {
+        gmtp_write_xmit(sd->sk, sd->skb);
+        del_timer(sd->sendmsg_timer);
+        kfree(sd->sendmsg_timer);
+    } else
+        mod_timer(sd->sendmsg_timer, jiffies + 1);
+}
+
+int gmtp_do_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)
+{
+    struct gmtp_sock *gp = gmtp_sk(sk);
+    const int flags = msg->msg_flags;
+    const int noblock = flags & MSG_DONTWAIT;
+    struct sk_buff *skb;
+    int rc, size;
+    long timeo;
+
+    if (len > gp->mss)
+        return -EMSGSIZE;
+
+    lock_sock(sk);
+
+    /* FIXME Check if sk queue is full */
+    timeo = sock_sndtimeo(sk, noblock);
+
+    /*
+     * We have to use sk_stream_wait_connect here to set sk_write_pending,
+     * so that the trick in gmtp_rcv_request_sent_state_process.
+     */
+    /* Wait for a connection to finish. */
+    if ((1 << sk->sk_state) & ~(GMTPF_OPEN | GMTPF_PASSIVE_CLOSE))
+        if ((rc = sk_stream_wait_connect(sk, &timeo)) != 0)
+            goto out_release;
+
+    size = sk->sk_prot->max_header + len;
+    release_sock(sk);
+    skb = sock_alloc_send_skb(sk, size, noblock, &rc);
+    lock_sock(sk);
+    if (skb == NULL)
+        goto out_release;
+
+    skb_reserve(skb, sk->sk_prot->max_header);
+    rc = memcpy_from_msg(skb_put(skb, len), msg, len);
+    if (rc != 0)
+        goto out_discard;
+
+    /** FIXME Enqueue packets when time is pending... */
+
+    /**
+     * Use a timer to rate-based congestion control protocols.
+     * The timer will expire when congestion control permits to release
+     * further packets into the network.
+     *
+     * Here, a while(timer_pending(...)) does not work for ns-3/dce
+     * So, we use a timer...
+     */
+    if(!timer_pending(&gp->xmit_timer)) {
+        gmtp_write_xmit(sk, skb);
+    } else {
+        struct timer_list *sendmsg_timer = kmalloc(
+                sizeof(struct timer_list), GFP_KERNEL);
+        struct gmtp_sendmsg_data *sd = kmalloc(sizeof(struct gmtp_sendmsg_data),
+                GFP_KERNEL);
+        sd->sk = sk;
+        sd->skb = skb;
+        sd->sendmsg_timer = sendmsg_timer;
+        setup_timer(sd->sendmsg_timer, gmtp_sendmsg_callback,
+                (unsigned long ) sd);
+        mod_timer(sd->sendmsg_timer, jiffies + 1);
+    }
+
+out_release:
+    release_sock(sk);
+    return rc ? : len;
+out_discard:
+    kfree_skb(skb);
+    goto out_release;
+}
+
+/*struct gmtp_sendmsg_data {
+    struct sock *sk;
+    struct msghdr *msg;
+    size_t len;
+};*/
+
+/*int gmtp_do_sendmsg_thread_func(void *data)
+{
+    struct gmtp_sendmsg_data *smd = (struct gmtp_sendmsg_data*) data;
+
+    return gmtp_do_sendmsg(smd->sk, smd->msg, smd->len);
+}*/
+
+size_t gmtp_media_adapt_cc(struct sock *sk, struct msghdr *msg, size_t len)
+{
+    struct gmtp_sock *gp = gmtp_sk(sk);
+    unsigned long tx_rate = min(gp->tx_max_rate, gp->tx_ucc_rate);
+
+    unsigned int datalen, datalen20, datalen40, datalen80;
+    unsigned int rate, new_len;
+
+    new_len = len;
+
+    if(tx_rate == UINT_MAX || gp->tx_ucc_type != GMTP_MEDIA_ADAPT_UCC)
+        return len;
+
+    if(gp->tx_total_rate <= tx_rate)
+        return len;
+
+    rate = DIV_ROUND_CLOSEST(1000 * tx_rate, gp->tx_total_rate);
+
+    if(rate == 0)
+        return len;
+
+    datalen20 = DIV_ROUND_CLOSEST(200 * len, 1000);
+    datalen40 = DIV_ROUND_CLOSEST(400 * len, 1000);
+    datalen80 = DIV_ROUND_CLOSEST(800 * len, 1000);
+
+    new_len = DIV_ROUND_CLOSEST(len * 1000, rate);
+
+    char label[90];
+
+    if(new_len >= datalen80)
+        new_len = datalen80;
+    else if(new_len >= datalen40)
+        new_len = datalen40;
+    else if(new_len >= datalen20)
+        new_len = datalen20;
+    else {
+        return 0;
+    }
+
+    if(new_len < 0) {
+        return 0;
+    }
+
+    pr_info("Cur_TX: %lu B/s, UCC_TX: %lu B/s. reducing to %u B (-%lu B) \n",
+            gp->tx_total_rate, tx_rate, new_len, len - new_len);
+    return new_len;
+}
+
+/**
+ * FIXME Make it multithreading.
+ * FIXME Send msg to remote clients (without relays)
+ */
+int gmtp_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)
+{
+    struct gmtp_sock *gp = gmtp_sk(sk);
+    struct gmtp_server_entry *s;
+    struct gmtp_relay_entry *r;
+    int ret = 0, j = 0;
+
+    s = (struct gmtp_server_entry*) gmtp_lookup_entry(server_hashtable,
+            gp->flowname);
+
+    if(s == NULL) {
+        pr_info("s: %p\n", s);
+        return gmtp_do_sendmsg(sk, msg, len);
+    }
+
+    /* For every socket(P) in server, send the same data */
+    list_for_each_entry(r, &s->relays.relay_list, relay_list) {
+
+        if(likely(r->sk != NULL)) {
+
+            struct msghdr *msgcpy;
+            struct inet_sock *inet = inet_sk(r->sk);
+            size_t nlen;
+
+            if(unlikely(r->sk->sk_state == GMTP_DELEGATED))
+                continue;
+
+            nlen = gmtp_media_adapt_cc(r->sk, msg, len);
+            if(nlen < 0)
+                continue;
+
+            msgcpy = kmalloc(nlen, gfp_any());
+            memcpy(msgcpy, msg, nlen);
+
+            pr_info("Sending to %pI4:%d (%u)\n", &inet->inet_daddr,
+                    htons(inet->inet_dport),
+                    gmtp_sk(r->sk)->gss);
+
+            ret = gmtp_do_sendmsg(r->sk, msgcpy, len);
+        }
+    }
+
+    kfree(msg);
+    return ret;
+}
+EXPORT_SYMBOL_GPL(gmtp_sendmsg);
+
+int inet_gmtp_listen(struct socket *sock, int backlog)
+{
+    struct sock *sk = sock->sk;
+    struct gmtp_sock *gs = gmtp_sk(sk);
+    unsigned char old_state;
+    int err;
+
+    gmtp_print_function();
+
+    lock_sock(sk);
+
+    err = -EINVAL;
+    if (sock->state != SS_UNCONNECTED || sock->type != SOCK_GMTP)
+        goto out;
+
+    old_state = sk->sk_state;
+    if (!((1 << old_state) & (GMTPF_CLOSED | GMTPF_LISTEN)))
+        goto out;
+
+    /* Really, if the socket is already in listen state
+     * we can only allow the backlog to be adjusted.
+     */
+    if (old_state != GMTP_LISTEN) {
+
+        gs->role = GMTP_ROLE_LISTEN;
+
+        err = inet_csk_listen_start(sk, backlog);
+        gmtp_print_debug("inet_csk_listen_start(sk, %d) "
+                "returns: %d", backlog, err);
+        if (err)
+            goto out;
+    }
+    err = 0;
+out:
+    release_sock(sk);
+    return err;
+}
+EXPORT_SYMBOL_GPL(inet_gmtp_listen);
+
+void gmtp_shutdown(struct sock *sk, int how)
+{
+    gmtp_print_function();
+    gmtp_print_debug("called shutdown(%x)", how);
+}
+EXPORT_SYMBOL_GPL(gmtp_shutdown);
+
+/* TODO Study thash_entries... This is from DCCP thash_entries */
+static int thash_entries;
+module_param(thash_entries, int, 0444);
+MODULE_PARM_DESC(thash_entries, "Number of ehash buckets");
+
+/**
+ * Unfortunately, we can't use the alloc_large_system_hash method...
+ * So, this method is an adaptation from dccp hashinfo initialization
+ */
+static int gmtp_create_inet_hashinfo(void)
+{
+    unsigned long goal;
+    int ehash_order, bhash_order, i;
+    int rc;
+
+    gmtp_print_function();
+    pr_info("thash_entries: %d\n", thash_entries);
+
+    BUILD_BUG_ON(sizeof(struct gmtp_skb_cb) >
+    FIELD_SIZEOF(struct sk_buff, cb));
+
+    rc = -ENOBUFS;
+
+    inet_hashinfo_init(&gmtp_inet_hashinfo);
+    gmtp_inet_hashinfo.bind_bucket_cachep =
+            kmem_cache_create("gmtp_bind_bucket",
+                    sizeof(struct inet_bind_bucket), 0,
+                    SLAB_HWCACHE_ALIGN, NULL);
+    if (!gmtp_inet_hashinfo.bind_bucket_cachep)
+        goto out_fail;
+
+    /*
+     * Size and allocate the main established and bind bucket
+     * hash tables.
+     *
+     * The methodology is similar to that of the buffer cache.
+     */
+    if (totalram_pages >= (128 * 1024))
+        goal = totalram_pages >> (21 - PAGE_SHIFT);
+    else
+        goal = totalram_pages >> (23 - PAGE_SHIFT);
+
+    if (thash_entries)
+        goal = (thash_entries *
+                sizeof(struct inet_ehash_bucket)) >> PAGE_SHIFT;
+    for (ehash_order = 0; (1UL << ehash_order) < goal; ehash_order++)
+        ;
+
+    do {
+        unsigned long hash_size = (1UL << ehash_order) * PAGE_SIZE /
+                sizeof(struct inet_ehash_bucket);
+
+        while (hash_size & (hash_size - 1))
+            hash_size--;
+        gmtp_inet_hashinfo.ehash_mask = hash_size - 1;
+        gmtp_inet_hashinfo.ehash = (struct inet_ehash_bucket *)
+                __get_free_pages(GFP_ATOMIC|__GFP_NOWARN,
+                        ehash_order);
+
+    } while (!gmtp_inet_hashinfo.ehash && --ehash_order > 0);
+
+    if (!gmtp_inet_hashinfo.ehash) {
+        gmtp_print_error("Failed to allocate GMTP established "
+                "hash table");
+        goto out_free_bind_bucket_cachep;
+    }
+
+    for (i = 0; i <= gmtp_inet_hashinfo.ehash_mask; i++)
+        INIT_HLIST_NULLS_HEAD(&gmtp_inet_hashinfo.ehash[i].chain, i);
+
+    if (inet_ehash_locks_alloc(&gmtp_inet_hashinfo))
+        goto out_free_gmtp_ehash;
+
+    bhash_order = ehash_order;
+
+    do {
+        gmtp_inet_hashinfo.bhash_size = (1UL << bhash_order) * PAGE_SIZE /
+                sizeof(struct inet_bind_hashbucket);
+        if ((gmtp_inet_hashinfo.bhash_size > (64 * 1024)) &&
+                bhash_order > 0)
+            continue;
+        gmtp_inet_hashinfo.bhash = (struct inet_bind_hashbucket *)
+                __get_free_pages(GFP_ATOMIC|__GFP_NOWARN,
+                        bhash_order);
+
+    } while (!gmtp_inet_hashinfo.bhash && --bhash_order >= 0);
+
+    if (!gmtp_inet_hashinfo.bhash) {
+        gmtp_print_error("Failed to allocate GMTP bind hash table");
+        goto out_free_gmtp_locks;
+    }
+
+    for (i = 0; i < gmtp_inet_hashinfo.bhash_size; i++) {
+        spin_lock_init(&gmtp_inet_hashinfo.bhash[i].lock);
+        INIT_HLIST_HEAD(&gmtp_inet_hashinfo.bhash[i].chain);
+    }
+
+    return 0;
+
+out_free_gmtp_locks:
+    inet_ehash_locks_free(&gmtp_inet_hashinfo);
+out_free_gmtp_ehash:
+    free_pages((unsigned long)gmtp_inet_hashinfo.ehash, ehash_order);
+out_free_bind_bucket_cachep:
+    kmem_cache_destroy(gmtp_inet_hashinfo.bind_bucket_cachep);
+out_fail:
+    gmtp_print_error("gmtp_init_hashinfo: FAIL");
+    gmtp_inet_hashinfo.bhash = NULL;
+    gmtp_inet_hashinfo.ehash = NULL;
+    gmtp_inet_hashinfo.bind_bucket_cachep = NULL;
+
+    return rc;
+}
+
+static int ghash_entries = 1024;
+module_param(ghash_entries, int, 0444);
+MODULE_PARM_DESC(ghash_entries, "Number of GMTP hash entries");
+
+/*************************************************/
+static int __init gmtp_init(void)
+{
+    int rc = 0;
+    unsigned char *rid;
+    __u8 relay_id[21];
+
+    gmtp_print_function();
+
+    rc = mcc_lib_init();
+    if(rc)
+        goto out;
+
+    rc = percpu_counter_init(&gmtp_orphan_count, 0, GFP_KERNEL);
+    if(rc) {
+        percpu_counter_destroy(&gmtp_orphan_count);
+        goto out;
+    }
+
+    client_hashtable = gmtp_build_hashtable(ghash_entries,
+            gmtp_client_hash_ops);
+    server_hashtable = gmtp_build_hashtable(ghash_entries,
+            gmtp_server_hash_ops);
+    if(client_hashtable == NULL || server_hashtable == NULL) {
+        rc = -ENOBUFS;
+        goto out;
+    }
+
+    gmtp_info = kmalloc(sizeof(struct gmtp_info), GFP_KERNEL);
+    if(gmtp_info == NULL) {
+        rc = -ENOBUFS;
+        goto out;
+    }
+    gmtp_info->relay_enabled = 0;
+    gmtp_info->pkt_sent = 0;
+    gmtp_info->control_sk = NULL;
+    gmtp_info->ctrl_addr = NULL;
+
+    rid = gmtp_build_relay_id();
+    if(rid == NULL) {
+        gmtp_pr_error("Relay ID build failed. Creating a random id.");
+        get_random_bytes(gmtp_info->relay_id, GMTP_FLOWNAME_LEN);
+    } else
+        memcpy(gmtp_info->relay_id, rid, GMTP_FLOWNAME_LEN);
+
+    flowname_strn(relay_id, gmtp_info->relay_id, MD5_LEN);
+        pr_info("Relay ID = %s\n", relay_id);
+
+    rc = gmtp_create_inet_hashinfo();
+    if(rc)
+        goto out;
+
+out:
+    return rc;
+}
+
+static void __exit gmtp_exit(void)
+{
+    gmtp_print_function();
+
+    free_pages((unsigned long)gmtp_inet_hashinfo.bhash,
+            get_order(gmtp_inet_hashinfo.bhash_size *
+                    sizeof(struct inet_bind_hashbucket)));
+    free_pages((unsigned long)gmtp_inet_hashinfo.ehash,
+            get_order((gmtp_inet_hashinfo.ehash_mask + 1) *
+                    sizeof(struct inet_ehash_bucket)));
+    inet_ehash_locks_free(&gmtp_inet_hashinfo);
+    kmem_cache_destroy(gmtp_inet_hashinfo.bind_bucket_cachep);
+
+    kfree_gmtp_info(gmtp_info);
+    kfree_gmtp_hashtable(client_hashtable);
+    kfree_gmtp_hashtable(server_hashtable);
+
+    percpu_counter_destroy(&gmtp_orphan_count);
+    mcc_lib_exit();
+}
+
+module_init(gmtp_init);
+module_exit(gmtp_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Joilnen Leite <joilnen@gmail.com>");
+MODULE_AUTHOR("Mrio Andr Menezes <mariomenezescosta@gmail.com>");
+MODULE_AUTHOR("Wendell Silva Soares <wss@ic.ufal.br>");
+MODULE_DESCRIPTION("GMTP - Global Media Transmission Protocol");
+
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/sockopt.c linux-4.9-rc2/net/gmtp/sockopt.c
--- linux-4.9-rc2-original/net/gmtp/sockopt.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/sockopt.c	2016-12-01 16:50:35.497419355 -0300
@@ -0,0 +1,205 @@
+#include <uapi/linux/gmtp.h>
+#include <linux/gmtp.h>
+#include "gmtp.h"
+
+static int gmtp_setsockopt_flowname(struct gmtp_sock *gp, char __user *optval,
+		unsigned int optlen)
+{
+	gmtp_print_function();
+
+	if(optlen > GMTP_FLOWNAME_LEN)
+		return -ENOBUFS;
+
+	memcpy(gp->flowname, optval, optlen);
+	return 0;
+}
+
+static int do_gmtp_setsockopt(struct sock *sk, int level, int optname,
+		char __user *optval, unsigned int optlen)
+{
+	struct gmtp_sock *gp = gmtp_sk(sk);
+	int val, err = 0;
+
+	gmtp_print_function();
+	gmtp_print_debug("Set optname: %d | optlen: %u", optname, optlen);
+
+	if (optlen < (int)sizeof(int))
+		return -EINVAL;
+
+	if(get_user(val, (int __user *)optval))
+		return -EFAULT;
+
+	lock_sock(sk);
+	switch(optname) {
+	case GMTP_SOCKOPT_FLOWNAME:
+		gmtp_pr_debug("GMTP_SOCKOPT_FLOWNAME");
+		err = gmtp_setsockopt_flowname(gp, optval, optlen);
+		break;
+	case GMTP_SOCKOPT_MEDIA_RATE:
+		gmtp_pr_debug("GMTP_SOCKOPT_MEDIA_RATE");
+		if(val > 0)
+			gp->tx_media_rate = (unsigned long)val;
+		else
+			err = -EINVAL;
+		break;
+	case GMTP_SOCKOPT_MAX_TX_RATE:
+		gmtp_pr_debug("GMTP_SOCKOPT_MAX_TX_RATE");
+		if(val > 0) {
+			gp->tx_max_rate = (unsigned long)val;
+			gp->tx_ucc_rate = gp->tx_max_rate;
+		} else
+			err = -EINVAL;
+		break;
+	case GMTP_SOCKOPT_UCC_TYPE:
+		gmtp_pr_debug("GMTP_SOCKOPT_UCC_TYPE");
+		if(val > 0)
+			gp->tx_ucc_type = (enum gmtp_ucc_type)val;
+		else
+			err = -EINVAL;
+		break;
+
+	case GMTP_SOCKOPT_SERVER_TIMEWAIT:
+		/** FIXME Gotos to fix strange error... */
+		goto role_relay;
+		gmtp_pr_debug("GMTP_SOCKOPT_SERVER_TIMEWAIT");
+		if(gp->role != GMTP_ROLE_SERVER)
+			err = -EOPNOTSUPP;
+		else
+			gp->server_timewait = (val != 0)? 1 : 0;
+		break;
+role_relay:
+	case GMTP_SOCKOPT_ROLE_RELAY:
+		gmtp_pr_debug("GMTP_SOCKOPT_ROLE_RELAY");
+		if(val != 0 && gp->role == GMTP_ROLE_UNDEFINED)
+			gp->role = GMTP_ROLE_RELAY;
+		else if(val == 0 && gp->role == GMTP_ROLE_RELAY)
+			gp->role = GMTP_ROLE_UNDEFINED;
+		else
+			err = -EOPNOTSUPP;
+		break;
+relay_enabled:
+	case GMTP_SOCKOPT_RELAY_ENABLED:
+		gmtp_pr_debug("GMTP_SOCKOPT_RELAY_ENABLED");
+		if(gp->role != GMTP_ROLE_RELAY)
+			err = -EOPNOTSUPP;
+		else
+			gmtp_info->relay_enabled = (val != 0) ? 1 : 0;
+		break;
+	default:
+		/** FIXME Gotos to fix strange error... */
+		goto relay_enabled;
+		err = -ENOPROTOOPT;
+		break;
+	}
+	release_sock(sk);
+
+	if(err != 0)
+		pr_warning("gmtp_setsockopt error: %d\n", err);
+
+	return err;
+}
+
+int gmtp_setsockopt(struct sock *sk, int level, int optname,
+		char __user *optval, unsigned int optlen)
+{
+	int ret;
+
+	gmtp_print_function();
+
+	if (level == SOL_GMTP)
+		ret = do_gmtp_setsockopt(sk, level, optname, optval, optlen);
+	else
+		ret = inet_csk(sk)->icsk_af_ops->setsockopt(sk, level,
+							     optname, optval,
+							     optlen);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(gmtp_setsockopt);
+
+static int gmtp_getsockopt_flowname(struct gmtp_sock *gp, char __user *optval,
+		unsigned int *optlen)
+{
+	int len;
+	__u8 *val;
+
+	val = gp->flowname;
+	len = GMTP_FLOWNAME_LEN * sizeof(*val);
+
+	if (put_user(len, optlen) || copy_to_user(optval, val, len))
+		return -EFAULT;
+
+	return 0;
+}
+
+static int do_gmtp_getsockopt(struct sock *sk, int level, int optname,
+		    char __user *optval, int __user *optlen)
+{
+	/* TODO Validate every getsockoptc using a C/C++ application */
+	struct gmtp_sock *gp;
+	int val, len;
+
+	gmtp_print_function();
+
+	if (get_user(len, optlen))
+		return -EFAULT;
+
+	if (len < (int)sizeof(int))
+		return -EINVAL;
+
+	gp = gmtp_sk(sk);
+	gmtp_print_debug("Get optname: %d | optlen: %u", optname, *optlen);
+
+	switch (optname) {
+	case GMTP_SOCKOPT_FLOWNAME:
+		return gmtp_getsockopt_flowname(gp, optval, optlen);
+	case GMTP_SOCKOPT_MEDIA_RATE:
+		val = (int)gp->tx_media_rate;
+		break;
+	case GMTP_SOCKOPT_MAX_TX_RATE:
+		val = (int) gp->tx_max_rate;
+		break;
+	case GMTP_SOCKOPT_UCC_TX_RATE:
+		val = (int) gp->tx_ucc_rate;
+		break;
+	case GMTP_SOCKOPT_GET_CUR_MSS:
+		val = (int) gp->mss;
+		break;
+	case GMTP_SOCKOPT_SERVER_TIMEWAIT:
+		val = (int) gp->server_timewait;
+		break;
+	case GMTP_SOCKOPT_ROLE_RELAY:
+		val = (gp->role == GMTP_ROLE_RELAY)? 1 : 0;
+		break;
+	case GMTP_SOCKOPT_RELAY_ENABLED:
+		val = gmtp_info->relay_enabled;
+		break;
+	case GMTP_SOCKOPT_NDP_RCV:
+		gmtp_pr_debug("GMTP_SOCKOPT_NDP_RCV");
+		val = (int) gp->ndp_count;
+		break;
+	case GMTP_SOCKOPT_NDP_SENT:
+		gmtp_pr_debug("GMTP_SOCKOPT_NDP_SENT");
+		val = (int) gp->ndp_sent;
+		break;
+	default:
+		return -ENOPROTOOPT;
+	}
+
+	len = sizeof(val);
+	if (put_user(len, optlen) || copy_to_user(optval, &val, len))
+		return -EFAULT;
+
+	return 0;
+}
+
+int gmtp_getsockopt(struct sock *sk, int level, int optname,
+		char __user *optval, int __user *optlen)
+{
+	gmtp_print_function();
+	if (level != SOL_GMTP)
+		return inet_csk(sk)->icsk_af_ops->getsockopt(sk, level,
+				optname, optval,
+				optlen);
+	return do_gmtp_getsockopt(sk, level, optname, optval, optlen);
+}
+EXPORT_SYMBOL_GPL(gmtp_getsockopt);
diff -uprN --new-file linux-4.9-rc2-original/net/gmtp/timer.c linux-4.9-rc2/net/gmtp/timer.c
--- linux-4.9-rc2-original/net/gmtp/timer.c	1969-12-31 21:00:00.000000000 -0300
+++ linux-4.9-rc2/net/gmtp/timer.c	2016-12-02 03:41:13.329984683 -0300
@@ -0,0 +1,344 @@
+/*
+ * timer.c
+ *
+ *  Created on: 04/02/2015
+ *      Author: wendell
+ */
+
+#include <linux/skbuff.h>
+#include <linux/export.h>
+
+#include <net/tcp.h>
+
+#include <linux/gmtp.h>
+#include "gmtp.h"
+
+static void gmtp_write_err(struct sock *sk)
+{
+	gmtp_print_function();
+
+	sk->sk_err = sk->sk_err_soft ? : ETIMEDOUT;
+	sk->sk_error_report(sk);
+
+	gmtp_send_reset(sk, GMTP_RESET_CODE_ABORTED);
+	gmtp_done(sk);
+}
+
+/* A write timeout has occurred. Process the after effects. */
+static int gmtp_write_timeout(struct sock *sk)
+{
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+	int retry_until;
+	gmtp_print_function();
+
+	if (sk->sk_state == GMTP_REQUESTING) {
+		if (icsk->icsk_retransmits != 0)
+			dst_negative_advice(sk);
+		retry_until = icsk->icsk_syn_retries ?
+			    : GMTP_SYN_RETRIES;
+
+	} else {
+		if (icsk->icsk_retransmits >= TCP_RETR1) {
+
+			dst_negative_advice(sk);
+		}
+
+		retry_until = TCP_RETR2;
+	}
+
+	if (icsk->icsk_retransmits >= retry_until) {
+		/* Has it gone just too far? */
+		gmtp_write_err(sk);
+		return 1;
+	}
+	return 0;
+}
+
+/*
+ *	The GMTP retransmit timer.
+ */
+static void gmtp_retransmit_timer(struct sock *sk)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	gmtp_print_function();
+
+	/*
+	 * More than than 4MSL (8 minutes) has passed, a RESET(aborted) was
+	 * sent, no need to retransmit, this sock is dead.
+	 */
+	if (gmtp_write_timeout(sk))
+		return;
+
+	if (gmtp_retransmit_skb(sk) != 0) {
+		/*
+		 * Retransmission failed because of local congestion,
+		 * do not backoff.
+		 */
+		if (--icsk->icsk_retransmits == 0)
+			icsk->icsk_retransmits = 1;
+		inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
+					  min(icsk->icsk_rto,
+					      TCP_RESOURCE_PROBE_INTERVAL),
+					  GMTP_RTO_MAX);
+		return;
+	}
+
+	icsk->icsk_backoff++;
+
+	icsk->icsk_rto = min(icsk->icsk_rto << 1, GMTP_RTO_MAX);
+	inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS, icsk->icsk_rto,
+				  GMTP_RTO_MAX);
+	if (icsk->icsk_retransmits > TCP_RETR1)
+		__sk_dst_reset(sk);
+}
+
+static void gmtp_write_timer(unsigned long data)
+{
+	struct sock *sk = (struct sock *)data;
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	int event = 0;
+	gmtp_print_function();
+
+	bh_lock_sock(sk);
+	if (sock_owned_by_user(sk)) {
+		pr_info("sock_owned_by_user(sk)\n");
+
+		/* Try again later */
+		sk_reset_timer(sk, &icsk->icsk_retransmit_timer,
+			       jiffies + (HZ / 20));
+		goto out;
+	}
+
+	if (sk->sk_state == GMTP_CLOSED || !icsk->icsk_pending)
+		goto out;
+
+	pr_info("icsk->icsk_timeout: %lu ms\n", icsk->icsk_timeout);
+
+	if (time_after(icsk->icsk_timeout, jiffies)) {
+		sk_reset_timer(sk, &icsk->icsk_retransmit_timer,
+			       icsk->icsk_timeout);
+		pr_info("time_after\n");
+		goto out;
+	}
+
+	pr_info("event...\n");
+	event = icsk->icsk_pending;
+	icsk->icsk_pending = 0;
+
+	switch (event) {
+        case ICSK_TIME_RETRANS:
+            pr_info("ICSK_TIME_RETRANS\n");
+            gmtp_retransmit_timer(sk);
+            break;
+	}
+out:
+	bh_unlock_sock(sk);
+	sock_put(sk);
+}
+
+/*
+ *	Timer for listening sockets
+ */
+static void gmtp_register_reply_timer(struct sock *sk)
+{
+
+	/* FIXME DCE cu off syn-ack timer from TCP and register_reply_timer
+	 * from us...
+	 */
+/*	inet_csk_reqsk_queue_prune(sk, GMTP_REQ_INTERVAL, GMTP_TIMEOUT_INIT,
+				   GMTP_RTO_MAX);*/
+	;
+}
+
+static void gmtp_reporter_ackrcv_timer(struct sock *sk)
+{
+	struct gmtp_sock *gp = gmtp_sk(sk);
+	struct gmtp_client *client, *temp;
+
+	gmtp_pr_func();
+
+	if(gp->myself == NULL)
+		return;
+
+	pr_info("Reporter has %u clients\n", gp->myself->nclients);
+
+	if(gp->myself->nclients == 0)
+		goto out;
+
+	list_for_each_entry_safe(client, temp, &gp->myself->clients->list, list)
+	{
+		unsigned int now = jiffies_to_msecs(jiffies);
+		int interval = (int) (now - client->ack_rx_tstamp);
+
+		pr_info("Client found: %pI4@%-5d\n", &client->addr,
+				ntohs(client->port));
+
+		if(unlikely(interval > jiffies_to_msecs(GMTP_ACK_TIMEOUT))) {
+			pr_info("Deleting client.\n");
+			list_del(&client->list);
+			kfree(client);
+			gp->myself->nclients--;
+		}
+	}
+
+out:
+	inet_csk_reset_keepalive_timer(sk, GMTP_ACK_TIMEOUT);
+}
+
+/** TODO implement method to disconnect dead relays */
+static void gmtp_server_ackrcv_timer(struct sock *sk)
+{
+	struct gmtp_sock *gp = gmtp_sk(sk);
+
+	gmtp_pr_func();
+
+	inet_csk_reset_keepalive_timer(sk, GMTP_ACK_TIMEOUT);
+}
+
+
+static void gmtp_client_sendack_timer(struct sock *sk)
+{
+	struct gmtp_sock *gp = gmtp_sk(sk);
+	unsigned int now = jiffies_to_msecs(jiffies);
+	unsigned int factor, next_ack_time = GMTP_ACK_INTERVAL;
+	int r_ack_interval = 0;
+
+	gmtp_pr_func();
+
+	r_ack_interval = (int)(now - gp->ack_rx_tstamp);
+	if(r_ack_interval > jiffies_to_msecs(GMTP_ACK_TIMEOUT)) {
+		gmtp_send_elect_response(gp->myself->mysock, GMTP_ELECT_AUTO);
+		return;
+	}
+
+	factor = DIV_ROUND_CLOSEST(r_ack_interval, GMTP_ACK_INTERVAL);
+	if(factor > 0) {
+		next_ack_time = DIV_ROUND_UP(GMTP_ACK_INTERVAL, factor);
+		next_ack_time = max(next_ack_time, gp->rx_rtt);
+	}
+
+	gmtp_send_ack(sk);
+	inet_csk_reset_keepalive_timer(sk, next_ack_time);
+}
+
+static void gmtp_keepalive_timer(unsigned long data)
+{
+	struct sock *sk = (struct sock *)data;
+	struct gmtp_sock *gp = gmtp_sk(sk);
+
+	print_gmtp_sock(sk);
+
+	bh_lock_sock(sk);
+	/* Only process if socket is not in use. */
+	if (sock_owned_by_user(sk)) {
+		/* Try again later. */
+		inet_csk_reset_keepalive_timer(sk, HZ / 20);
+		goto out;
+	}
+
+	if (sk->sk_state == GMTP_LISTEN) {
+		gmtp_register_reply_timer(sk);
+		goto out;
+	}
+
+	if(sk->sk_state == GMTP_OPEN) {
+		switch(gp->role) {
+		case GMTP_ROLE_REPORTER:
+			gmtp_reporter_ackrcv_timer(sk);
+			goto out;
+		case GMTP_ROLE_SERVER:
+			gmtp_server_ackrcv_timer(sk);
+		}
+	}
+
+	if(gp->type == GMTP_SOCK_TYPE_REPORTER) {
+		unsigned int timeout = 0;
+		switch(sk->sk_state) {
+		case GMTP_REQUESTING:
+			timeout = jiffies_to_msecs(jiffies) - gp->req_stamp;
+			if(likely(timeout <= GMTP_TIMEOUT_INIT))
+				gmtp_send_elect_request(sk, GMTP_REQ_INTERVAL);
+			else
+				gmtp_send_elect_response(gp->myself->mysock,
+						GMTP_ELECT_AUTO);
+			break;
+		case GMTP_OPEN:
+			gmtp_client_sendack_timer(sk);
+			break;
+		}
+	}
+out:
+	bh_unlock_sock(sk);
+	sock_put(sk);
+}
+
+/* This is the same as tcp_delack_timer, sans prequeue & mem_reclaim stuff
+ * FIXME This function is probably not necessary.
+ * Maybe we can keep it empty, just to avoid null pointers.
+ **/
+static void gmtp_delack_timer(unsigned long data)
+{
+	struct sock *sk = (struct sock *)data;
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	gmtp_print_function();
+
+	bh_lock_sock(sk);
+	if (sock_owned_by_user(sk)) {
+		/* Try again later. */
+		icsk->icsk_ack.blocked = 1;
+		NET_INC_STATS(sock_net(sk), LINUX_MIB_DELAYEDACKLOCKED);
+		sk_reset_timer(sk, &icsk->icsk_delack_timer,
+			       jiffies + TCP_DELACK_MIN);
+		goto out;
+	}
+
+	if (sk->sk_state == GMTP_CLOSED ||
+	    !(icsk->icsk_ack.pending & ICSK_ACK_TIMER))
+		goto out;
+	if (time_after(icsk->icsk_ack.timeout, jiffies)) {
+		sk_reset_timer(sk, &icsk->icsk_delack_timer,
+			       icsk->icsk_ack.timeout);
+		goto out;
+	}
+
+	icsk->icsk_ack.pending &= ~ICSK_ACK_TIMER;
+
+	if (inet_csk_ack_scheduled(sk)) {
+		if (!icsk->icsk_ack.pingpong) {
+			/* Delayed ACK missed: inflate ATO. */
+			icsk->icsk_ack.ato = min(icsk->icsk_ack.ato << 1,
+						 icsk->icsk_rto);
+		} else {
+			/* Delayed ACK missed: leave pingpong mode and
+			 * deflate ATO.
+			 */
+			icsk->icsk_ack.pingpong = 0;
+			icsk->icsk_ack.ato = TCP_ATO_MIN;
+		}
+		gmtp_send_ack(sk);
+		NET_INC_STATS(sock_net(sk), LINUX_MIB_DELAYEDACKS);
+	}
+out:
+	bh_unlock_sock(sk);
+	sock_put(sk);
+}
+
+void gmtp_write_xmit_timer(unsigned long data)
+{
+	struct gmtp_packet_info *pkt_info = (struct gmtp_packet_info*) data;
+	gmtp_write_xmit(pkt_info->sk, pkt_info->skb);
+	del_timer_sync(&gmtp_sk(pkt_info->sk)->xmit_timer);
+	kfree(pkt_info);
+}
+EXPORT_SYMBOL_GPL(gmtp_write_xmit_timer);
+
+void gmtp_init_xmit_timers(struct sock *sk)
+{
+	struct gmtp_sock *gp = gmtp_sk(sk);
+	gmtp_pr_func();
+
+	inet_csk_init_xmit_timers(sk, &gmtp_write_timer, &gmtp_delack_timer,
+				&gmtp_keepalive_timer);
+}
+
+
